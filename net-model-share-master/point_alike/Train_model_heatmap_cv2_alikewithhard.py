"""This is the main training interface using heatmap trick
Author: You-Yi Jau, Rui Zhu
Date: 2019/12/12
"""

from functools import partial
from re import U
from sys import call_tracing
import cv2
from cv2 import distanceTransform
import numpy as np
from scipy.stats.stats import sem
from tensorflow.python.util.tf_inspect import FullArgSpec
import torch
import os
# from torch.autograd import Variable
# import torch.backends.cudnn as cudnn
import torch.optim
import torch.nn as nn
import torch.nn.functional as F
import torch.utils.data
# from tqdm import tqdm
# from utils.loader import dataLoader, modelLoader, pretrainedLoader
import logging
import copy
import random

from utils.tools import dict_update

from utils.utils import labels2Dto3D, flattenDetection, flattenDetection_new, labels2Dto3D_flattened, labels2Dto3D_sort, warp_points
from utils.utils import getPtsFromHeatmap, filter_points, getPtsFromLabels2D, getPtsFromLabels2D_torch, sample_desc_from_points_torch, getPtsFromHeatmapByCoordinates
# from utils.utils import pltImshow, saveImg
from utils.utils import precisionRecall_torch_soft
from utils.utils import compute_valid_mask
from utils import html
from utils.draw import draw_keypoints_pair_train, draw_match_pair_train
from utils.utils import saveImg
from utils.utils import inv_warp_image, batch_inv_warp_image 
# from utils.utils import save_checkpoint
from scipy.linalg import hadamard

from pathlib import Path
from Train_model_frontend import Train_model_frontend

def remove_borders(images, borders=3):

    shape = images.shape

    if len(shape) == 4:
        for batch_id in range(shape[0]):
            images[batch_id, :, 0:borders, :] = 0
            images[batch_id, :, :, 0:borders] = 0
            images[batch_id, :, shape[2] - borders:shape[2], :] = 0
            images[batch_id, :, :, shape[3] - borders:shape[3]] = 0
    elif len(shape) == 3:
        images[:, 0:borders, :] = 0
        images[:, :, 0:borders] = 0
        images[:, shape[1] - borders:shape[1], :] = 0
        images[:, :, shape[2] - borders:shape[2]] = 0
    else:
        images[0:borders, :] = 0
        images[:, 0:borders] = 0
        images[shape[0] - borders:shape[0], :] = 0
        images[:, shape[1] - borders:shape[1]] = 0

    return images

def grid_indexes(size):
    weights = np.zeros((size, size, 1, 2), dtype=np.float32)

    columns = []
    for idx in range(1, 1+size):
        columns.append(np.ones((size))*idx)
    columns = np.asarray(columns)

    rows = []
    for idx in range(1, 1+size):
        rows.append(np.asarray(range(1, 1+size)))
    rows = np.asarray(rows)

    weights[:, :, 0, 0] = columns
    weights[:, :, 0, 1] = rows

    return weights.transpose([3, 2, 0, 1])

def ones_multiple_channels(size, num_channels):

    ones = np.ones((size, size))
    weights = np.zeros((size, size, num_channels, num_channels), dtype=np.float32)

    for i in range(num_channels):
        weights[:, :, i, i] = ones
    
    return weights.transpose([3, 2, 0, 1])

def get_kernel_size(factor):
    """
    Find the kernel size given the desired factor of upsampling.
    """
    return 2 * factor - factor % 2

def linear_upsample_weights(half_factor, number_of_classes):
    """
    Create weights matrix for transposed convolution with linear filter
    initialization.
    """

    filter_size = get_kernel_size(half_factor)

    weights = np.zeros((filter_size,
                        filter_size,
                        number_of_classes,
                        number_of_classes), dtype=np.float32)

    upsample_kernel = np.ones((filter_size, filter_size))
    for i in range(number_of_classes):
        weights[:, :, i, i] = upsample_kernel

    return weights.transpose([3, 2, 0, 1])

def create_kernels(MSIP_sizes, device):      
    kernels = {}
    for ksize in MSIP_sizes:
        ones_kernel = ones_multiple_channels(ksize, 1)
        indexes_kernel = grid_indexes(ksize)
        upsample_filter_np = linear_upsample_weights(ksize // 2, 1)
        
        ones_kernel_t = torch.tensor(ones_kernel, device=device)
        indexes_kernel_t = torch.tensor(indexes_kernel, device=device)
        upsample_filter_t = torch.tensor(upsample_filter_np, device=device)

        kernels['ones_kernel_'+str(ksize)] = ones_kernel_t
        kernels['indexes_kernel_'+str(ksize)] = indexes_kernel_t
        kernels['upsample_filter_'+str(ksize)] = upsample_filter_t
    return kernels

def ip_layer(scores, w_size, kernels):
    eps = 1e-6
    scores_shape = scores.shape     # [b, 1, H, W]
    # maxpool
    scores_pool = F.max_pool2d(scores.detach(), kernel_size=w_size, stride=w_size)
    scores_max_unpool = F.conv_transpose2d(scores_pool, kernels['upsample_filter_'+str(w_size)], stride=w_size)
    exp_map = torch.exp(torch.divide(scores, scores_max_unpool + eps)) - 1*(1.-eps)
    sum_exp_map = F.conv2d(exp_map, kernels['ones_kernel_' + str(w_size)], stride=w_size)
    indexes_map = F.conv2d(exp_map, kernels['indexes_kernel_' + str(w_size)], stride=w_size)
    indexes_map = torch.divide(indexes_map, sum_exp_map + eps)

    max_scores_pool = torch.max(torch.max(scores_pool, dim=3, keepdim=True).values, dim=2, keepdim=True).values
    norm_scores_pool= torch.divide(scores_pool, max_scores_pool + eps)
    return indexes_map, [scores_pool, norm_scores_pool]

def ip_softscores(scores, w_size, kernels):
    eps = 1e-6
    scores_shape = scores.shape     # [b, 1, H, W]
    # maxpool
    scores_pool = F.max_pool2d(scores, kernel_size=w_size, stride=w_size)
    scores_max_unpool = F.conv_transpose2d(scores_pool, kernels['upsample_filter_'+str(w_size)], stride=w_size)

    exp_map = torch.exp(torch.divide(scores, scores_max_unpool + eps)) - 1*(1.-eps)
    sum_exp_map = F.conv2d(exp_map, kernels['ones_kernel_' + str(w_size)], stride=w_size)
    scores_map = F.conv2d(exp_map*scores, kernels['ones_kernel_' + str(w_size)], stride=w_size)
    soft_scores = torch.divide(scores_map, sum_exp_map + eps)

    return soft_scores

def grid_indexes_nms_conv(scores, kernels, w_size):

    weights, indexes = F.max_pool2d(scores, kernel_size=w_size, stride=w_size, return_indices=True)
    weights_norm = torch.divide(weights, torch.add(weights, np.finfo(float).eps))

    score_map = F.max_unpool2d(weights_norm, indexes, kernel_size=w_size, stride=w_size)
    # score_map = unpool(weights_norm, indexes, ksize=[1, window_size, window_size, 1], scope='unpool')

    indexes_label = F.conv2d(score_map, kernels['indexes_kernel_'+str(w_size)], stride=w_size).to(scores.device)

    ind_rand = (torch.rand(indexes_label.shape) * w_size + 1).int().float().to(scores.device)

    indexes_label = torch.where(indexes_label == 0, ind_rand, indexes_label)

    return indexes_label, weights, score_map

def loss_ln_indexes_norm(pre_indexes, label_indexes, weights_indexes, window_size, n=2):

    norm_sq = torch.sum(((pre_indexes - label_indexes) / window_size)**n, dim=1, keepdim=True)
    weigthed_norm_sq = 1000 * weights_indexes * norm_sq
    loss = torch.mean(weigthed_norm_sq, dim=(0,1,2,3))
    return loss

def thd_img(img, thd=0.015):
    img[img < thd] = 0
    img[img >= thd] = 1
    return img


def toNumpy(tensor):
    return tensor.detach().cpu().numpy()

def log_sinkhorn_iterations(Z, log_mu, log_nu, iters: int):
    """ Perform Sinkhorn Normalization in Log-space for stability"""
    u, v = torch.zeros_like(log_mu), torch.zeros_like(log_nu)
    for _ in range(iters):
        u = log_mu - torch.logsumexp(Z + v.unsqueeze(1), dim=2)
        v = log_nu - torch.logsumexp(Z + u.unsqueeze(2), dim=1)
    return Z + u.unsqueeze(2) + v.unsqueeze(1)

def log_optimal_transport(scores, iters: int):
    """ Perform Differentiable Optimal Transport in Log-space for stability"""
    b, m, n = scores.shape
    one = scores.new_tensor(1)
    ms, ns = (m*one).to(scores), (n*one).to(scores)

    # bins0 = alpha.expand(b, m, 1)
    # bins1 = alpha.expand(b, 1, n)
    # alpha = alpha.expand(b, 1, 1)

    # couplings = torch.cat([torch.cat([scores, bins0], -1),
    #                        torch.cat([bins1, alpha], -1)], 1)

    norm = - (ms + ns).log()
    # log_mu = torch.cat([norm.expand(m), ns.log()[None] + norm])
    # log_nu = torch.cat([norm.expand(n), ms.log()[None] + norm])
    log_mu = norm.expand(m)
    log_nu = norm.expand(n)
    log_mu, log_nu = log_mu[None].expand(b, -1), log_nu[None].expand(b, -1)
    Z = log_sinkhorn_iterations(scores, log_mu, log_nu, iters)
    Z = Z - norm  # multiply probabilities by M+N
    return Z

def dual_softmax(scores):
    
    b, m, n = scores.shape
    # one = scores.new_tensor(1)
    # ms, ns = (m*one).to(scores), (n*one).to(scores)

    # bins0 = alpha.expand(b, m, 1)
    # bins1 = alpha.expand(b, 1, n)
    # alpha = alpha.expand(b, 1, 1)

    # couplings = torch.cat([torch.cat([scores, bins0], -1),
    #                        torch.cat([bins1, alpha], -1)], 1)
    
    couplings_max_col = torch.max(scores, dim=1).values.unsqueeze(1).repeat(1, m, 1)
    couplings_max_row = torch.max(scores, dim=2).values.unsqueeze(2).repeat(1, 1, n)
    # print(couplings_max_col.shape, couplings_max_row.shape)
    out_scores = (F.softmax(scores - couplings_max_col, 1) * F.softmax(scores - couplings_max_row, 2)).log()
    return out_scores

def img_overlap(img_r, img_g, img_gray):  # img_b repeat
    img = np.concatenate((img_gray, img_gray, img_gray), axis=0)
    img[0, :, :] += img_r[0, :, :]
    img[1, :, :] += img_g[0, :, :]
    img[img > 1] = 1
    img[img < 0] = 0
    return img

class FocalLoss(nn.Module):
    r"""
        This criterion is a implemenation of Focal Loss, which is proposed in 
        Focal Loss for Dense Object Detection.

            Loss(x, class) = - \alpha (1-softmax(x)[class])^gamma \log(softmax(x)[class])

        The losses are averaged across observations for each minibatch.

        Args:
            alpha(1D Tensor, Variable) : the scalar factor for this criterion
            gamma(float, double) : gamma > 0; reduces the relative loss for well-classiﬁed examples (p > .5), 
                                   putting more focus on hard, misclassiﬁed examples
            size_average(bool): By default, the losses are averaged over observations for each minibatch.
                                However, if the field size_average is set to False, the losses are
                                instead summed for each minibatch.


    """
    def __init__(self, alpha=0.25, gamma=2, reduction="None"):
        super(FocalLoss, self).__init__()
        self.alpha = alpha
        self.gamma = gamma
        self.reduction = None

    def forward(self, inputs, targets):
        p = inputs
        loss_func_BCE = nn.BCELoss(reduction='none').cuda()
        ce_loss = loss_func_BCE(nn.functional.softmax(inputs, dim=1), targets)
        # ce_loss = F.binary_cross_entropy_with_logits(
        #     inputs, targets, reduction="none"
        # )
        p_t = p * targets + (1 - p) * (1 - targets)
        loss = ce_loss * ((1 - p_t) ** self.gamma)

        if self.alpha >= 0:
            alpha_t = self.alpha * targets + (1 - self.alpha) * (1 - targets)
            loss = alpha_t * loss

        if self.reduction == None:
            pass
        else:
            loss = loss.sum()

        return loss

class Train_model_heatmap_cv2_alikewithhard(Train_model_frontend):
    """ Wrapper around pytorch net to help with pre and post image processing. """

    """
    * SuperPointFrontend_torch:
    ** note: the input, output is different from that of SuperPointFrontend
    heatmap: torch (batch_size, H, W, 1)
    dense_desc: torch (batch_size, H, W, 256)
    pts: [batch_size, np (N, 3)]
    desc: [batch_size, np(256, N)]
    """
    default_config = {
        "train_iter": 170000,
        "save_interval": 2000,
        "tensorboard_interval": 200,
        "model": {"subpixel": {"enable": False}},
        "data": {"gaussian_label": {"enable": False}},
    }

    def __init__(self, config, save_path=Path("."), device="cpu", verbose=False):
        # config
        # Update config
        print("Load Train_model_heatmap!!")

        self.config = self.default_config
        self.config = dict_update(self.config, config)
        print("check config!!", self.config)

        # init parameters
        self.device = device
        self.save_path = save_path
        self._train = True
        self._eval = True
        self.cell_size = 8
        self.subpixel = False
        # self.correspond = 2

        self.max_iter = config["train_iter"]
        self.conf_thresh    = config['model']['detection_threshold']
        self.nms_dist       = config['model']['nms']
        self.correspond     = 2   # ori:2 1.5
        self.ori_diff       = 5       # 方向差
        self.ori_ratio      = 0.5    # patch内方向差满足要求点对比例阈值
        self.w_size         = 8
        self.net_index      = (((torch.linspace(16,1,16)**4).unsqueeze(0) @ hadamard(16)) == ((torch.linspace(1,16,16)**4).unsqueeze(0) @ hadamard(16))).long().squeeze(0).unsqueeze(1).repeat(1,8).view(-1).bool()      

        # self.net_index     = (((torch.linspace(32,1,32)**8).unsqueeze(0) @ hadamard(32)) == ((torch.linspace(1,32,32)**8).unsqueeze(0) @ hadamard(32))).long().squeeze(0).unsqueeze(1).repeat(1,4).view(-1).bool()


        self.gaussian = False
        if self.config["data"]["gaussian_label"]["enable"]:
            self.gaussian = True

        if self.config["model"]["dense_loss"]["enable"]:
            print("use dense_loss!")
            from utils.loss_functions.sparse_loss import descriptor_loss_dense_supervised, descriptor_loss_dense_selfsupervised
            from utils.loss_functions.sparse_loss import descriptor_loss_dense_selfsupervised_new
            self.desc_params = self.config["model"]["dense_loss"]["params"]
            if self.config["model"]["dense_loss"]["self_supervised"]:
                # self.descriptor_loss = descriptor_loss_dense_selfsupervised
                self.descriptor_loss = descriptor_loss_dense_selfsupervised_new
            else:
                self.descriptor_loss = descriptor_loss_dense_supervised
            self.desc_loss_type = "dense"
        elif self.config["model"]["sparse_loss"]["enable"]:
            print("use sparse_loss!") # 稀疏描述子（半稠密）
            self.desc_params = self.config["model"]["sparse_loss"]["params"]
            from utils.loss_functions.sparse_loss import descriptor_loss_sparse_supervised

            self.descriptor_loss = descriptor_loss_sparse_supervised
            self.desc_loss_type = "sparse"

        self.webdir = "/".join(str(self.save_path).split("/")[:-1]) + "/web"
        self.html = html.HTML(self.webdir, 'show_html')
        self.ims, self.txts, self.links = [], [], []

        self.logdir = "./" + "/".join(str(self.save_path).split("/")[:-1])

        logname = self.logdir + r"/log.txt"
        self.logger = logging.getLogger("LOG")
        self.logger.setLevel(logging.DEBUG)
        # 建立一个filehandler来把日志记录在文件里，级别为debug以上
        fh = logging.FileHandler(logname)
        fh.setLevel(logging.DEBUG)
       
        # 设置日志格式
        formatter = logging.Formatter("%(asctime)s %(name)s %(levelname)s: %(message)s ")
        fh.setFormatter(formatter)
        #将相应的handler添加在logger对象中
        self.logger.addHandler(fh)
        # load model
        # self.net = self.loadModel(*config['model'])
        self.printImportantConfig()

        self.last_loss_1 = []    # step t-1
        self.last_loss_2 = []    # step t-2
        
        self.FA_bin_thr = 0.9   # 0.9 0.8
        self.FR_bin_thr = 0.6   # 0.6 0.5

        self.hn_k_neighbor_ratio = 0.75 # 1 / 1000.
        pass

    def show_html(self, imgA, imgB, pntA, pntB, show_label, show_pred, H, W, H_ATA):
        # imgA = imgA.transpose(1,2)  # transpose，WTF!
        # imgB = imgB.transpose(1,2)

        if not os.path.isdir(self.webdir):
            os.mkdir(self.webdir)
        image_path = self.webdir + "/images"

        if not os.path.isdir(image_path):
            os.mkdir(image_path)


        from utils.var_dim import toNumpy
        from utils.utils import saveImg

        pntA = toNumpy(pntA)
        pntB = toNumpy(pntB)
       
        # inv_homography = H_ATA.inverse()
        # warped_img = inv_warp_image(  # 利用变换矩阵变换图像
        #     imgB.unsqueeze(0).cpu() * 255, inv_homography.unsqueeze(0), mode="bilinear"
        # )

        warped_img = imgB.squeeze().cpu() * 255

        matches_mask = (show_label == show_pred)
        real_pred = (show_pred != -1)
        matches_mask = real_pred*matches_mask
        unmatches_mask = real_pred*(matches_mask == False)

        #将tensor转成numpy
        matches_mask = matches_mask.squeeze(0).cpu().numpy()
        unmatches_mask = unmatches_mask.squeeze(0).cpu().numpy()
        show_pred = show_pred.squeeze(0).cpu().numpy()
        show_label = show_label.squeeze(0).cpu().numpy()

        matches = np.hstack([pntA[matches_mask],pntB[show_pred[matches_mask]]])
        unmatches = np.hstack([pntA[unmatches_mask],pntB[show_pred[unmatches_mask]]])



        show_data = {}
        # show_data.update({'image1':warped_img})
        # show_data.update({'image2':imgB.cpu().numpy().squeeze() * 255})
        show_data.update({'image1':imgA.cpu().numpy().squeeze() * 255})
        show_data.update({'image2':warped_img})
        show_data.update({'keypoints1':pntA})
        show_data.update({'keypoints2':pntB})
        show_data.update({'matches':matches})
        show_data.update({'unmatches':unmatches})

        img_pts_A = draw_keypoints_match(show_data)
        imgA_name = "%d_match.bmp" % self.n_iter
        saveImg(img_pts_A, os.path.join(image_path,imgA_name))

        
        matches_mask = (show_label != -1)
        matches = np.hstack([pntA[matches_mask],pntB[show_label[matches_mask]]])
        show_data.update({'matches':matches})

        img_pts_A_label = draw_keypoints_match(show_data,show_label=True)
        imgA_label_name = "%d_match_label.bmp" % self.n_iter
        saveImg(img_pts_A_label, os.path.join(image_path,imgA_label_name))

        self.ims, self.txts, self.links = [], [], []
        self.html.add_header(self.n_iter)
        
        self.ims.append(imgA_name)
        self.txts.append("match")
        self.links.append(imgA_name)

        self.ims.append(imgA_label_name)
        self.txts.append("match_label")
        self.links.append(imgA_label_name)

        self.html.add_images(self.ims, self.txts, self.links)
        self.html.save()

    def UWTXent(self, sim, add, divide_num, t):
        pow_sim = torch.pow((sim / divide_num + add), t)
        uwt_sim = pow_sim / torch.sum(pow_sim, dim=1).unsqueeze(-1).repeat(1, pow_sim.shape[-1])
        return uwt_sim

    def get_point_pair(self, dis, dis_thre=-1):  # 获得匹配点
        # a2b_min_id = torch.argmin(dis, dim=1)
        # len_p = len(a2b_min_id)
        # ch = dis[list(range(len_p)), a2b_min_id] < dis_thre

        # idx_x = a2b_min_id[ch]
        # dis_pair = dis[ch, a2b_min_id[ch]]
        
        # return dis_pair
        correspond = self.correspond if dis_thre == -1 else dis_thre
            

        a2b_min_id = torch.argmin(dis, dim=1)  # M X 1
        len_p = len(a2b_min_id)
        ch = dis[list(range(len_p)), a2b_min_id] < correspond
        reshape_as = torch.tensor(list(range(len_p)), device=self.device)
        # reshape_bs = b_s

        a_s = reshape_as[ch]
        b_s = a2b_min_id[ch]
        d_k = dis[ch, a2b_min_id[ch]]
     
        return a_s, b_s, d_k, ch

    def get_score_pair(self, scA, scB, dis, dis_thre=3):
        a2b_min_id = torch.argmin(dis, dim=1)
        len_p = len(a2b_min_id)
        ch = dis[list(range(len_p)), a2b_min_id] < dis_thre

        idx_x = a2b_min_id[ch]
        dis_pair = dis[ch, a2b_min_id[ch]]

        scA_pair = scA[ch]
        scB_pair = scB[a2b_min_id[ch]]

        return scA_pair, scB_pair, dis_pair

    def get_dis(self, p_a, p_b):
        eps = 1e-12
        x = torch.unsqueeze(p_a[:, 0], 1) - torch.unsqueeze(p_b[:, 0], 0)  # N 2 -> NA 1 - 1 NB -> NA NB
        y = torch.unsqueeze(p_a[:, 1], 1) - torch.unsqueeze(p_b[:, 1], 0)
        dis = torch.sqrt(torch.pow(x, 2) + torch.pow(y, 2) + eps)
        return dis
    
    def get_descart_dis(self, p_a, p_b):
        x = torch.unsqueeze(p_a[:, 0], 1) - torch.unsqueeze(p_b[:, 0], 0)  # N 2 -> NA 1 - 1 NB -> NA NB
        x_min = torch.min(torch.abs(x), 180 - torch.abs(x))
        dis = ((x_min <= self.ori_diff) * (x_min >= 0)).int()
        return dis

    def get_dis_dim1(self, p_a, p_b):
        x = torch.unsqueeze(p_a[:, 0], 1) - torch.unsqueeze(p_b[:, 0], 0)  # N 2 -> NA 1 - 1 NB -> NA NB
        x_min = torch.abs(x)
        dis = x_min <= self.ori_diff
        return dis

    def get_dis_dim_caltrans(self, p_a, p_b, trans_angle):
        x = torch.unsqueeze(p_a[:, 0], 1) - torch.unsqueeze(p_b[:, 0], 0)  # N 2 -> NA 1 - 1 NB -> NA NB
        # x_min = torch.abs(x - trans_angle)
        x_min = torch.min(torch.abs(x - trans_angle), torch.abs(torch.abs(x - trans_angle) - 360))
        dis = x_min <= self.ori_diff
        # print(torch.sum(dis))
        return dis, x_min
    
    def get_dis_dim_AT(self, p_a, p_b):
        x = torch.unsqueeze(p_a[:, 0], 1) - torch.unsqueeze(p_b[:, 0], 0)  # N 2 -> NA 1 - 1 NB -> NA NB
        # x_min = torch.abs(x - trans_angle)
        x_min = torch.min(torch.abs(x), torch.abs(torch.abs(x) - 180))
        dis = x_min <= self.ori_diff
        # print(torch.sum(dis))
        return dis, x_min


    def get_manhattan_dis(self, p_a, p_b):
        eps = 1e-12
        x = torch.abs(torch.unsqueeze(p_a[:, 0], 1) - torch.unsqueeze(p_b[:, 0], 0))  # N 2 -> NA 1 - 1 NB -> NA NB
        y = torch.abs(torch.unsqueeze(p_a[:, 1], 1) - torch.unsqueeze(p_b[:, 1], 0))
        # dis = torch.sqrt(torch.pow(x, 2) + torch.pow(y, 2) + eps)
        dis = x + y
        return dis

    def get_des_hanmingdis(self, des_a, des_b):
        desc_binary_a = torch.where(des_a >= 0, torch.ones_like(des_a), torch.zeros_like(des_a))
        desc_binary_b = torch.where(des_b >= 0, torch.ones_like(des_b), torch.zeros_like(des_b))
        hanming_dist = torch.ones((des_a.shape[0], des_b.shape[0]), device=self.device) * des_a.shape[1] - desc_binary_a @ desc_binary_b.t() - (1 - desc_binary_a) @ (1 - desc_binary_b.t())
        return hanming_dist

    def get_des_hanmingdis_wht(self, des_a, des_b):
        hadama_trans = torch.tensor(hadamard(des_a.shape[1]), device=des_a.device).float()
        wht_desc_a, wht_desc_b = des_a @ hadama_trans, des_b @ hadama_trans
        desc_binary_a = torch.where(wht_desc_a > 0, torch.ones_like(wht_desc_a), torch.zeros_like(wht_desc_a))
        desc_binary_b = torch.where(wht_desc_b > 0, torch.ones_like(wht_desc_b), torch.zeros_like(wht_desc_b))
        desc_binary_double_a = torch.cat((desc_binary_a, desc_binary_a), dim=-1)        # N X 256
        desc_binary_double_b = torch.cat((desc_binary_b, desc_binary_b), dim=-1)
        hanming_dist = desc_binary_double_a.shape[1] - desc_binary_double_a @ desc_binary_double_b.t() - (1 - desc_binary_double_a) @ (1 - desc_binary_double_b.t())
        return hanming_dist
    
    def get_des_hanmingdis_wht_permute(self, des_a, des_b):
        hadama_trans = torch.tensor(hadamard(des_a.shape[1]), device=des_a.device).float()
        wht_desc_a, wht_desc_b = des_a @ hadama_trans, des_b @ hadama_trans
        half_dim =  wht_desc_a.shape[1] // 2 
        desc_binary_a = torch.where(wht_desc_a > 0, torch.ones_like(wht_desc_a), torch.zeros_like(wht_desc_a))  # Nxdim
        desc_binary_b = torch.where(wht_desc_b > 0, torch.ones_like(wht_desc_b), torch.zeros_like(wht_desc_b))  # Mxdim
        # index = (((torch.linspace(16,1,16)**4).unsqueeze(0) @ hadamard(16)) == ((torch.linspace(1,16,16)**4).unsqueeze(0) @ hadamard(16))).long().squeeze(0).unsqueeze(1).repeat(1,8).view(-1).bool()
        hanming_dist_part_begin = half_dim - desc_binary_a[:, self.net_index] @ desc_binary_b[:, self.net_index].t() - (1 - desc_binary_a[:, self.net_index]) @ (1 - desc_binary_b[:, self.net_index].t())       
        hanming_dist_part_end = half_dim - desc_binary_a[:, self.net_index==False] @ desc_binary_b[:, self.net_index==False].t() - (1 - desc_binary_a[:, self.net_index==False]) @ (1 - desc_binary_b[:, self.net_index==False].t())    
        hanming_dist_part_end_min = torch.where(hanming_dist_part_end >= half_dim // 2, half_dim - hanming_dist_part_end, hanming_dist_part_end)        # 0-32
        # hanming_dist = torch.ones((wht_desc_a.shape[0], wht_desc_b.shape[0]), device=self.device) * wht_desc_a.shape[1] - desc_binary_a @ desc_binary_b.t() - (1 - desc_binary_a) @ (1 - desc_binary_b.t())
        return hanming_dist_part_begin, hanming_dist_part_end_min

    def get_match_nomatch_dis_nosampler_hadama(self, desA, desB, repeat_mask):
        hadamadist_AtoB = self.get_des_hanmingdis_wht((desA + 1)/2, (desB + 1)/2)
        # match_indicesA, match_indicesB, _, _ = self.get_match_point_pair(hadamadist_AtoB, dis_thre=129)      
        return hadamadist_AtoB[repeat_mask == 1], hadamadist_AtoB[repeat_mask == 0]

    def get_ori_consistence(self, ori_kp_patch, ori_all_patch):
        # ori_kp_patch: NTx16
        # ori_all_patch: 16x(HxW) 
        assert ori_kp_patch.shape[1] == ori_all_patch.shape[0]
        num_ori = torch.zeros((ori_kp_patch.shape[0], ori_all_patch.shape[1]), device=ori_kp_patch.device)
        for d in range(ori_kp_patch.shape[1]):
            num_ori += self.get_descart_dis(ori_kp_patch[:, d].unsqueeze(1), ori_all_patch[d, :].unsqueeze(0).transpose(0, 1))
        
        return num_ori >= int(self.ori_ratio * ori_kp_patch.shape[1])

    def get_ori_consistence_ratio(self, ori_kp_patch, ori_all_patch):
        # ori_kp_patch: NTx16
        # ori_all_patch: 16x(HxW) 
        assert ori_kp_patch.shape[1] == ori_all_patch.shape[0]
        num_ori = torch.zeros((ori_kp_patch.shape[0], ori_all_patch.shape[1]), device=ori_kp_patch.device)
        for d in range(ori_kp_patch.shape[1]):
            num_ori += self.get_descart_dis(ori_kp_patch[:, d].unsqueeze(1), ori_all_patch[d, :].unsqueeze(0).transpose(0, 1))
        return num_ori.float() / ori_kp_patch.shape[1]

    def get_main_ori_consistence(self, ori_kp, ori_all):
        # ori_kp: NTx1
        # ori_all: 1x(HxW) 
        assert ori_kp.shape[1] == ori_all.shape[0]
        mask = self.get_descart_dis(ori_kp[:, 0].unsqueeze(1), ori_all[0, :].unsqueeze(0).transpose(0, 1))
        return mask == 1

    def get_main_ori_consistence_caltrans(self, ori_kpA, ori_kpB, trans_angle):
        # ori_kp: NTx1
        # ori_all: 1x(HxW) 
        # print(ori_kpA.shape, ori_kpB.shape)
        assert ori_kpA.shape[1] == ori_kpB.shape[1]
        mask, dis = self.get_dis_dim_caltrans(ori_kpA[:, 0].unsqueeze(1), ori_kpB[:, 0].unsqueeze(1), trans_angle)
        return mask, dis

    def get_main_ori_consistence_AT(self, ori_kpA, ori_kpB):
        # ori_kp: NTx1
        # ori_all: 1x(HxW) 
        # print(ori_kpA.shape, ori_kpB.shape)
        assert ori_kpA.shape[1] == ori_kpB.shape[1]
        mask, dis = self.get_dis_dim_AT(ori_kpA[:, 0].unsqueeze(1), ori_kpB[:, 0].unsqueeze(1))
        return mask, dis

    def get_ori_pattern(self, ori_kpA, ori_kpB):
        assert ori_kpA.shape[1] == ori_kpB.shape[1]
        num_ori = torch.zeros((ori_kpA.shape[0], ori_kpB.shape[0]), device=ori_kpA.device)
        for d in range(ori_kpA.shape[1]):
            num_ori += self.get_dis_dim1(ori_kpA[:, d].unsqueeze(1), ori_kpB[:, d].unsqueeze(1))
        return num_ori.float() / ori_kpA.shape[1]


    def thresholding_desc(self, descs):
        norm = torch.sqrt(torch.sum(descs * descs, dim = 1)) * 0.2
        norm = norm.int().unsqueeze(-1).expand_as(descs).float()
        descs = torch.where(descs < norm, torch.sqrt(descs), torch.sqrt(norm)).int().float()
        return descs

    def get_match_nomatch_dis_nosampler_hadama_permute(self, desA, desB, repeat_mask, th1=30, th2=55):
        desA_thr, desB_thr = self.thresholding_desc(torch.round(desA * 5000) + 5000), self.thresholding_desc(torch.round(desB * 5000) + 5000)
        hanming_distAtoB_part_begin, hanming_distAtoB_part_end_min = self.get_des_hanmingdis_wht_permute(desA_thr, desB_thr)
        hadamadist_AtoB = hanming_distAtoB_part_begin + hanming_distAtoB_part_end_min
        mask1 = hanming_distAtoB_part_begin < th1
        mask2 = hadamadist_AtoB < th2
        hadamadist_AtoB[mask1 == False] = desA.shape[-1] + 1    # 不满足阈值的对距离赋值为129
        hadamadist_AtoB[mask2 == False] = desA.shape[-1] + 1
        # # 单向最近邻
        # match_indicesA, match_indicesB, min_dis = self.get_point_pair(hadamadist_AtoB, dis_thre=desA.shape[-1] + 1)
        # if min_dis.shape[0] >= 30:
        #     # Top30
        #     top30_mask = torch.topk(min_dis, 30, largest=False).indices  
        # else:
        #     top30_mask = torch.ones_like(match_indicesA).to(self.device).bool()    
        return hadamadist_AtoB[repeat_mask == 1], hadamadist_AtoB[repeat_mask == 0], hadamadist_AtoB

    def get_des_hanmingdis_wht_permute_256(self, des_a, des_b):
        hadama_trans = torch.tensor(hadamard(des_a.shape[1]), device=des_a.device).float()
        wht_desc_a, wht_desc_b = des_a @ hadama_trans, des_b @ hadama_trans
        half_dim =  wht_desc_a.shape[1] // 2 
        desc_binary_a = torch.where(wht_desc_a > 0, torch.ones_like(wht_desc_a), torch.zeros_like(wht_desc_a))  # Nxdim
        desc_binary_b = torch.where(wht_desc_b > 0, torch.ones_like(wht_desc_b), torch.zeros_like(wht_desc_b))  # Mxdim
        # index = (((torch.linspace(16,1,16)**4).unsqueeze(0) @ hadamard(16)) == ((torch.linspace(1,16,16)**4).unsqueeze(0) @ hadamard(16))).long().squeeze(0).unsqueeze(1).repeat(1,8).view(-1).bool()
        hanming_dist_part_begin = half_dim - desc_binary_a[:, self.net_index] @ desc_binary_b[:, self.net_index].t() - (1 - desc_binary_a[:, self.net_index]) @ (1 - desc_binary_b[:, self.net_index].t())       
        hanming_dist_part_end = half_dim - desc_binary_a[:, self.net_index==False] @ desc_binary_b[:, self.net_index==False].t() - (1 - desc_binary_a[:, self.net_index==False]) @ (1 - desc_binary_b[:, self.net_index==False].t())    
        # hanming_dist_part_end_min = torch.where(hanming_dist_part_end >= half_dim // 2, half_dim - hanming_dist_part_end, hanming_dist_part_end)        # 0-32
        # hanming_dist = torch.ones((wht_desc_a.shape[0], wht_desc_b.shape[0]), device=self.device) * wht_desc_a.shape[1] - desc_binary_a @ desc_binary_b.t() - (1 - desc_binary_a) @ (1 - desc_binary_b.t())
        return hanming_dist_part_begin, hanming_dist_part_end

    def get_des_hanmingdis_wht_nohadama_permute_256(self, des_a, des_b):
        # hadama_trans = torch.tensor(hadamard(des_a.shape[1]), device=des_a.device).float()
        # wht_desc_a, wht_desc_b = des_a @ hadama_trans, des_b @ hadama_trans
        half_dim =  des_a.shape[1] // 2 
        desc_binary_a = torch.where(des_a > 0, torch.ones_like(des_a), torch.zeros_like(des_a))  # Nxdim
        desc_binary_b = torch.where(des_b > 0, torch.ones_like(des_b), torch.zeros_like(des_b))  # Mxdim
        # index = (((torch.linspace(16,1,16)**4).unsqueeze(0) @ hadamard(16)) == ((torch.linspace(1,16,16)**4).unsqueeze(0) @ hadamard(16))).long().squeeze(0).unsqueeze(1).repeat(1,8).view(-1).bool()
        hanming_dist_part_begin = half_dim - desc_binary_a[:, self.net_index] @ desc_binary_b[:, self.net_index].t() - (1 - desc_binary_a[:, self.net_index]) @ (1 - desc_binary_b[:, self.net_index].t())       
        hanming_dist_part_end = half_dim - desc_binary_a[:, self.net_index==False] @ desc_binary_b[:, self.net_index==False].t() - (1 - desc_binary_a[:, self.net_index==False]) @ (1 - desc_binary_b[:, self.net_index==False].t())    
        # hanming_dist_part_end_min = torch.where(hanming_dist_part_end >= half_dim // 2, half_dim - hanming_dist_part_end, hanming_dist_part_end)        # 0-32
        # hanming_dist = torch.ones((wht_desc_a.shape[0], wht_desc_b.shape[0]), device=self.device) * wht_desc_a.shape[1] - desc_binary_a @ desc_binary_b.t() - (1 - desc_binary_a) @ (1 - desc_binary_b.t())
        return hanming_dist_part_begin, hanming_dist_part_end


    def get_match_nomatch_dis_nosampler_hadama_permute_256(self, desA, desB, repeat_mask, th1=60, th2=110):
        '''
            desA, desB: 0和45度的256维描述子
        '''
        desA_0_thr, desB_0_thr = self.thresholding_desc(torch.round(desA[:, :128] * 5000) + 5000), self.thresholding_desc(torch.round(desB[:, :128] * 5000) + 5000)
        desA_45_thr, desB_45_thr = self.thresholding_desc(torch.round(desA[:, 128:] * 5000) + 5000), self.thresholding_desc(torch.round(desB[:, 128:] * 5000) + 5000)
        hanming_distAtoB_part_begin_0, hanming_distAtoB_part_end_0 = self.get_des_hanmingdis_wht_permute_256(desA_0_thr, desB_0_thr)
        hanming_distAtoB_part_begin_45, hanming_distAtoB_part_end_45 = self.get_des_hanmingdis_wht_permute_256(desA_45_thr, desB_45_thr)
        hanming_distAtoB_part_begin = hanming_distAtoB_part_begin_0 + hanming_distAtoB_part_begin_45
        hanming_distAtoB_part_end = hanming_distAtoB_part_end_0 + hanming_distAtoB_part_end_45
        hanming_distAtoB_part_end_min = torch.where(hanming_distAtoB_part_end >= desA.shape[-1] // 4, desA.shape[-1] // 2 - hanming_distAtoB_part_end, hanming_distAtoB_part_end)        # 0-32

        hadamadist_AtoB = hanming_distAtoB_part_begin + hanming_distAtoB_part_end_min
        hadamadist_AtoB_nothr = copy.deepcopy(hadamadist_AtoB)
        hadamadist_AtoB_m_nothr,  hadamadist_AtoB_nm_nothr = hadamadist_AtoB_nothr[repeat_mask == 1], hadamadist_AtoB_nothr[repeat_mask == 0]

        mask1 = hanming_distAtoB_part_begin < th1
        mask2 = hadamadist_AtoB < th2
        hadamadist_AtoB[mask1 == False] = desA.shape[-1] + 1    # 不满足阈值的对距离赋值为129
        hadamadist_AtoB[mask2 == False] = desA.shape[-1] + 1
        # # 单向最近邻
        # match_indicesA, match_indicesB, min_dis = self.get_point_pair(hadamadist_AtoB, dis_thre=desA.shape[-1] + 1)
        # if min_dis.shape[0] >= 30:
        #     # Top30
        #     top30_mask = torch.topk(min_dis, 30, largest=False).indices  
        # else:
        #     top30_mask = torch.ones_like(match_indicesA).to(self.device).bool()    
        return hadamadist_AtoB_m_nothr, hadamadist_AtoB_nm_nothr, hadamadist_AtoB

    def get_match_nomatch_dis_nosampler_nohadama_permute_256(self, desA, desB, repeat_mask, th1=60, th2=110):
        '''
            desA, desB: 0和45度的256维描述子
        '''
        # desA_0_thr, desB_0_thr = self.thresholding_desc(torch.round(desA[:, :128] * 5000) + 5000), self.thresholding_desc(torch.round(desB[:, :128] * 5000) + 5000)
        # desA_45_thr, desB_45_thr = self.thresholding_desc(torch.round(desA[:, 128:] * 5000) + 5000), self.thresholding_desc(torch.round(desB[:, 128:] * 5000) + 5000)
        hanming_distAtoB_part_begin_0, hanming_distAtoB_part_end_0 = self.get_des_hanmingdis_wht_nohadama_permute_256(desA[:, :128], desB[:, :128])
        hanming_distAtoB_part_begin_45, hanming_distAtoB_part_end_45 = self.get_des_hanmingdis_wht_nohadama_permute_256(desA[:, 128:], desB[:, 128:])
        hanming_distAtoB_part_begin = hanming_distAtoB_part_begin_0 + hanming_distAtoB_part_begin_45
        hanming_distAtoB_part_end = hanming_distAtoB_part_end_0 + hanming_distAtoB_part_end_45
        hanming_distAtoB_part_end_min = torch.where(hanming_distAtoB_part_end >= desA.shape[-1] // 4, desA.shape[-1] // 2 - hanming_distAtoB_part_end, hanming_distAtoB_part_end)        # 0-32

        hadamadist_AtoB = hanming_distAtoB_part_begin + hanming_distAtoB_part_end_min
        hadamadist_AtoB_nothr = copy.deepcopy(hadamadist_AtoB)
        hadamadist_AtoB_m_nothr,  hadamadist_AtoB_nm_nothr = hadamadist_AtoB_nothr[repeat_mask == 1], hadamadist_AtoB_nothr[repeat_mask == 0]

        mask1 = hanming_distAtoB_part_begin < th1
        mask2 = hadamadist_AtoB < th2
        hadamadist_AtoB[mask1 == False] = desA.shape[-1] + 1    # 不满足阈值的对距离赋值为129
        hadamadist_AtoB[mask2 == False] = desA.shape[-1] + 1
        # # 单向最近邻
        # match_indicesA, match_indicesB, min_dis = self.get_point_pair(hadamadist_AtoB, dis_thre=desA.shape[-1] + 1)
        # if min_dis.shape[0] >= 30:
        #     # Top30
        #     top30_mask = torch.topk(min_dis, 30, largest=False).indices  
        # else:
        #     top30_mask = torch.ones_like(match_indicesA).to(self.device).bool()    
        return hadamadist_AtoB_m_nothr, hadamadist_AtoB_nm_nothr, hadamadist_AtoB


    def detector_selfsupervised_msip_loss(self, descA, descB, Homo, inv_Homo):  
        heatmapA = flattenDetection_new(descA)  #(B, 1, H, W)
        heatmapB = flattenDetection_new(descB)
        mask_borders = torch.ones_like(heatmapA)    # border_area: 0, valid_area: 1
        
        warped_heatmapA = batch_inv_warp_image(heatmapA * mask_borders, Homo, mode='bilinear').to(self.device).detach()
        warped_heatmapB = batch_inv_warp_image(heatmapB * mask_borders, inv_Homo, mode='bilinear').to(self.device).detach()
        visibleA_mask = batch_inv_warp_image(mask_borders, inv_Homo, mode='bilinear').to(self.device)
        visibleB_mask = batch_inv_warp_image(mask_borders, Homo, mode='bilinear').to(self.device)
        
        visibleA_mask = visibleA_mask * mask_borders
        visibleB_mask = visibleB_mask * mask_borders

        heatmapA *= visibleA_mask
        heatmapB *= visibleB_mask
        warped_heatmapA *= visibleB_mask
        warped_heatmapB *= visibleA_mask

        H, W = heatmapA.shape[2], heatmapA.shape[3]
        MSIP_sizes = [8]
        MSIP_factor_loss = [2]   # [256.0, 64.0, 16.0, 4.0, 1.0]
        loss_indexes = 0
        ip_layer_kernels = create_kernels(MSIP_sizes, device=self.device)

        torch.manual_seed(12345)
        # torch.cuda.manual_seed(12345)

        for idx in range(len(MSIP_sizes)):
            win = MSIP_sizes[idx]
            _, weights_visibleA, map_nms = grid_indexes_nms_conv(visibleA_mask, ip_layer_kernels, win)
            _, weights_visibleB, _ = grid_indexes_nms_conv(visibleB_mask, ip_layer_kernels, win)
            imgA_indexes_nms_warped, _, _ = grid_indexes_nms_conv(warped_heatmapA, ip_layer_kernels, win)
            imgB_indexes_nms_warped, _, _ = grid_indexes_nms_conv(warped_heatmapB, ip_layer_kernels, win)       

            imgA_indexes, _ = ip_layer(heatmapA, win, ip_layer_kernels)     # [2, H/win, W/win]
            imgB_indexes, _ = ip_layer(heatmapB, win, ip_layer_kernels)
            weightA = ip_softscores(heatmapA, win, ip_layer_kernels).detach()        # [H/win, W/win]
            weightB = ip_softscores(heatmapB, win, ip_layer_kernels).detach()
            
            coordinate_weighting = True
            if coordinate_weighting:
                shape = weightA.shape

                weightA = torch.flatten(weightA)
                weightB = torch.flatten(weightB)

                weightA = F.softmax(weightA, dim=-1)
                weightB = F.softmax(weightB, dim=-1)

                weightA = 100 * weights_visibleA * torch.reshape(weightA, shape)
                weightB = 100 * weights_visibleB * torch.reshape(weightB, shape)
            else:
                weightA = weights_visibleA
                weightB = weights_visibleB
        
            lossA = loss_ln_indexes_norm(imgA_indexes, imgB_indexes_nms_warped, weightA, win, n=2)
            lossB = loss_ln_indexes_norm(imgB_indexes, imgA_indexes_nms_warped, weightB, win, n=2)

            loss_indexes += (lossA + lossB) / 2. * MSIP_factor_loss[idx]
       
        return loss_indexes

    def detector_selfsupervised_loss(self, descA, descB, maskA, maskB, Homo):
        """
        # apply loss on detectors, default is softmax
        :param descA, descB: prediction
            tensor [batch_size, 65, Hc, Wc]
        :param maskA, maskB: valid region in an image
            tensor [batch_size, 1, Hc, Wc]
        :param loss_type:
            str (l2 or softmax)
            softmax is used in original paper
        :return: normalized loss
            tensor
        """
        from utils.utils import warp_points
        batch_size = descA.shape[0]
        
        heatmapA = flattenDetection(descA)  #(B, C, h, w)
        heatmapB = flattenDetection(descB)
        H, W = heatmapA.shape[2], heatmapA.shape[3]
        # ptsA = getPtsFromHeatmap(heatmapA.to('cpu'), self.conf_thresh, self.nms_dist)   # (x,y, prob) 3行n列
        # ptsB = getPtsFromHeatmap(heatmapB.to('cpu'), self.conf_thresh, self.nms_dist)
        pntsA = [getPtsFromHeatmap(heatmapA[i,:,:,:].squeeze().cpu().detach().numpy(), self.conf_thresh, self.nms_dist) for i in range(batch_size)]
        pntsB = [getPtsFromHeatmap(heatmapB[i,:,:,:].squeeze().cpu().detach().numpy(), self.conf_thresh, self.nms_dist) for i in range(batch_size)]
        # ptsA: is list
        
        dis_mean_total = 0
        for idx in range(batch_size):
            pntA, pntB = pntsA[idx], pntsB[idx]
            pntA = torch.tensor(pntA.transpose()).type(torch.FloatTensor)
            pntB = torch.tensor(pntB.transpose()).type(torch.FloatTensor)

            pntA_H = warp_points(pntA[:2, :].transpose(0,1), Homo[idx].squeeze())  # 利用变换矩阵变换坐标点
            pntA_H, mask_points = filter_points(pntA_H, torch.tensor([W, H]), return_mask=True)


            key_dis = self.get_dis(pntA_H[:, :2], pntB[:, :2])
            dis_pair = self.get_point_pair(key_dis, dis_thre=3)  # p -> k
            dis_pair_mean = torch.mean(dis_pair)

            dis_mean_total += dis_pair_mean


            self.get_score_pair()

        loss_dis_pair = dis_mean_total / batch_size


        return loss_dis_pair

    def detector_loss(self, input, target, mask=None, loss_type="softmax"):
        """
        # apply loss on detectors, default is softmax
        :param input: prediction
            tensor [batch_size, 65, Hc, Wc]
        :param target: constructed from labels
            tensor [batch_size, 65, Hc, Wc]
        :param mask: valid region in an image
            tensor [batch_size, 1, Hc, Wc]
        :param loss_type:
            str (l2 or softmax)
            softmax is used in original paper
        :return: normalized loss
            tensor
        """
        if loss_type == "l2":
            loss_func = nn.MSELoss(reduction="mean")
            loss = loss_func(input, target)
        elif loss_type == "softmax":
            loss_func_BCE = nn.BCELoss(reduction='none').cuda()     # BCELoss二分类交叉熵； reduction = ‘none’，直接返回向量形式的 loss
            loss = loss_func_BCE(nn.functional.softmax(input, dim=1), target)
            loss = (loss.sum(dim=1) * mask).sum()
            loss = loss / (mask.sum() + 1e-10)
        elif loss_type == "focalloss":
            loss_func_Focal = FocalLoss().cuda()
            loss = loss_func_Focal(input, target)
            loss = (loss.sum(dim=1) * mask).sum()
            loss = loss / (mask.sum() + 1e-10)
        return loss

    def detector_selfsupervised_loss_dkd(self, kpA, kpB, descA, descB, desc_mapA, desc_mapB, scoreddisA, scoreddisB, scoresA, scoresB, scores_mapA, scores_mapB, Homo, inv_Homo, H, W, wrp=1, wpl=1, wdl=1, wrl=1, t_des=0.02, t_rel=1):
        batch_size = len(kpA)

        dis_mean_total = 0
        dis_peak_scored = 0
        dis_desc = 0
        dis_rel = 0
        eps = 1e-12
        valid_batch_size = batch_size
        for idx in range(batch_size):
            pntA, pntB = kpA[idx], kpB[idx]     # M X 2 (x,y)
            pntA = pntA.float()
            pntB = pntB.float()
            # pntA = torch.tensor(pntA, device=self.device).type(torch.FloatTensor)
            # pntB = torch.tensor(pntB, device=self.device).type(torch.FloatTensor)
            pntA = (pntA + 1) / 2 * pntA.new_tensor([[W - 1, H - 1]]).to(pntA.device)
            pntB = (pntB + 1) / 2 * pntB.new_tensor([[W - 1, H - 1]]).to(pntB.device)
            pntA_H = warp_points(pntA[:, :2], Homo[idx].squeeze(), device=self.device)  # 利用变换矩阵变换坐标点
            pntA_H, mask_pointA = filter_points(pntA_H, torch.tensor([W, H], device=self.device), return_mask=True)
            pntB_invH = warp_points(pntB[:, :2], inv_Homo[idx].squeeze(), device=self.device)
            pntB_invH, mask_pointB = filter_points(pntB_invH, torch.tensor([W, H], device=self.device), return_mask=True)
            
            try:
                assert pntA_H.shape[0] > 0 and pntB_invH.shape[0] > 0 
                # print(pntA_H.shape, pntB.shape, pntB_invH.shape, pntA.shape)
                key_disAB = self.get_dis(pntA_H[:, :2], pntB[:, :2])
                key_disBA = self.get_dis(pntB_invH[:, :2], pntA[:, :2])
                pairAB_A, pairAB_B, dis_pairAB, _ = self.get_point_pair(key_disAB, dis_thre=self.correspond)  # p -> k
                pairBA_B, pairBA_A, dis_pairBA, _ = self.get_point_pair(key_disBA, dis_thre=self.correspond)  # p -> k
                key_manhattandisAB = self.get_manhattan_dis(pntA_H[:, :2], pntB[:, :2])
                key_manhattandisBA = self.get_manhattan_dis(pntB_invH[:, :2], pntA[:, :2])
                assert dis_pairAB.shape[0] > 0 and dis_pairBA.shape[0] > 0     
                # dis_pair_meanAB = torch.mean(dis_pairAB)
                # dis_pair_meanBA = torch.mean(dis_pairBA)
                dis_pair_meanAB = torch.mean(key_manhattandisAB[pairAB_A, pairAB_B])
                dis_pair_meanBA = torch.mean(key_manhattandisBA[pairBA_B, pairBA_A])

                dis_peak_mean = torch.mean(torch.cat((scoreddisA[idx], scoreddisB[idx]), dim=0))
                # dis_peak_meanB = torch.mean(scoreddisB[idx])

                dis_mean_total += dis_pair_meanAB + dis_pair_meanBA
                dis_peak_scored += dis_peak_mean

                pntA_H_normalized = pntA_H / pntA_H.new_tensor([W - 1, H - 1]).to(pntA_H.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)
                pntB_invH_normalized = pntB_invH / pntB_invH.new_tensor([W - 1, H - 1]).to(pntB_invH.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)

                cross_sim_AB = descA[idx] @ desc_mapB[idx, :, :, :].view(-1, H * W)
                cross_sim_BA = descB[idx] @ desc_mapA[idx, :, :, :].view(-1, H * W)   # M x H x W
                valid_cross_sim_AB = cross_sim_AB[mask_pointA, :]   # repeat_nA x (H X W)
                valid_cross_sim_BA = cross_sim_BA[mask_pointB, :]   # repeat_nB x (H X W)
                soft_valid_cross_sim_AtoB = F.softmax((valid_cross_sim_AB - 1) / t_des, dim=-1).view(-1, H, W)
                soft_valid_cross_sim_BtoA = F.softmax((valid_cross_sim_BA - 1) / t_des, dim=-1).view(-1, H, W)

                soft_valid_cross_sim_AB_all = F.grid_sample(soft_valid_cross_sim_AtoB.unsqueeze(0),
                                                            pntA_H_normalized.view(1, 1, -1, 2),
                                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # repeat_nA x repeat_nA
                
                soft_valid_cross_sim_BA_all = F.grid_sample(soft_valid_cross_sim_BtoA.unsqueeze(0),
                                                            pntB_invH_normalized.view(1, 1, -1, 2),
                                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # repeat_nA x repeat_nA

                valid_mask_AB = torch.eye(valid_cross_sim_AB.shape[0]) == 1
                valid_mask_BA = torch.eye(valid_cross_sim_BA.shape[0]) == 1

                # 取对角线
                soft_valid_cross_sim_AB = soft_valid_cross_sim_AB_all[valid_mask_AB]
                soft_valid_cross_sim_BA = soft_valid_cross_sim_BA_all[valid_mask_BA]
                log_soft_valid_cross_sim_AB = -torch.log(soft_valid_cross_sim_AB + eps)
                log_soft_valid_cross_sim_BA = -torch.log(soft_valid_cross_sim_BA + eps)
                dis_cross_sim_mean = torch.sum(torch.cat((log_soft_valid_cross_sim_AB, log_soft_valid_cross_sim_BA), dim=-1), dim=-1) / (pntA.shape[0] + pntB.shape[0])
                dis_desc += dis_cross_sim_mean
                
                exp_valid_cross_sim_AtoB = torch.exp((valid_cross_sim_AB - 1) / t_rel).view(-1, H, W)
                exp_valid_cross_sim_BtoA = torch.exp((valid_cross_sim_BA - 1) / t_rel).view(-1, H, W)
                exp_valid_cross_sim_AB_all = F.grid_sample(exp_valid_cross_sim_AtoB.unsqueeze(0),
                                                        pntA_H_normalized.view(1, 1, -1, 2),
                                                        mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # repeat_nA x repeat_nA
                
                exp_valid_cross_sim_BA_all = F.grid_sample(exp_valid_cross_sim_BtoA.unsqueeze(0),
                                                            pntB_invH_normalized.view(1, 1, -1, 2),
                                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # repeat_nA x repeat_nA
                rel_valid_cross_sim_AB = exp_valid_cross_sim_AB_all[valid_mask_AB]
                rel_valid_cross_sim_BA = exp_valid_cross_sim_BA_all[valid_mask_BA]

                scoresAB_all = F.grid_sample(scores_mapB[idx, :, :, :].unsqueeze(0),
                                            pntA_H_normalized.view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)      # 1 x repeat_nA

                scoresBA_all = F.grid_sample(scores_mapA[idx, :, :, :].unsqueeze(0),
                                            pntB_invH_normalized.view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)      # 1 x repeat_nB

                scores_AAB = scoresA[idx][mask_pointA] * scoresAB_all
                scores_BBA = scoresB[idx][mask_pointB] * scoresBA_all
                scores_sum_AAB = torch.sum(scores_AAB, dim=-1)
                scores_sum_BBA = torch.sum(scores_BBA, dim=-1)
                scores_normalize_AAB = scores_AAB / (scores_sum_AAB + eps)
                scores_normalize_BBA = scores_BBA / (scores_sum_BBA + eps)
                rel_meanA = torch.sum(scores_normalize_AAB * (1 - rel_valid_cross_sim_AB), dim=-1) / pntA.shape[0]
                rel_meanB = torch.sum(scores_normalize_BBA * (1 - rel_valid_cross_sim_BA), dim=-1) / pntB.shape[0]
                dis_rel += rel_meanA + rel_meanB

            except:
                # dis_mean_total += 0
                # dis_peak_scored += 0
                # dis_desc += 0
                # dis_rel += 0
                print('Overlapping too small or Repeatable point pairs distance is greater than correspond(4):', pntA.shape[0], pntA_H.shape[0], pntB.shape[0], pntB_invH.shape[0])
                valid_batch_size -= 1

        valid_batch_size = valid_batch_size if valid_batch_size > 0 else eps
        # Reprojection Loss 
        reprojection_loss = dis_mean_total / (valid_batch_size * 2)
        # Dispersity Peak Loss
        dispersity_peak_loss = dis_peak_scored / valid_batch_size
        # NRE Loss
        descriptor_loss = dis_desc / valid_batch_size
        # Reliability Loss
        reliability_loss = dis_rel / (valid_batch_size * 2)
        
        loss_total = wrp * reprojection_loss + wpl * dispersity_peak_loss + wdl * descriptor_loss + wrl * reliability_loss
        loss_group = {
            'reprojection_loss': reprojection_loss, 
            'dispersity_peak_loss': dispersity_peak_loss,
            'descriptor_loss': descriptor_loss,
            'reliability_loss': reliability_loss}
        return loss_total, loss_group

    def detector_selfsupervised_loss_dkd_dense(self, kpA, kpB, pmaskA, pmaskB, descA, descB, desc_mapA, desc_mapB, scoreddisA, scoreddisB, scoresA, scoresB, scores_mapA, scores_mapB, Homo, inv_Homo, H, W, wrp=1, wpl=1, wdl=1, wrl=1, t_des=0.02, t_rel=1):
        # pmaskA: (BxMax_num) 32x300=9600
        batch_size = len(kpA)
        max_num = pmaskA.shape[-1] // batch_size    # 300
        dis_mean_total = 0
        dis_neighbor_mean_total = 0
        dis_peak_scored = 0
        dis_desc = 0
        dis_rel = 0
        eps = 1e-12
        valid_batch_size = batch_size
        countA, countB = 0, 0
        for idx in range(batch_size):
            pntA, pntB = kpA[idx], kpB[idx]     # M X 2 (x,y)
            pntA = pntA.float()
            pntB = pntB.float()
            # pntA = torch.tensor(pntA, device=self.device).type(torch.FloatTensor)
            # pntB = torch.tensor(pntB, device=self.device).type(torch.FloatTensor)
            numA, numB = pntA.shape[0], pntB.shape[0]
            pmA, pmB = pmaskA[max_num * idx:max_num * idx + numA].bool(), pmaskB[max_num * idx:max_num * idx + numB].bool()
            pntA, pntB = pntA[pmA, :], pntB[pmB, :]
            new_numA, new_numB = pntA.shape[0], pntB.shape[0]
            pntA = (pntA + 1) / 2 * pntA.new_tensor([[W - 1, H - 1]]).to(pntA.device)
            pntB = (pntB + 1) / 2 * pntB.new_tensor([[W - 1, H - 1]]).to(pntB.device)
            pntA_H = warp_points(pntA[:, :2], Homo[idx].squeeze(), device=self.device)  # 利用变换矩阵变换坐标点
            pntA_H, mask_pointA = filter_points(pntA_H, torch.tensor([W, H], device=self.device), return_mask=True)
            pntB_invH = warp_points(pntB[:, :2], inv_Homo[idx].squeeze(), device=self.device)
            pntB_invH, mask_pointB = filter_points(pntB_invH, torch.tensor([W, H], device=self.device), return_mask=True)
            
            try:
                assert pntA_H.shape[0] > 0 and pntB_invH.shape[0] > 0 
                # print(pntA_H.shape, pntB.shape, pntB_invH.shape, pntA.shape)
                key_disAB = self.get_dis(pntA_H[:, :2], pntB[:, :2])
                key_disBA = self.get_dis(pntB_invH[:, :2], pntA[:, :2])
                pairAB_A, pairAB_B, dis_pairAB, vmaskAH = self.get_point_pair(key_disAB, dis_thre=self.correspond)  # p -> k
                pairBA_B, pairBA_A, dis_pairBA, vmaskBH  = self.get_point_pair(key_disBA, dis_thre=self.correspond)  # p -> k
                key_manhattandisAB = self.get_manhattan_dis(pntA_H[:, :2], pntB[:, :2])
                key_manhattandisBA = self.get_manhattan_dis(pntB_invH[:, :2], pntA[:, :2])
                assert dis_pairAB.shape[0] > 0 and dis_pairBA.shape[0] > 0     
                # dis_pair_meanAB = torch.mean(dis_pairAB)
                # dis_pair_meanBA = torch.mean(dis_pairBA)
                dis_pair_meanAB = torch.mean(key_manhattandisAB[pairAB_A, pairAB_B])
                dis_pair_meanBA = torch.mean(key_manhattandisBA[pairBA_B, pairBA_A])
                dis_peak_mean = torch.mean(torch.cat((scoreddisA[idx][pmA], scoreddisB[idx][pmB]), dim=0))
                # dis_peak_meanB = torch.mean(scoreddisB[idx])
                
                dis_mean_total += dis_pair_meanAB + dis_pair_meanBA
                dis_peak_scored += dis_peak_mean
                pntA_H_normalized = pntA_H / pntA_H.new_tensor([W - 1, H - 1]).to(pntA_H.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)
                pntB_invH_normalized = pntB_invH / pntB_invH.new_tensor([W - 1, H - 1]).to(pntB_invH.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)

                current_descA, current_descB = descA[countA:countA+new_numA], descB[countB:countB+new_numB]
                
                # SOSR:
                k_neighbor = 3
                cross_sim_AA_sp = current_descA @ current_descA.transpose(0, 1)
                cross_sim_BB_sp = current_descB @ current_descB.transpose(0, 1)
                match_sim_AB_AA = cross_sim_AA_sp[mask_pointA, :][:, mask_pointA][pairAB_A, :][:, pairAB_A]
                match_sim_BA_BB = cross_sim_BB_sp[mask_pointB, :][:, mask_pointB][pairBA_B, :][:, pairBA_B]
                match_sim_AB_BB = cross_sim_BB_sp[pairAB_B, :][:, pairAB_B]
                match_sim_BA_AA = cross_sim_AA_sp[pairBA_A, :][:, pairBA_A]
                match_values_AB_AA, match_indices_AB_AA = torch.topk(match_sim_AB_AA, dim=1, k=k_neighbor, largest=False)
                match_values_BA_BB, match_indices_BA_BB = torch.topk(match_sim_BA_BB, dim=1, k=k_neighbor, largest=False)
                match_values_AB_BB_all = match_sim_AB_BB[:, match_indices_AB_AA]
                match_values_BA_AA_all = match_sim_BA_AA[:, match_indices_BA_BB]
                match_values_AB_BB = torch.diagonal(match_values_AB_BB_all, 0, dim1=0, dim2=1).transpose(0, 1)
                match_values_BA_AA = torch.diagonal(match_values_BA_AA_all, 0, dim1=0, dim2=1).transpose(0, 1)
                neighbor_dis_AB = (match_values_AB_AA - match_values_AB_BB) * (match_values_AB_AA - match_values_AB_BB)
                neighbor_dis_BA = (match_values_BA_BB - match_values_BA_AA) * (match_values_BA_BB - match_values_BA_AA)
                dis_neighbor_mean_total += torch.mean(torch.sum(neighbor_dis_AB, dim=1)) + torch.mean(torch.sum(neighbor_dis_BA, dim=1))

                # PA VS PB
                cross_sim_AB_sp = current_descA @ current_descB.transpose(0, 1)
                # cross_sim_BA_sp = current_descB @ current_descA.transpose(0, 1)
                cross_sim_AB_out_sp = torch.cat((cross_sim_AB_sp, torch.ones((new_numA, 1), device=cross_sim_AB_sp.device)), dim=-1)      # NA X (NB + 1)
                # cross_sim_BA_out_sp = torch.cat((cross_sim_BA_sp, torch.ones((numB, 1), device=cross_sim_BA_sp.device)), dim=-1)      # NB X (NA + 1)
                valid_indexesA = torch.tensor(list(range(new_numA)), device=self.device)[mask_pointA][pairAB_A]
                # valid_indexesB = torch.tensor(list(range(numB)), device=self.device)[mask_pointB][pairBA_B]
                cross_sim_AB_out_sp[valid_indexesA, -1] -= 1
                # cross_sim_BA_out_sp[valid_indexesB, -1] -= 1
                # print(cross_sim_AB_out[:, -1])
                # valid_cross_sim_AB_sp = cross_sim_AB_sp[mask_pointA, :]   # repeat_nA x nB
                # valid_cross_sim_BA = cross_sim_BA[mask_pointB, :]   # repeat_nB x nA

                soft_cross_sim_AtoB_sp = F.softmax((cross_sim_AB_out_sp - 1) / t_des, dim=-1)
                # soft_cross_sim_BtoA = F.softmax((cross_sim_BA_out - 1) / t_des, dim=-1)
                
                soft_valid_cross_sim_AB_sp = soft_cross_sim_AtoB_sp[mask_pointA, :-1][pairAB_A, pairAB_B]
                # soft_valid_cross_sim_BA = soft_cross_sim_BtoA[mask_pointB, :-1][pairBA_B, pairBA_A]
                soft_novalid_cross_sim_AB_sp = soft_cross_sim_AtoB_sp[cross_sim_AB_out_sp[:, -1]==1, -1]
                # soft_novalid_cross_sim_BA = soft_cross_sim_BtoA[cross_sim_BA_out[:, -1]==1, -1]
                log_soft_valid_cross_sim_AB_sp = -torch.log(soft_valid_cross_sim_AB_sp + eps)
                # log_soft_valid_cross_sim_BA = -torch.log(soft_valid_cross_sim_BA + eps)
                log_soft_novalid_cross_sim_AB_sp = -torch.log(soft_novalid_cross_sim_AB_sp + eps)
                # log_soft_novalid_cross_sim_BA = -torch.log(soft_novalid_cross_sim_BA + eps)
                dis_cross_sim_mean_sp = torch.sum(torch.cat((log_soft_valid_cross_sim_AB_sp, log_soft_novalid_cross_sim_AB_sp), dim=-1), dim=-1) / new_numA
                dis_desc += dis_cross_sim_mean_sp

                # PA VS PAB
                cross_sim_AB = current_descA @ desc_mapB[idx, :, :, :].view(-1, H * W)
                cross_sim_BA = current_descB @ desc_mapA[idx, :, :, :].view(-1, H * W)   # M x H x W
                cross_sim_AB_out = torch.cat((cross_sim_AB, torch.ones((new_numA, 1), device=cross_sim_AB.device)), dim=-1)      # NA X (H X W + 1)
                cross_sim_BA_out = torch.cat((cross_sim_BA, torch.ones((new_numB, 1), device=cross_sim_BA.device)), dim=-1)      # NB X (H X W + 1)

                match_mask_A = copy.deepcopy(mask_pointA)
                match_mask_B = copy.deepcopy(mask_pointB)
                match_mask_A[mask_pointA] = copy.deepcopy(vmaskAH)
                match_mask_B[mask_pointB] = copy.deepcopy(vmaskBH)
 
                # cross_sim_AB_out[mask_pointA, -1] -= 1
                # cross_sim_BA_out[mask_pointB, -1] -= 1
                cross_sim_AB_out[match_mask_A, -1] -= 1
                cross_sim_BA_out[match_mask_B, -1] -= 1
                soft_cross_sim_AtoB = F.softmax((cross_sim_AB_out - 1) / t_des, dim=-1)         # NA X (H X W + 1)
                soft_cross_sim_BtoA = F.softmax((cross_sim_BA_out - 1) / t_des, dim=-1)         # NB X (H X W + 1)
                soft_cross_sim_AB_all = F.grid_sample(soft_cross_sim_AtoB[:, :-1].view(-1, H, W).unsqueeze(0),
                                                    pntA_H_normalized[vmaskAH, :].detach().view(1, 1, -1, 2),
                                                    mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NA x match_nA
                
                soft_cross_sim_BA_all = F.grid_sample(soft_cross_sim_BtoA[:, :-1].view(-1, H, W).unsqueeze(0),
                                                    pntB_invH_normalized[vmaskBH, :].detach().view(1, 1, -1, 2),
                                                    mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NB x match_nB
                # soft_valid_cross_sim_AB_all = soft_cross_sim_AB_all[mask_pointA, :]             # repeat_nA x repeat_nA
                # soft_valid_cross_sim_BA_all = soft_cross_sim_BA_all[mask_pointB, :]             # repeat_nB x repeat_nB

                soft_valid_cross_sim_AB_all = soft_cross_sim_AB_all[match_mask_A, :]             # match_nA x match_nA
                soft_valid_cross_sim_BA_all = soft_cross_sim_BA_all[match_mask_B, :]             # match_nB x match_nB

                valid_mask_AB = torch.eye(soft_valid_cross_sim_AB_all.shape[0]) == 1
                valid_mask_BA = torch.eye(soft_valid_cross_sim_BA_all.shape[0]) == 1


                # 取对角线
                soft_valid_cross_sim_AB = soft_valid_cross_sim_AB_all[valid_mask_AB]
                soft_valid_cross_sim_BA = soft_valid_cross_sim_BA_all[valid_mask_BA]

                # soft_novalid_cross_sim_AB = soft_cross_sim_AtoB[mask_pointA==False, -1]              # (NA-repeat_nA) x 1
                # soft_novalid_cross_sim_BA = soft_cross_sim_BtoA[mask_pointB==False, -1]
                soft_novalid_cross_sim_AB = soft_cross_sim_AtoB[match_mask_A==False, -1]               # (NA-match_nA) x 1
                soft_novalid_cross_sim_BA = soft_cross_sim_BtoA[match_mask_B==False, -1]

                log_soft_valid_cross_sim_AB = -torch.log(soft_valid_cross_sim_AB + eps)
                log_soft_valid_cross_sim_BA = -torch.log(soft_valid_cross_sim_BA + eps)
                log_soft_novalid_cross_sim_AB = -torch.log(soft_novalid_cross_sim_AB + eps)
                log_soft_novalid_cross_sim_BA = -torch.log(soft_novalid_cross_sim_BA + eps)

                dis_cross_sim_mean = torch.sum(torch.cat((log_soft_valid_cross_sim_AB, log_soft_valid_cross_sim_BA, log_soft_novalid_cross_sim_AB, log_soft_novalid_cross_sim_BA), dim=-1), dim=-1) / (pntA.shape[0] + pntB.shape[0])
                dis_desc += dis_cross_sim_mean
                
                valid_cross_sim_AB = cross_sim_AB[mask_pointA, :]   # repeat_nA x (H X W)
                valid_cross_sim_BA = cross_sim_BA[mask_pointB, :]   # repeat_nB x (H X W)
                exp_valid_cross_sim_AtoB = torch.exp((valid_cross_sim_AB - 1) / t_rel).view(-1, H, W)
                exp_valid_cross_sim_BtoA = torch.exp((valid_cross_sim_BA - 1) / t_rel).view(-1, H, W)
                exp_valid_cross_sim_AB_all = F.grid_sample(exp_valid_cross_sim_AtoB.unsqueeze(0),
                                                        pntA_H_normalized.detach().view(1, 1, -1, 2),
                                                        mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # repeat_nA x repeat_nA
                
                exp_valid_cross_sim_BA_all = F.grid_sample(exp_valid_cross_sim_BtoA.unsqueeze(0),
                                                        pntB_invH_normalized.detach().view(1, 1, -1, 2),
                                                        mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # repeat_nB x repeat_nB

                repeat_mask_AB = torch.eye(exp_valid_cross_sim_AB_all.shape[0]) == 1
                repeat_mask_BA = torch.eye(exp_valid_cross_sim_BA_all.shape[0]) == 1
                rel_valid_cross_sim_AB = exp_valid_cross_sim_AB_all[repeat_mask_AB]
                rel_valid_cross_sim_BA = exp_valid_cross_sim_BA_all[repeat_mask_BA]

                scoresAB_all = F.grid_sample(scores_mapB[idx, :, :, :].unsqueeze(0),
                                            pntA_H_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)      # 1 x repeat_nA

                scoresBA_all = F.grid_sample(scores_mapA[idx, :, :, :].unsqueeze(0),
                                            pntB_invH_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)      # 1 x repeat_nB
                scores_AAB = scoresA[idx][pmA][mask_pointA] * scoresAB_all
                scores_BBA = scoresB[idx][pmB][mask_pointB] * scoresBA_all
                scores_sum_AAB = torch.sum(scores_AAB, dim=-1)
                scores_sum_BBA = torch.sum(scores_BBA, dim=-1)
                scores_normalize_AAB = scores_AAB / (scores_sum_AAB + eps)
                scores_normalize_BBA = scores_BBA / (scores_sum_BBA + eps)
                rel_meanA = torch.sum(scores_normalize_AAB * (1 - rel_valid_cross_sim_AB), dim=-1) / pntA_H_normalized.shape[0]
                rel_meanB = torch.sum(scores_normalize_BBA * (1 - rel_valid_cross_sim_BA), dim=-1) / pntB_invH_normalized.shape[0]
                dis_rel += rel_meanA + rel_meanB
                countA += new_numA
                countB += new_numB

                # # Penalty
                # scores_mean += (-torch.log(torch.mean(scoresA[idx], dim=-1) + eps) - torch.log(torch.mean(scoresB[idx], dim=-1) + eps)) 
                # print(scores_mean)
            except:
                # dis_mean_total += 0
                # dis_peak_scored += 0
                # dis_desc += 0
                # dis_rel += 0
                print('Overlapping too small or Repeatable point pairs distance is greater than correspond(4):', pntA.shape[0], pntA_H.shape[0], pntB.shape[0], pntB_invH.shape[0])
                valid_batch_size -= 1
                countA += new_numA
                countB += new_numB

        valid_batch_size = valid_batch_size if valid_batch_size > 0 else eps
        # Reprojection Loss 
        reprojection_loss = dis_mean_total / (valid_batch_size * 2)
        # Dispersity Peak Loss
        dispersity_peak_loss = dis_peak_scored / valid_batch_size
        # NRE Loss
        descriptor_loss = dis_desc / (2 * valid_batch_size)
        # Reliability Loss
        reliability_loss = dis_rel / (valid_batch_size * 2)
        # SOSR Loss
        sosr_loss = dis_neighbor_mean_total / ((valid_batch_size * 2))
        # # Score Penalty
        # score_penalty = scores_mean / (valid_batch_size * 2)
        loss_total = wrp * reprojection_loss + wpl * dispersity_peak_loss + wdl * descriptor_loss + wrl * reliability_loss + sosr_loss
        loss_group = {
            'reprojection_loss': reprojection_loss, 
            'dispersity_peak_loss': dispersity_peak_loss,
            'descriptor_loss': descriptor_loss,
            'reliability_loss': reliability_loss,
            'sosr_loss': sosr_loss
            }
        return loss_total, loss_group

    def detector_selfsupervised_loss_dkd_dense_ext(self, kpA, kpB, pmaskA, pmaskB, descA, descB, desc_mapA, desc_mapB, scoreddisA, scoreddisB, scoresA, scoresB, scores_mapA, scores_mapB, Homo, inv_Homo, H, W, wrp=1, wpl=1, wdl=1, wrl=1, t_des=0.02, t_rel=1):
        # pmaskA: (BxMax_num) 32x300=9600
        batch_size = len(kpA)
        max_num = pmaskA.shape[-1] // batch_size    # 300
        dis_mean_total = 0
        dis_neighbor_mean_total = 0
        dis_peak_scored = 0
        dis_desc = 0
        dis_rel = 0
        eps = 1e-12
        valid_batch_size = batch_size
        countA, countB = 0, 0
        for idx in range(batch_size):
            pntA, pntB = kpA[idx], kpB[idx]     # M X 2 (x,y)
            pntA = pntA.float()
            pntB = pntB.float()
            # pntA = torch.tensor(pntA, device=self.device).type(torch.FloatTensor)
            # pntB = torch.tensor(pntB, device=self.device).type(torch.FloatTensor)
            numA, numB = pntA.shape[0], pntB.shape[0]
            pmA, pmB = pmaskA[max_num * idx:max_num * idx + numA].bool(), pmaskB[max_num * idx:max_num * idx + numB].bool()
            pntA, pntB = pntA[pmA, :], pntB[pmB, :]
            new_numA, new_numB = pntA.shape[0], pntB.shape[0]
            pntA = (pntA + 1) / 2 * pntA.new_tensor([[W + 3, H - 1]]).to(pntA.device)
            pntB = (pntB + 1) / 2 * pntB.new_tensor([[W + 3, H - 1]]).to(pntB.device)

            pntA[:, 0] -= 2
            pntB[:, 0] -= 2

            pntA_H = warp_points(pntA[:, :2], Homo[idx].squeeze(), device=self.device)  # 利用变换矩阵变换坐标点
            pntA_H, mask_pointA = filter_points(pntA_H, torch.tensor([W, H], device=self.device), return_mask=True)
            pntB_invH = warp_points(pntB[:, :2], inv_Homo[idx].squeeze(), device=self.device)
            pntB_invH, mask_pointB = filter_points(pntB_invH, torch.tensor([W, H], device=self.device), return_mask=True)
            
            try:
                assert pntA_H.shape[0] > 0 and pntB_invH.shape[0] > 0 
                # print(pntA_H.shape, pntB.shape, pntB_invH.shape, pntA.shape)
                key_disAB = self.get_dis(pntA_H[:, :2], pntB[:, :2])
                key_disBA = self.get_dis(pntB_invH[:, :2], pntA[:, :2])
                pairAB_A, pairAB_B, dis_pairAB, vmaskAH = self.get_point_pair(key_disAB, dis_thre=self.correspond)  # p -> k
                pairBA_B, pairBA_A, dis_pairBA, vmaskBH  = self.get_point_pair(key_disBA, dis_thre=self.correspond)  # p -> k
                key_manhattandisAB = self.get_manhattan_dis(pntA_H[:, :2], pntB[:, :2])
                key_manhattandisBA = self.get_manhattan_dis(pntB_invH[:, :2], pntA[:, :2])
                assert dis_pairAB.shape[0] > 0 and dis_pairBA.shape[0] > 0     
                # dis_pair_meanAB = torch.mean(dis_pairAB)
                # dis_pair_meanBA = torch.mean(dis_pairBA)

                pntA_H_normalized = pntA_H / pntA_H.new_tensor([W - 1, H - 1]).to(pntA_H.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)
                pntB_invH_normalized = pntB_invH / pntB_invH.new_tensor([W - 1, H - 1]).to(pntB_invH.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)

                # 用于score_map
                pntA_H_new = copy.deepcopy(pntA_H.detach())
                pntB_invH_new = copy.deepcopy(pntB_invH.detach())
                pntA_H_new[:, 0] += 2
                pntB_invH_new[:, 0] += 2
                pntA_H_normalized_new = pntA_H_new / pntA_H_new.new_tensor([W + 3, H - 1]).to(pntA_H.device) * 2 - 1
                pntB_invH_normalized_new = pntB_invH_new / pntB_invH_new.new_tensor([W + 3, H - 1]).to(pntB_invH.device) * 2 - 1 

                current_descA, current_descB = descA[countA:countA+new_numA], descB[countB:countB+new_numB]
                
                # SOSR:
                k_neighbor = 3
                cross_sim_AA_sp = current_descA @ current_descA.transpose(0, 1)
                cross_sim_BB_sp = current_descB @ current_descB.transpose(0, 1)
                match_sim_AB_AA = cross_sim_AA_sp[mask_pointA, :][:, mask_pointA][pairAB_A, :][:, pairAB_A]
                match_sim_BA_BB = cross_sim_BB_sp[mask_pointB, :][:, mask_pointB][pairBA_B, :][:, pairBA_B]
                match_sim_AB_BB = cross_sim_BB_sp[pairAB_B, :][:, pairAB_B]
                match_sim_BA_AA = cross_sim_AA_sp[pairBA_A, :][:, pairBA_A]
                match_values_AB_AA, match_indices_AB_AA = torch.topk(match_sim_AB_AA, dim=1, k=k_neighbor, largest=False)
                match_values_BA_BB, match_indices_BA_BB = torch.topk(match_sim_BA_BB, dim=1, k=k_neighbor, largest=False)
                match_values_AB_BB_all = match_sim_AB_BB[:, match_indices_AB_AA]
                match_values_BA_AA_all = match_sim_BA_AA[:, match_indices_BA_BB]
                match_values_AB_BB = torch.diagonal(match_values_AB_BB_all, 0, dim1=0, dim2=1).transpose(0, 1)
                match_values_BA_AA = torch.diagonal(match_values_BA_AA_all, 0, dim1=0, dim2=1).transpose(0, 1)
                neighbor_dis_AB = (match_values_AB_AA - match_values_AB_BB) * (match_values_AB_AA - match_values_AB_BB)
                neighbor_dis_BA = (match_values_BA_BB - match_values_BA_AA) * (match_values_BA_BB - match_values_BA_AA)

                # PA VS PB
                cross_sim_AB_sp = current_descA @ current_descB.transpose(0, 1)
                # cross_sim_BA_sp = current_descB @ current_descA.transpose(0, 1)
                cross_sim_AB_out_sp = torch.cat((cross_sim_AB_sp, torch.ones((new_numA, 1), device=cross_sim_AB_sp.device)), dim=-1)      # NA X (NB + 1)
                # cross_sim_BA_out_sp = torch.cat((cross_sim_BA_sp, torch.ones((numB, 1), device=cross_sim_BA_sp.device)), dim=-1)      # NB X (NA + 1)
                valid_indexesA = torch.tensor(list(range(new_numA)), device=self.device)[mask_pointA][pairAB_A]
                # valid_indexesB = torch.tensor(list(range(numB)), device=self.device)[mask_pointB][pairBA_B]
                cross_sim_AB_out_sp[valid_indexesA, -1] -= 1
                # cross_sim_BA_out_sp[valid_indexesB, -1] -= 1
                # print(cross_sim_AB_out[:, -1])
                # valid_cross_sim_AB_sp = cross_sim_AB_sp[mask_pointA, :]   # repeat_nA x nB
                # valid_cross_sim_BA = cross_sim_BA[mask_pointB, :]   # repeat_nB x nA

                soft_cross_sim_AtoB_sp = F.softmax((cross_sim_AB_out_sp - 1) / t_des, dim=-1)
                # soft_cross_sim_BtoA = F.softmax((cross_sim_BA_out - 1) / t_des, dim=-1)
                
                soft_valid_cross_sim_AB_sp = soft_cross_sim_AtoB_sp[mask_pointA, :-1][pairAB_A, pairAB_B]
                # soft_valid_cross_sim_BA = soft_cross_sim_BtoA[mask_pointB, :-1][pairBA_B, pairBA_A]
                soft_novalid_cross_sim_AB_sp = soft_cross_sim_AtoB_sp[cross_sim_AB_out_sp[:, -1]==1, -1]
                # soft_novalid_cross_sim_BA = soft_cross_sim_BtoA[cross_sim_BA_out[:, -1]==1, -1]
                log_soft_valid_cross_sim_AB_sp = -torch.log(soft_valid_cross_sim_AB_sp + eps)
                # log_soft_valid_cross_sim_BA = -torch.log(soft_valid_cross_sim_BA + eps)
                log_soft_novalid_cross_sim_AB_sp = -torch.log(soft_novalid_cross_sim_AB_sp + eps)
                # log_soft_novalid_cross_sim_BA = -torch.log(soft_novalid_cross_sim_BA + eps)
                dis_cross_sim_mean_sp = torch.sum(torch.cat((log_soft_valid_cross_sim_AB_sp, log_soft_novalid_cross_sim_AB_sp), dim=-1), dim=-1) / new_numA


                # PA VS PAB
                cross_sim_AB = current_descA @ desc_mapB[idx, :, :, :].view(-1, H * W)
                cross_sim_BA = current_descB @ desc_mapA[idx, :, :, :].view(-1, H * W)   # M x H x W
                cross_sim_AB_out = torch.cat((cross_sim_AB, torch.ones((new_numA, 1), device=cross_sim_AB.device)), dim=-1)      # NA X (H X W + 1)
                cross_sim_BA_out = torch.cat((cross_sim_BA, torch.ones((new_numB, 1), device=cross_sim_BA.device)), dim=-1)      # NB X (H X W + 1)

                match_mask_A = copy.deepcopy(mask_pointA)
                match_mask_B = copy.deepcopy(mask_pointB)
                match_mask_A[mask_pointA] = copy.deepcopy(vmaskAH)
                match_mask_B[mask_pointB] = copy.deepcopy(vmaskBH)
 
                # cross_sim_AB_out[mask_pointA, -1] -= 1
                # cross_sim_BA_out[mask_pointB, -1] -= 1
                cross_sim_AB_out[match_mask_A, -1] -= 1
                cross_sim_BA_out[match_mask_B, -1] -= 1
                soft_cross_sim_AtoB = F.softmax((cross_sim_AB_out - 1) / t_des, dim=-1)         # NA X (H X W + 1)
                soft_cross_sim_BtoA = F.softmax((cross_sim_BA_out - 1) / t_des, dim=-1)         # NB X (H X W + 1)
                soft_cross_sim_AB_all = F.grid_sample(soft_cross_sim_AtoB[:, :-1].view(-1, H, W).unsqueeze(0),
                                                    pntA_H_normalized[vmaskAH, :].detach().view(1, 1, -1, 2),
                                                    mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NA x match_nA
                
                soft_cross_sim_BA_all = F.grid_sample(soft_cross_sim_BtoA[:, :-1].view(-1, H, W).unsqueeze(0),
                                                    pntB_invH_normalized[vmaskBH, :].detach().view(1, 1, -1, 2),
                                                    mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NB x match_nB
                # soft_valid_cross_sim_AB_all = soft_cross_sim_AB_all[mask_pointA, :]             # repeat_nA x repeat_nA
                # soft_valid_cross_sim_BA_all = soft_cross_sim_BA_all[mask_pointB, :]             # repeat_nB x repeat_nB

                soft_valid_cross_sim_AB_all = soft_cross_sim_AB_all[match_mask_A, :]             # match_nA x match_nA
                soft_valid_cross_sim_BA_all = soft_cross_sim_BA_all[match_mask_B, :]             # match_nB x match_nB

                valid_mask_AB = torch.eye(soft_valid_cross_sim_AB_all.shape[0]) == 1
                valid_mask_BA = torch.eye(soft_valid_cross_sim_BA_all.shape[0]) == 1

                # 取对角线
                soft_valid_cross_sim_AB = soft_valid_cross_sim_AB_all[valid_mask_AB]
                soft_valid_cross_sim_BA = soft_valid_cross_sim_BA_all[valid_mask_BA]

                # soft_novalid_cross_sim_AB = soft_cross_sim_AtoB[mask_pointA==False, -1]              # (NA-repeat_nA) x 1
                # soft_novalid_cross_sim_BA = soft_cross_sim_BtoA[mask_pointB==False, -1]
                soft_novalid_cross_sim_AB = soft_cross_sim_AtoB[match_mask_A==False, -1]               # (NA-match_nA) x 1
                soft_novalid_cross_sim_BA = soft_cross_sim_BtoA[match_mask_B==False, -1]

                log_soft_valid_cross_sim_AB = -torch.log(soft_valid_cross_sim_AB + eps)
                log_soft_valid_cross_sim_BA = -torch.log(soft_valid_cross_sim_BA + eps)
                log_soft_novalid_cross_sim_AB = -torch.log(soft_novalid_cross_sim_AB + eps)
                log_soft_novalid_cross_sim_BA = -torch.log(soft_novalid_cross_sim_BA + eps)

                dis_cross_sim_mean = torch.sum(torch.cat((log_soft_valid_cross_sim_AB, log_soft_valid_cross_sim_BA, log_soft_novalid_cross_sim_AB, log_soft_novalid_cross_sim_BA), dim=-1), dim=-1) / (pntA.shape[0] + pntB.shape[0])

                
                valid_cross_sim_AB = cross_sim_AB[mask_pointA, :]   # repeat_nA x (H X W)
                valid_cross_sim_BA = cross_sim_BA[mask_pointB, :]   # repeat_nB x (H X W)
                exp_valid_cross_sim_AtoB = torch.exp((valid_cross_sim_AB - 1) / t_rel).view(-1, H, W)
                exp_valid_cross_sim_BtoA = torch.exp((valid_cross_sim_BA - 1) / t_rel).view(-1, H, W)
                exp_valid_cross_sim_AB_all = F.grid_sample(exp_valid_cross_sim_AtoB.unsqueeze(0),
                                                        pntA_H_normalized.detach().view(1, 1, -1, 2),
                                                        mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # repeat_nA x repeat_nA
                
                exp_valid_cross_sim_BA_all = F.grid_sample(exp_valid_cross_sim_BtoA.unsqueeze(0),
                                                        pntB_invH_normalized.detach().view(1, 1, -1, 2),
                                                        mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # repeat_nB x repeat_nB

                repeat_mask_AB = torch.eye(exp_valid_cross_sim_AB_all.shape[0]) == 1
                repeat_mask_BA = torch.eye(exp_valid_cross_sim_BA_all.shape[0]) == 1
                rel_valid_cross_sim_AB = exp_valid_cross_sim_AB_all[repeat_mask_AB]
                rel_valid_cross_sim_BA = exp_valid_cross_sim_BA_all[repeat_mask_BA]

                # pntA_H_normalized_new = copy.deepcopy(pntA_H_normalized.detach())
                # pntB_invH_normalized_new = copy.deepcopy(pntB_invH_normalized.detach())

                # pntA_H_normalized_new[:, 0] += 2
                # pntB_invH_normalized_new[:, 0] += 2

                scoresAB_all = F.grid_sample(scores_mapB[idx, :, :, :].unsqueeze(0),
                                            pntA_H_normalized_new.view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)      # 1 x repeat_nA

                scoresBA_all = F.grid_sample(scores_mapA[idx, :, :, :].unsqueeze(0),
                                            pntB_invH_normalized_new.view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)      # 1 x repeat_nB

                scores_AAB = scoresA[idx][pmA][mask_pointA] * scoresAB_all
                scores_BBA = scoresB[idx][pmB][mask_pointB] * scoresBA_all
                scores_sum_AAB = torch.sum(scores_AAB, dim=-1)
                scores_sum_BBA = torch.sum(scores_BBA, dim=-1)
                scores_normalize_AAB = scores_AAB / (scores_sum_AAB + eps)
                scores_normalize_BBA = scores_BBA / (scores_sum_BBA + eps)
                rel_meanA = torch.sum(scores_normalize_AAB * (1 - rel_valid_cross_sim_AB), dim=-1) / pntA_H_normalized.shape[0]
                rel_meanB = torch.sum(scores_normalize_BBA * (1 - rel_valid_cross_sim_BA), dim=-1) / pntB_invH_normalized.shape[0]

                countA += new_numA
                countB += new_numB
                
                dis_neighbor_mean_total += torch.mean(torch.sum(neighbor_dis_AB, dim=1)) + torch.mean(torch.sum(neighbor_dis_BA, dim=1))
                dis_desc += dis_cross_sim_mean_sp
                dis_desc += dis_cross_sim_mean

                dis_pair_meanAB = torch.mean(key_manhattandisAB[pairAB_A, pairAB_B])
                dis_pair_meanBA = torch.mean(key_manhattandisBA[pairBA_B, pairBA_A])

                dis_peak_mean = torch.mean(torch.cat((scoreddisA[idx][pmA], scoreddisB[idx][pmB]), dim=0))
                # dis_peak_meanB = torch.mean(scoreddisB[idx])
                
                dis_mean_total += dis_pair_meanAB + dis_pair_meanBA
                dis_peak_scored += dis_peak_mean

                dis_rel += rel_meanA + rel_meanB
                # # Penalty
                # scores_mean += (-torch.log(torch.mean(scoresA[idx], dim=-1) + eps) - torch.log(torch.mean(scoresB[idx], dim=-1) + eps)) 
                # print(scores_mean)
            except:
                # dis_mean_total += 0
                # dis_peak_scored += 0
                # dis_desc += 0
                # dis_rel += 0
                print('Overlapping too small or Repeatable point pairs distance is greater than correspond(4):', pntA.shape[0], pntA_H.shape[0], pntB.shape[0], pntB_invH.shape[0], dis_pairAB.shape[0], dis_pairBA.shape[0])
                valid_batch_size -= 1
                countA += new_numA
                countB += new_numB

        valid_batch_size = valid_batch_size if valid_batch_size > 0 else eps
        # Reprojection Loss 
        reprojection_loss = dis_mean_total / (valid_batch_size * 2)
        # Dispersity Peak Loss
        dispersity_peak_loss = dis_peak_scored / valid_batch_size
        # NRE Loss
        descriptor_loss = dis_desc / (2 * valid_batch_size)
        # Reliability Loss
        reliability_loss = dis_rel / (valid_batch_size * 2)
        # SOSR Loss
        sosr_loss = dis_neighbor_mean_total / ((valid_batch_size * 2))
        # # Score Penalty
        # score_penalty = scores_mean / (valid_batch_size * 2)
        loss_total = wrp * reprojection_loss + wpl * dispersity_peak_loss + wdl * descriptor_loss + wrl * reliability_loss + sosr_loss
        loss_group = {
            'reprojection_loss': reprojection_loss, 
            'dispersity_peak_loss': dispersity_peak_loss,
            'descriptor_loss': descriptor_loss,
            'reliability_loss': reliability_loss,
            'sosr_loss': sosr_loss
            }
        return loss_total, loss_group

    def detector_selfsupervised_loss_dkd_dense_ext_restrict(self, kpA, kpB, pmaskA, pmaskB, descA, descB, desc_mapA, desc_mapB, scoreddisA, scoreddisB, scoresA, scoresB, scores_mapA, scores_mapB, Homo, inv_Homo, H, W, wrp=1, wpl=1, wdl=1, wrl=1, t_des=0.02, t_rel=1):
        # pmaskA: (BxMax_num) 32x300=9600
        batch_size = len(kpA)
        max_num = pmaskA.shape[-1] // batch_size    # 300
        dis_mean_total = 0
        dis_neighbor_mean_total = 0
        dis_peak_scored = 0
        dis_desc = 0
        dis_rel = 0
        eps = 1e-12
        valid_batch_size = batch_size
        countA, countB = 0, 0
        for idx in range(batch_size):
            pntA, pntB = kpA[idx], kpB[idx]     # M X 2 (x,y)
            pntA = pntA.float()
            pntB = pntB.float()
            # pntA = torch.tensor(pntA, device=self.device).type(torch.FloatTensor)
            # pntB = torch.tensor(pntB, device=self.device).type(torch.FloatTensor)
            numA, numB = pntA.shape[0], pntB.shape[0]
            pmA, pmB = pmaskA[max_num * idx:max_num * idx + numA].bool(), pmaskB[max_num * idx:max_num * idx + numB].bool()
            pntA, pntB = pntA[pmA, :], pntB[pmB, :]
            new_numA, new_numB = pntA.shape[0], pntB.shape[0]
            pntA = (pntA + 1) / 2 * pntA.new_tensor([[W + 3, H - 1]]).to(pntA.device)
            pntB = (pntB + 1) / 2 * pntB.new_tensor([[W + 3, H - 1]]).to(pntB.device)

            pntA[:, 0] -= 2
            pntB[:, 0] -= 2

            pntA_H = warp_points(pntA[:, :2], Homo[idx].squeeze(), device=self.device)  # 利用变换矩阵变换坐标点
            pntA_H, mask_pointA = filter_points(pntA_H, torch.tensor([W, H], device=self.device), return_mask=True)
            pntB_invH = warp_points(pntB[:, :2], inv_Homo[idx].squeeze(), device=self.device)
            pntB_invH, mask_pointB = filter_points(pntB_invH, torch.tensor([W, H], device=self.device), return_mask=True)
            
            try:
                assert pntA_H.shape[0] > 0 and pntB_invH.shape[0] > 0 
                # print(pntA_H.shape, pntB.shape, pntB_invH.shape, pntA.shape)
                key_disAB = self.get_dis(pntA_H[:, :2], pntB[:, :2])
                key_disBA = self.get_dis(pntB_invH[:, :2], pntA[:, :2])
                pairAB_A, pairAB_B, dis_pairAB, vmaskAH = self.get_point_pair(key_disAB, dis_thre=self.correspond)  # p -> k
                pairBA_B, pairBA_A, dis_pairBA, vmaskBH  = self.get_point_pair(key_disBA, dis_thre=self.correspond)  # p -> k
                key_manhattandisAB = self.get_manhattan_dis(pntA_H[:, :2], pntB[:, :2])
                key_manhattandisBA = self.get_manhattan_dis(pntB_invH[:, :2], pntA[:, :2])
                assert dis_pairAB.shape[0] > 0 and dis_pairBA.shape[0] > 0     
                # dis_pair_meanAB = torch.mean(dis_pairAB)
                # dis_pair_meanBA = torch.mean(dis_pairBA)

                pntA_H_normalized = pntA_H / pntA_H.new_tensor([W - 1, H - 1]).to(pntA_H.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)
                pntB_invH_normalized = pntB_invH / pntB_invH.new_tensor([W - 1, H - 1]).to(pntB_invH.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)

                # 用于score_map
                pntA_H_new = copy.deepcopy(pntA_H.detach())
                pntB_invH_new = copy.deepcopy(pntB_invH.detach())
                pntA_H_new[:, 0] += 2
                pntB_invH_new[:, 0] += 2
                pntA_H_normalized_new = pntA_H_new / pntA_H_new.new_tensor([W + 3, H - 1]).to(pntA_H.device) * 2 - 1
                pntB_invH_normalized_new = pntB_invH_new / pntB_invH_new.new_tensor([W + 3, H - 1]).to(pntB_invH.device) * 2 - 1 

                current_descA, current_descB = descA[countA:countA+new_numA], descB[countB:countB+new_numB]
                
                # SOSR:
                k_neighbor = 3
                cross_sim_AA_sp = current_descA @ current_descA.transpose(0, 1)
                cross_sim_BB_sp = current_descB @ current_descB.transpose(0, 1)
                match_sim_AB_AA = cross_sim_AA_sp[mask_pointA, :][:, mask_pointA][pairAB_A, :][:, pairAB_A]
                match_sim_BA_BB = cross_sim_BB_sp[mask_pointB, :][:, mask_pointB][pairBA_B, :][:, pairBA_B]
                match_sim_AB_BB = cross_sim_BB_sp[pairAB_B, :][:, pairAB_B]
                match_sim_BA_AA = cross_sim_AA_sp[pairBA_A, :][:, pairBA_A]
                match_values_AB_AA, match_indices_AB_AA = torch.topk(match_sim_AB_AA, dim=1, k=k_neighbor, largest=False)
                match_values_BA_BB, match_indices_BA_BB = torch.topk(match_sim_BA_BB, dim=1, k=k_neighbor, largest=False)
                match_values_AB_BB_all = match_sim_AB_BB[:, match_indices_AB_AA]
                match_values_BA_AA_all = match_sim_BA_AA[:, match_indices_BA_BB]
                match_values_AB_BB = torch.diagonal(match_values_AB_BB_all, 0, dim1=0, dim2=1).transpose(0, 1)
                match_values_BA_AA = torch.diagonal(match_values_BA_AA_all, 0, dim1=0, dim2=1).transpose(0, 1)
                neighbor_dis_AB = (match_values_AB_AA - match_values_AB_BB) * (match_values_AB_AA - match_values_AB_BB)
                neighbor_dis_BA = (match_values_BA_BB - match_values_BA_AA) * (match_values_BA_BB - match_values_BA_AA)

                # PA VS PB
                cross_sim_AB_sp = current_descA @ current_descB.transpose(0, 1)
                valid_cross_sim_AB_sp_mean = torch.mean(cross_sim_AB_sp[mask_pointA, :][pairAB_A, pairAB_B], dim=-1)
                novalid_cross_sim_AB_sp_mean = (torch.sum(torch.sum(cross_sim_AB_sp.detach(), 1), 0) - valid_cross_sim_AB_sp_mean * pairAB_A.shape[0]) / (new_numA * new_numB - pairAB_A.shape[0])
                valid_cross_sim_BA_sp_mean = torch.mean(cross_sim_AB_sp[:, mask_pointB][pairBA_A, pairBA_B], dim=-1)
                novalid_cross_sim_BA_sp_mean = (torch.sum(torch.sum(cross_sim_AB_sp.detach(), 1), 0) - valid_cross_sim_BA_sp_mean * pairBA_B.shape[0]) / (new_numA * new_numB - pairBA_B.shape[0])

                valid_indexesA = torch.tensor(list(range(new_numA)), device=self.device)[mask_pointA][pairAB_A]
                # cross_sim_BA_sp = current_descB @ current_descA.transpose(0, 1)
                cross_sim_AB_out_sp = torch.cat((cross_sim_AB_sp, torch.ones((new_numA, 1), device=cross_sim_AB_sp.device) * 2), dim=-1)      # NA X (NB + 1)
                # cross_sim_BA_out_sp = torch.cat((cross_sim_BA_sp, torch.ones((numB, 1), device=cross_sim_BA_sp.device)), dim=-1)      # NB X (NA + 1)
                # valid_indexesB = torch.tensor(list(range(numB)), device=self.device)[mask_pointB][pairBA_B]
                cross_sim_AB_out_sp[valid_indexesA, -1] = novalid_cross_sim_AB_sp_mean
                novalid_indexesA = torch.tensor(list(range(new_numA)), device=self.device)[cross_sim_AB_out_sp[:, -1]==2]
                cross_sim_AB_out_sp[novalid_indexesA, -1] = valid_cross_sim_AB_sp_mean

                soft_cross_sim_AtoB_sp = F.softmax((cross_sim_AB_out_sp - 1) / t_des, dim=-1)
                # soft_cross_sim_BtoA = F.softmax((cross_sim_BA_out - 1) / t_des, dim=-1)
                
                soft_valid_cross_sim_AB_sp = soft_cross_sim_AtoB_sp[mask_pointA, :-1][pairAB_A, pairAB_B]
                # soft_valid_cross_sim_BA = soft_cross_sim_BtoA[mask_pointB, :-1][pairBA_B, pairBA_A]
                soft_novalid_cross_sim_AB_sp = soft_cross_sim_AtoB_sp[novalid_indexesA, -1]
                # soft_novalid_cross_sim_BA = soft_cross_sim_BtoA[cross_sim_BA_out[:, -1]==1, -1]
                log_soft_valid_cross_sim_AB_sp = -torch.log(soft_valid_cross_sim_AB_sp + eps)
                # log_soft_valid_cross_sim_BA = -torch.log(soft_valid_cross_sim_BA + eps)
                log_soft_novalid_cross_sim_AB_sp = -torch.log(soft_novalid_cross_sim_AB_sp + eps)
                # log_soft_novalid_cross_sim_BA = -torch.log(soft_novalid_cross_sim_BA + eps)
                dis_cross_sim_mean_sp = torch.sum(torch.cat((log_soft_valid_cross_sim_AB_sp, log_soft_novalid_cross_sim_AB_sp), dim=-1), dim=-1) / new_numA


                # PA VS PAB
                match_mask_A = copy.deepcopy(mask_pointA)
                match_mask_B = copy.deepcopy(mask_pointB)
                match_mask_A[mask_pointA] = copy.deepcopy(vmaskAH)
                match_mask_B[mask_pointB] = copy.deepcopy(vmaskBH)

                cross_sim_AB = current_descA @ desc_mapB[idx, :, :, :].view(-1, H * W)
                cross_sim_AB_all = F.grid_sample(cross_sim_AB.view(-1, H, W).unsqueeze(0),
                                                pntA_H_normalized[vmaskAH, :].detach().view(1, 1, -1, 2),
                                                mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NA x match_nA

                valid_cross_sim_AB_mean = torch.trace(cross_sim_AB_all[match_mask_A, :]) / cross_sim_AB_all[match_mask_A, :].shape[0]
                # novalid_cross_sim_AB_mean = (torch.sum(torch.sum(cross_sim_AB.detach(), 1), 1) - valid_cross_sim_AB_mean * pairAB_A.shape[0]) / (new_numA * H * W - pairAB_A.shape[0])

                cross_sim_BA = current_descB @ desc_mapA[idx, :, :, :].view(-1, H * W)   # M x H x W
                cross_sim_BA_all = F.grid_sample(cross_sim_BA.view(-1, H, W).unsqueeze(0),
                                                pntB_invH_normalized[vmaskBH, :].detach().view(1, 1, -1, 2),
                                                mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NB x match_nB

                valid_cross_sim_BA_mean = torch.trace(cross_sim_BA_all[match_mask_B, :]) / cross_sim_BA_all[match_mask_B, :].shape[0]
                # novalid_cross_sim_BA_mean = (torch.sum(torch.sum(cross_sim_BA.detach(), 1), 1) - valid_cross_sim_BA_mean * pairBA_B.shape[0]) / (new_numB * H * W - pairBA_B.shape[0])

                cross_sim_AB_out = torch.cat((cross_sim_AB, torch.ones((new_numA, 1), device=cross_sim_AB.device)), dim=-1)      # NA X (H X W + 1)
                cross_sim_BA_out = torch.cat((cross_sim_BA, torch.ones((new_numB, 1), device=cross_sim_BA.device)), dim=-1)      # NB X (H X W + 1)
                # print(match_mask_A.shape, cross_sim_AB_out.shape)
                # cross_sim_AB_out[mask_pointA, -1] -= 1
                # cross_sim_BA_out[mask_pointB, -1] -= 1
                # cross_sim_AB_out[match_mask_A, -1] -= 1
                cross_sim_AB_out[match_mask_A, -1] = novalid_cross_sim_AB_sp_mean
                cross_sim_AB_out[match_mask_A==False, -1] = valid_cross_sim_AB_mean
                # print(1)
                cross_sim_BA_out[match_mask_B, -1] = novalid_cross_sim_BA_sp_mean
                cross_sim_BA_out[match_mask_B==False, -1] = valid_cross_sim_BA_mean

                soft_cross_sim_AtoB = F.softmax((cross_sim_AB_out - 1) / t_des, dim=-1)         # NA X (H X W + 1)
                soft_cross_sim_BtoA = F.softmax((cross_sim_BA_out - 1) / t_des, dim=-1)         # NB X (H X W + 1)
                soft_cross_sim_AB_all = F.grid_sample(soft_cross_sim_AtoB[:, :-1].view(-1, H, W).unsqueeze(0),
                                                    pntA_H_normalized[vmaskAH, :].detach().view(1, 1, -1, 2),
                                                    mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NA x match_nA
                
                soft_cross_sim_BA_all = F.grid_sample(soft_cross_sim_BtoA[:, :-1].view(-1, H, W).unsqueeze(0),
                                                    pntB_invH_normalized[vmaskBH, :].detach().view(1, 1, -1, 2),
                                                    mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NB x match_nB
                # soft_valid_cross_sim_AB_all = soft_cross_sim_AB_all[mask_pointA, :]             # repeat_nA x repeat_nA
                # soft_valid_cross_sim_BA_all = soft_cross_sim_BA_all[mask_pointB, :]             # repeat_nB x repeat_nB

                soft_valid_cross_sim_AB_all = soft_cross_sim_AB_all[match_mask_A, :]             # match_nA x match_nA
                soft_valid_cross_sim_BA_all = soft_cross_sim_BA_all[match_mask_B, :]             # match_nB x match_nB

                valid_mask_AB = torch.eye(soft_valid_cross_sim_AB_all.shape[0]) == 1
                valid_mask_BA = torch.eye(soft_valid_cross_sim_BA_all.shape[0]) == 1

                # 取对角线
                soft_valid_cross_sim_AB = soft_valid_cross_sim_AB_all[valid_mask_AB]
                soft_valid_cross_sim_BA = soft_valid_cross_sim_BA_all[valid_mask_BA]

                # soft_novalid_cross_sim_AB = soft_cross_sim_AtoB[mask_pointA==False, -1]              # (NA-repeat_nA) x 1
                # soft_novalid_cross_sim_BA = soft_cross_sim_BtoA[mask_pointB==False, -1]
                soft_novalid_cross_sim_AB = soft_cross_sim_AtoB[match_mask_A==False, -1]               # (NA-match_nA) x 1
                soft_novalid_cross_sim_BA = soft_cross_sim_BtoA[match_mask_B==False, -1]

                log_soft_valid_cross_sim_AB = -torch.log(soft_valid_cross_sim_AB + eps)
                log_soft_valid_cross_sim_BA = -torch.log(soft_valid_cross_sim_BA + eps)
                log_soft_novalid_cross_sim_AB = -torch.log(soft_novalid_cross_sim_AB + eps)
                log_soft_novalid_cross_sim_BA = -torch.log(soft_novalid_cross_sim_BA + eps)

                dis_cross_sim_mean = torch.sum(torch.cat((log_soft_valid_cross_sim_AB, log_soft_valid_cross_sim_BA, log_soft_novalid_cross_sim_AB, log_soft_novalid_cross_sim_BA), dim=-1), dim=-1) / (pntA.shape[0] + pntB.shape[0])

                
                valid_cross_sim_AB = cross_sim_AB[mask_pointA, :]   # repeat_nA x (H X W)
                valid_cross_sim_BA = cross_sim_BA[mask_pointB, :]   # repeat_nB x (H X W)
                exp_valid_cross_sim_AtoB = torch.exp((valid_cross_sim_AB - 1) / t_rel).view(-1, H, W)
                exp_valid_cross_sim_BtoA = torch.exp((valid_cross_sim_BA - 1) / t_rel).view(-1, H, W)
                exp_valid_cross_sim_AB_all = F.grid_sample(exp_valid_cross_sim_AtoB.unsqueeze(0),
                                                        pntA_H_normalized.detach().view(1, 1, -1, 2),
                                                        mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # repeat_nA x repeat_nA
                
                exp_valid_cross_sim_BA_all = F.grid_sample(exp_valid_cross_sim_BtoA.unsqueeze(0),
                                                        pntB_invH_normalized.detach().view(1, 1, -1, 2),
                                                        mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # repeat_nB x repeat_nB

                repeat_mask_AB = torch.eye(exp_valid_cross_sim_AB_all.shape[0]) == 1
                repeat_mask_BA = torch.eye(exp_valid_cross_sim_BA_all.shape[0]) == 1
                rel_valid_cross_sim_AB = exp_valid_cross_sim_AB_all[repeat_mask_AB]
                rel_valid_cross_sim_BA = exp_valid_cross_sim_BA_all[repeat_mask_BA]

                # pntA_H_normalized_new = copy.deepcopy(pntA_H_normalized.detach())
                # pntB_invH_normalized_new = copy.deepcopy(pntB_invH_normalized.detach())

                # pntA_H_normalized_new[:, 0] += 2
                # pntB_invH_normalized_new[:, 0] += 2

                scoresAB_all = F.grid_sample(scores_mapB[idx, :, :, :].unsqueeze(0),
                                            pntA_H_normalized_new.view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)      # 1 x repeat_nA

                scoresBA_all = F.grid_sample(scores_mapA[idx, :, :, :].unsqueeze(0),
                                            pntB_invH_normalized_new.view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)      # 1 x repeat_nB

                scores_AAB = scoresA[idx][pmA][mask_pointA] * scoresAB_all
                scores_BBA = scoresB[idx][pmB][mask_pointB] * scoresBA_all
                scores_sum_AAB = torch.sum(scores_AAB, dim=-1)
                scores_sum_BBA = torch.sum(scores_BBA, dim=-1)
                scores_normalize_AAB = scores_AAB / (scores_sum_AAB + eps)
                scores_normalize_BBA = scores_BBA / (scores_sum_BBA + eps)
                rel_meanA = torch.sum(scores_normalize_AAB * (1 - rel_valid_cross_sim_AB), dim=-1) / pntA_H_normalized.shape[0]
                rel_meanB = torch.sum(scores_normalize_BBA * (1 - rel_valid_cross_sim_BA), dim=-1) / pntB_invH_normalized.shape[0]

                countA += new_numA
                countB += new_numB
                
                dis_neighbor_mean_total += torch.mean(torch.sum(neighbor_dis_AB, dim=1)) + torch.mean(torch.sum(neighbor_dis_BA, dim=1))
                dis_desc += dis_cross_sim_mean_sp
                dis_desc += dis_cross_sim_mean

                dis_pair_meanAB = torch.mean(key_manhattandisAB[pairAB_A, pairAB_B])
                dis_pair_meanBA = torch.mean(key_manhattandisBA[pairBA_B, pairBA_A])

                dis_peak_mean = torch.mean(torch.cat((scoreddisA[idx][pmA], scoreddisB[idx][pmB]), dim=0))
                # dis_peak_meanB = torch.mean(scoreddisB[idx])
                
                dis_mean_total += dis_pair_meanAB + dis_pair_meanBA
                dis_peak_scored += dis_peak_mean

                dis_rel += rel_meanA + rel_meanB
                # # Penalty
                # scores_mean += (-torch.log(torch.mean(scoresA[idx], dim=-1) + eps) - torch.log(torch.mean(scoresB[idx], dim=-1) + eps)) 
                # print(scores_mean)
            except:
                # dis_mean_total += 0
                # dis_peak_scored += 0
                # dis_desc += 0
                # dis_rel += 0
                print('Overlapping too small or Repeatable point pairs distance is greater than correspond(4):', pntA.shape[0], pntA_H.shape[0], pntB.shape[0], pntB_invH.shape[0], dis_pairAB.shape[0], dis_pairBA.shape[0])
                valid_batch_size -= 1
                countA += new_numA
                countB += new_numB

        valid_batch_size = valid_batch_size if valid_batch_size > 0 else eps
        # Reprojection Loss 
        reprojection_loss = dis_mean_total / (valid_batch_size * 2)
        # Dispersity Peak Loss
        dispersity_peak_loss = dis_peak_scored / valid_batch_size
        # NRE Loss
        descriptor_loss = dis_desc / (2 * valid_batch_size)
        # Reliability Loss
        reliability_loss = dis_rel / (valid_batch_size * 2)
        # SOSR Loss
        sosr_loss = dis_neighbor_mean_total / ((valid_batch_size * 2))
        # # Score Penalty
        # score_penalty = scores_mean / (valid_batch_size * 2)
        loss_total = wrp * reprojection_loss + wpl * dispersity_peak_loss + wdl * descriptor_loss + wrl * reliability_loss + sosr_loss
        loss_group = {
            'reprojection_loss': reprojection_loss, 
            'dispersity_peak_loss': dispersity_peak_loss,
            'descriptor_loss': descriptor_loss,
            'reliability_loss': reliability_loss,
            'sosr_loss': sosr_loss
            }
        return loss_total, loss_group

    def detector_selfsupervised_loss_dkd_dense_ext_restrict_modify(self, kpA, kpB, pmaskA, pmaskB, descA, descB, desc_mapA, desc_mapB, scoreddisA, scoreddisB, scoresA, scoresB, scores_mapA, scores_mapB, Homo, inv_Homo, inv_Homo_en, H, W, wrp=1, wpl=1, wdl=1, wrl=1, t_des=0.02, t_rel=1):
        # pmaskA: (BxMax_num) 32x300=9600
        batch_size = len(kpA)
        max_num = pmaskA.shape[-1] // batch_size    # 300
        dis_mean_total = 0
        dis_neighbor_mean_total = 0
        dis_peak_scored = 0
        dis_desc = 0
        dis_rel = 0
        desc_std = 0
        eps = 1e-12
        valid_batch_size = batch_size
        countA, countB = 0, 0
        for idx in range(batch_size):
            pntA, pntB = kpA[idx], kpB[idx]     # M X 2 (x,y)
            pntA = pntA.float()
            pntB = pntB.float()
            # pntA = torch.tensor(pntA, device=self.device).type(torch.FloatTensor)
            # pntB = torch.tensor(pntB, device=self.device).type(torch.FloatTensor)
            numA, numB = pntA.shape[0], pntB.shape[0]
            pmA, pmB = pmaskA[max_num * idx:max_num * idx + numA].bool(), pmaskB[max_num * idx:max_num * idx + numB].bool()
            pntA, pntB = pntA[pmA, :], pntB[pmB, :]
            new_numA, new_numB = pntA.shape[0], pntB.shape[0]
            pntA = (pntA + 1) / 2 * pntA.new_tensor([[W + 3, H - 1]]).to(pntA.device)
            pntB = (pntB + 1) / 2 * pntB.new_tensor([[W + 3, H - 1]]).to(pntB.device)

            pntA[:, 0] -= 2
            pntB[:, 0] -= 2

            pntA_H = warp_points(pntA[:, :2], Homo[idx].squeeze(), device=self.device)  # 利用变换矩阵变换坐标点
            pntA_H, mask_pointA = filter_points(pntA_H, torch.tensor([W, H], device=self.device), return_mask=True)
            pntB_invH = warp_points(pntB[:, :2], inv_Homo[idx].squeeze(), device=self.device)
            pntB_invH, mask_pointB = filter_points(pntB_invH, torch.tensor([W, H], device=self.device), return_mask=True)
            
            try:
                assert pntA_H.shape[0] > 0 and pntB_invH.shape[0] > 0 
                # print(pntA_H.shape, pntB.shape, pntB_invH.shape, pntA.shape)
                key_disAB = self.get_dis(pntA_H[:, :2], pntB[:, :2])
                key_disBA = self.get_dis(pntB_invH[:, :2], pntA[:, :2])
                pairAB_A, pairAB_B, dis_pairAB, vmaskAH = self.get_point_pair(key_disAB, dis_thre=self.correspond)  # p -> k
                pairBA_B, pairBA_A, dis_pairBA, vmaskBH  = self.get_point_pair(key_disBA, dis_thre=self.correspond)  # p -> k
                key_manhattandisAB = self.get_manhattan_dis(pntA_H[:, :2], pntB[:, :2])
                key_manhattandisBA = self.get_manhattan_dis(pntB_invH[:, :2], pntA[:, :2])
                assert dis_pairAB.shape[0] > 0 and dis_pairBA.shape[0] > 0     
                # dis_pair_meanAB = torch.mean(dis_pairAB)
                # dis_pair_meanBA = torch.mean(dis_pairBA)

                pntA_H_normalized = pntA_H / pntA_H.new_tensor([W - 1, H - 1]).to(pntA_H.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)
                pntB_invH_normalized = pntB_invH / pntB_invH.new_tensor([W - 1, H - 1]).to(pntB_invH.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)

                # 用于score_map
                pntA_H_new = copy.deepcopy(pntA_H.detach())
                pntB_invH_new = copy.deepcopy(pntB_invH.detach())
                pntA_H_new[:, 0] += 2
                pntB_invH_new[:, 0] += 2
                
                pntA_H_normalized_new = pntA_H_new / pntA_H_new.new_tensor([W + 3, H - 1]).to(pntA_H.device) * 2 - 1

                pntB_invH_new = warp_points(pntB_invH_new[:, :2], inv_Homo_en[idx].squeeze(), device=self.device)       # 转到A上，而不是AT上
                
                pntB_invH_normalized_new = pntB_invH_new / pntB_invH_new.new_tensor([W + 3, H - 1]).to(pntB_invH.device) * 2 - 1 

                current_descA, current_descB = descA[countA:countA+new_numA], descB[countB:countB+new_numB]
                
                # SOSR:
                k_neighbor = 3
                cross_sim_AA_sp = current_descA @ current_descA.transpose(0, 1)
                cross_sim_BB_sp = current_descB @ current_descB.transpose(0, 1)
                match_sim_AB_AA = cross_sim_AA_sp[mask_pointA, :][:, mask_pointA][pairAB_A, :][:, pairAB_A]
                match_sim_BA_BB = cross_sim_BB_sp[mask_pointB, :][:, mask_pointB][pairBA_B, :][:, pairBA_B]
                match_sim_AB_BB = cross_sim_BB_sp[pairAB_B, :][:, pairAB_B]
                match_sim_BA_AA = cross_sim_AA_sp[pairBA_A, :][:, pairBA_A]
                match_values_AB_AA, match_indices_AB_AA = torch.topk(match_sim_AB_AA, dim=1, k=k_neighbor, largest=False)
                match_values_BA_BB, match_indices_BA_BB = torch.topk(match_sim_BA_BB, dim=1, k=k_neighbor, largest=False)
                match_values_AB_BB_all = match_sim_AB_BB[:, match_indices_AB_AA]
                match_values_BA_AA_all = match_sim_BA_AA[:, match_indices_BA_BB]
                match_values_AB_BB = torch.diagonal(match_values_AB_BB_all, 0, dim1=0, dim2=1).transpose(0, 1)
                match_values_BA_AA = torch.diagonal(match_values_BA_AA_all, 0, dim1=0, dim2=1).transpose(0, 1)
                neighbor_dis_AB = (match_values_AB_AA - match_values_AB_BB) * (match_values_AB_AA - match_values_AB_BB)
                neighbor_dis_BA = (match_values_BA_BB - match_values_BA_AA) * (match_values_BA_BB - match_values_BA_AA)

                # PA VS PB
                cross_sim_AB_sp = current_descA @ current_descB.transpose(0, 1)
                valid_cross_sim_AB_sp_mean = torch.mean(cross_sim_AB_sp[mask_pointA, :][pairAB_A, pairAB_B], dim=-1)
                novalid_cross_sim_AB_sp_mean = (torch.sum(torch.sum(cross_sim_AB_sp.detach(), 1), 0) - valid_cross_sim_AB_sp_mean * pairAB_A.shape[0]) / (new_numA * new_numB - pairAB_A.shape[0])
                valid_cross_sim_BA_sp_mean = torch.mean(cross_sim_AB_sp[:, mask_pointB][pairBA_A, pairBA_B], dim=-1)
                novalid_cross_sim_BA_sp_mean = (torch.sum(torch.sum(cross_sim_AB_sp.detach(), 1), 0) - valid_cross_sim_BA_sp_mean * pairBA_B.shape[0]) / (new_numA * new_numB - pairBA_B.shape[0])

                valid_indexesA = torch.tensor(list(range(new_numA)), device=self.device)[mask_pointA][pairAB_A]
                # cross_sim_BA_sp = current_descB @ current_descA.transpose(0, 1)
                cross_sim_AB_out_sp = torch.cat((cross_sim_AB_sp, torch.ones((new_numA, 1), device=cross_sim_AB_sp.device) * 2), dim=-1)      # NA X (NB + 1)
                # cross_sim_BA_out_sp = torch.cat((cross_sim_BA_sp, torch.ones((numB, 1), device=cross_sim_BA_sp.device)), dim=-1)      # NB X (NA + 1)
                # valid_indexesB = torch.tensor(list(range(numB)), device=self.device)[mask_pointB][pairBA_B]
                cross_sim_AB_out_sp[valid_indexesA, -1] = novalid_cross_sim_AB_sp_mean
                novalid_indexesA = torch.tensor(list(range(new_numA)), device=self.device)[cross_sim_AB_out_sp[:, -1]==2]
                cross_sim_AB_out_sp[novalid_indexesA, -1] = valid_cross_sim_AB_sp_mean

                soft_cross_sim_AtoB_sp = F.softmax((cross_sim_AB_out_sp - 1) / t_des, dim=-1)
                # soft_cross_sim_BtoA = F.softmax((cross_sim_BA_out - 1) / t_des, dim=-1)
                
                soft_valid_cross_sim_AB_sp = soft_cross_sim_AtoB_sp[mask_pointA, :-1][pairAB_A, pairAB_B]
                # soft_valid_cross_sim_BA = soft_cross_sim_BtoA[mask_pointB, :-1][pairBA_B, pairBA_A]
                soft_novalid_cross_sim_AB_sp = soft_cross_sim_AtoB_sp[novalid_indexesA, -1]
                # soft_novalid_cross_sim_BA = soft_cross_sim_BtoA[cross_sim_BA_out[:, -1]==1, -1]
                log_soft_valid_cross_sim_AB_sp = -torch.log(soft_valid_cross_sim_AB_sp + eps)
                # log_soft_valid_cross_sim_BA = -torch.log(soft_valid_cross_sim_BA + eps)
                log_soft_novalid_cross_sim_AB_sp = -torch.log(soft_novalid_cross_sim_AB_sp + eps)
                # log_soft_novalid_cross_sim_BA = -torch.log(soft_novalid_cross_sim_BA + eps)
                dis_cross_sim_mean_sp = torch.sum(torch.cat((log_soft_valid_cross_sim_AB_sp, log_soft_novalid_cross_sim_AB_sp), dim=-1), dim=-1) / new_numA


                # PA VS PAB
                match_mask_A = copy.deepcopy(mask_pointA)
                match_mask_B = copy.deepcopy(mask_pointB)
                match_mask_A[mask_pointA] = copy.deepcopy(vmaskAH)
                match_mask_B[mask_pointB] = copy.deepcopy(vmaskBH)

                cross_sim_AB = current_descA @ desc_mapB[idx, :, :, :].view(-1, H * W)
                cross_sim_AB_all = F.grid_sample(cross_sim_AB.view(-1, H, W).unsqueeze(0),
                                                pntA_H_normalized[vmaskAH, :].detach().view(1, 1, -1, 2),
                                                mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NA x match_nA

                valid_cross_sim_AB_mean = torch.trace(cross_sim_AB_all[match_mask_A, :]) / cross_sim_AB_all[match_mask_A, :].shape[0]
                # novalid_cross_sim_AB_mean = (torch.sum(torch.sum(cross_sim_AB.detach(), 1), 1) - valid_cross_sim_AB_mean * pairAB_A.shape[0]) / (new_numA * H * W - pairAB_A.shape[0])

                cross_sim_BA = current_descB @ desc_mapA[idx, :, :, :].view(-1, H * W)   # M x H x W
                cross_sim_BA_all = F.grid_sample(cross_sim_BA.view(-1, H, W).unsqueeze(0),
                                                pntB_invH_normalized[vmaskBH, :].detach().view(1, 1, -1, 2),
                                                mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NB x match_nB

                valid_cross_sim_BA_mean = torch.trace(cross_sim_BA_all[match_mask_B, :]) / cross_sim_BA_all[match_mask_B, :].shape[0]
                # novalid_cross_sim_BA_mean = (torch.sum(torch.sum(cross_sim_BA.detach(), 1), 1) - valid_cross_sim_BA_mean * pairBA_B.shape[0]) / (new_numB * H * W - pairBA_B.shape[0])

                cross_sim_AB_out = torch.cat((cross_sim_AB, torch.ones((new_numA, 1), device=cross_sim_AB.device)), dim=-1)      # NA X (H X W + 1)
                cross_sim_BA_out = torch.cat((cross_sim_BA, torch.ones((new_numB, 1), device=cross_sim_BA.device)), dim=-1)      # NB X (H X W + 1)
                # print(match_mask_A.shape, cross_sim_AB_out.shape)
                # cross_sim_AB_out[mask_pointA, -1] -= 1
                # cross_sim_BA_out[mask_pointB, -1] -= 1
                # cross_sim_AB_out[match_mask_A, -1] -= 1
                cross_sim_AB_out[match_mask_A, -1] = novalid_cross_sim_AB_sp_mean
                cross_sim_AB_out[match_mask_A==False, -1] = valid_cross_sim_AB_mean
                # print(1)
                cross_sim_BA_out[match_mask_B, -1] = novalid_cross_sim_BA_sp_mean
                cross_sim_BA_out[match_mask_B==False, -1] = valid_cross_sim_BA_mean

                soft_cross_sim_AtoB = F.softmax((cross_sim_AB_out - 1) / t_des, dim=-1)         # NA X (H X W + 1)
                soft_cross_sim_BtoA = F.softmax((cross_sim_BA_out - 1) / t_des, dim=-1)         # NB X (H X W + 1)
                soft_cross_sim_AB_all = F.grid_sample(soft_cross_sim_AtoB[:, :-1].view(-1, H, W).unsqueeze(0),
                                                    pntA_H_normalized[vmaskAH, :].detach().view(1, 1, -1, 2),
                                                    mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NA x match_nA
                
                soft_cross_sim_BA_all = F.grid_sample(soft_cross_sim_BtoA[:, :-1].view(-1, H, W).unsqueeze(0),
                                                    pntB_invH_normalized[vmaskBH, :].detach().view(1, 1, -1, 2),
                                                    mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NB x match_nB
                # soft_valid_cross_sim_AB_all = soft_cross_sim_AB_all[mask_pointA, :]             # repeat_nA x repeat_nA
                # soft_valid_cross_sim_BA_all = soft_cross_sim_BA_all[mask_pointB, :]             # repeat_nB x repeat_nB

                soft_valid_cross_sim_AB_all = soft_cross_sim_AB_all[match_mask_A, :]             # match_nA x match_nA
                soft_valid_cross_sim_BA_all = soft_cross_sim_BA_all[match_mask_B, :]             # match_nB x match_nB

                valid_mask_AB = torch.eye(soft_valid_cross_sim_AB_all.shape[0]) == 1
                valid_mask_BA = torch.eye(soft_valid_cross_sim_BA_all.shape[0]) == 1

                # 取对角线
                soft_valid_cross_sim_AB = soft_valid_cross_sim_AB_all[valid_mask_AB]
                soft_valid_cross_sim_BA = soft_valid_cross_sim_BA_all[valid_mask_BA]

                # soft_novalid_cross_sim_AB = soft_cross_sim_AtoB[mask_pointA==False, -1]              # (NA-repeat_nA) x 1
                # soft_novalid_cross_sim_BA = soft_cross_sim_BtoA[mask_pointB==False, -1]
                soft_novalid_cross_sim_AB = soft_cross_sim_AtoB[match_mask_A==False, -1]               # (NA-match_nA) x 1
                soft_novalid_cross_sim_BA = soft_cross_sim_BtoA[match_mask_B==False, -1]

                log_soft_valid_cross_sim_AB = -torch.log(soft_valid_cross_sim_AB + eps)
                log_soft_valid_cross_sim_BA = -torch.log(soft_valid_cross_sim_BA + eps)
                log_soft_novalid_cross_sim_AB = -torch.log(soft_novalid_cross_sim_AB + eps)
                log_soft_novalid_cross_sim_BA = -torch.log(soft_novalid_cross_sim_BA + eps)

                dis_cross_sim_mean = torch.sum(torch.cat((log_soft_valid_cross_sim_AB, log_soft_valid_cross_sim_BA, log_soft_novalid_cross_sim_AB, log_soft_novalid_cross_sim_BA), dim=-1), dim=-1) / (pntA.shape[0] + pntB.shape[0])

                
                valid_cross_sim_AB = cross_sim_AB[mask_pointA, :]   # repeat_nA x (H X W)
                valid_cross_sim_BA = cross_sim_BA[mask_pointB, :]   # repeat_nB x (H X W)
                exp_valid_cross_sim_AtoB = torch.exp((valid_cross_sim_AB - 1) / t_rel).view(-1, H, W)
                exp_valid_cross_sim_BtoA = torch.exp((valid_cross_sim_BA - 1) / t_rel).view(-1, H, W)
                exp_valid_cross_sim_AB_all = F.grid_sample(exp_valid_cross_sim_AtoB.unsqueeze(0),
                                                        pntA_H_normalized.detach().view(1, 1, -1, 2),
                                                        mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # repeat_nA x repeat_nA
                
                exp_valid_cross_sim_BA_all = F.grid_sample(exp_valid_cross_sim_BtoA.unsqueeze(0),
                                                        pntB_invH_normalized.detach().view(1, 1, -1, 2),
                                                        mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # repeat_nB x repeat_nB

                repeat_mask_AB = torch.eye(exp_valid_cross_sim_AB_all.shape[0]) == 1
                repeat_mask_BA = torch.eye(exp_valid_cross_sim_BA_all.shape[0]) == 1
                rel_valid_cross_sim_AB = exp_valid_cross_sim_AB_all[repeat_mask_AB]
                rel_valid_cross_sim_BA = exp_valid_cross_sim_BA_all[repeat_mask_BA]

                # pntA_H_normalized_new = copy.deepcopy(pntA_H_normalized.detach())
                # pntB_invH_normalized_new = copy.deepcopy(pntB_invH_normalized.detach())

                # pntA_H_normalized_new[:, 0] += 2
                # pntB_invH_normalized_new[:, 0] += 2

                scoresAB_all = F.grid_sample(scores_mapB[idx, :, :, :].unsqueeze(0),
                                            pntA_H_normalized_new.view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)      # 1 x repeat_nA

                scoresBA_all = F.grid_sample(scores_mapA[idx, :, :, :].unsqueeze(0),
                                            pntB_invH_normalized_new.view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)      # 1 x repeat_nB

                scores_AAB = scoresA[idx][pmA][mask_pointA] * scoresAB_all
                scores_BBA = scoresB[idx][pmB][mask_pointB] * scoresBA_all
                scores_sum_AAB = torch.sum(scores_AAB, dim=-1)
                scores_sum_BBA = torch.sum(scores_BBA, dim=-1)
                scores_normalize_AAB = scores_AAB / (scores_sum_AAB + eps)
                scores_normalize_BBA = scores_BBA / (scores_sum_BBA + eps)
                rel_meanA = torch.sum(scores_normalize_AAB * (1 - rel_valid_cross_sim_AB), dim=-1) / pntA_H_normalized_new.shape[0]
                rel_meanB = torch.sum(scores_normalize_BBA * (1 - rel_valid_cross_sim_BA), dim=-1) / pntB_invH_normalized_new.shape[0]

                # # 熵loss
                # current_descA_std, current_descB_std = descA_std[countA:countA+new_numA], descB_std[countB:countB+new_numB]
                # desc_std += torch.mean(current_descA_std) + torch.mean(current_descB_std)

                countA += new_numA
                countB += new_numB
                
                dis_neighbor_mean_total += torch.mean(torch.sum(neighbor_dis_AB, dim=1)) + torch.mean(torch.sum(neighbor_dis_BA, dim=1))
                dis_desc += dis_cross_sim_mean_sp
                dis_desc += dis_cross_sim_mean

                dis_pair_meanAB = torch.mean(key_manhattandisAB[pairAB_A, pairAB_B])
                dis_pair_meanBA = torch.mean(key_manhattandisBA[pairBA_B, pairBA_A])

                dis_peak_mean = torch.mean(torch.cat((scoreddisA[idx][pmA], scoreddisB[idx][pmB]), dim=0))
                # dis_peak_meanB = torch.mean(scoreddisB[idx])
                
                dis_mean_total += dis_pair_meanAB + dis_pair_meanBA
                dis_peak_scored += dis_peak_mean

                dis_rel += rel_meanA + rel_meanB
                # # Penalty
                # scores_mean += (-torch.log(torch.mean(scoresA[idx], dim=-1) + eps) - torch.log(torch.mean(scoresB[idx], dim=-1) + eps)) 
                # print(scores_mean)
            except:
                # dis_mean_total += 0
                # dis_peak_scored += 0
                # dis_desc += 0
                # dis_rel += 0
                print('Overlapping too small or Repeatable point pairs distance is greater than correspond(4):', pntA.shape[0], pntA_H.shape[0], pntB.shape[0], pntB_invH.shape[0], dis_pairAB.shape[0], dis_pairBA.shape[0])
                valid_batch_size -= 1
                countA += new_numA
                countB += new_numB

        valid_batch_size = valid_batch_size if valid_batch_size > 0 else eps
        # Reprojection Loss 
        reprojection_loss = dis_mean_total / (valid_batch_size * 2)
        # Dispersity Peak Loss
        dispersity_peak_loss = dis_peak_scored / valid_batch_size
        # NRE Loss
        descriptor_loss = dis_desc / (2 * valid_batch_size)
        # Reliability Loss
        reliability_loss = dis_rel / (valid_batch_size * 2)
        # SOSR Loss
        sosr_loss = dis_neighbor_mean_total / ((valid_batch_size * 2))
        # # Entropy loss
        # std_loss = (valid_batch_size * 2) / desc_std  
        # # Score Penalty
        # score_penalty = scores_mean / (valid_batch_size * 2)
        loss_total = wrp * reprojection_loss + wpl * dispersity_peak_loss + wdl * descriptor_loss + wrl * reliability_loss + sosr_loss
        loss_group = {
            'reprojection_loss': reprojection_loss, 
            'dispersity_peak_loss': dispersity_peak_loss,
            'descriptor_loss': descriptor_loss,
            'reliability_loss': reliability_loss,
            'sosr_loss': sosr_loss,
            # 'std_loss': std_loss,
            }
        return loss_total, loss_group

    def detector_selfsupervised_loss_dkd_dense_ext_restrict_modify_oriR(self, kpA, kpB, pmaskA, pmaskB, descA, descB, desc_mapA, desc_mapB, scoreddisA, scoreddisB, scoresA, scoresB, scores_mapA, scores_mapB, Homo, inv_Homo, inv_Homo_en, ori_allA, ori_allB, ori_all_patchA, ori_all_patchB, ori_kpA, ori_kpB, ori_kp_patchA, ori_kp_patchB, kmask_T_allA, kmask_T_allB, H, W, wrp=1, wpl=1, wdl=1, wrl=1, t_des=0.02, t_rel=1):
        # pmaskA: (BxMax_num) 32x350=11200
        batch_size = len(kpA)
        max_num = pmaskA.shape[-1] // batch_size    # 350
        dis_mean_total = 0
        dis_neighbor_mean_total = 0
        dis_peak_scored = 0
        dis_desc = 0
        dis_rel = 0
        desc_std = 0
        eps = 1e-12
        valid_batch_size = batch_size
        countA, countB = 0, 0
        # countA_T, countB_T = 0, 0
        for idx in range(batch_size):
            pntA, pntB = kpA[idx], kpB[idx]     # M X 2 (x,y)
            # kmask_TA, kmask_TB = kmask_T_allA[idx], kmask_T_allB[idx]
            pntA = pntA.float()
            pntB = pntB.float()

            # 剔除部分按压区域的点且保留在重叠区域的点
            numA, numB = pntA.shape[0], pntB.shape[0]
            # numA_T, numB_T = pntA[kmask_TA].shape[0], pntB[kmask_TB].shape[0]
            pmA, pmB = pmaskA[max_num * idx:max_num * idx + numA].bool(), pmaskB[max_num * idx:max_num * idx + numB].bool()
            pntA, pntB = pntA[pmA, :], pntB[pmB, :]
            new_numA, new_numB = pntA.shape[0], pntB.shape[0]
            
            pntA = (pntA + 1) / 2 * pntA.new_tensor([[W + 3, H - 1]]).to(pntA.device)
            pntB = (pntB + 1) / 2 * pntB.new_tensor([[W + 3, H - 1]]).to(pntB.device)

            # [120, 40] -> [120, 36],实际只取中心118x32区域的点对
            pntA[:, 0] -= 2
            pntB[:, 0] -= 2
            
            pntA_normalized = pntA / pntA.new_tensor([W - 1, H - 1]).to(pntA.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)
            pntB_normalized = pntB / pntB.new_tensor([W - 1, H - 1]).to(pntB.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)

            pntA_H = warp_points(pntA[:, :2], Homo[idx].squeeze(), device=self.device)  # 利用变换矩阵变换坐标点
            # pntA_H, mask_pointA = filter_points(pntA_H, torch.tensor([W, H], device=self.device), return_mask=True)
            pntB_invH = warp_points(pntB[:, :2], inv_Homo[idx].squeeze(), device=self.device)
            # pntB_invH, mask_pointB = filter_points(pntB_invH, torch.tensor([W, H], device=self.device), return_mask=True)
            
            try:
                assert pntA_H.shape[0] > 0 and pntB_invH.shape[0] > 0 
                
                # 点对欧氏距离
                key_disAB = self.get_dis(pntA_H[:, :2], pntB[:, :2])
                key_disBA = self.get_dis(pntB_invH[:, :2], pntA[:, :2])
                pairAB_A, pairAB_B, dis_pairAB, _ = self.get_point_pair(key_disAB, dis_thre=self.correspond)  # p -> k # NTA(<1.5), NTA(<1.5), NTA(<1.5), NTA        
                pairBA_B, pairBA_A, dis_pairBA, _  = self.get_point_pair(key_disBA, dis_thre=self.correspond)  # p -> k # NTB(<1.5), NTB(<1.5), NTB(<1.5), NTB 
                
                # 点距离mask
                nn_maskAB = torch.zeros((pntA_H.shape[0], pntB.shape[0]), device=self.device) 
                nn_maskAB[pairAB_A, pairAB_B] = 1

                nn_maskBA = torch.zeros((pntB_invH.shape[0], pntA.shape[0]), device=self.device) 
                nn_maskBA[pairBA_B, pairBA_A] = 1

                # 点对曼哈顿距离
                key_manhattandisAB = self.get_manhattan_dis(pntA_H[:, :2], pntB[:, :2])
                key_manhattandisBA = self.get_manhattan_dis(pntB_invH[:, :2], pntA[:, :2])
                assert dis_pairAB.shape[0] > 0 and dis_pairBA.shape[0] > 0     

                pntA_H_normalized = pntA_H / pntA_H.new_tensor([W - 1, H - 1]).to(pntA_H.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)
                pntB_invH_normalized = pntB_invH / pntB_invH.new_tensor([W - 1, H - 1]).to(pntB_invH.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)

                # 用于score_map
                pntA_H_new = copy.deepcopy(pntA_H.detach())
                pntB_invH_new = copy.deepcopy(pntB_invH.detach())
                pntA_H_new[:, 0] += 2
                pntB_invH_new[:, 0] += 2
                
                pntA_H_normalized_new = pntA_H_new / pntA_H_new.new_tensor([W + 3, H - 1]).to(pntA_H.device) * 2 - 1

                pntB_invH_new = warp_points(pntB_invH_new[:, :2], inv_Homo_en[idx].squeeze(), device=self.device)       # 转到A上，而不是AT上
                
                pntB_invH_normalized_new = pntB_invH_new / pntB_invH_new.new_tensor([W + 3, H - 1]).to(pntB_invH.device) * 2 - 1 

                # PA VS PB 有一定偏移
                ori_kpA_ext = F.grid_sample(ori_allA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntA_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  
                ori_kpB_ext = F.grid_sample(ori_allB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntB_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  

                main_ori_maskATB = self.get_main_ori_consistence(ori_kpA[countA:countA+numA][pmA].unsqueeze(1), ori_kpB_ext)  # NTA x NTB 
                main_ori_maskBTA = self.get_main_ori_consistence(ori_kpB[countB:countB+numB][pmB].unsqueeze(1), ori_kpA_ext)  # NTB x NTA 
                
                # print(ori_all_patchA[idx, :, :5, 0], ori_all_patchB[idx, :, :5, 0])
                # exit()
                ori_kpA_patch_ext = F.grid_sample(ori_all_patchA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntA_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  
                ori_kpB_patch_ext = F.grid_sample(ori_all_patchB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntB_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  

                ori_maskATB = self.get_ori_consistence(ori_kp_patchA[countA:countA+numA][pmA, :], ori_kpB_patch_ext)  # NTA x NTB
                ori_maskBTA = self.get_ori_consistence(ori_kp_patchB[countB:countB+numB][pmB, :], ori_kpA_patch_ext)  # NTB x NTA

                match_maskAB = (nn_maskAB == 1) * main_ori_maskATB
                match_maskBA = (nn_maskBA == 1) * main_ori_maskBTA
                # match_maskAB = (nn_maskAB == 1) * main_ori_maskATB * ori_maskATB
                # match_maskBA = (nn_maskBA == 1) * main_ori_maskBTA * ori_maskBTA

                pairAB_A_new, pairAB_B_new = torch.where(match_maskAB == 1)
                pairBA_B_new, pairBA_A_new = torch.where(match_maskBA == 1)
                assert pairAB_A_new.shape[0] > 0 and pairBA_B_new.shape[0] > 0 
                # print('1:', pairAB_A_new.shape[0], pairBA_B_new.shape[0])
                # PA VS PAB 没有中心点距离偏移
                # 中心主方向一致性
                ori_kpAB_ext = F.grid_sample(ori_allB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntA_H_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  
                ori_kpBA_ext = F.grid_sample(ori_allA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntB_invH_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  
                main_ori_maskATAB = self.get_main_ori_consistence(ori_kpA[countA:countA+numA][pmA].unsqueeze(1), ori_kpAB_ext)  # NTAxNTA 
                main_ori_maskBTBA = self.get_main_ori_consistence(ori_kpB[countB:countB+numB][pmB].unsqueeze(1), ori_kpBA_ext)  # NTBxNTB 

                # 4x4邻域方向一致性
                ori_kpAB_patch_ext = F.grid_sample(ori_all_patchB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntA_H_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  
                ori_kpBA_patch_ext = F.grid_sample(ori_all_patchA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntB_invH_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  

                ori_maskATAB = self.get_ori_consistence(ori_kp_patchA[countA:countA+numA][pmA, :], ori_kpAB_patch_ext)  # NTAxNTA 
                ori_maskBTBA = self.get_ori_consistence(ori_kp_patchB[countB:countB+numB][pmB, :], ori_kpBA_patch_ext)  # NTBxNTB

                # vmaskAH = torch.diag(main_ori_maskATAB) == 1
                # vmaskBH = torch.diag(main_ori_maskBTBA) == 1
                vmaskAH = torch.diag(main_ori_maskATAB * ori_maskATAB) == 1
                vmaskBH = torch.diag(main_ori_maskBTBA * ori_maskBTBA) == 1
                assert torch.sum(vmaskAH) > 0 and torch.sum(vmaskBH) > 0
                # print('2:', torch.sum(vmaskAH), torch.sum(vmaskBH))

                current_descA, current_descB = descA[countA:countA+new_numA], descB[countB:countB+new_numB]
                
                # SOSR: 简化的self-attention
                k_neighbor = 3
                cross_sim_AA_sp = current_descA @ current_descA.transpose(0, 1)
                cross_sim_BB_sp = current_descB @ current_descB.transpose(0, 1)

                match_sim_AB_AA = cross_sim_AA_sp[pairAB_A_new, :][:, pairAB_A_new]
                match_sim_BA_BB = cross_sim_BB_sp[pairBA_B_new, :][:, pairBA_B_new]
                match_sim_AB_BB = cross_sim_BB_sp[pairAB_B_new, :][:, pairAB_B_new]
                match_sim_BA_AA = cross_sim_AA_sp[pairBA_A_new, :][:, pairBA_A_new]
                match_values_AB_AA, match_indices_AB_AA = torch.topk(match_sim_AB_AA, dim=1, k=k_neighbor, largest=False)
                match_values_BA_BB, match_indices_BA_BB = torch.topk(match_sim_BA_BB, dim=1, k=k_neighbor, largest=False)
                match_values_AB_BB_all = match_sim_AB_BB[:, match_indices_AB_AA]
                match_values_BA_AA_all = match_sim_BA_AA[:, match_indices_BA_BB]
                match_values_AB_BB = torch.diagonal(match_values_AB_BB_all, 0, dim1=0, dim2=1).transpose(0, 1)
                match_values_BA_AA = torch.diagonal(match_values_BA_AA_all, 0, dim1=0, dim2=1).transpose(0, 1)
                neighbor_dis_AB = (match_values_AB_AA - match_values_AB_BB) * (match_values_AB_AA - match_values_AB_BB)
                neighbor_dis_BA = (match_values_BA_BB - match_values_BA_AA) * (match_values_BA_BB - match_values_BA_AA)

                # PA VS PB
                cross_sim_AB_sp = current_descA @ current_descB.transpose(0, 1)
                # print('5:', cross_sim_AB_sp.shape, match_maskAB.shape, match_maskBA.shape)
                valid_cross_sim_AB_sp_mean = torch.mean(cross_sim_AB_sp[match_maskAB == 1], dim=-1)
                novalid_cross_sim_AB_sp_mean = (torch.sum(torch.sum(cross_sim_AB_sp.detach(), 1), 0) - valid_cross_sim_AB_sp_mean * pairAB_A_new.shape[0]) / (new_numA * new_numB - pairAB_A_new.shape[0] + eps)
                valid_cross_sim_BA_sp_mean = torch.mean(cross_sim_AB_sp[match_maskBA.transpose(0, 1) == 1], dim=-1)
                novalid_cross_sim_BA_sp_mean = (torch.sum(torch.sum(cross_sim_AB_sp.detach(), 1), 0) - valid_cross_sim_BA_sp_mean * pairBA_B_new.shape[0]) / (new_numA * new_numB - pairBA_B_new.shape[0] + eps)

                valid_indexesA = torch.tensor(list(range(new_numA)), device=self.device)[pairAB_A_new]
                # cross_sim_BA_sp = current_descB @ current_descA.transpose(0, 1)
                cross_sim_AB_out_sp = torch.cat((cross_sim_AB_sp, torch.ones((new_numA, 1), device=cross_sim_AB_sp.device) * 2), dim=-1)      # NA X (NB + 1)
                # cross_sim_BA_out_sp = torch.cat((cross_sim_BA_sp, torch.ones((numB, 1), device=cross_sim_BA_sp.device)), dim=-1)      # NB X (NA + 1)
                # valid_indexesB = torch.tensor(list(range(numB)), device=self.device)[mask_pointB][pairBA_B]
                cross_sim_AB_out_sp[valid_indexesA, -1] = novalid_cross_sim_AB_sp_mean
                novalid_indexesA = torch.tensor(list(range(new_numA)), device=self.device)[cross_sim_AB_out_sp[:, -1]==2]
                cross_sim_AB_out_sp[novalid_indexesA, -1] = valid_cross_sim_AB_sp_mean

                soft_cross_sim_AtoB_sp = F.softmax((cross_sim_AB_out_sp - 1) / t_des, dim=-1)
                # soft_cross_sim_BtoA = F.softmax((cross_sim_BA_out - 1) / t_des, dim=-1)
                
                soft_valid_cross_sim_AB_sp = soft_cross_sim_AtoB_sp[:, :-1][match_maskAB==1]
                # soft_valid_cross_sim_BA = soft_cross_sim_BtoA[mask_pointB, :-1][pairBA_B, pairBA_A]
                soft_novalid_cross_sim_AB_sp = soft_cross_sim_AtoB_sp[novalid_indexesA, -1]
                # soft_novalid_cross_sim_BA = soft_cross_sim_BtoA[cross_sim_BA_out[:, -1]==1, -1]
                log_soft_valid_cross_sim_AB_sp = -torch.log(soft_valid_cross_sim_AB_sp + eps)
                # log_soft_valid_cross_sim_BA = -torch.log(soft_valid_cross_sim_BA + eps)
                log_soft_novalid_cross_sim_AB_sp = -torch.log(soft_novalid_cross_sim_AB_sp + eps)
                # log_soft_novalid_cross_sim_BA = -torch.log(soft_novalid_cross_sim_BA + eps)
                dis_cross_sim_mean_sp = torch.sum(torch.cat((log_soft_valid_cross_sim_AB_sp, log_soft_novalid_cross_sim_AB_sp), dim=-1), dim=-1) / new_numA

                # PA VS PAB
                # match_mask_A = copy.deepcopy(mask_pointA)
                # match_mask_B = copy.deepcopy(mask_pointB)
                match_mask_A = copy.deepcopy(vmaskAH)
                match_mask_B = copy.deepcopy(vmaskBH)

                cross_sim_AB = current_descA @ desc_mapB[idx, :, :, :].view(-1, H * W)
                cross_sim_AB_all = F.grid_sample(cross_sim_AB.view(-1, H, W).unsqueeze(0),
                                                pntA_H_normalized[vmaskAH, :].detach().view(1, 1, -1, 2),
                                                mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NA x match_nA

                valid_cross_sim_AB_mean = torch.trace(cross_sim_AB_all[match_mask_A, :]) / cross_sim_AB_all[match_mask_A, :].shape[0]
                # novalid_cross_sim_AB_mean = (torch.sum(torch.sum(cross_sim_AB.detach(), 1), 1) - valid_cross_sim_AB_mean * pairAB_A.shape[0]) / (new_numA * H * W - pairAB_A.shape[0])

                cross_sim_BA = current_descB @ desc_mapA[idx, :, :, :].view(-1, H * W)   # M x H x W
                cross_sim_BA_all = F.grid_sample(cross_sim_BA.view(-1, H, W).unsqueeze(0),
                                                pntB_invH_normalized[vmaskBH, :].detach().view(1, 1, -1, 2),
                                                mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NB x match_nB

                valid_cross_sim_BA_mean = torch.trace(cross_sim_BA_all[match_mask_B, :]) / cross_sim_BA_all[match_mask_B, :].shape[0]
                # novalid_cross_sim_BA_mean = (torch.sum(torch.sum(cross_sim_BA.detach(), 1), 1) - valid_cross_sim_BA_mean * pairBA_B.shape[0]) / (new_numB * H * W - pairBA_B.shape[0])

                cross_sim_AB_out = torch.cat((cross_sim_AB, torch.ones((new_numA, 1), device=cross_sim_AB.device)), dim=-1)      # NA X (H X W + 1)
                cross_sim_BA_out = torch.cat((cross_sim_BA, torch.ones((new_numB, 1), device=cross_sim_BA.device)), dim=-1)      # NB X (H X W + 1)
                # print(match_mask_A.shape, cross_sim_AB_out.shape)
                # cross_sim_AB_out[mask_pointA, -1] -= 1
                # cross_sim_BA_out[mask_pointB, -1] -= 1
                # cross_sim_AB_out[match_mask_A, -1] -= 1
                cross_sim_AB_out[match_mask_A, -1] = novalid_cross_sim_AB_sp_mean
                cross_sim_AB_out[match_mask_A==False, -1] = valid_cross_sim_AB_mean

                cross_sim_BA_out[match_mask_B, -1] = novalid_cross_sim_BA_sp_mean
                cross_sim_BA_out[match_mask_B==False, -1] = valid_cross_sim_BA_mean

                soft_cross_sim_AtoB = F.softmax((cross_sim_AB_out - 1) / t_des, dim=-1)         # NA X (H X W + 1)
                soft_cross_sim_BtoA = F.softmax((cross_sim_BA_out - 1) / t_des, dim=-1)         # NB X (H X W + 1)
                soft_cross_sim_AB_all = F.grid_sample(soft_cross_sim_AtoB[:, :-1].view(-1, H, W).unsqueeze(0),
                                                    pntA_H_normalized[vmaskAH, :].detach().view(1, 1, -1, 2),
                                                    mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NA x match_nA
                
                soft_cross_sim_BA_all = F.grid_sample(soft_cross_sim_BtoA[:, :-1].view(-1, H, W).unsqueeze(0),
                                                    pntB_invH_normalized[vmaskBH, :].detach().view(1, 1, -1, 2),
                                                    mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NB x match_nB
                # soft_valid_cross_sim_AB_all = soft_cross_sim_AB_all[mask_pointA, :]             # repeat_nA x repeat_nA
                # soft_valid_cross_sim_BA_all = soft_cross_sim_BA_all[mask_pointB, :]             # repeat_nB x repeat_nB

                soft_valid_cross_sim_AB_all = soft_cross_sim_AB_all[match_mask_A, :]             # match_nA x match_nA
                soft_valid_cross_sim_BA_all = soft_cross_sim_BA_all[match_mask_B, :]             # match_nB x match_nB

                valid_mask_AB = torch.eye(soft_valid_cross_sim_AB_all.shape[0]) == 1
                valid_mask_BA = torch.eye(soft_valid_cross_sim_BA_all.shape[0]) == 1

                # 取对角线
                soft_valid_cross_sim_AB = soft_valid_cross_sim_AB_all[valid_mask_AB]
                soft_valid_cross_sim_BA = soft_valid_cross_sim_BA_all[valid_mask_BA]

                # soft_novalid_cross_sim_AB = soft_cross_sim_AtoB[mask_pointA==False, -1]              # (NA-repeat_nA) x 1
                # soft_novalid_cross_sim_BA = soft_cross_sim_BtoA[mask_pointB==False, -1]
                soft_novalid_cross_sim_AB = soft_cross_sim_AtoB[match_mask_A==False, -1]               # (NA-match_nA) x 1
                soft_novalid_cross_sim_BA = soft_cross_sim_BtoA[match_mask_B==False, -1]
                # print(soft_novalid_cross_sim_AB, soft_novalid_cross_sim_BA)

                log_soft_valid_cross_sim_AB = -torch.log(soft_valid_cross_sim_AB + eps)
                log_soft_valid_cross_sim_BA = -torch.log(soft_valid_cross_sim_BA + eps)
                log_soft_novalid_cross_sim_AB = -torch.log(soft_novalid_cross_sim_AB + eps)
                log_soft_novalid_cross_sim_BA = -torch.log(soft_novalid_cross_sim_BA + eps)

                dis_cross_sim_mean = torch.sum(torch.cat((log_soft_valid_cross_sim_AB, log_soft_valid_cross_sim_BA, log_soft_novalid_cross_sim_AB, log_soft_novalid_cross_sim_BA), dim=-1), dim=-1) / (pntA.shape[0] + pntB.shape[0])

                # valid_cross_sim_AB = cross_sim_AB[mask_pointA, :]   # repeat_nA x (H X W)
                # valid_cross_sim_BA = cross_sim_BA[mask_pointB, :]   # repeat_nB x (H X W)
                exp_valid_cross_sim_AtoB = torch.exp((cross_sim_AB - 1) / t_rel).view(-1, H, W)
                exp_valid_cross_sim_BtoA = torch.exp((cross_sim_BA - 1) / t_rel).view(-1, H, W)
                exp_valid_cross_sim_AB_all = F.grid_sample(exp_valid_cross_sim_AtoB.unsqueeze(0),
                                                        pntA_H_normalized.detach().view(1, 1, -1, 2),
                                                        mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # repeat_nA x repeat_nA
                
                exp_valid_cross_sim_BA_all = F.grid_sample(exp_valid_cross_sim_BtoA.unsqueeze(0),
                                                        pntB_invH_normalized.detach().view(1, 1, -1, 2),
                                                        mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # repeat_nB x repeat_nB

                repeat_mask_AB = torch.eye(exp_valid_cross_sim_AB_all.shape[0]) == 1
                repeat_mask_BA = torch.eye(exp_valid_cross_sim_BA_all.shape[0]) == 1
                rel_valid_cross_sim_AB = exp_valid_cross_sim_AB_all[repeat_mask_AB]
                rel_valid_cross_sim_BA = exp_valid_cross_sim_BA_all[repeat_mask_BA]

                # pntA_H_normalized_new = copy.deepcopy(pntA_H_normalized.detach())
                # pntB_invH_normalized_new = copy.deepcopy(pntB_invH_normalized.detach())

                # pntA_H_normalized_new[:, 0] += 2
                # pntB_invH_normalized_new[:, 0] += 2

                scoresAB_all = F.grid_sample(scores_mapB[idx, :, :, :].unsqueeze(0),
                                            pntA_H_normalized_new.view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)      # 1 x repeat_nA

                scoresBA_all = F.grid_sample(scores_mapA[idx, :, :, :].unsqueeze(0),
                                            pntB_invH_normalized_new.view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)      # 1 x repeat_nB

                scores_AAB = scoresA[idx][pmA] * scoresAB_all
                scores_BBA = scoresB[idx][pmB] * scoresBA_all
                scores_sum_AAB = torch.sum(scores_AAB, dim=-1)
                scores_sum_BBA = torch.sum(scores_BBA, dim=-1)
                scores_normalize_AAB = scores_AAB / (scores_sum_AAB + eps)
                scores_normalize_BBA = scores_BBA / (scores_sum_BBA + eps)
                rel_meanA = torch.sum(scores_normalize_AAB * (1 - rel_valid_cross_sim_AB), dim=-1) / pntA_H_normalized_new.shape[0]
                rel_meanB = torch.sum(scores_normalize_BBA * (1 - rel_valid_cross_sim_BA), dim=-1) / pntB_invH_normalized_new.shape[0]

                # # 熵loss
                # current_descA_std, current_descB_std = descA_std[countA:countA+new_numA], descB_std[countB:countB+new_numB]
                # desc_std += torch.mean(current_descA_std) + torch.mean(current_descB_std)

                countA += new_numA
                countB += new_numB
                # countA_T += numA_T
                # countB_T += numB_T

                dis_neighbor_mean_total += torch.mean(torch.sum(neighbor_dis_AB, dim=1)) + torch.mean(torch.sum(neighbor_dis_BA, dim=1))
                dis_desc += dis_cross_sim_mean_sp
                dis_desc += dis_cross_sim_mean

                dis_pair_meanAB = torch.mean(key_manhattandisAB[pairAB_A, pairAB_B])
                dis_pair_meanBA = torch.mean(key_manhattandisBA[pairBA_B, pairBA_A])

                dis_peak_mean = torch.mean(torch.cat((scoreddisA[idx][pmA], scoreddisB[idx][pmB]), dim=0))
                # dis_peak_meanB = torch.mean(scoreddisB[idx])
                
                dis_mean_total += dis_pair_meanAB + dis_pair_meanBA
                dis_peak_scored += dis_peak_mean

                dis_rel += rel_meanA + rel_meanB
                # # Penalty
                # scores_mean += (-torch.log(torch.mean(scoresA[idx], dim=-1) + eps) - torch.log(torch.mean(scoresB[idx], dim=-1) + eps)) 
                # print(scores_mean)
            except:
                # dis_mean_total += 0
                # dis_peak_scored += 0
                # dis_desc += 0
                # dis_rel += 0
                # print('Overlapping too small or Repeatable point pairs distance is greater than correspond(1.5):', pntA.shape[0], pntA_H.shape[0], pntB.shape[0], pntB_invH.shape[0], dis_pairAB.shape[0], dis_pairBA.shape[0])
                valid_batch_size -= 1
                countA += new_numA
                countB += new_numB
                # countA_T += numA_T
                # countB_T += numB_T

        valid_batch_size = valid_batch_size if valid_batch_size > 0 else eps
        # Reprojection Loss 
        reprojection_loss = dis_mean_total / (valid_batch_size * 2)
        # Dispersity Peak Loss
        dispersity_peak_loss = dis_peak_scored / valid_batch_size
        # NRE Loss
        descriptor_loss = dis_desc / (2 * valid_batch_size)
        # Reliability Loss
        reliability_loss = dis_rel / (valid_batch_size * 2)
        # SOSR Loss
        sosr_loss = dis_neighbor_mean_total / ((valid_batch_size * 2))
        # # Entropy loss
        # std_loss = (valid_batch_size * 2) / desc_std  
        # # Score Penalty
        # score_penalty = scores_mean / (valid_batch_size * 2)
        loss_total = wrp * reprojection_loss + wpl * dispersity_peak_loss + wdl * descriptor_loss + wrl * reliability_loss + sosr_loss
        loss_group = {
            'reprojection_loss': reprojection_loss, 
            'dispersity_peak_loss': dispersity_peak_loss,
            'descriptor_loss': descriptor_loss,
            'reliability_loss': reliability_loss,
            'sosr_loss': sosr_loss,
            # 'std_loss': std_loss,
            }
        return loss_total, loss_group

    def detector_selfsupervised_loss_dkd_dense_ext_restrict_modify_oriR_ratio(self, kpA, kpB, pmaskA, pmaskB, descA, descB, desc_mapA, desc_mapB, scoreddisA, scoreddisB, scoresA, scoresB, scores_mapA, scores_mapB, Homo, inv_Homo, inv_Homo_en, ori_allA, ori_allB, ori_all_patchA, ori_all_patchB, ori_kpA, ori_kpB, ori_kp_patchA, ori_kp_patchB, kmask_T_allA, kmask_T_allB, H, W, wrp=1, wpl=1, wdl=1, wrl=1, t_des=0.02, t_rel=1):
        # pmaskA: (BxMax_num) 32x350=11200
        batch_size = len(kpA)
        max_num = pmaskA.shape[-1] // batch_size    # 350
        dis_mean_total = 0
        dis_neighbor_mean_total = 0
        dis_peak_scored = 0
        dis_desc = 0
        dis_rel = 0
        desc_std = 0
        eps = 1e-12
        valid_batch_size = batch_size
        countA, countB = 0, 0
        # countA_T, countB_T = 0, 0
        for idx in range(batch_size):
            pntA, pntB = kpA[idx], kpB[idx]     # M X 2 (x,y)
            # kmask_TA, kmask_TB = kmask_T_allA[idx], kmask_T_allB[idx]
            pntA = pntA.float()
            pntB = pntB.float()

            # 剔除部分按压区域的点且保留在重叠区域的点
            numA, numB = pntA.shape[0], pntB.shape[0]
            # numA_T, numB_T = pntA[kmask_TA].shape[0], pntB[kmask_TB].shape[0]
            pmA, pmB = pmaskA[max_num * idx:max_num * idx + numA].bool(), pmaskB[max_num * idx:max_num * idx + numB].bool()
            pntA, pntB = pntA[pmA, :], pntB[pmB, :]
            new_numA, new_numB = pntA.shape[0], pntB.shape[0]
            
            pntA = (pntA + 1) / 2 * pntA.new_tensor([[W + 3, H - 1]]).to(pntA.device)
            pntB = (pntB + 1) / 2 * pntB.new_tensor([[W + 3, H - 1]]).to(pntB.device)

            # [120, 40] -> [120, 36],实际只取中心118x32区域的点对
            pntA[:, 0] -= 2
            pntB[:, 0] -= 2
            
            pntA_normalized = pntA / pntA.new_tensor([W - 1, H - 1]).to(pntA.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)
            pntB_normalized = pntB / pntB.new_tensor([W - 1, H - 1]).to(pntB.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)

            pntA_H = warp_points(pntA[:, :2], Homo[idx].squeeze(), device=self.device)  # 利用变换矩阵变换坐标点
            # pntA_H, mask_pointA = filter_points(pntA_H, torch.tensor([W, H], device=self.device), return_mask=True)
            pntB_invH = warp_points(pntB[:, :2], inv_Homo[idx].squeeze(), device=self.device)
            # pntB_invH, mask_pointB = filter_points(pntB_invH, torch.tensor([W, H], device=self.device), return_mask=True)
            
            try:
                assert pntA_H.shape[0] > 0 and pntB_invH.shape[0] > 0 
                
                # 点对欧氏距离
                key_disAB = self.get_dis(pntA_H[:, :2], pntB[:, :2])
                key_disBA = self.get_dis(pntB_invH[:, :2], pntA[:, :2])
                pairAB_A, pairAB_B, dis_pairAB, _ = self.get_point_pair(key_disAB, dis_thre=self.correspond)  # p -> k # NTA(<1.5), NTA(<1.5), NTA(<1.5), NTA        
                pairBA_B, pairBA_A, dis_pairBA, _  = self.get_point_pair(key_disBA, dis_thre=self.correspond)  # p -> k # NTB(<1.5), NTB(<1.5), NTB(<1.5), NTB 
                
                # 点距离mask
                nn_maskAB = torch.zeros((pntA_H.shape[0], pntB.shape[0]), device=self.device) 
                nn_maskAB[pairAB_A, pairAB_B] = 1

                nn_maskBA = torch.zeros((pntB_invH.shape[0], pntA.shape[0]), device=self.device) 
                nn_maskBA[pairBA_B, pairBA_A] = 1

                # 点对曼哈顿距离
                key_manhattandisAB = self.get_manhattan_dis(pntA_H[:, :2], pntB[:, :2])
                key_manhattandisBA = self.get_manhattan_dis(pntB_invH[:, :2], pntA[:, :2])
                assert dis_pairAB.shape[0] > 0 and dis_pairBA.shape[0] > 0     

                pntA_H_normalized = pntA_H / pntA_H.new_tensor([W - 1, H - 1]).to(pntA_H.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)
                pntB_invH_normalized = pntB_invH / pntB_invH.new_tensor([W - 1, H - 1]).to(pntB_invH.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)

                # 用于score_map
                pntA_H_new = copy.deepcopy(pntA_H.detach())
                pntB_invH_new = copy.deepcopy(pntB_invH.detach())
                pntA_H_new[:, 0] += 2
                pntB_invH_new[:, 0] += 2
                
                pntA_H_normalized_new = pntA_H_new / pntA_H_new.new_tensor([W + 3, H - 1]).to(pntA_H.device) * 2 - 1

                pntB_invH_new = warp_points(pntB_invH_new[:, :2], inv_Homo_en[idx].squeeze(), device=self.device)       # 转到A上，而不是AT上
                
                pntB_invH_normalized_new = pntB_invH_new / pntB_invH_new.new_tensor([W + 3, H - 1]).to(pntB_invH.device) * 2 - 1 

                # PA VS PB 有一定偏移
                ori_kpA_ext = F.grid_sample(ori_allA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntA_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  
                ori_kpB_ext = F.grid_sample(ori_allB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntB_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  

                main_ori_maskATB = self.get_main_ori_consistence(ori_kpA[countA:countA+numA][pmA].unsqueeze(1), ori_kpB_ext)  # NTA x NTB 
                main_ori_maskBTA = self.get_main_ori_consistence(ori_kpB[countB:countB+numB][pmB].unsqueeze(1), ori_kpA_ext)  # NTB x NTA 
                
                # print(ori_all_patchA[idx, :, :5, 0], ori_all_patchB[idx, :, :5, 0])
                # exit()
                ori_kpA_patch_ext = F.grid_sample(ori_all_patchA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntA_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  
                ori_kpB_patch_ext = F.grid_sample(ori_all_patchB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntB_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  

                ori_maskATB = self.get_ori_consistence_ratio(ori_kp_patchA[countA:countA+numA][pmA, :], ori_kpB_patch_ext)  # NTA x NTB
                ori_maskBTA = self.get_ori_consistence_ratio(ori_kp_patchB[countB:countB+numB][pmB, :], ori_kpA_patch_ext)  # NTB x NTA

                # match_maskAB = (nn_maskAB == 1) * main_ori_maskATB
                # match_maskBA = (nn_maskBA == 1) * main_ori_maskBTA
                match_maskAB = (nn_maskAB == 1) * main_ori_maskATB * (ori_maskATB >= self.ori_ratio)
                match_maskBA = (nn_maskBA == 1) * main_ori_maskBTA * (ori_maskBTA >= self.ori_ratio)

                pairAB_A_new, pairAB_B_new = torch.where(match_maskAB == 1)
                pairBA_B_new, pairBA_A_new = torch.where(match_maskBA == 1)
                assert pairAB_A_new.shape[0] > 0 and pairBA_B_new.shape[0] > 0 
                # print('1:', pairAB_A_new.shape[0], pairBA_B_new.shape[0])
                # PA VS PAB 没有中心点距离偏移
                # 中心主方向一致性
                ori_kpAB_ext = F.grid_sample(ori_allB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntA_H_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  
                ori_kpBA_ext = F.grid_sample(ori_allA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntB_invH_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  
                main_ori_maskATAB = self.get_main_ori_consistence(ori_kpA[countA:countA+numA][pmA].unsqueeze(1), ori_kpAB_ext)  # NTAxNTA 
                main_ori_maskBTBA = self.get_main_ori_consistence(ori_kpB[countB:countB+numB][pmB].unsqueeze(1), ori_kpBA_ext)  # NTBxNTB 

                # 4x4邻域方向一致性
                ori_kpAB_patch_ext = F.grid_sample(ori_all_patchB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntA_H_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  
                ori_kpBA_patch_ext = F.grid_sample(ori_all_patchA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntB_invH_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  

                ori_maskATAB = self.get_ori_consistence_ratio(ori_kp_patchA[countA:countA+numA][pmA, :], ori_kpAB_patch_ext)  # NTAxNTA 
                ori_maskBTBA = self.get_ori_consistence_ratio(ori_kp_patchB[countB:countB+numB][pmB, :], ori_kpBA_patch_ext)  # NTBxNTB

                # vmaskAH = torch.diag(main_ori_maskATAB) == 1
                # vmaskBH = torch.diag(main_ori_maskBTBA) == 1
                vmaskAH = torch.diag(main_ori_maskATAB * (ori_maskATAB >= self.ori_ratio)) == 1
                vmaskBH = torch.diag(main_ori_maskBTBA * (ori_maskBTBA >= self.ori_ratio)) == 1
                assert torch.sum(vmaskAH) > 0 and torch.sum(vmaskBH) > 0
                # print('2:', torch.sum(vmaskAH), torch.sum(vmaskBH))

                current_descA, current_descB = descA[countA:countA+new_numA], descB[countB:countB+new_numB]
                
                # SOSR: 简化的self-attention
                k_neighbor = 3
                cross_sim_AA_sp = current_descA @ current_descA.transpose(0, 1)
                cross_sim_BB_sp = current_descB @ current_descB.transpose(0, 1)

                match_sim_AB_AA = cross_sim_AA_sp[pairAB_A_new, :][:, pairAB_A_new]
                match_sim_BA_BB = cross_sim_BB_sp[pairBA_B_new, :][:, pairBA_B_new]
                match_sim_AB_BB = cross_sim_BB_sp[pairAB_B_new, :][:, pairAB_B_new]
                match_sim_BA_AA = cross_sim_AA_sp[pairBA_A_new, :][:, pairBA_A_new]
                match_values_AB_AA, match_indices_AB_AA = torch.topk(match_sim_AB_AA, dim=1, k=k_neighbor, largest=False)
                match_values_BA_BB, match_indices_BA_BB = torch.topk(match_sim_BA_BB, dim=1, k=k_neighbor, largest=False)
                match_values_AB_BB_all = match_sim_AB_BB[:, match_indices_AB_AA]
                match_values_BA_AA_all = match_sim_BA_AA[:, match_indices_BA_BB]
                match_values_AB_BB = torch.diagonal(match_values_AB_BB_all, 0, dim1=0, dim2=1).transpose(0, 1)
                match_values_BA_AA = torch.diagonal(match_values_BA_AA_all, 0, dim1=0, dim2=1).transpose(0, 1)
                neighbor_dis_AB = (match_values_AB_AA - match_values_AB_BB) * (match_values_AB_AA - match_values_AB_BB)
                neighbor_dis_BA = (match_values_BA_BB - match_values_BA_AA) * (match_values_BA_BB - match_values_BA_AA)

                # PA VS PB
                cross_sim_AB_sp = current_descA @ current_descB.transpose(0, 1)
                # print('5:', cross_sim_AB_sp.shape, match_maskAB.shape, match_maskBA.shape)
                valid_cross_sim_AB_sp_mean = torch.mean(cross_sim_AB_sp[match_maskAB == 1], dim=-1)
                novalid_cross_sim_AB_sp_mean = (torch.sum(torch.sum(cross_sim_AB_sp.detach(), 1), 0) - valid_cross_sim_AB_sp_mean * pairAB_A_new.shape[0]) / (new_numA * new_numB - pairAB_A_new.shape[0] + eps)
                valid_cross_sim_BA_sp_mean = torch.mean(cross_sim_AB_sp[match_maskBA.transpose(0, 1) == 1], dim=-1)
                novalid_cross_sim_BA_sp_mean = (torch.sum(torch.sum(cross_sim_AB_sp.detach(), 1), 0) - valid_cross_sim_BA_sp_mean * pairBA_B_new.shape[0]) / (new_numA * new_numB - pairBA_B_new.shape[0] + eps)

                valid_indexesA = torch.tensor(list(range(new_numA)), device=self.device)[pairAB_A_new]
                # cross_sim_BA_sp = current_descB @ current_descA.transpose(0, 1)
                cross_sim_AB_out_sp = torch.cat((cross_sim_AB_sp, torch.ones((new_numA, 1), device=cross_sim_AB_sp.device) * 2), dim=-1)      # NA X (NB + 1)
                # cross_sim_BA_out_sp = torch.cat((cross_sim_BA_sp, torch.ones((numB, 1), device=cross_sim_BA_sp.device)), dim=-1)      # NB X (NA + 1)
                # valid_indexesB = torch.tensor(list(range(numB)), device=self.device)[mask_pointB][pairBA_B]
                cross_sim_AB_out_sp[valid_indexesA, -1] = novalid_cross_sim_AB_sp_mean
                novalid_indexesA = torch.tensor(list(range(new_numA)), device=self.device)[cross_sim_AB_out_sp[:, -1]==2]
                cross_sim_AB_out_sp[novalid_indexesA, -1] = valid_cross_sim_AB_sp_mean

                soft_cross_sim_AtoB_sp = F.softmax((cross_sim_AB_out_sp - 1) / t_des, dim=-1)
                # soft_cross_sim_BtoA = F.softmax((cross_sim_BA_out - 1) / t_des, dim=-1)
                
                soft_valid_cross_sim_AB_sp = soft_cross_sim_AtoB_sp[:, :-1][match_maskAB==1]
                # soft_valid_cross_sim_BA = soft_cross_sim_BtoA[mask_pointB, :-1][pairBA_B, pairBA_A]
                soft_novalid_cross_sim_AB_sp = soft_cross_sim_AtoB_sp[novalid_indexesA, -1]
                # soft_novalid_cross_sim_BA = soft_cross_sim_BtoA[cross_sim_BA_out[:, -1]==1, -1]
                log_soft_valid_cross_sim_AB_sp = -torch.log(soft_valid_cross_sim_AB_sp + eps) * ori_maskATB[match_maskAB==1]
                # log_soft_valid_cross_sim_BA = -torch.log(soft_valid_cross_sim_BA + eps)
                log_soft_novalid_cross_sim_AB_sp = -torch.log(soft_novalid_cross_sim_AB_sp + eps)
                # log_soft_novalid_cross_sim_BA = -torch.log(soft_novalid_cross_sim_BA + eps)
                dis_cross_sim_mean_sp = torch.sum(torch.cat((log_soft_valid_cross_sim_AB_sp, log_soft_novalid_cross_sim_AB_sp), dim=-1), dim=-1) / new_numA

                # PA VS PAB
                # match_mask_A = copy.deepcopy(mask_pointA)
                # match_mask_B = copy.deepcopy(mask_pointB)
                match_mask_A = copy.deepcopy(vmaskAH)
                match_mask_B = copy.deepcopy(vmaskBH)

                cross_sim_AB = current_descA @ desc_mapB[idx, :, :, :].view(-1, H * W)
                cross_sim_AB_all = F.grid_sample(cross_sim_AB.view(-1, H, W).unsqueeze(0),
                                                pntA_H_normalized[vmaskAH, :].detach().view(1, 1, -1, 2),
                                                mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NA x match_nA

                valid_cross_sim_AB_mean = torch.trace(cross_sim_AB_all[match_mask_A, :]) / cross_sim_AB_all[match_mask_A, :].shape[0]
                # novalid_cross_sim_AB_mean = (torch.sum(torch.sum(cross_sim_AB.detach(), 1), 1) - valid_cross_sim_AB_mean * pairAB_A.shape[0]) / (new_numA * H * W - pairAB_A.shape[0])

                cross_sim_BA = current_descB @ desc_mapA[idx, :, :, :].view(-1, H * W)   # M x H x W
                cross_sim_BA_all = F.grid_sample(cross_sim_BA.view(-1, H, W).unsqueeze(0),
                                                pntB_invH_normalized[vmaskBH, :].detach().view(1, 1, -1, 2),
                                                mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NB x match_nB

                valid_cross_sim_BA_mean = torch.trace(cross_sim_BA_all[match_mask_B, :]) / cross_sim_BA_all[match_mask_B, :].shape[0]
                # novalid_cross_sim_BA_mean = (torch.sum(torch.sum(cross_sim_BA.detach(), 1), 1) - valid_cross_sim_BA_mean * pairBA_B.shape[0]) / (new_numB * H * W - pairBA_B.shape[0])

                cross_sim_AB_out = torch.cat((cross_sim_AB, torch.ones((new_numA, 1), device=cross_sim_AB.device)), dim=-1)      # NA X (H X W + 1)
                cross_sim_BA_out = torch.cat((cross_sim_BA, torch.ones((new_numB, 1), device=cross_sim_BA.device)), dim=-1)      # NB X (H X W + 1)
                # print(match_mask_A.shape, cross_sim_AB_out.shape)
                # cross_sim_AB_out[mask_pointA, -1] -= 1
                # cross_sim_BA_out[mask_pointB, -1] -= 1
                # cross_sim_AB_out[match_mask_A, -1] -= 1
                cross_sim_AB_out[match_mask_A, -1] = novalid_cross_sim_AB_sp_mean
                cross_sim_AB_out[match_mask_A==False, -1] = valid_cross_sim_AB_mean

                cross_sim_BA_out[match_mask_B, -1] = novalid_cross_sim_BA_sp_mean
                cross_sim_BA_out[match_mask_B==False, -1] = valid_cross_sim_BA_mean

                soft_cross_sim_AtoB = F.softmax((cross_sim_AB_out - 1) / t_des, dim=-1)         # NA X (H X W + 1)
                soft_cross_sim_BtoA = F.softmax((cross_sim_BA_out - 1) / t_des, dim=-1)         # NB X (H X W + 1)
                soft_cross_sim_AB_all = F.grid_sample(soft_cross_sim_AtoB[:, :-1].view(-1, H, W).unsqueeze(0),
                                                    pntA_H_normalized[vmaskAH, :].detach().view(1, 1, -1, 2),
                                                    mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NA x match_nA
                
                soft_cross_sim_BA_all = F.grid_sample(soft_cross_sim_BtoA[:, :-1].view(-1, H, W).unsqueeze(0),
                                                    pntB_invH_normalized[vmaskBH, :].detach().view(1, 1, -1, 2),
                                                    mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NB x match_nB
                # soft_valid_cross_sim_AB_all = soft_cross_sim_AB_all[mask_pointA, :]             # repeat_nA x repeat_nA
                # soft_valid_cross_sim_BA_all = soft_cross_sim_BA_all[mask_pointB, :]             # repeat_nB x repeat_nB

                soft_valid_cross_sim_AB_all = soft_cross_sim_AB_all[match_mask_A, :]             # match_nA x match_nA
                soft_valid_cross_sim_BA_all = soft_cross_sim_BA_all[match_mask_B, :]             # match_nB x match_nB

                valid_mask_AB = torch.eye(soft_valid_cross_sim_AB_all.shape[0]) == 1
                valid_mask_BA = torch.eye(soft_valid_cross_sim_BA_all.shape[0]) == 1

                # 取对角线
                soft_valid_cross_sim_AB = soft_valid_cross_sim_AB_all[valid_mask_AB]
                soft_valid_cross_sim_BA = soft_valid_cross_sim_BA_all[valid_mask_BA]

                # soft_novalid_cross_sim_AB = soft_cross_sim_AtoB[mask_pointA==False, -1]              # (NA-repeat_nA) x 1
                # soft_novalid_cross_sim_BA = soft_cross_sim_BtoA[mask_pointB==False, -1]
                soft_novalid_cross_sim_AB = soft_cross_sim_AtoB[match_mask_A==False, -1]               # (NA-match_nA) x 1
                soft_novalid_cross_sim_BA = soft_cross_sim_BtoA[match_mask_B==False, -1]
                # print(soft_novalid_cross_sim_AB, soft_novalid_cross_sim_BA)

                log_soft_valid_cross_sim_AB = -torch.log(soft_valid_cross_sim_AB + eps) * torch.diag(ori_maskATAB)[vmaskAH]
                log_soft_valid_cross_sim_BA = -torch.log(soft_valid_cross_sim_BA + eps) * torch.diag(ori_maskBTBA)[vmaskBH]
                log_soft_novalid_cross_sim_AB = -torch.log(soft_novalid_cross_sim_AB + eps)
                log_soft_novalid_cross_sim_BA = -torch.log(soft_novalid_cross_sim_BA + eps)

                dis_cross_sim_mean = torch.sum(torch.cat((log_soft_valid_cross_sim_AB, log_soft_valid_cross_sim_BA, log_soft_novalid_cross_sim_AB, log_soft_novalid_cross_sim_BA), dim=-1), dim=-1) / (pntA.shape[0] + pntB.shape[0])

                # valid_cross_sim_AB = cross_sim_AB[mask_pointA, :]   # repeat_nA x (H X W)
                # valid_cross_sim_BA = cross_sim_BA[mask_pointB, :]   # repeat_nB x (H X W)
                exp_valid_cross_sim_AtoB = torch.exp((cross_sim_AB - 1) / t_rel).view(-1, H, W)
                exp_valid_cross_sim_BtoA = torch.exp((cross_sim_BA - 1) / t_rel).view(-1, H, W)
                exp_valid_cross_sim_AB_all = F.grid_sample(exp_valid_cross_sim_AtoB.unsqueeze(0),
                                                        pntA_H_normalized.detach().view(1, 1, -1, 2),
                                                        mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # repeat_nA x repeat_nA
                
                exp_valid_cross_sim_BA_all = F.grid_sample(exp_valid_cross_sim_BtoA.unsqueeze(0),
                                                        pntB_invH_normalized.detach().view(1, 1, -1, 2),
                                                        mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # repeat_nB x repeat_nB

                repeat_mask_AB = torch.eye(exp_valid_cross_sim_AB_all.shape[0]) == 1
                repeat_mask_BA = torch.eye(exp_valid_cross_sim_BA_all.shape[0]) == 1
                rel_valid_cross_sim_AB = exp_valid_cross_sim_AB_all[repeat_mask_AB]
                rel_valid_cross_sim_BA = exp_valid_cross_sim_BA_all[repeat_mask_BA]

                # pntA_H_normalized_new = copy.deepcopy(pntA_H_normalized.detach())
                # pntB_invH_normalized_new = copy.deepcopy(pntB_invH_normalized.detach())

                # pntA_H_normalized_new[:, 0] += 2
                # pntB_invH_normalized_new[:, 0] += 2

                scoresAB_all = F.grid_sample(scores_mapB[idx, :, :, :].unsqueeze(0),
                                            pntA_H_normalized_new.view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)      # 1 x repeat_nA

                scoresBA_all = F.grid_sample(scores_mapA[idx, :, :, :].unsqueeze(0),
                                            pntB_invH_normalized_new.view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)      # 1 x repeat_nB

                scores_AAB = scoresA[idx][pmA] * scoresAB_all
                scores_BBA = scoresB[idx][pmB] * scoresBA_all
                scores_sum_AAB = torch.sum(scores_AAB, dim=-1)
                scores_sum_BBA = torch.sum(scores_BBA, dim=-1)
                scores_normalize_AAB = scores_AAB / (scores_sum_AAB + eps)
                scores_normalize_BBA = scores_BBA / (scores_sum_BBA + eps)
                rel_meanA = torch.sum(scores_normalize_AAB * (1 - rel_valid_cross_sim_AB), dim=-1) / pntA_H_normalized_new.shape[0]
                rel_meanB = torch.sum(scores_normalize_BBA * (1 - rel_valid_cross_sim_BA), dim=-1) / pntB_invH_normalized_new.shape[0]

                # # 熵loss
                # current_descA_std, current_descB_std = descA_std[countA:countA+new_numA], descB_std[countB:countB+new_numB]
                # desc_std += torch.mean(current_descA_std) + torch.mean(current_descB_std)

                countA += new_numA
                countB += new_numB
                # countA_T += numA_T
                # countB_T += numB_T

                dis_neighbor_mean_total += torch.mean(torch.sum(neighbor_dis_AB, dim=1)) + torch.mean(torch.sum(neighbor_dis_BA, dim=1))
                dis_desc += dis_cross_sim_mean_sp
                dis_desc += dis_cross_sim_mean

                dis_pair_meanAB = torch.mean(key_manhattandisAB[pairAB_A, pairAB_B])
                dis_pair_meanBA = torch.mean(key_manhattandisBA[pairBA_B, pairBA_A])

                dis_peak_mean = torch.mean(torch.cat((scoreddisA[idx][pmA], scoreddisB[idx][pmB]), dim=0))
                # dis_peak_meanB = torch.mean(scoreddisB[idx])
                
                dis_mean_total += dis_pair_meanAB + dis_pair_meanBA
                dis_peak_scored += dis_peak_mean

                dis_rel += rel_meanA + rel_meanB
                # # Penalty
                # scores_mean += (-torch.log(torch.mean(scoresA[idx], dim=-1) + eps) - torch.log(torch.mean(scoresB[idx], dim=-1) + eps)) 
                # print(scores_mean)
            except:
                # dis_mean_total += 0
                # dis_peak_scored += 0
                # dis_desc += 0
                # dis_rel += 0
                # print('Overlapping too small or Repeatable point pairs distance is greater than correspond(1.5):', pntA.shape[0], pntA_H.shape[0], pntB.shape[0], pntB_invH.shape[0], dis_pairAB.shape[0], dis_pairBA.shape[0])
                valid_batch_size -= 1
                countA += new_numA
                countB += new_numB
                # countA_T += numA_T
                # countB_T += numB_T

        valid_batch_size = valid_batch_size if valid_batch_size > 0 else eps
        # Reprojection Loss 
        reprojection_loss = dis_mean_total / (valid_batch_size * 2)
        # Dispersity Peak Loss
        dispersity_peak_loss = dis_peak_scored / valid_batch_size
        # NRE Loss
        descriptor_loss = dis_desc / (2 * valid_batch_size)
        # Reliability Loss
        reliability_loss = dis_rel / (valid_batch_size * 2)
        # SOSR Loss
        sosr_loss = dis_neighbor_mean_total / ((valid_batch_size * 2))
        # # Entropy loss
        # std_loss = (valid_batch_size * 2) / desc_std  
        # # Score Penalty
        # score_penalty = scores_mean / (valid_batch_size * 2)
        loss_total = wrp * reprojection_loss + wpl * dispersity_peak_loss + wdl * descriptor_loss + wrl * reliability_loss + sosr_loss
        loss_group = {
            'reprojection_loss': reprojection_loss, 
            'dispersity_peak_loss': dispersity_peak_loss,
            'descriptor_loss': descriptor_loss,
            'reliability_loss': reliability_loss,
            'sosr_loss': sosr_loss,
            # 'std_loss': std_loss,
            }
        return loss_total, loss_group

    def detector_selfsupervised_loss_dkd_dense_ext_restrict_modify_oriR_ratio_FA(self, kpA, kpB, pmaskA, pmaskB, descA, descB, desc_mapA, desc_mapB, scoreddisA, scoreddisB, scoresA, scoresB, scores_mapA, scores_mapB, Homo, inv_Homo, inv_Homo_en, ori_allA, ori_allB, ori_all_patchA, ori_all_patchB, ori_kpA, ori_kpB, ori_kp_patchA, ori_kp_patchB, kmask_T_allA, kmask_T_allB, FA_flag, H, W, wrp=1, wpl=1, wdl=1, wrl=1, t_des=0.02, t_rel=1):
        # pmaskA: (BxMax_num) 32x350=11200
        batch_size = len(kpA)
        max_num = pmaskA.shape[-1] // batch_size    # 350
        dis_mean_total = 0
        dis_neighbor_mean_total = 0
        dis_peak_scored = 0
        dis_desc = 0
        dis_rel = 0
        desc_std = 0
        eps = 1e-12
        valid_batch_size = batch_size
        valid_batch_size_FA = 0
        countA, countB = 0, 0
        dis_desc_fa = 0
        # countA_T, countB_T = 0, 0
        for idx in range(batch_size):
            pntA, pntB = kpA[idx], kpB[idx]     # M X 2 (x,y)
            # kmask_TA, kmask_TB = kmask_T_allA[idx], kmask_T_allB[idx]
            pntA = pntA.float()
            pntB = pntB.float()

            # 剔除部分按压区域的点且保留在重叠区域的点
            numA, numB = pntA.shape[0], pntB.shape[0]
            # numA_T, numB_T = pntA[kmask_TA].shape[0], pntB[kmask_TB].shape[0]
            pmA, pmB = pmaskA[max_num * idx:max_num * idx + numA].bool(), pmaskB[max_num * idx:max_num * idx + numB].bool()
            pntA, pntB = pntA[pmA, :], pntB[pmB, :]
            new_numA, new_numB = pntA.shape[0], pntB.shape[0]
            
            pntA = (pntA + 1) / 2 * pntA.new_tensor([[W + 3, H - 1]]).to(pntA.device)
            pntB = (pntB + 1) / 2 * pntB.new_tensor([[W + 3, H - 1]]).to(pntB.device)

            # [120, 40] -> [120, 36],实际只取中心118x32区域的点对
            pntA[:, 0] -= 2
            pntB[:, 0] -= 2
            
            pntA_normalized = pntA / pntA.new_tensor([W - 1, H - 1]).to(pntA.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)
            pntB_normalized = pntB / pntB.new_tensor([W - 1, H - 1]).to(pntB.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)

            pntA_H = warp_points(pntA[:, :2], Homo[idx].squeeze(), device=self.device)  # 利用变换矩阵变换坐标点
            # pntA_H, mask_pointA = filter_points(pntA_H, torch.tensor([W, H], device=self.device), return_mask=True)
            pntB_invH = warp_points(pntB[:, :2], inv_Homo[idx].squeeze(), device=self.device)
            # pntB_invH, mask_pointB = filter_points(pntB_invH, torch.tensor([W, H], device=self.device), return_mask=True)
            
            current_descA, current_descB = descA[countA:countA+new_numA], descB[countB:countB+new_numB]
            cross_sim_AB_sp = current_descA @ current_descB.transpose(0, 1)

            # Net FA余弦相似度小
            if FA_flag[idx] == 1:
                dis_desc_fa += (2 - torch.mean(torch.sqrt(2 * (1 - cross_sim_AB_sp) + eps)))
                valid_batch_size -= 1
                valid_batch_size_FA += 1
                countA += new_numA
                countB += new_numB
                continue
            
            # 真匹配的trans
            try:
                assert pntA_H.shape[0] > 0 and pntB_invH.shape[0] > 0 
                
                # 点对欧氏距离
                key_disAB = self.get_dis(pntA_H[:, :2], pntB[:, :2])
                key_disBA = self.get_dis(pntB_invH[:, :2], pntA[:, :2])
                pairAB_A, pairAB_B, dis_pairAB, _ = self.get_point_pair(key_disAB, dis_thre=self.correspond)  # p -> k # NTA(<1.5), NTA(<1.5), NTA(<1.5), NTA        
                pairBA_B, pairBA_A, dis_pairBA, _  = self.get_point_pair(key_disBA, dis_thre=self.correspond)  # p -> k # NTB(<1.5), NTB(<1.5), NTB(<1.5), NTB 
                
                # 点距离mask
                nn_maskAB = torch.zeros((pntA_H.shape[0], pntB.shape[0]), device=self.device) 
                nn_maskAB[pairAB_A, pairAB_B] = 1

                nn_maskBA = torch.zeros((pntB_invH.shape[0], pntA.shape[0]), device=self.device) 
                nn_maskBA[pairBA_B, pairBA_A] = 1

                # 点对曼哈顿距离
                key_manhattandisAB = self.get_manhattan_dis(pntA_H[:, :2], pntB[:, :2])
                key_manhattandisBA = self.get_manhattan_dis(pntB_invH[:, :2], pntA[:, :2])
                assert dis_pairAB.shape[0] > 0 and dis_pairBA.shape[0] > 0     

                pntA_H_normalized = pntA_H / pntA_H.new_tensor([W - 1, H - 1]).to(pntA_H.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)
                pntB_invH_normalized = pntB_invH / pntB_invH.new_tensor([W - 1, H - 1]).to(pntB_invH.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)

                # 用于score_map
                pntA_H_new = copy.deepcopy(pntA_H.detach())
                pntB_invH_new = copy.deepcopy(pntB_invH.detach())
                pntA_H_new[:, 0] += 2
                pntB_invH_new[:, 0] += 2
                
                pntA_H_normalized_new = pntA_H_new / pntA_H_new.new_tensor([W + 3, H - 1]).to(pntA_H.device) * 2 - 1

                pntB_invH_new = warp_points(pntB_invH_new[:, :2], inv_Homo_en[idx].squeeze(), device=self.device)       # 转到A上，而不是AT上
                
                pntB_invH_normalized_new = pntB_invH_new / pntB_invH_new.new_tensor([W + 3, H - 1]).to(pntB_invH.device) * 2 - 1 

                # PA VS PB 有一定偏移
                ori_kpA_ext = F.grid_sample(ori_allA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntA_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  
                ori_kpB_ext = F.grid_sample(ori_allB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntB_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  

                main_ori_maskATB = self.get_main_ori_consistence(ori_kpA[countA:countA+numA][pmA].unsqueeze(1), ori_kpB_ext)  # NTA x NTB 
                main_ori_maskBTA = self.get_main_ori_consistence(ori_kpB[countB:countB+numB][pmB].unsqueeze(1), ori_kpA_ext)  # NTB x NTA 
                
                # print(ori_all_patchA[idx, :, :5, 0], ori_all_patchB[idx, :, :5, 0])
                # exit()
                ori_kpA_patch_ext = F.grid_sample(ori_all_patchA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntA_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  
                ori_kpB_patch_ext = F.grid_sample(ori_all_patchB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntB_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  

                ori_maskATB = self.get_ori_consistence_ratio(ori_kp_patchA[countA:countA+numA][pmA, :], ori_kpB_patch_ext)  # NTA x NTB
                ori_maskBTA = self.get_ori_consistence_ratio(ori_kp_patchB[countB:countB+numB][pmB, :], ori_kpA_patch_ext)  # NTB x NTA

                # match_maskAB = (nn_maskAB == 1) * main_ori_maskATB
                # match_maskBA = (nn_maskBA == 1) * main_ori_maskBTA
                match_maskAB = (nn_maskAB == 1) * main_ori_maskATB * (ori_maskATB >= self.ori_ratio)
                match_maskBA = (nn_maskBA == 1) * main_ori_maskBTA * (ori_maskBTA >= self.ori_ratio)

                pairAB_A_new, pairAB_B_new = torch.where(match_maskAB == 1)
                pairBA_B_new, pairBA_A_new = torch.where(match_maskBA == 1)
                assert pairAB_A_new.shape[0] > 0 and pairBA_B_new.shape[0] > 0 
                # print('1:', pairAB_A_new.shape[0], pairBA_B_new.shape[0])
                # PA VS PAB 没有中心点距离偏移
                # 中心主方向一致性
                ori_kpAB_ext = F.grid_sample(ori_allB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntA_H_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  
                ori_kpBA_ext = F.grid_sample(ori_allA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntB_invH_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  
                main_ori_maskATAB = self.get_main_ori_consistence(ori_kpA[countA:countA+numA][pmA].unsqueeze(1), ori_kpAB_ext)  # NTAxNTA 
                main_ori_maskBTBA = self.get_main_ori_consistence(ori_kpB[countB:countB+numB][pmB].unsqueeze(1), ori_kpBA_ext)  # NTBxNTB 

                # 4x4邻域方向一致性
                ori_kpAB_patch_ext = F.grid_sample(ori_all_patchB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntA_H_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  
                ori_kpBA_patch_ext = F.grid_sample(ori_all_patchA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntB_invH_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  

                ori_maskATAB = self.get_ori_consistence_ratio(ori_kp_patchA[countA:countA+numA][pmA, :], ori_kpAB_patch_ext)  # NTAxNTA 
                ori_maskBTBA = self.get_ori_consistence_ratio(ori_kp_patchB[countB:countB+numB][pmB, :], ori_kpBA_patch_ext)  # NTBxNTB

                # vmaskAH = torch.diag(main_ori_maskATAB) == 1
                # vmaskBH = torch.diag(main_ori_maskBTBA) == 1
                vmaskAH = torch.diag(main_ori_maskATAB * (ori_maskATAB >= self.ori_ratio)) == 1
                vmaskBH = torch.diag(main_ori_maskBTBA * (ori_maskBTBA >= self.ori_ratio)) == 1
                assert torch.sum(vmaskAH) > 0 and torch.sum(vmaskBH) > 0
                # print('2:', torch.sum(vmaskAH), torch.sum(vmaskBH))
                
                # SOSR: 简化的self-attention
                k_neighbor = 3
                cross_sim_AA_sp = current_descA @ current_descA.transpose(0, 1)
                cross_sim_BB_sp = current_descB @ current_descB.transpose(0, 1)

                match_sim_AB_AA = cross_sim_AA_sp[pairAB_A_new, :][:, pairAB_A_new]
                match_sim_BA_BB = cross_sim_BB_sp[pairBA_B_new, :][:, pairBA_B_new]
                match_sim_AB_BB = cross_sim_BB_sp[pairAB_B_new, :][:, pairAB_B_new]
                match_sim_BA_AA = cross_sim_AA_sp[pairBA_A_new, :][:, pairBA_A_new]
                match_values_AB_AA, match_indices_AB_AA = torch.topk(match_sim_AB_AA, dim=1, k=k_neighbor, largest=False)
                match_values_BA_BB, match_indices_BA_BB = torch.topk(match_sim_BA_BB, dim=1, k=k_neighbor, largest=False)
                match_values_AB_BB_all = match_sim_AB_BB[:, match_indices_AB_AA]
                match_values_BA_AA_all = match_sim_BA_AA[:, match_indices_BA_BB]
                match_values_AB_BB = torch.diagonal(match_values_AB_BB_all, 0, dim1=0, dim2=1).transpose(0, 1)
                match_values_BA_AA = torch.diagonal(match_values_BA_AA_all, 0, dim1=0, dim2=1).transpose(0, 1)
                neighbor_dis_AB = (match_values_AB_AA - match_values_AB_BB) * (match_values_AB_AA - match_values_AB_BB)
                neighbor_dis_BA = (match_values_BA_BB - match_values_BA_AA) * (match_values_BA_BB - match_values_BA_AA)

                # PA VS PB
                # print('5:', cross_sim_AB_sp.shape, match_maskAB.shape, match_maskBA.shape)
                valid_cross_sim_AB_sp_mean = torch.mean(cross_sim_AB_sp[match_maskAB == 1], dim=-1)
                novalid_cross_sim_AB_sp_mean = (torch.sum(torch.sum(cross_sim_AB_sp.detach(), 1), 0) - valid_cross_sim_AB_sp_mean * pairAB_A_new.shape[0]) / (new_numA * new_numB - pairAB_A_new.shape[0] + eps)
                valid_cross_sim_BA_sp_mean = torch.mean(cross_sim_AB_sp[match_maskBA.transpose(0, 1) == 1], dim=-1)
                novalid_cross_sim_BA_sp_mean = (torch.sum(torch.sum(cross_sim_AB_sp.detach(), 1), 0) - valid_cross_sim_BA_sp_mean * pairBA_B_new.shape[0]) / (new_numA * new_numB - pairBA_B_new.shape[0] + eps)

                valid_indexesA = torch.tensor(list(range(new_numA)), device=self.device)[pairAB_A_new]
                # cross_sim_BA_sp = current_descB @ current_descA.transpose(0, 1)
                cross_sim_AB_out_sp = torch.cat((cross_sim_AB_sp, torch.ones((new_numA, 1), device=cross_sim_AB_sp.device) * 2), dim=-1)      # NA X (NB + 1)
                # cross_sim_BA_out_sp = torch.cat((cross_sim_BA_sp, torch.ones((numB, 1), device=cross_sim_BA_sp.device)), dim=-1)      # NB X (NA + 1)
                # valid_indexesB = torch.tensor(list(range(numB)), device=self.device)[mask_pointB][pairBA_B]
                cross_sim_AB_out_sp[valid_indexesA, -1] = novalid_cross_sim_AB_sp_mean
                novalid_indexesA = torch.tensor(list(range(new_numA)), device=self.device)[cross_sim_AB_out_sp[:, -1]==2]
                cross_sim_AB_out_sp[novalid_indexesA, -1] = valid_cross_sim_AB_sp_mean

                soft_cross_sim_AtoB_sp = F.softmax((cross_sim_AB_out_sp - 1) / t_des, dim=-1)
                # soft_cross_sim_BtoA = F.softmax((cross_sim_BA_out - 1) / t_des, dim=-1)
                
                soft_valid_cross_sim_AB_sp = soft_cross_sim_AtoB_sp[:, :-1][match_maskAB==1]
                # soft_valid_cross_sim_BA = soft_cross_sim_BtoA[mask_pointB, :-1][pairBA_B, pairBA_A]
                soft_novalid_cross_sim_AB_sp = soft_cross_sim_AtoB_sp[novalid_indexesA, -1]
                # soft_novalid_cross_sim_BA = soft_cross_sim_BtoA[cross_sim_BA_out[:, -1]==1, -1]
                log_soft_valid_cross_sim_AB_sp = -torch.log(soft_valid_cross_sim_AB_sp + eps) * ori_maskATB[match_maskAB==1]
                # log_soft_valid_cross_sim_BA = -torch.log(soft_valid_cross_sim_BA + eps)
                log_soft_novalid_cross_sim_AB_sp = -torch.log(soft_novalid_cross_sim_AB_sp + eps)
                # log_soft_novalid_cross_sim_BA = -torch.log(soft_novalid_cross_sim_BA + eps)
                dis_cross_sim_mean_sp = torch.sum(torch.cat((log_soft_valid_cross_sim_AB_sp, log_soft_novalid_cross_sim_AB_sp), dim=-1), dim=-1) / new_numA

                # PA VS PAB
                # match_mask_A = copy.deepcopy(mask_pointA)
                # match_mask_B = copy.deepcopy(mask_pointB)
                match_mask_A = copy.deepcopy(vmaskAH)
                match_mask_B = copy.deepcopy(vmaskBH)

                cross_sim_AB = current_descA @ desc_mapB[idx, :, :, :].view(-1, H * W)
                cross_sim_AB_all = F.grid_sample(cross_sim_AB.view(-1, H, W).unsqueeze(0),
                                                pntA_H_normalized[vmaskAH, :].detach().view(1, 1, -1, 2),
                                                mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NA x match_nA

                valid_cross_sim_AB_mean = torch.trace(cross_sim_AB_all[match_mask_A, :]) / cross_sim_AB_all[match_mask_A, :].shape[0]
                # novalid_cross_sim_AB_mean = (torch.sum(torch.sum(cross_sim_AB.detach(), 1), 1) - valid_cross_sim_AB_mean * pairAB_A.shape[0]) / (new_numA * H * W - pairAB_A.shape[0])

                cross_sim_BA = current_descB @ desc_mapA[idx, :, :, :].view(-1, H * W)   # M x H x W
                cross_sim_BA_all = F.grid_sample(cross_sim_BA.view(-1, H, W).unsqueeze(0),
                                                pntB_invH_normalized[vmaskBH, :].detach().view(1, 1, -1, 2),
                                                mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NB x match_nB

                valid_cross_sim_BA_mean = torch.trace(cross_sim_BA_all[match_mask_B, :]) / cross_sim_BA_all[match_mask_B, :].shape[0]
                # novalid_cross_sim_BA_mean = (torch.sum(torch.sum(cross_sim_BA.detach(), 1), 1) - valid_cross_sim_BA_mean * pairBA_B.shape[0]) / (new_numB * H * W - pairBA_B.shape[0])

                cross_sim_AB_out = torch.cat((cross_sim_AB, torch.ones((new_numA, 1), device=cross_sim_AB.device)), dim=-1)      # NA X (H X W + 1)
                cross_sim_BA_out = torch.cat((cross_sim_BA, torch.ones((new_numB, 1), device=cross_sim_BA.device)), dim=-1)      # NB X (H X W + 1)
                # print(match_mask_A.shape, cross_sim_AB_out.shape)
                # cross_sim_AB_out[mask_pointA, -1] -= 1
                # cross_sim_BA_out[mask_pointB, -1] -= 1
                # cross_sim_AB_out[match_mask_A, -1] -= 1
                cross_sim_AB_out[match_mask_A, -1] = novalid_cross_sim_AB_sp_mean
                cross_sim_AB_out[match_mask_A==False, -1] = valid_cross_sim_AB_mean

                cross_sim_BA_out[match_mask_B, -1] = novalid_cross_sim_BA_sp_mean
                cross_sim_BA_out[match_mask_B==False, -1] = valid_cross_sim_BA_mean

                soft_cross_sim_AtoB = F.softmax((cross_sim_AB_out - 1) / t_des, dim=-1)         # NA X (H X W + 1)
                soft_cross_sim_BtoA = F.softmax((cross_sim_BA_out - 1) / t_des, dim=-1)         # NB X (H X W + 1)
                soft_cross_sim_AB_all = F.grid_sample(soft_cross_sim_AtoB[:, :-1].view(-1, H, W).unsqueeze(0),
                                                    pntA_H_normalized[vmaskAH, :].detach().view(1, 1, -1, 2),
                                                    mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NA x match_nA
                
                soft_cross_sim_BA_all = F.grid_sample(soft_cross_sim_BtoA[:, :-1].view(-1, H, W).unsqueeze(0),
                                                    pntB_invH_normalized[vmaskBH, :].detach().view(1, 1, -1, 2),
                                                    mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NB x match_nB
                # soft_valid_cross_sim_AB_all = soft_cross_sim_AB_all[mask_pointA, :]             # repeat_nA x repeat_nA
                # soft_valid_cross_sim_BA_all = soft_cross_sim_BA_all[mask_pointB, :]             # repeat_nB x repeat_nB

                soft_valid_cross_sim_AB_all = soft_cross_sim_AB_all[match_mask_A, :]             # match_nA x match_nA
                soft_valid_cross_sim_BA_all = soft_cross_sim_BA_all[match_mask_B, :]             # match_nB x match_nB

                valid_mask_AB = torch.eye(soft_valid_cross_sim_AB_all.shape[0]) == 1
                valid_mask_BA = torch.eye(soft_valid_cross_sim_BA_all.shape[0]) == 1

                # 取对角线
                soft_valid_cross_sim_AB = soft_valid_cross_sim_AB_all[valid_mask_AB]
                soft_valid_cross_sim_BA = soft_valid_cross_sim_BA_all[valid_mask_BA]

                # soft_novalid_cross_sim_AB = soft_cross_sim_AtoB[mask_pointA==False, -1]              # (NA-repeat_nA) x 1
                # soft_novalid_cross_sim_BA = soft_cross_sim_BtoA[mask_pointB==False, -1]
                soft_novalid_cross_sim_AB = soft_cross_sim_AtoB[match_mask_A==False, -1]               # (NA-match_nA) x 1
                soft_novalid_cross_sim_BA = soft_cross_sim_BtoA[match_mask_B==False, -1]
                # print(soft_novalid_cross_sim_AB, soft_novalid_cross_sim_BA)

                log_soft_valid_cross_sim_AB = -torch.log(soft_valid_cross_sim_AB + eps) * torch.diag(ori_maskATAB)[vmaskAH]
                log_soft_valid_cross_sim_BA = -torch.log(soft_valid_cross_sim_BA + eps) * torch.diag(ori_maskBTBA)[vmaskBH]
                log_soft_novalid_cross_sim_AB = -torch.log(soft_novalid_cross_sim_AB + eps)
                log_soft_novalid_cross_sim_BA = -torch.log(soft_novalid_cross_sim_BA + eps)

                dis_cross_sim_mean = torch.sum(torch.cat((log_soft_valid_cross_sim_AB, log_soft_valid_cross_sim_BA, log_soft_novalid_cross_sim_AB, log_soft_novalid_cross_sim_BA), dim=-1), dim=-1) / (pntA.shape[0] + pntB.shape[0])

                # valid_cross_sim_AB = cross_sim_AB[mask_pointA, :]   # repeat_nA x (H X W)
                # valid_cross_sim_BA = cross_sim_BA[mask_pointB, :]   # repeat_nB x (H X W)
                exp_valid_cross_sim_AtoB = torch.exp((cross_sim_AB - 1) / t_rel).view(-1, H, W)
                exp_valid_cross_sim_BtoA = torch.exp((cross_sim_BA - 1) / t_rel).view(-1, H, W)
                exp_valid_cross_sim_AB_all = F.grid_sample(exp_valid_cross_sim_AtoB.unsqueeze(0),
                                                        pntA_H_normalized.detach().view(1, 1, -1, 2),
                                                        mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # repeat_nA x repeat_nA
                
                exp_valid_cross_sim_BA_all = F.grid_sample(exp_valid_cross_sim_BtoA.unsqueeze(0),
                                                        pntB_invH_normalized.detach().view(1, 1, -1, 2),
                                                        mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # repeat_nB x repeat_nB

                repeat_mask_AB = torch.eye(exp_valid_cross_sim_AB_all.shape[0]) == 1
                repeat_mask_BA = torch.eye(exp_valid_cross_sim_BA_all.shape[0]) == 1
                rel_valid_cross_sim_AB = exp_valid_cross_sim_AB_all[repeat_mask_AB]
                rel_valid_cross_sim_BA = exp_valid_cross_sim_BA_all[repeat_mask_BA]

                # pntA_H_normalized_new = copy.deepcopy(pntA_H_normalized.detach())
                # pntB_invH_normalized_new = copy.deepcopy(pntB_invH_normalized.detach())

                # pntA_H_normalized_new[:, 0] += 2
                # pntB_invH_normalized_new[:, 0] += 2

                scoresAB_all = F.grid_sample(scores_mapB[idx, :, :, :].unsqueeze(0),
                                            pntA_H_normalized_new.view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)      # 1 x repeat_nA

                scoresBA_all = F.grid_sample(scores_mapA[idx, :, :, :].unsqueeze(0),
                                            pntB_invH_normalized_new.view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)      # 1 x repeat_nB

                scores_AAB = scoresA[idx][pmA] * scoresAB_all
                scores_BBA = scoresB[idx][pmB] * scoresBA_all
                scores_sum_AAB = torch.sum(scores_AAB, dim=-1)
                scores_sum_BBA = torch.sum(scores_BBA, dim=-1)
                scores_normalize_AAB = scores_AAB / (scores_sum_AAB + eps)
                scores_normalize_BBA = scores_BBA / (scores_sum_BBA + eps)
                rel_meanA = torch.sum(scores_normalize_AAB * (1 - rel_valid_cross_sim_AB), dim=-1) / pntA_H_normalized_new.shape[0]
                rel_meanB = torch.sum(scores_normalize_BBA * (1 - rel_valid_cross_sim_BA), dim=-1) / pntB_invH_normalized_new.shape[0]

                # # 熵loss
                # current_descA_std, current_descB_std = descA_std[countA:countA+new_numA], descB_std[countB:countB+new_numB]
                # desc_std += torch.mean(current_descA_std) + torch.mean(current_descB_std)

                countA += new_numA
                countB += new_numB
                # countA_T += numA_T
                # countB_T += numB_T

                dis_neighbor_mean_total += torch.mean(torch.sum(neighbor_dis_AB, dim=1)) + torch.mean(torch.sum(neighbor_dis_BA, dim=1))
                dis_desc += dis_cross_sim_mean_sp
                dis_desc += dis_cross_sim_mean

                dis_pair_meanAB = torch.mean(key_manhattandisAB[pairAB_A, pairAB_B])
                dis_pair_meanBA = torch.mean(key_manhattandisBA[pairBA_B, pairBA_A])

                dis_peak_mean = torch.mean(torch.cat((scoreddisA[idx][pmA], scoreddisB[idx][pmB]), dim=0))
                # dis_peak_meanB = torch.mean(scoreddisB[idx])
                
                dis_mean_total += dis_pair_meanAB + dis_pair_meanBA
                dis_peak_scored += dis_peak_mean

                dis_rel += rel_meanA + rel_meanB
                # # Penalty
                # scores_mean += (-torch.log(torch.mean(scoresA[idx], dim=-1) + eps) - torch.log(torch.mean(scoresB[idx], dim=-1) + eps)) 
                # print(scores_mean)
            except:
                # dis_mean_total += 0
                # dis_peak_scored += 0
                # dis_desc += 0
                # dis_rel += 0
                # print('Overlapping too small or Repeatable point pairs distance is greater than correspond(1.5):', pntA.shape[0], pntA_H.shape[0], pntB.shape[0], pntB_invH.shape[0], dis_pairAB.shape[0], dis_pairBA.shape[0])
                valid_batch_size -= 1
                countA += new_numA
                countB += new_numB
                # countA_T += numA_T
                # countB_T += numB_T

        valid_batch_size = valid_batch_size if valid_batch_size > 0 else eps
        # Reprojection Loss 
        reprojection_loss = dis_mean_total / (valid_batch_size * 2)
        # Dispersity Peak Loss
        dispersity_peak_loss = dis_peak_scored / valid_batch_size
        # NRE Loss
        descriptor_loss = dis_desc / (2 * valid_batch_size)
        # Reliability Loss
        reliability_loss = dis_rel / (valid_batch_size * 2)
        # SOSR Loss
        sosr_loss = dis_neighbor_mean_total / ((valid_batch_size * 2))
        # # Entropy loss
        # std_loss = (valid_batch_size * 2) / desc_std  
        # # Score Penalty
        # score_penalty = scores_mean / (valid_batch_size * 2)
        # FA Desc loss
        FA_des_loss = dis_desc_fa / valid_batch_size_FA if valid_batch_size_FA > 0 else 0

        loss_total = wrp * reprojection_loss + wpl * dispersity_peak_loss + wdl * descriptor_loss + wrl * reliability_loss + sosr_loss + FA_des_loss
        loss_group = {
            'reprojection_loss': reprojection_loss, 
            'dispersity_peak_loss': dispersity_peak_loss,
            'descriptor_loss': descriptor_loss,
            'reliability_loss': reliability_loss,
            'sosr_loss': sosr_loss,
            # 'std_loss': std_loss,
            'FA_des_loss': FA_des_loss,
            }
        return loss_total, loss_group

    def detector_selfsupervised_loss_dkd_dense_ext_restrict_modify_oriR_ratio_FA_bw(self, kpA, kpB, pmaskA, pmaskB, descA, descB, desc_mapA, desc_mapB, scoreddisA, scoreddisB, scoresA, scoresB, scores_mapA, scores_mapB, Homo, inv_Homo, inv_Homo_en, ori_allA, ori_allB, ori_all_patchA, ori_all_patchB, ori_kpA, ori_kpB, ori_kp_patchA, ori_kp_patchB, kmask_T_allA, kmask_T_allB, bin_allA, bin_allB, bin_kpA, bin_kpB, bin_T_kpA, bin_T_kpB, FA_flag, H, W, wrp=1, wpl=1, wdl=1, wrl=1, t_des=0.02, t_rel=1):
        # pmaskA: (BxMax_num) 32x350=11200
        batch_size = len(kpA)
        max_num = pmaskA.shape[-1] // batch_size    # 350
        dis_mean_total = 0
        dis_neighbor_mean_total = 0
        dis_peak_scored = 0
        dis_desc = 0
        dis_rel = 0
        desc_std = 0
        eps = 1e-12
        valid_batch_size = batch_size
        valid_batch_size_FA = 0
        countA, countB = 0, 0
        dis_desc_fa = 0
        # countA_T, countB_T = 0, 0
        for idx in range(batch_size):
            pntA, pntB = kpA[idx], kpB[idx]     # M X 2 (x,y)
            # kmask_TA, kmask_TB = kmask_T_allA[idx], kmask_T_allB[idx]
            pntA = pntA.float()
            pntB = pntB.float()

            # 剔除部分按压区域的点且保留在重叠区域的点
            numA, numB = pntA.shape[0], pntB.shape[0]
            # numA_T, numB_T = pntA[kmask_TA].shape[0], pntB[kmask_TB].shape[0]
            pmA, pmB = pmaskA[max_num * idx:max_num * idx + numA].bool(), pmaskB[max_num * idx:max_num * idx + numB].bool()
            pntA, pntB = pntA[pmA, :], pntB[pmB, :]
            new_numA, new_numB = pntA.shape[0], pntB.shape[0]
            
            pntA = (pntA + 1) / 2 * pntA.new_tensor([[W + 3, H - 1]]).to(pntA.device)
            pntB = (pntB + 1) / 2 * pntB.new_tensor([[W + 3, H - 1]]).to(pntB.device)

            # [120, 40] -> [120, 36],实际只取中心118x32区域的点对
            pntA[:, 0] -= 2
            pntB[:, 0] -= 2
            
            pntA_normalized = pntA / pntA.new_tensor([W - 1, H - 1]).to(pntA.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)
            pntB_normalized = pntB / pntB.new_tensor([W - 1, H - 1]).to(pntB.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)

            pntA_H = warp_points(pntA[:, :2], Homo[idx].squeeze(), device=self.device)  # 利用变换矩阵变换坐标点
            # pntA_H, mask_pointA = filter_points(pntA_H, torch.tensor([W, H], device=self.device), return_mask=True)
            pntB_invH = warp_points(pntB[:, :2], inv_Homo[idx].squeeze(), device=self.device)
            # pntB_invH, mask_pointB = filter_points(pntB_invH, torch.tensor([W, H], device=self.device), return_mask=True)
            
            current_descA, current_descB = descA[countA:countA+new_numA], descB[countB:countB+new_numB]
            cross_sim_AB_sp = current_descA @ current_descB.transpose(0, 1)
            
            # 黑白相似度
            current_binA, current_binB = bin_kpA[countA:countA+new_numA], bin_kpB[countB:countB+new_numB]   # [NA, 256] [NB_256]
            bin_distAB = current_binA.shape[-1] - (current_binA @ current_binB.transpose(0, 1)) - ((1 - current_binA) @ (1 - current_binB.transpose(0, 1))) # [NA, NB]

            # Net FA余弦相似度小
            if FA_flag[idx] == 1:
                FA_bin_mask = bin_distAB >= (1 - self.FA_bin_thr) * current_binA.shape[-1] 
                # print(current_binA.shape, bin_distAB[0, :])
                # print(FA_bin_mask.shape, torch.sum(FA_bin_mask))
                dis_desc_fa += (2 - torch.mean(torch.sqrt(2 * (1 - cross_sim_AB_sp[FA_bin_mask]) + eps)))

                valid_batch_size -= 1
                valid_batch_size_FA += 1
                countA += new_numA
                countB += new_numB
                continue
            
            # 真匹配的trans
            try:
                assert pntA_H.shape[0] > 0 and pntB_invH.shape[0] > 0 
                
                # 点对欧氏距离
                key_disAB = self.get_dis(pntA_H[:, :2], pntB[:, :2])
                key_disBA = self.get_dis(pntB_invH[:, :2], pntA[:, :2])
                pairAB_A, pairAB_B, dis_pairAB, _ = self.get_point_pair(key_disAB, dis_thre=self.correspond)  # p -> k # NTA(<1.5), NTA(<1.5), NTA(<1.5), NTA        
                pairBA_B, pairBA_A, dis_pairBA, _  = self.get_point_pair(key_disBA, dis_thre=self.correspond)  # p -> k # NTB(<1.5), NTB(<1.5), NTB(<1.5), NTB 
                
                # 点距离mask
                nn_maskAB = torch.zeros((pntA_H.shape[0], pntB.shape[0]), device=self.device) 
                nn_maskAB[pairAB_A, pairAB_B] = 1

                nn_maskBA = torch.zeros((pntB_invH.shape[0], pntA.shape[0]), device=self.device) 
                nn_maskBA[pairBA_B, pairBA_A] = 1

                # 点对曼哈顿距离
                key_manhattandisAB = self.get_manhattan_dis(pntA_H[:, :2], pntB[:, :2])
                key_manhattandisBA = self.get_manhattan_dis(pntB_invH[:, :2], pntA[:, :2])
                # print('pdis:', dis_pairAB.shape[0], dis_pairBA.shape[0])
                assert dis_pairAB.shape[0] > 0 and dis_pairBA.shape[0] > 0     

                pntA_H_normalized = pntA_H / pntA_H.new_tensor([W - 1, H - 1]).to(pntA_H.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)
                pntB_invH_normalized = pntB_invH / pntB_invH.new_tensor([W - 1, H - 1]).to(pntB_invH.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)

                # 用于score_map
                pntA_H_new = copy.deepcopy(pntA_H.detach())
                pntB_invH_new = copy.deepcopy(pntB_invH.detach())
                pntA_H_new[:, 0] += 2
                pntB_invH_new[:, 0] += 2
                
                pntA_H_normalized_new = pntA_H_new / pntA_H_new.new_tensor([W + 3, H - 1]).to(pntA_H.device) * 2 - 1

                pntB_invH_new = warp_points(pntB_invH_new[:, :2], inv_Homo_en[idx].squeeze(), device=self.device)       # 转到A上，而不是AT上
                
                pntB_invH_normalized_new = pntB_invH_new / pntB_invH_new.new_tensor([W + 3, H - 1]).to(pntB_invH.device) * 2 - 1 

                # PA VS PB 有一定偏移
                ori_kpA_ext = F.grid_sample(ori_allA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntA_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  
                ori_kpB_ext = F.grid_sample(ori_allB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntB_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  

                main_ori_maskATB = self.get_main_ori_consistence(ori_kpA[countA:countA+numA][pmA].unsqueeze(1), ori_kpB_ext)  # NTA x NTB 
                main_ori_maskBTA = self.get_main_ori_consistence(ori_kpB[countB:countB+numB][pmB].unsqueeze(1), ori_kpA_ext)  # NTB x NTA 
                
                # print('1_2:', main_ori_maskATB.shape[0])
                # exit()
                ori_kpA_patch_ext = F.grid_sample(ori_all_patchA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntA_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  
                ori_kpB_patch_ext = F.grid_sample(ori_all_patchB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntB_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  
                # print('1_2_1:', ori_kpA_patch_ext.shape[0])
                ori_maskATB = self.get_ori_consistence_ratio(ori_kp_patchA[countA:countA+numA][pmA, :], ori_kpB_patch_ext)  # NTA x NTB
                ori_maskBTA = self.get_ori_consistence_ratio(ori_kp_patchB[countB:countB+numB][pmB, :], ori_kpA_patch_ext)  # NTB x NTA
                # print('1_2_2:', ori_maskATB.shape[0])
                # match_maskAB = (nn_maskAB == 1) * main_ori_maskATB
                # match_maskBA = (nn_maskBA == 1) * main_ori_maskBTA
                # print(nn_maskAB.shape, main_ori_maskATB.shape, ori_maskATB.shape)
                match_maskAB = (nn_maskAB == 1) * main_ori_maskATB * (ori_maskATB >= self.ori_ratio)
                match_maskBA = (nn_maskBA == 1) * main_ori_maskBTA * (ori_maskBTA >= self.ori_ratio)
                # pairAB_A_new, pairAB_B_new = torch.where(match_maskAB == 1)
                # pairBA_B_new, pairBA_A_new = torch.where(match_maskBA == 1)
                # assert pairAB_A_new.shape[0] > 0 and pairBA_B_new.shape[0] > 0 

                # PA VS PAB 没有中心点距离偏移
                # 中心主方向一致性
                ori_kpAB_ext = F.grid_sample(ori_allB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntA_H_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  
                ori_kpBA_ext = F.grid_sample(ori_allA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntB_invH_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  
                main_ori_maskATAB = self.get_main_ori_consistence(ori_kpA[countA:countA+numA][pmA].unsqueeze(1), ori_kpAB_ext)  # NTAxNTA 
                main_ori_maskBTBA = self.get_main_ori_consistence(ori_kpB[countB:countB+numB][pmB].unsqueeze(1), ori_kpBA_ext)  # NTBxNTB 

                # 4x4邻域方向一致性
                ori_kpAB_patch_ext = F.grid_sample(ori_all_patchB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntA_H_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  
                ori_kpBA_patch_ext = F.grid_sample(ori_all_patchA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntB_invH_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  

                ori_maskATAB = self.get_ori_consistence_ratio(ori_kp_patchA[countA:countA+numA][pmA, :], ori_kpAB_patch_ext)  # NTAxNTA 
                ori_maskBTBA = self.get_ori_consistence_ratio(ori_kp_patchB[countB:countB+numB][pmB, :], ori_kpBA_patch_ext)  # NTBxNTB
                
                # vmaskAH = torch.diag(main_ori_maskATAB) == 1
                # vmaskBH = torch.diag(main_ori_maskBTBA) == 1
                # vmaskAH = torch.diag(main_ori_maskATAB * (ori_maskATAB >= self.ori_ratio)) == 1
                # vmaskBH = torch.diag(main_ori_maskBTBA * (ori_maskBTBA >= self.ori_ratio)) == 1
                # assert torch.sum(vmaskAH) > 0 and torch.sum(vmaskBH) > 0
                
                # 黑白相似度
                print((1 - self.FR_bin_thr) * current_binA.shape[-1])
                bin_maskATB = bin_distAB <= (1 - self.FR_bin_thr) * current_binA.shape[-1]  
                bin_maskBTA = bin_maskATB.transpose(0, 1)  

                match_maskAB = match_maskAB * bin_maskATB
                match_maskBA = match_maskBA * bin_maskBTA

                pairAB_A_new, pairAB_B_new = torch.where(match_maskAB == 1)
                pairBA_B_new, pairBA_A_new = torch.where(match_maskBA == 1)
                print('bin_mask:', pairAB_A_new.shape[0], pairBA_B_new.shape[0])
                assert pairAB_A_new.shape[0] > 0 and pairBA_B_new.shape[0] > 0 

                bin_kpAB_T = F.grid_sample(bin_allB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntA_H_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # [256, NTA]
                bin_kpBA_T = F.grid_sample(bin_allA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntB_invH_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # [256, NTB]
                bin_distATAB = bin_kpAB_T.shape[0] - (bin_T_kpA[countA:countA+numA][pmA, :] @ bin_kpAB_T) - ((1 - bin_T_kpA[countA:countA+numA][pmA, :]) @ (1 - bin_kpAB_T)) # [NTA, NTA]
                bin_distBTBA = bin_kpBA_T.shape[0] - (bin_T_kpB[countB:countB+numB][pmB, :] @ bin_kpBA_T) - ((1 - bin_T_kpB[countB:countB+numB][pmB, :]) @ (1 - bin_kpBA_T)) # [NTA, NTA]

                bin_maskATAB = bin_distATAB <= (1 - self.FR_bin_thr) * bin_kpAB_T.shape[0] 
                bin_maskBTBA = bin_distBTBA <= (1 - self.FR_bin_thr) * bin_kpBA_T.shape[0] 
                
                vmaskAH = torch.diag(main_ori_maskATAB * (ori_maskATAB >= self.ori_ratio) * bin_maskATAB) == 1
                vmaskBH = torch.diag(main_ori_maskBTBA * (ori_maskBTBA >= self.ori_ratio) * bin_maskBTBA) == 1
                # print('main_ori:', torch.sum(vmaskAH), torch.sum(vmaskBH))
                assert torch.sum(vmaskAH) > 0 and torch.sum(vmaskBH) > 0

                # SOSR: 简化的self-attention
                k_neighbor = 3
                cross_sim_AA_sp = current_descA @ current_descA.transpose(0, 1)
                cross_sim_BB_sp = current_descB @ current_descB.transpose(0, 1)
                # print('SOSR:', pairAB_A_new.shape[0], pairBA_B_new.shape[0])
                assert pairAB_A_new.shape[0] >= k_neighbor and pairBA_B_new.shape[0] >= k_neighbor 

                match_sim_AB_AA = cross_sim_AA_sp[pairAB_A_new, :][:, pairAB_A_new]
                match_sim_BA_BB = cross_sim_BB_sp[pairBA_B_new, :][:, pairBA_B_new]
                match_sim_AB_BB = cross_sim_BB_sp[pairAB_B_new, :][:, pairAB_B_new]
                match_sim_BA_AA = cross_sim_AA_sp[pairBA_A_new, :][:, pairBA_A_new]
                match_values_AB_AA, match_indices_AB_AA = torch.topk(match_sim_AB_AA, dim=1, k=k_neighbor, largest=False)
                match_values_BA_BB, match_indices_BA_BB = torch.topk(match_sim_BA_BB, dim=1, k=k_neighbor, largest=False)
                match_values_AB_BB_all = match_sim_AB_BB[:, match_indices_AB_AA]
                match_values_BA_AA_all = match_sim_BA_AA[:, match_indices_BA_BB]
                match_values_AB_BB = torch.diagonal(match_values_AB_BB_all, 0, dim1=0, dim2=1).transpose(0, 1)
                match_values_BA_AA = torch.diagonal(match_values_BA_AA_all, 0, dim1=0, dim2=1).transpose(0, 1)
                neighbor_dis_AB = (match_values_AB_AA - match_values_AB_BB) * (match_values_AB_AA - match_values_AB_BB)
                neighbor_dis_BA = (match_values_BA_BB - match_values_BA_AA) * (match_values_BA_BB - match_values_BA_AA)

                # PA VS PB
                valid_cross_sim_AB_sp_mean = torch.mean(cross_sim_AB_sp[match_maskAB == 1], dim=-1)
                novalid_cross_sim_AB_sp_mean = (torch.sum(torch.sum(cross_sim_AB_sp.detach(), 1), 0) - valid_cross_sim_AB_sp_mean * pairAB_A_new.shape[0]) / (new_numA * new_numB - pairAB_A_new.shape[0] + eps)
                valid_cross_sim_BA_sp_mean = torch.mean(cross_sim_AB_sp[match_maskBA.transpose(0, 1) == 1], dim=-1)
                novalid_cross_sim_BA_sp_mean = (torch.sum(torch.sum(cross_sim_AB_sp.detach(), 1), 0) - valid_cross_sim_BA_sp_mean * pairBA_B_new.shape[0]) / (new_numA * new_numB - pairBA_B_new.shape[0] + eps)

                valid_indexesA = torch.tensor(list(range(new_numA)), device=self.device)[pairAB_A_new]
                # cross_sim_BA_sp = current_descB @ current_descA.transpose(0, 1)
                cross_sim_AB_out_sp = torch.cat((cross_sim_AB_sp, torch.ones((new_numA, 1), device=cross_sim_AB_sp.device) * 2), dim=-1)      # NA X (NB + 1)
                # cross_sim_BA_out_sp = torch.cat((cross_sim_BA_sp, torch.ones((numB, 1), device=cross_sim_BA_sp.device)), dim=-1)      # NB X (NA + 1)
                # valid_indexesB = torch.tensor(list(range(numB)), device=self.device)[mask_pointB][pairBA_B]
                cross_sim_AB_out_sp[valid_indexesA, -1] = novalid_cross_sim_AB_sp_mean
                novalid_indexesA = torch.tensor(list(range(new_numA)), device=self.device)[cross_sim_AB_out_sp[:, -1]==2]
                cross_sim_AB_out_sp[novalid_indexesA, -1] = valid_cross_sim_AB_sp_mean

                soft_cross_sim_AtoB_sp = F.softmax((cross_sim_AB_out_sp - 1) / t_des, dim=-1)
                # soft_cross_sim_BtoA = F.softmax((cross_sim_BA_out - 1) / t_des, dim=-1)
                
                soft_valid_cross_sim_AB_sp = soft_cross_sim_AtoB_sp[:, :-1][match_maskAB==1]
                # soft_valid_cross_sim_BA = soft_cross_sim_BtoA[mask_pointB, :-1][pairBA_B, pairBA_A]
                soft_novalid_cross_sim_AB_sp = soft_cross_sim_AtoB_sp[novalid_indexesA, -1]
                # soft_novalid_cross_sim_BA = soft_cross_sim_BtoA[cross_sim_BA_out[:, -1]==1, -1]
                log_soft_valid_cross_sim_AB_sp = -torch.log(soft_valid_cross_sim_AB_sp + eps) * ori_maskATB[match_maskAB==1]
                # log_soft_valid_cross_sim_BA = -torch.log(soft_valid_cross_sim_BA + eps)
                log_soft_novalid_cross_sim_AB_sp = -torch.log(soft_novalid_cross_sim_AB_sp + eps)
                # log_soft_novalid_cross_sim_BA = -torch.log(soft_novalid_cross_sim_BA + eps)
                dis_cross_sim_mean_sp = torch.sum(torch.cat((log_soft_valid_cross_sim_AB_sp, log_soft_novalid_cross_sim_AB_sp), dim=-1), dim=-1) / new_numA

                # PA VS PAB
                # match_mask_A = copy.deepcopy(mask_pointA)
                # match_mask_B = copy.deepcopy(mask_pointB)
                match_mask_A = copy.deepcopy(vmaskAH)
                match_mask_B = copy.deepcopy(vmaskBH)

                cross_sim_AB = current_descA @ desc_mapB[idx, :, :, :].view(-1, H * W)
                cross_sim_AB_all = F.grid_sample(cross_sim_AB.view(-1, H, W).unsqueeze(0),
                                                pntA_H_normalized[vmaskAH, :].detach().view(1, 1, -1, 2),
                                                mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NA x match_nA

                valid_cross_sim_AB_mean = torch.trace(cross_sim_AB_all[match_mask_A, :]) / cross_sim_AB_all[match_mask_A, :].shape[0]
                # novalid_cross_sim_AB_mean = (torch.sum(torch.sum(cross_sim_AB.detach(), 1), 1) - valid_cross_sim_AB_mean * pairAB_A.shape[0]) / (new_numA * H * W - pairAB_A.shape[0])

                cross_sim_BA = current_descB @ desc_mapA[idx, :, :, :].view(-1, H * W)   # M x H x W
                cross_sim_BA_all = F.grid_sample(cross_sim_BA.view(-1, H, W).unsqueeze(0),
                                                pntB_invH_normalized[vmaskBH, :].detach().view(1, 1, -1, 2),
                                                mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NB x match_nB

                valid_cross_sim_BA_mean = torch.trace(cross_sim_BA_all[match_mask_B, :]) / cross_sim_BA_all[match_mask_B, :].shape[0]
                # novalid_cross_sim_BA_mean = (torch.sum(torch.sum(cross_sim_BA.detach(), 1), 1) - valid_cross_sim_BA_mean * pairBA_B.shape[0]) / (new_numB * H * W - pairBA_B.shape[0])

                cross_sim_AB_out = torch.cat((cross_sim_AB, torch.ones((new_numA, 1), device=cross_sim_AB.device)), dim=-1)      # NA X (H X W + 1)
                cross_sim_BA_out = torch.cat((cross_sim_BA, torch.ones((new_numB, 1), device=cross_sim_BA.device)), dim=-1)      # NB X (H X W + 1)

                # cross_sim_AB_out[mask_pointA, -1] -= 1
                # cross_sim_BA_out[mask_pointB, -1] -= 1
                # cross_sim_AB_out[match_mask_A, -1] -= 1
                cross_sim_AB_out[match_mask_A, -1] = novalid_cross_sim_AB_sp_mean
                cross_sim_AB_out[match_mask_A==False, -1] = valid_cross_sim_AB_mean

                cross_sim_BA_out[match_mask_B, -1] = novalid_cross_sim_BA_sp_mean
                cross_sim_BA_out[match_mask_B==False, -1] = valid_cross_sim_BA_mean

                soft_cross_sim_AtoB = F.softmax((cross_sim_AB_out - 1) / t_des, dim=-1)         # NA X (H X W + 1)
                soft_cross_sim_BtoA = F.softmax((cross_sim_BA_out - 1) / t_des, dim=-1)         # NB X (H X W + 1)
                soft_cross_sim_AB_all = F.grid_sample(soft_cross_sim_AtoB[:, :-1].view(-1, H, W).unsqueeze(0),
                                                    pntA_H_normalized[vmaskAH, :].detach().view(1, 1, -1, 2),
                                                    mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NA x match_nA
                
                soft_cross_sim_BA_all = F.grid_sample(soft_cross_sim_BtoA[:, :-1].view(-1, H, W).unsqueeze(0),
                                                    pntB_invH_normalized[vmaskBH, :].detach().view(1, 1, -1, 2),
                                                    mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NB x match_nB
                # soft_valid_cross_sim_AB_all = soft_cross_sim_AB_all[mask_pointA, :]             # repeat_nA x repeat_nA
                # soft_valid_cross_sim_BA_all = soft_cross_sim_BA_all[mask_pointB, :]             # repeat_nB x repeat_nB

                soft_valid_cross_sim_AB_all = soft_cross_sim_AB_all[match_mask_A, :]             # match_nA x match_nA
                soft_valid_cross_sim_BA_all = soft_cross_sim_BA_all[match_mask_B, :]             # match_nB x match_nB

                valid_mask_AB = torch.eye(soft_valid_cross_sim_AB_all.shape[0]) == 1
                valid_mask_BA = torch.eye(soft_valid_cross_sim_BA_all.shape[0]) == 1

                # 取对角线
                soft_valid_cross_sim_AB = soft_valid_cross_sim_AB_all[valid_mask_AB]
                soft_valid_cross_sim_BA = soft_valid_cross_sim_BA_all[valid_mask_BA]

                # soft_novalid_cross_sim_AB = soft_cross_sim_AtoB[mask_pointA==False, -1]              # (NA-repeat_nA) x 1
                # soft_novalid_cross_sim_BA = soft_cross_sim_BtoA[mask_pointB==False, -1]
                soft_novalid_cross_sim_AB = soft_cross_sim_AtoB[match_mask_A==False, -1]               # (NA-match_nA) x 1
                soft_novalid_cross_sim_BA = soft_cross_sim_BtoA[match_mask_B==False, -1]
                # print(soft_novalid_cross_sim_AB, soft_novalid_cross_sim_BA)

                log_soft_valid_cross_sim_AB = -torch.log(soft_valid_cross_sim_AB + eps) * torch.diag(ori_maskATAB)[vmaskAH] * torch.diag(bin_distATAB)[vmaskAH] / bin_kpAB_T.shape[0]
                log_soft_valid_cross_sim_BA = -torch.log(soft_valid_cross_sim_BA + eps) * torch.diag(ori_maskBTBA)[vmaskBH] * torch.diag(bin_distBTBA)[vmaskBH] / bin_kpBA_T.shape[0]
                log_soft_novalid_cross_sim_AB = -torch.log(soft_novalid_cross_sim_AB + eps)
                log_soft_novalid_cross_sim_BA = -torch.log(soft_novalid_cross_sim_BA + eps)

                dis_cross_sim_mean = torch.sum(torch.cat((log_soft_valid_cross_sim_AB, log_soft_valid_cross_sim_BA, log_soft_novalid_cross_sim_AB, log_soft_novalid_cross_sim_BA), dim=-1), dim=-1) / (pntA.shape[0] + pntB.shape[0])

                # valid_cross_sim_AB = cross_sim_AB[mask_pointA, :]   # repeat_nA x (H X W)
                # valid_cross_sim_BA = cross_sim_BA[mask_pointB, :]   # repeat_nB x (H X W)
                exp_valid_cross_sim_AtoB = torch.exp((cross_sim_AB - 1) / t_rel).view(-1, H, W)
                exp_valid_cross_sim_BtoA = torch.exp((cross_sim_BA - 1) / t_rel).view(-1, H, W)
                exp_valid_cross_sim_AB_all = F.grid_sample(exp_valid_cross_sim_AtoB.unsqueeze(0),
                                                        pntA_H_normalized.detach().view(1, 1, -1, 2),
                                                        mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # repeat_nA x repeat_nA
                
                exp_valid_cross_sim_BA_all = F.grid_sample(exp_valid_cross_sim_BtoA.unsqueeze(0),
                                                        pntB_invH_normalized.detach().view(1, 1, -1, 2),
                                                        mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # repeat_nB x repeat_nB

                repeat_mask_AB = torch.eye(exp_valid_cross_sim_AB_all.shape[0]) == 1
                repeat_mask_BA = torch.eye(exp_valid_cross_sim_BA_all.shape[0]) == 1
                rel_valid_cross_sim_AB = exp_valid_cross_sim_AB_all[repeat_mask_AB]
                rel_valid_cross_sim_BA = exp_valid_cross_sim_BA_all[repeat_mask_BA]

                # pntA_H_normalized_new = copy.deepcopy(pntA_H_normalized.detach())
                # pntB_invH_normalized_new = copy.deepcopy(pntB_invH_normalized.detach())

                # pntA_H_normalized_new[:, 0] += 2
                # pntB_invH_normalized_new[:, 0] += 2

                scoresAB_all = F.grid_sample(scores_mapB[idx, :, :, :].unsqueeze(0),
                                            pntA_H_normalized_new.view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)      # 1 x repeat_nA

                scoresBA_all = F.grid_sample(scores_mapA[idx, :, :, :].unsqueeze(0),
                                            pntB_invH_normalized_new.view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)      # 1 x repeat_nB

                scores_AAB = scoresA[idx][pmA] * scoresAB_all
                scores_BBA = scoresB[idx][pmB] * scoresBA_all
                scores_sum_AAB = torch.sum(scores_AAB, dim=-1)
                scores_sum_BBA = torch.sum(scores_BBA, dim=-1)
                scores_normalize_AAB = scores_AAB / (scores_sum_AAB + eps)
                scores_normalize_BBA = scores_BBA / (scores_sum_BBA + eps)
                rel_meanA = torch.sum(scores_normalize_AAB * (1 - rel_valid_cross_sim_AB), dim=-1) / pntA_H_normalized_new.shape[0]
                rel_meanB = torch.sum(scores_normalize_BBA * (1 - rel_valid_cross_sim_BA), dim=-1) / pntB_invH_normalized_new.shape[0]

                # # 熵loss
                # current_descA_std, current_descB_std = descA_std[countA:countA+new_numA], descB_std[countB:countB+new_numB]
                # desc_std += torch.mean(current_descA_std) + torch.mean(current_descB_std)

                countA += new_numA
                countB += new_numB
                # countA_T += numA_T
                # countB_T += numB_T

                dis_neighbor_mean_total += torch.mean(torch.sum(neighbor_dis_AB, dim=1)) + torch.mean(torch.sum(neighbor_dis_BA, dim=1))
                dis_desc += dis_cross_sim_mean_sp
                dis_desc += dis_cross_sim_mean

                dis_pair_meanAB = torch.mean(key_manhattandisAB[pairAB_A, pairAB_B])
                dis_pair_meanBA = torch.mean(key_manhattandisBA[pairBA_B, pairBA_A])

                dis_peak_mean = torch.mean(torch.cat((scoreddisA[idx][pmA], scoreddisB[idx][pmB]), dim=0))
                # dis_peak_meanB = torch.mean(scoreddisB[idx])
                
                dis_mean_total += dis_pair_meanAB + dis_pair_meanBA
                dis_peak_scored += dis_peak_mean

                dis_rel += rel_meanA + rel_meanB
                # # Penalty
                # scores_mean += (-torch.log(torch.mean(scoresA[idx], dim=-1) + eps) - torch.log(torch.mean(scoresB[idx], dim=-1) + eps)) 
                # print(scores_mean)
            except:
                # dis_mean_total += 0
                # dis_peak_scored += 0
                # dis_desc += 0
                # dis_rel += 0
                # print('Overlapping too small or Repeatable point pairs distance is greater than correspond(1.5):', pntA.shape[0], pntA_H.shape[0], pntB.shape[0], pntB_invH.shape[0], dis_pairAB.shape[0], dis_pairBA.shape[0])
                valid_batch_size -= 1
                countA += new_numA
                countB += new_numB
                # countA_T += numA_T
                # countB_T += numB_T

        valid_batch_size = valid_batch_size if valid_batch_size > 0 else eps
        # Reprojection Loss 
        reprojection_loss = dis_mean_total / (valid_batch_size * 2)
        # Dispersity Peak Loss
        dispersity_peak_loss = dis_peak_scored / valid_batch_size
        # NRE Loss
        descriptor_loss = dis_desc / (2 * valid_batch_size)
        # Reliability Loss
        reliability_loss = dis_rel / (valid_batch_size * 2)
        # SOSR Loss
        sosr_loss = dis_neighbor_mean_total / ((valid_batch_size * 2))
        # # Entropy loss
        # std_loss = (valid_batch_size * 2) / desc_std  
        # # Score Penalty
        # score_penalty = scores_mean / (valid_batch_size * 2)
        # FA Desc loss
        FA_des_loss = dis_desc_fa / valid_batch_size_FA if valid_batch_size_FA > 0 else 0

        loss_total = wrp * reprojection_loss + wpl * dispersity_peak_loss + wdl * descriptor_loss + wrl * reliability_loss + sosr_loss + FA_des_loss
        loss_group = {
            'reprojection_loss': reprojection_loss, 
            'dispersity_peak_loss': dispersity_peak_loss,
            'descriptor_loss': descriptor_loss,
            'reliability_loss': reliability_loss,
            'sosr_loss': sosr_loss,
            # 'std_loss': std_loss,
            'FA_des_loss': FA_des_loss,
            }
        return loss_total, loss_group

    def detector_selfsupervised_loss_dkd_patch_ext_restrict_modify_oriR_ratio_FA_bw(self, kpA, kpB, pmaskA, pmaskB, descA, descB, desc_mapA, desc_mapB, scoreddisA, scoreddisB, scoresA, scoresB, scores_mapA, scores_mapB, Homo, inv_Homo, inv_Homo_en, ori_all_patchA, ori_all_patchB, ori_kp_patchA, ori_kp_patchB, bin_allA, bin_allB, bin_kpA, bin_kpB, FA_flag, H, W, wrp=1, wpl=1, wdl=1, wrl=1, t_des=0.02, t_rel=1):
        # pmaskA: (BxMax_num) 32x350=11200
        batch_size = len(kpA)
        max_num = pmaskA.shape[-1] // batch_size    # 350
        dis_mean_total = 0
        dis_neighbor_mean_total = 0
        dis_peak_scored = 0
        dis_desc = 0
        dis_rel = 0
        desc_std = 0
        eps = 1e-12
        valid_batch_size = batch_size
        valid_batch_size_FA = 0
        countA, countB = 0, 0
        dis_desc_fa = 0
        # countA_T, countB_T = 0, 0
        for idx in range(batch_size):
            pntA, pntB = kpA[idx], kpB[idx]     # M X 2 (x,y)
            # kmask_TA, kmask_TB = kmask_T_allA[idx], kmask_T_allB[idx]
            pntA = pntA.float()
            pntB = pntB.float()

            # 剔除部分按压区域的点,且保留在重叠区域的点
            numA, numB = pntA.shape[0], pntB.shape[0]
            # numA_T, numB_T = pntA[kmask_TA].shape[0], pntB[kmask_TB].shape[0]
            pmA, pmB = pmaskA[max_num * idx:max_num * idx + numA].bool(), pmaskB[max_num * idx:max_num * idx + numB].bool()
            pntA, pntB = pntA[pmA, :], pntB[pmB, :]
            new_numA, new_numB = pntA.shape[0], pntB.shape[0]       
            
            pntA = (pntA + 1) / 2 * pntA.new_tensor([[W + 3, H - 1]]).to(pntA.device)
            pntB = (pntB + 1) / 2 * pntB.new_tensor([[W + 3, H - 1]]).to(pntB.device)

            # [120, 40] -> [120, 36],实际只取中心118x32区域的点对
            pntA[:, 0] -= 2
            pntB[:, 0] -= 2
            
            pntA_normalized = pntA / pntA.new_tensor([W - 1, H - 1]).to(pntA.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)
            pntB_normalized = pntB / pntB.new_tensor([W - 1, H - 1]).to(pntB.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)

            pntA_H = warp_points(pntA[:, :2], Homo[idx].squeeze(), device=self.device)  # 利用变换矩阵变换坐标点
            pntA_H, mask_pointA = filter_points(pntA_H, torch.tensor([W, H], device=self.device), return_mask=True)
            pntB_invH = warp_points(pntB[:, :2], inv_Homo[idx].squeeze(), device=self.device)
            pntB_invH, mask_pointB = filter_points(pntB_invH, torch.tensor([W, H], device=self.device), return_mask=True)
            
            current_descA, current_descB = descA[countA:countA+new_numA], descB[countB:countB+new_numB]
            cross_sim_AB_sp = current_descA @ current_descB.transpose(0, 1)
            
            # 黑白相似度
            current_binA, current_binB = bin_kpA[countA:countA+new_numA], bin_kpB[countB:countB+new_numB]   # [NA, 256] [NB_256]
            bin_distAB = current_binA.shape[-1] - (current_binA @ current_binB.transpose(0, 1)) - ((1 - current_binA) @ (1 - current_binB.transpose(0, 1))) # [NA, NB]

            # Net FA余弦相似度小
            if FA_flag[idx] == 1:
                FA_bin_mask = bin_distAB >= (1 - self.FA_bin_thr) * current_binA.shape[-1] 
                # print(current_binA.shape, bin_distAB[0, :])
                # print(FA_bin_mask.shape, torch.sum(FA_bin_mask))
                dis_desc_fa += (2 - torch.mean(torch.sqrt(2 * (1 - cross_sim_AB_sp[FA_bin_mask]) + eps)))

                valid_batch_size -= 1
                valid_batch_size_FA += 1
                countA += new_numA
                countB += new_numB
                continue
            
            # 真匹配的trans
            try:
                assert pntA_H.shape[0] > 0 and pntB_invH.shape[0] > 0 
                
                # 点对欧氏距离
                key_disAB = self.get_dis(pntA_H[:, :2], pntB[:, :2])
                key_disBA = self.get_dis(pntB_invH[:, :2], pntA[:, :2])
                pairAB_A, pairAB_B, dis_pairAB, _ = self.get_point_pair(key_disAB, dis_thre=self.correspond)  # p -> k # NTA(<1.5), NTA(<1.5), NTA(<1.5), NTA        
                pairBA_B, pairBA_A, dis_pairBA, _  = self.get_point_pair(key_disBA, dis_thre=self.correspond)  # p -> k # NTB(<1.5), NTB(<1.5), NTB(<1.5), NTB 
                
                # 点距离mask
                nn_maskAB = torch.zeros((pntA_H.shape[0], pntB.shape[0]), device=self.device) 
                nn_maskAB[pairAB_A, pairAB_B] = 1

                nn_maskBA = torch.zeros((pntB_invH.shape[0], pntA.shape[0]), device=self.device) 
                nn_maskBA[pairBA_B, pairBA_A] = 1

                # 点对曼哈顿距离
                key_manhattandisAB = self.get_manhattan_dis(pntA_H[:, :2], pntB[:, :2])
                key_manhattandisBA = self.get_manhattan_dis(pntB_invH[:, :2], pntA[:, :2])
                # print('pdis:', dis_pairAB.shape[0], dis_pairBA.shape[0])
                assert dis_pairAB.shape[0] > 0 and dis_pairBA.shape[0] > 0     

                pntA_H_normalized = pntA_H / pntA_H.new_tensor([W - 1, H - 1]).to(pntA_H.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)
                pntB_invH_normalized = pntB_invH / pntB_invH.new_tensor([W - 1, H - 1]).to(pntB_invH.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)

                # 用于score_map
                pntA_H_new = copy.deepcopy(pntA_H.detach())
                pntB_invH_new = copy.deepcopy(pntB_invH.detach())
                pntA_H_new[:, 0] += 2
                pntB_invH_new[:, 0] += 2
                
                pntA_H_normalized_new = pntA_H_new / pntA_H_new.new_tensor([W + 3, H - 1]).to(pntA_H.device) * 2 - 1

                # pntB_invH_new = warp_points(pntB_invH_new[:, :2], inv_Homo_en[idx].squeeze(), device=self.device)       # 转到A上，而不是AT上
                
                pntB_invH_normalized_new = pntB_invH_new / pntB_invH_new.new_tensor([W + 3, H - 1]).to(pntB_invH.device) * 2 - 1 

                # # PA VS PB 有一定偏移
                # ori_kpA_ext = F.grid_sample(ori_allA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                #                             pntA_normalized.detach().view(1, 1, -1, 2),
                #                             mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  
                # ori_kpB_ext = F.grid_sample(ori_allB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                #                             pntB_normalized.detach().view(1, 1, -1, 2),
                #                             mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  

                # main_ori_maskATB = self.get_main_ori_consistence(ori_kpA[countA:countA+numA][pmA].unsqueeze(1), ori_kpB_ext)  # NTA x NTB 
                # main_ori_maskBTA = self.get_main_ori_consistence(ori_kpB[countB:countB+numB][pmB].unsqueeze(1), ori_kpA_ext)  # NTB x NTA 
                
                # print('1_2:', main_ori_maskATB.shape[0])
                # exit()
                # ori_kpA_patch_ext = F.grid_sample(ori_all_patchA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                #                             pntA_normalized.detach().view(1, 1, -1, 2),
                #                             mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  
                # ori_kpB_patch_ext = F.grid_sample(ori_all_patchB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                #                             pntB_normalized.detach().view(1, 1, -1, 2),
                #                             mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  
                # print('1_2_1:', pntB_invH_normalized_new.shape[0])
                ori_maskATB = self.get_ori_pattern(ori_kp_patchA[countA:countA+new_numA], ori_kp_patchB[countB:countB+new_numB])  # NTA x NTB
                # print('1_2_2:', ori_maskATB.shape)
                ori_maskBTA = ori_maskATB.transpose(0, 1)
                # print('1_2_2:', ori_maskATB.shape[0])
                # match_maskAB = (nn_maskAB == 1) * main_ori_maskATB
                # match_maskBA = (nn_maskBA == 1) * main_ori_maskBTA
                # print(nn_maskAB.shape, main_ori_maskATB.shape, ori_maskATB.shape)
                match_maskAB = (nn_maskAB == 1) * (ori_maskATB >= self.ori_ratio)[mask_pointA, :]           # repeatNA X NTB
                match_maskBA = (nn_maskBA == 1) * (ori_maskBTA >= self.ori_ratio)[mask_pointB, :]           # repeatNB X NTA
                # pairAB_A_new, pairAB_B_new = torch.where(match_maskAB == 1)
                # pairBA_B_new, pairBA_A_new = torch.where(match_maskBA == 1)
                # assert pairAB_A_new.shape[0] > 0 and pairBA_B_new.shape[0] > 0 

                # # PA VS PAB 没有中心点距离偏移
                # # 中心主方向一致性
                # ori_kpAB_ext = F.grid_sample(ori_allB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                #                             pntA_H_normalized.detach().view(1, 1, -1, 2),
                #                             mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  
                # ori_kpBA_ext = F.grid_sample(ori_allA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                #                             pntB_invH_normalized.detach().view(1, 1, -1, 2),
                #                             mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  
                # main_ori_maskATAB = self.get_main_ori_consistence(ori_kpA[countA:countA+new_numA].unsqueeze(1), ori_kpAB_ext)  # NTAxNTA 
                # main_ori_maskBTBA = self.get_main_ori_consistence(ori_kpB[countB:countB+new_numB].unsqueeze(1), ori_kpBA_ext)  # NTBxNTB 

                # 4x4邻域方向一致性
                ori_kpAB_patch_ext = F.grid_sample(ori_all_patchB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntA_H_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  
                ori_kpBA_patch_ext = F.grid_sample(ori_all_patchA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntB_invH_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  
                # print('1_2_4:', ori_kpAB_patch_ext.shape)
                ori_maskATAB = self.get_ori_pattern(ori_kp_patchA[countA:countA+new_numA], ori_kpAB_patch_ext.transpose(0, 1))  # NTA x repeatNA
                ori_maskBTBA = self.get_ori_pattern(ori_kp_patchB[countB:countB+new_numB], ori_kpBA_patch_ext.transpose(0, 1))  # NTB x repeatNB
                
                ori_maskATAB = ori_maskATAB[mask_pointA, :]
                ori_maskBTBA = ori_maskBTBA[mask_pointB, :]
                # vmaskAH = torch.diag(main_ori_maskATAB) == 1
                # vmaskBH = torch.diag(main_ori_maskBTBA) == 1
                # vmaskAH = torch.diag(main_ori_maskATAB * (ori_maskATAB >= self.ori_ratio)) == 1
                # vmaskBH = torch.diag(main_ori_maskBTBA * (ori_maskBTBA >= self.ori_ratio)) == 1
                # assert torch.sum(vmaskAH) > 0 and torch.sum(vmaskBH) > 0
                
                # 黑白相似度
                bin_maskATB = bin_distAB <= (1 - self.FR_bin_thr) * current_binA.shape[-1]  
                bin_maskBTA = bin_maskATB.transpose(0, 1)  

                match_maskAB = match_maskAB * bin_maskATB[mask_pointA, :]               # repeatNA X NB
                match_maskBA = match_maskBA * bin_maskBTA[mask_pointB, :]               # repeatNB X NA

                pairAB_A_new, pairAB_B_new = torch.where(match_maskAB == 1)
                pairBA_B_new, pairBA_A_new = torch.where(match_maskBA == 1)
                # print('bin_mask:', pairAB_A_new.shape[0], pairBA_B_new.shape[0])
                assert pairAB_A_new.shape[0] > 0 and pairBA_B_new.shape[0] > 0 

                bin_kpAB_T = F.grid_sample(bin_allB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntA_H_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # [256, repeatNA]
                bin_kpBA_T = F.grid_sample(bin_allA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntB_invH_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # [256, repeatNB]
                bin_distATAB = bin_kpAB_T.shape[0] - (current_binA @ bin_kpAB_T) - ((1 - current_binA) @ (1 - bin_kpAB_T)) # [NTA, repeatNA]
                bin_distBTBA = bin_kpBA_T.shape[0] - (current_binB @ bin_kpBA_T) - ((1 - current_binB) @ (1 - bin_kpBA_T)) # [NTB, repeatNB]

                bin_maskATAB = bin_distATAB <= (1 - self.FR_bin_thr) * bin_kpAB_T.shape[0] 
                bin_maskBTBA = bin_distBTBA <= (1 - self.FR_bin_thr) * bin_kpBA_T.shape[0] 
                bin_maskATAB = bin_maskATAB[mask_pointA, :]
                bin_maskBTBA = bin_maskBTBA[mask_pointB, :]

                vmaskAH = torch.diag((ori_maskATAB >= self.ori_ratio) * bin_maskATAB) == 1
                vmaskBH = torch.diag((ori_maskBTBA >= self.ori_ratio) * bin_maskBTBA) == 1
                # print('main_ori:', torch.sum(vmaskAH), torch.sum(vmaskBH))
                assert torch.sum(vmaskAH) > 0 and torch.sum(vmaskBH) > 0

                # SOSR: 简化的self-attention
                k_neighbor = 3
                cross_sim_AA_sp = current_descA @ current_descA.transpose(0, 1)
                cross_sim_BB_sp = current_descB @ current_descB.transpose(0, 1)
                # print('SOSR:', pairAB_A_new.shape[0], pairBA_B_new.shape[0])
                assert pairAB_A_new.shape[0] >= k_neighbor and pairBA_B_new.shape[0] >= k_neighbor 

                match_sim_AB_AA = cross_sim_AA_sp[mask_pointA, :][:, mask_pointA][pairAB_A_new, :][:, pairAB_A_new]
                match_sim_BA_BB = cross_sim_BB_sp[mask_pointB, :][:, mask_pointB][pairBA_B_new, :][:, pairBA_B_new]
                match_sim_AB_BB = cross_sim_BB_sp[pairAB_B_new, :][:, pairAB_B_new]
                match_sim_BA_AA = cross_sim_AA_sp[pairBA_A_new, :][:, pairBA_A_new]
                match_values_AB_AA, match_indices_AB_AA = torch.topk(match_sim_AB_AA, dim=1, k=k_neighbor, largest=False)
                match_values_BA_BB, match_indices_BA_BB = torch.topk(match_sim_BA_BB, dim=1, k=k_neighbor, largest=False)
                match_values_AB_BB_all = match_sim_AB_BB[:, match_indices_AB_AA]
                match_values_BA_AA_all = match_sim_BA_AA[:, match_indices_BA_BB]
                match_values_AB_BB = torch.diagonal(match_values_AB_BB_all, 0, dim1=0, dim2=1).transpose(0, 1)
                match_values_BA_AA = torch.diagonal(match_values_BA_AA_all, 0, dim1=0, dim2=1).transpose(0, 1)
                neighbor_dis_AB = (match_values_AB_AA - match_values_AB_BB) * (match_values_AB_AA - match_values_AB_BB)
                neighbor_dis_BA = (match_values_BA_BB - match_values_BA_AA) * (match_values_BA_BB - match_values_BA_AA)
                # print('1_1')
                # PA VS PB
                valid_cross_sim_AB_sp_mean = torch.mean(cross_sim_AB_sp[mask_pointA, :][match_maskAB == 1], dim=-1)
                novalid_cross_sim_AB_sp_mean = (torch.sum(torch.sum(cross_sim_AB_sp[mask_pointA, :].detach(), 1), 0) - valid_cross_sim_AB_sp_mean * pairAB_A_new.shape[0]) / (cross_sim_AB_sp[mask_pointA, :].shape[0] * new_numB - pairAB_A_new.shape[0] + eps)
                valid_cross_sim_BA_sp_mean = torch.mean(cross_sim_AB_sp[:, mask_pointB][match_maskBA.transpose(0, 1) == 1], dim=-1)
                novalid_cross_sim_BA_sp_mean = (torch.sum(torch.sum(cross_sim_AB_sp[:, mask_pointB].detach(), 1), 0) - valid_cross_sim_BA_sp_mean * pairBA_B_new.shape[0]) / (new_numA * cross_sim_AB_sp[:, mask_pointB].shape[1] - pairBA_B_new.shape[0] + eps)

                valid_indexesA = torch.tensor(list(range(cross_sim_AB_sp[mask_pointA, :].shape[0])), device=self.device)[pairAB_A_new]
                # cross_sim_BA_sp = current_descB @ current_descA.transpose(0, 1)
                cross_sim_AB_out_sp = torch.cat((cross_sim_AB_sp[mask_pointA, :], torch.ones((cross_sim_AB_sp[mask_pointA, :].shape[0], 1), device=cross_sim_AB_sp.device) * 2), dim=-1)      # NA X (NB + 1)
                # cross_sim_BA_out_sp = torch.cat((cross_sim_BA_sp, torch.ones((numB, 1), device=cross_sim_BA_sp.device)), dim=-1)      # NB X (NA + 1)
                # valid_indexesB = torch.tensor(list(range(numB)), device=self.device)[mask_pointB][pairBA_B]
                # print('1_2')
                cross_sim_AB_out_sp[valid_indexesA, -1] = novalid_cross_sim_AB_sp_mean
                novalid_indexesA = torch.tensor(list(range(cross_sim_AB_sp[mask_pointA, :].shape[0])), device=self.device)[cross_sim_AB_out_sp[:, -1]==2]
                cross_sim_AB_out_sp[novalid_indexesA, -1] = valid_cross_sim_AB_sp_mean

                soft_cross_sim_AtoB_sp = F.softmax((cross_sim_AB_out_sp - 1) / t_des, dim=-1)
                # soft_cross_sim_BtoA = F.softmax((cross_sim_BA_out - 1) / t_des, dim=-1)
                # print('1_3')
                soft_valid_cross_sim_AB_sp = soft_cross_sim_AtoB_sp[:, :-1][match_maskAB==1]
                # soft_valid_cross_sim_BA = soft_cross_sim_BtoA[mask_pointB, :-1][pairBA_B, pairBA_A]
                soft_novalid_cross_sim_AB_sp = soft_cross_sim_AtoB_sp[novalid_indexesA, -1]
                # soft_novalid_cross_sim_BA = soft_cross_sim_BtoA[cross_sim_BA_out[:, -1]==1, -1]
                log_soft_valid_cross_sim_AB_sp = -torch.log(soft_valid_cross_sim_AB_sp + eps) * ori_maskATB[mask_pointA, :][match_maskAB==1] * (1 - bin_distAB[mask_pointA, :][match_maskAB==1] / current_binA.shape[-1])
                # log_soft_valid_cross_sim_BA = -torch.log(soft_valid_cross_sim_BA + eps)
                log_soft_novalid_cross_sim_AB_sp = -torch.log(soft_novalid_cross_sim_AB_sp + eps)
                # log_soft_novalid_cross_sim_BA = -torch.log(soft_novalid_cross_sim_BA + eps)
                dis_cross_sim_mean_sp = torch.sum(torch.cat((log_soft_valid_cross_sim_AB_sp, log_soft_novalid_cross_sim_AB_sp), dim=-1), dim=-1) / cross_sim_AB_sp[mask_pointA, :].shape[0]
                # print(2)
                # PA VS PAB
                # match_mask_A = copy.deepcopy(mask_pointA)
                # match_mask_B = copy.deepcopy(mask_pointB)
                match_mask_A = copy.deepcopy(vmaskAH)
                match_mask_B = copy.deepcopy(vmaskBH)

                cross_sim_AB = current_descA @ desc_mapB[idx, :, :, :].view(-1, H * W)
                cross_sim_AB = cross_sim_AB[mask_pointA, :]
                cross_sim_AB_all = F.grid_sample(cross_sim_AB.view(-1, H, W).unsqueeze(0),
                                                pntA_H_normalized[vmaskAH, :].detach().view(1, 1, -1, 2),
                                                mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NA x match_nA
                valid_cross_sim_AB_mean = torch.trace(cross_sim_AB_all[match_mask_A, :]) / cross_sim_AB_all[match_mask_A, :].shape[0]
                # novalid_cross_sim_AB_mean = (torch.sum(torch.sum(cross_sim_AB.detach(), 1), 1) - valid_cross_sim_AB_mean * pairAB_A.shape[0]) / (new_numA * H * W - pairAB_A.shape[0])

                cross_sim_BA = current_descB @ desc_mapA[idx, :, :, :].view(-1, H * W)   # M x H x W
                cross_sim_BA = cross_sim_BA[mask_pointB, :]
                cross_sim_BA_all = F.grid_sample(cross_sim_BA.view(-1, H, W).unsqueeze(0),
                                                pntB_invH_normalized[vmaskBH, :].detach().view(1, 1, -1, 2),
                                                mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NB x match_nB
                valid_cross_sim_BA_mean = torch.trace(cross_sim_BA_all[match_mask_B, :]) / cross_sim_BA_all[match_mask_B, :].shape[0]
                # novalid_cross_sim_BA_mean = (torch.sum(torch.sum(cross_sim_BA.detach(), 1), 1) - valid_cross_sim_BA_mean * pairBA_B.shape[0]) / (new_numB * H * W - pairBA_B.shape[0])

                cross_sim_AB_out = torch.cat((cross_sim_AB, torch.ones((cross_sim_AB.shape[0], 1), device=cross_sim_AB.device)), dim=-1)      # NA X (H X W + 1)
                cross_sim_BA_out = torch.cat((cross_sim_BA, torch.ones((cross_sim_BA.shape[0], 1), device=cross_sim_BA.device)), dim=-1)      # NB X (H X W + 1)
                # print(3)
                # cross_sim_AB_out[mask_pointA, -1] -= 1
                # cross_sim_BA_out[mask_pointB, -1] -= 1
                # cross_sim_AB_out[match_mask_A, -1] -= 1
                cross_sim_AB_out[match_mask_A, -1] = novalid_cross_sim_AB_sp_mean
                cross_sim_AB_out[match_mask_A==False, -1] = valid_cross_sim_AB_mean

                cross_sim_BA_out[match_mask_B, -1] = novalid_cross_sim_BA_sp_mean
                cross_sim_BA_out[match_mask_B==False, -1] = valid_cross_sim_BA_mean

                soft_cross_sim_AtoB = F.softmax((cross_sim_AB_out - 1) / t_des, dim=-1)         # NA X (H X W + 1)
                soft_cross_sim_BtoA = F.softmax((cross_sim_BA_out - 1) / t_des, dim=-1)         # NB X (H X W + 1)
                soft_cross_sim_AB_all = F.grid_sample(soft_cross_sim_AtoB[:, :-1].view(-1, H, W).unsqueeze(0),
                                                    pntA_H_normalized[vmaskAH, :].detach().view(1, 1, -1, 2),
                                                    mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NA x match_nA
                
                soft_cross_sim_BA_all = F.grid_sample(soft_cross_sim_BtoA[:, :-1].view(-1, H, W).unsqueeze(0),
                                                    pntB_invH_normalized[vmaskBH, :].detach().view(1, 1, -1, 2),
                                                    mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NB x match_nB
                # soft_valid_cross_sim_AB_all = soft_cross_sim_AB_all[mask_pointA, :]             # repeat_nA x repeat_nA
                # soft_valid_cross_sim_BA_all = soft_cross_sim_BA_all[mask_pointB, :]             # repeat_nB x repeat_nB

                soft_valid_cross_sim_AB_all = soft_cross_sim_AB_all[match_mask_A, :]             # match_nA x match_nA
                soft_valid_cross_sim_BA_all = soft_cross_sim_BA_all[match_mask_B, :]             # match_nB x match_nB

                valid_mask_AB = torch.eye(soft_valid_cross_sim_AB_all.shape[0]) == 1
                valid_mask_BA = torch.eye(soft_valid_cross_sim_BA_all.shape[0]) == 1
                # print(4)
                # 取对角线
                soft_valid_cross_sim_AB = soft_valid_cross_sim_AB_all[valid_mask_AB]
                soft_valid_cross_sim_BA = soft_valid_cross_sim_BA_all[valid_mask_BA]

                # soft_novalid_cross_sim_AB = soft_cross_sim_AtoB[mask_pointA==False, -1]              # (NA-repeat_nA) x 1
                # soft_novalid_cross_sim_BA = soft_cross_sim_BtoA[mask_pointB==False, -1]
                soft_novalid_cross_sim_AB = soft_cross_sim_AtoB[match_mask_A==False, -1]               # (NA-match_nA) x 1
                soft_novalid_cross_sim_BA = soft_cross_sim_BtoA[match_mask_B==False, -1]
                # print(soft_novalid_cross_sim_AB, soft_novalid_cross_sim_BA)

                log_soft_valid_cross_sim_AB = -torch.log(soft_valid_cross_sim_AB + eps) * torch.diag(ori_maskATAB)[vmaskAH] * (1 - torch.diag(bin_distATAB[mask_pointA, :])[vmaskAH] / bin_kpAB_T.shape[0])
                log_soft_valid_cross_sim_BA = -torch.log(soft_valid_cross_sim_BA + eps) * torch.diag(ori_maskBTBA)[vmaskBH] * (1 - torch.diag(bin_distBTBA[mask_pointB, :])[vmaskBH] / bin_kpBA_T.shape[0])
                log_soft_novalid_cross_sim_AB = -torch.log(soft_novalid_cross_sim_AB + eps)
                log_soft_novalid_cross_sim_BA = -torch.log(soft_novalid_cross_sim_BA + eps)

                dis_cross_sim_mean = torch.sum(torch.cat((log_soft_valid_cross_sim_AB, log_soft_valid_cross_sim_BA, log_soft_novalid_cross_sim_AB, log_soft_novalid_cross_sim_BA), dim=-1), dim=-1) / (pntA_H.shape[0] + pntB_invH.shape[0])
                # print(5)
                # valid_cross_sim_AB = cross_sim_AB[mask_pointA, :]   # repeat_nA x (H X W)
                # valid_cross_sim_BA = cross_sim_BA[mask_pointB, :]   # repeat_nB x (H X W)
                exp_valid_cross_sim_AtoB = torch.exp((cross_sim_AB - 1) / t_rel).view(-1, H, W)
                exp_valid_cross_sim_BtoA = torch.exp((cross_sim_BA - 1) / t_rel).view(-1, H, W)
                exp_valid_cross_sim_AB_all = F.grid_sample(exp_valid_cross_sim_AtoB.unsqueeze(0),
                                                        pntA_H_normalized.detach().view(1, 1, -1, 2),
                                                        mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # repeat_nA x repeat_nA
                
                exp_valid_cross_sim_BA_all = F.grid_sample(exp_valid_cross_sim_BtoA.unsqueeze(0),
                                                        pntB_invH_normalized.detach().view(1, 1, -1, 2),
                                                        mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # repeat_nB x repeat_nB

                repeat_mask_AB = torch.eye(exp_valid_cross_sim_AB_all.shape[0]) == 1
                repeat_mask_BA = torch.eye(exp_valid_cross_sim_BA_all.shape[0]) == 1
                rel_valid_cross_sim_AB = exp_valid_cross_sim_AB_all[repeat_mask_AB]
                rel_valid_cross_sim_BA = exp_valid_cross_sim_BA_all[repeat_mask_BA]

                # pntA_H_normalized_new = copy.deepcopy(pntA_H_normalized.detach())
                # pntB_invH_normalized_new = copy.deepcopy(pntB_invH_normalized.detach())

                # pntA_H_normalized_new[:, 0] += 2
                # pntB_invH_normalized_new[:, 0] += 2

                scoresAB_all = F.grid_sample(scores_mapB[idx, :, :, :].unsqueeze(0),
                                            pntA_H_normalized_new.view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)      # 1 x repeat_nA

                scoresBA_all = F.grid_sample(scores_mapA[idx, :, :, :].unsqueeze(0),
                                            pntB_invH_normalized_new.view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)      # 1 x repeat_nB
                # print(6)
                scores_AAB = scoresA[idx][pmA][mask_pointA] * scoresAB_all
                scores_BBA = scoresB[idx][pmB][mask_pointB] * scoresBA_all
                scores_sum_AAB = torch.sum(scores_AAB, dim=-1)
                scores_sum_BBA = torch.sum(scores_BBA, dim=-1)
                scores_normalize_AAB = scores_AAB / (scores_sum_AAB + eps)
                scores_normalize_BBA = scores_BBA / (scores_sum_BBA + eps)
                rel_meanA = torch.sum(scores_normalize_AAB * (1 - rel_valid_cross_sim_AB), dim=-1) / pntA_H_normalized_new.shape[0]
                rel_meanB = torch.sum(scores_normalize_BBA * (1 - rel_valid_cross_sim_BA), dim=-1) / pntB_invH_normalized_new.shape[0]

                # # 熵loss
                # current_descA_std, current_descB_std = descA_std[countA:countA+new_numA], descB_std[countB:countB+new_numB]
                # desc_std += torch.mean(current_descA_std) + torch.mean(current_descB_std)

                countA += new_numA
                countB += new_numB
                # countA_T += numA_T
                # countB_T += numB_T

                dis_neighbor_mean_total += torch.mean(torch.sum(neighbor_dis_AB, dim=1)) + torch.mean(torch.sum(neighbor_dis_BA, dim=1))
                dis_desc += dis_cross_sim_mean_sp
                dis_desc += dis_cross_sim_mean

                dis_pair_meanAB = torch.mean(key_manhattandisAB[pairAB_A, pairAB_B])
                dis_pair_meanBA = torch.mean(key_manhattandisBA[pairBA_B, pairBA_A])

                dis_peak_mean = torch.mean(torch.cat((scoreddisA[idx][pmA], scoreddisB[idx][pmB]), dim=0))
                # dis_peak_meanB = torch.mean(scoreddisB[idx])
                
                dis_mean_total += dis_pair_meanAB + dis_pair_meanBA
                dis_peak_scored += dis_peak_mean

                dis_rel += rel_meanA + rel_meanB
                # # Penalty
                # scores_mean += (-torch.log(torch.mean(scoresA[idx], dim=-1) + eps) - torch.log(torch.mean(scoresB[idx], dim=-1) + eps)) 
                # print(scores_mean)
            except:
                # dis_mean_total += 0
                # dis_peak_scored += 0
                # dis_desc += 0
                # dis_rel += 0
                # print('Overlapping too small or Repeatable point pairs distance is greater than correspond(1.5):', pntA.shape[0], pntA_H.shape[0], pntB.shape[0], pntB_invH.shape[0], dis_pairAB.shape[0], dis_pairBA.shape[0])
                valid_batch_size -= 1
                countA += new_numA
                countB += new_numB
                # countA_T += numA_T
                # countB_T += numB_T

        valid_batch_size = valid_batch_size if valid_batch_size > 0 else eps
        # Reprojection Loss 
        reprojection_loss = dis_mean_total / (valid_batch_size * 2)
        # Dispersity Peak Loss
        dispersity_peak_loss = dis_peak_scored / valid_batch_size
        # NRE Loss
        descriptor_loss = dis_desc / (2 * valid_batch_size)
        # Reliability Loss
        reliability_loss = dis_rel / (valid_batch_size * 2)
        # SOSR Loss
        sosr_loss = dis_neighbor_mean_total / ((valid_batch_size * 2))
        # # Entropy loss
        # std_loss = (valid_batch_size * 2) / desc_std  
        # # Score Penalty
        # score_penalty = scores_mean / (valid_batch_size * 2)
        # FA Desc loss
        FA_des_loss = dis_desc_fa / valid_batch_size_FA if valid_batch_size_FA > 0 else 0

        loss_total = wrp * reprojection_loss + wpl * dispersity_peak_loss + wdl * descriptor_loss + wrl * reliability_loss + sosr_loss + FA_des_loss
        loss_group = {
            'reprojection_loss': reprojection_loss, 
            'dispersity_peak_loss': dispersity_peak_loss,
            'descriptor_loss': descriptor_loss,
            'reliability_loss': reliability_loss,
            'sosr_loss': sosr_loss,
            # 'std_loss': std_loss,
            'FA_des_loss': FA_des_loss,
            }
        return loss_total, loss_group

    def detector_selfsupervised_loss_dkd_patch_ext_restrict_modify_oriR_ratio_FA_bw_new(self, kpA, kpB, pmaskA, pmaskB, descA, descB, desc_mapA, desc_mapB, scoreddisA, scoreddisB, scoresA, scoresB, scores_mapA, scores_mapB, Homo, inv_Homo, inv_Homo_en, ori_all_patchA, ori_all_patchB, ori_kp_patchA, ori_kp_patchB, bin_allA, bin_allB, bin_kpA, bin_kpB, FA_flag, H, W, wrp=1, wpl=1, wdl=1, wrl=1, t_des=0.02, t_rel=1):
        # pmaskA: (BxMax_num) 32x350=11200
        batch_size = len(kpA)
        max_num = pmaskA.shape[-1] // batch_size    # 350
        dis_mean_total = 0
        dis_neighbor_mean_total = 0
        dis_peak_scored = 0
        dis_desc = 0
        dis_rel = 0
        desc_std = 0
        eps = 1e-12
        valid_batch_size = batch_size
        valid_batch_size_FA = 0
        countA, countB = 0, 0
        dis_desc_fa = 0
        # countA_T, countB_T = 0, 0
        for idx in range(batch_size):
            pntA, pntB = kpA[idx], kpB[idx]     # M X 2 (x,y)
            # kmask_TA, kmask_TB = kmask_T_allA[idx], kmask_T_allB[idx]
            pntA = pntA.float()
            pntB = pntB.float()

            # 剔除部分按压区域的点,且保留在重叠区域的点
            numA, numB = pntA.shape[0], pntB.shape[0]
            # numA_T, numB_T = pntA[kmask_TA].shape[0], pntB[kmask_TB].shape[0]
            pmA, pmB = pmaskA[max_num * idx:max_num * idx + numA].bool(), pmaskB[max_num * idx:max_num * idx + numB].bool()
            pntA, pntB = pntA[pmA, :], pntB[pmB, :]
            new_numA, new_numB = pntA.shape[0], pntB.shape[0]       
            
            pntA = (pntA + 1) / 2 * pntA.new_tensor([[W + 3, H - 1]]).to(pntA.device)
            pntB = (pntB + 1) / 2 * pntB.new_tensor([[W + 3, H - 1]]).to(pntB.device)

            # [120, 40] -> [120, 36],实际只取中心118x32区域的点对
            pntA[:, 0] -= 2
            pntB[:, 0] -= 2
            
            pntA_normalized = pntA / pntA.new_tensor([W - 1, H - 1]).to(pntA.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)
            pntB_normalized = pntB / pntB.new_tensor([W - 1, H - 1]).to(pntB.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)

            pntA_H = warp_points(pntA[:, :2], Homo[idx].squeeze(), device=self.device)  # 利用变换矩阵变换坐标点
            pntA_H, mask_pointA = filter_points(pntA_H, torch.tensor([W, H], device=self.device), return_mask=True)
            pntB_invH = warp_points(pntB[:, :2], inv_Homo[idx].squeeze(), device=self.device)
            pntB_invH, mask_pointB = filter_points(pntB_invH, torch.tensor([W, H], device=self.device), return_mask=True)
            
            current_descA, current_descB = descA[countA:countA+new_numA], descB[countB:countB+new_numB]
            cross_sim_AB_sp = current_descA @ current_descB.transpose(0, 1)
            
            # 黑白相似度
            current_binA, current_binB = bin_kpA[countA:countA+new_numA], bin_kpB[countB:countB+new_numB]   # [NA, 256] [NB_256]
            bin_distAB = current_binA.shape[-1] - (current_binA @ current_binB.transpose(0, 1)) - ((1 - current_binA) @ (1 - current_binB.transpose(0, 1))) # [NA, NB]

            # Net FA余弦相似度小
            if FA_flag[idx] == 1:
                FA_bin_mask = bin_distAB >= (1 - self.FA_bin_thr) * current_binA.shape[-1] 
                # print(current_binA.shape, bin_distAB[0, :])
                # print(FA_bin_mask.shape, torch.sum(FA_bin_mask))
                dis_desc_fa += (2 - torch.mean(torch.sqrt(2 * (1 - cross_sim_AB_sp[FA_bin_mask]) + eps)))

                valid_batch_size -= 1
                valid_batch_size_FA += 1
                countA += new_numA
                countB += new_numB
                continue
            
            # 真匹配的trans
            try:
                assert pntA_H.shape[0] > 0 and pntB_invH.shape[0] > 0 
                
                # 点对欧氏距离
                key_disAB = self.get_dis(pntA_H[:, :2], pntB[:, :2])
                key_disBA = self.get_dis(pntB_invH[:, :2], pntA[:, :2])
                pairAB_A, pairAB_B, dis_pairAB, _ = self.get_point_pair(key_disAB, dis_thre=self.correspond)  # p -> k # NTA(<1.5), NTA(<1.5), NTA(<1.5), NTA        
                pairBA_B, pairBA_A, dis_pairBA, _  = self.get_point_pair(key_disBA, dis_thre=self.correspond)  # p -> k # NTB(<1.5), NTB(<1.5), NTB(<1.5), NTB 
                
                # 点距离mask
                nn_maskAB = torch.zeros((pntA_H.shape[0], pntB.shape[0]), device=self.device) 
                nn_maskAB[pairAB_A, pairAB_B] = 1

                nn_maskBA = torch.zeros((pntB_invH.shape[0], pntA.shape[0]), device=self.device) 
                nn_maskBA[pairBA_B, pairBA_A] = 1

                # 点对曼哈顿距离
                key_manhattandisAB = self.get_manhattan_dis(pntA_H[:, :2], pntB[:, :2])
                key_manhattandisBA = self.get_manhattan_dis(pntB_invH[:, :2], pntA[:, :2])
                # print('pdis:', dis_pairAB.shape[0], dis_pairBA.shape[0])
                assert dis_pairAB.shape[0] > 0 and dis_pairBA.shape[0] > 0     

                pntA_H_normalized = pntA_H / pntA_H.new_tensor([W - 1, H - 1]).to(pntA_H.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)
                pntB_invH_normalized = pntB_invH / pntB_invH.new_tensor([W - 1, H - 1]).to(pntB_invH.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)

                # 用于score_map
                pntA_H_new = copy.deepcopy(pntA_H.detach())
                pntB_invH_new = copy.deepcopy(pntB_invH.detach())
                pntA_H_new[:, 0] += 2
                pntB_invH_new[:, 0] += 2
                
                pntA_H_normalized_new = pntA_H_new / pntA_H_new.new_tensor([W + 3, H - 1]).to(pntA_H.device) * 2 - 1

                # pntB_invH_new = warp_points(pntB_invH_new[:, :2], inv_Homo_en[idx].squeeze(), device=self.device)       # 转到A上，而不是AT上
                
                pntB_invH_normalized_new = pntB_invH_new / pntB_invH_new.new_tensor([W + 3, H - 1]).to(pntB_invH.device) * 2 - 1 

                # # PA VS PB 有一定偏移
                # ori_kpA_ext = F.grid_sample(ori_allA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                #                             pntA_normalized.detach().view(1, 1, -1, 2),
                #                             mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  
                # ori_kpB_ext = F.grid_sample(ori_allB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                #                             pntB_normalized.detach().view(1, 1, -1, 2),
                #                             mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  

                # main_ori_maskATB = self.get_main_ori_consistence(ori_kpA[countA:countA+numA][pmA].unsqueeze(1), ori_kpB_ext)  # NTA x NTB 
                # main_ori_maskBTA = self.get_main_ori_consistence(ori_kpB[countB:countB+numB][pmB].unsqueeze(1), ori_kpA_ext)  # NTB x NTA 
                
                # print('1_2:', main_ori_maskATB.shape[0])
                # exit()
                # ori_kpA_patch_ext = F.grid_sample(ori_all_patchA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                #                             pntA_normalized.detach().view(1, 1, -1, 2),
                #                             mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  
                # ori_kpB_patch_ext = F.grid_sample(ori_all_patchB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                #                             pntB_normalized.detach().view(1, 1, -1, 2),
                #                             mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  
                # print('1_2_1:', pntB_invH_normalized_new.shape[0])
                ori_maskATB = self.get_ori_pattern(ori_kp_patchA[countA:countA+new_numA], ori_kp_patchB[countB:countB+new_numB])  # NTA x NTB
                # print('1_2_2:', ori_maskATB.shape)
                ori_maskBTA = ori_maskATB.transpose(0, 1)
                # print('1_2_2:', ori_maskATB.shape[0])
                # match_maskAB = (nn_maskAB == 1) * main_ori_maskATB
                # match_maskBA = (nn_maskBA == 1) * main_ori_maskBTA
                # print(nn_maskAB.shape, main_ori_maskATB.shape, ori_maskATB.shape)
                match_maskAB = (nn_maskAB == 1) * (ori_maskATB >= self.ori_ratio)[mask_pointA, :]           # repeatNA X NTB
                match_maskBA = (nn_maskBA == 1) * (ori_maskBTA >= self.ori_ratio)[mask_pointB, :]           # repeatNB X NTA
                # pairAB_A_new, pairAB_B_new = torch.where(match_maskAB == 1)
                # pairBA_B_new, pairBA_A_new = torch.where(match_maskBA == 1)
                # assert pairAB_A_new.shape[0] > 0 and pairBA_B_new.shape[0] > 0 

                # # PA VS PAB 没有中心点距离偏移
                # # 中心主方向一致性
                # ori_kpAB_ext = F.grid_sample(ori_allB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                #                             pntA_H_normalized.detach().view(1, 1, -1, 2),
                #                             mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  
                # ori_kpBA_ext = F.grid_sample(ori_allA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                #                             pntB_invH_normalized.detach().view(1, 1, -1, 2),
                #                             mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  
                # main_ori_maskATAB = self.get_main_ori_consistence(ori_kpA[countA:countA+new_numA].unsqueeze(1), ori_kpAB_ext)  # NTAxNTA 
                # main_ori_maskBTBA = self.get_main_ori_consistence(ori_kpB[countB:countB+new_numB].unsqueeze(1), ori_kpBA_ext)  # NTBxNTB 

                # 4x4邻域方向一致性
                ori_kpAB_patch_ext = F.grid_sample(ori_all_patchB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntA_H_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  
                ori_kpBA_patch_ext = F.grid_sample(ori_all_patchA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntB_invH_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  
                # print('1_2_4:', ori_kpAB_patch_ext.shape)
                ori_maskATAB = self.get_ori_pattern(ori_kp_patchA[countA:countA+new_numA], ori_kpAB_patch_ext.transpose(0, 1))  # NTA x repeatNA
                ori_maskBTBA = self.get_ori_pattern(ori_kp_patchB[countB:countB+new_numB], ori_kpBA_patch_ext.transpose(0, 1))  # NTB x repeatNB
                
                ori_maskATAB = ori_maskATAB[mask_pointA, :]         # repeatNA x repeatNA
                ori_maskBTBA = ori_maskBTBA[mask_pointB, :]
                # vmaskAH = torch.diag(main_ori_maskATAB) == 1
                # vmaskBH = torch.diag(main_ori_maskBTBA) == 1
                # vmaskAH = torch.diag(main_ori_maskATAB * (ori_maskATAB >= self.ori_ratio)) == 1
                # vmaskBH = torch.diag(main_ori_maskBTBA * (ori_maskBTBA >= self.ori_ratio)) == 1
                # assert torch.sum(vmaskAH) > 0 and torch.sum(vmaskBH) > 0
                
                # 黑白相似度
                bin_maskATB = bin_distAB <= (1 - self.FR_bin_thr) * current_binA.shape[-1]  
                bin_maskBTA = bin_maskATB.transpose(0, 1)  

                match_maskAB = match_maskAB * bin_maskATB[mask_pointA, :]               # repeatNA X NB
                match_maskBA = match_maskBA * bin_maskBTA[mask_pointB, :]               # repeatNB X NA

                pairAB_A_new, pairAB_B_new = torch.where(match_maskAB == 1)
                pairBA_B_new, pairBA_A_new = torch.where(match_maskBA == 1)
                # print('bin_mask:', pairAB_A_new.shape[0], pairBA_B_new.shape[0])
                assert pairAB_A_new.shape[0] > 0 and pairBA_B_new.shape[0] > 0 

                bin_kpAB_T = F.grid_sample(bin_allB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntA_H_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # [256, repeatNA]
                bin_kpBA_T = F.grid_sample(bin_allA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntB_invH_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # [256, repeatNB]
                bin_distATAB = bin_kpAB_T.shape[0] - (current_binA @ bin_kpAB_T) - ((1 - current_binA) @ (1 - bin_kpAB_T)) # [NTA, repeatNA]
                bin_distBTBA = bin_kpBA_T.shape[0] - (current_binB @ bin_kpBA_T) - ((1 - current_binB) @ (1 - bin_kpBA_T)) # [NTB, repeatNB]

                bin_maskATAB = bin_distATAB <= (1 - self.FR_bin_thr) * bin_kpAB_T.shape[0] 
                bin_maskBTBA = bin_distBTBA <= (1 - self.FR_bin_thr) * bin_kpBA_T.shape[0] 
                bin_maskATAB = bin_maskATAB[mask_pointA, :]
                bin_maskBTBA = bin_maskBTBA[mask_pointB, :]

                vmaskAH = torch.diag((ori_maskATAB >= self.ori_ratio) * bin_maskATAB) == 1      # [repeatNA, 1]
                vmaskBH = torch.diag((ori_maskBTBA >= self.ori_ratio) * bin_maskBTBA) == 1      # [repeatNB, 1]
                # print('main_ori:', torch.sum(vmaskAH), torch.sum(vmaskBH))
                assert torch.sum(vmaskAH) > 0 and torch.sum(vmaskBH) > 0

                # SOSR: 简化的self-attention
                k_neighbor = 3
                cross_sim_AA_sp = current_descA @ current_descA.transpose(0, 1)
                cross_sim_BB_sp = current_descB @ current_descB.transpose(0, 1)
                # print('SOSR:', pairAB_A_new.shape[0], pairBA_B_new.shape[0])
                assert pairAB_A_new.shape[0] >= k_neighbor and pairBA_B_new.shape[0] >= k_neighbor 

                match_sim_AB_AA = cross_sim_AA_sp[mask_pointA, :][:, mask_pointA][pairAB_A_new, :][:, pairAB_A_new]
                match_sim_BA_BB = cross_sim_BB_sp[mask_pointB, :][:, mask_pointB][pairBA_B_new, :][:, pairBA_B_new]
                match_sim_AB_BB = cross_sim_BB_sp[pairAB_B_new, :][:, pairAB_B_new]
                match_sim_BA_AA = cross_sim_AA_sp[pairBA_A_new, :][:, pairBA_A_new]
                match_values_AB_AA, match_indices_AB_AA = torch.topk(match_sim_AB_AA, dim=1, k=k_neighbor, largest=False)
                match_values_BA_BB, match_indices_BA_BB = torch.topk(match_sim_BA_BB, dim=1, k=k_neighbor, largest=False)
                match_values_AB_BB_all = match_sim_AB_BB[:, match_indices_AB_AA]
                match_values_BA_AA_all = match_sim_BA_AA[:, match_indices_BA_BB]
                match_values_AB_BB = torch.diagonal(match_values_AB_BB_all, 0, dim1=0, dim2=1).transpose(0, 1)
                match_values_BA_AA = torch.diagonal(match_values_BA_AA_all, 0, dim1=0, dim2=1).transpose(0, 1)
                neighbor_dis_AB = (match_values_AB_AA - match_values_AB_BB) * (match_values_AB_AA - match_values_AB_BB)
                neighbor_dis_BA = (match_values_BA_BB - match_values_BA_AA) * (match_values_BA_BB - match_values_BA_AA)
                # print('1_1')
                # PA VS PB
                valid_cross_sim_AB_sp_mean = torch.mean(cross_sim_AB_sp[mask_pointA, :][match_maskAB == 1], dim=-1)
                novalid_cross_sim_AB_sp_mean = (torch.sum(torch.sum(cross_sim_AB_sp.detach(), 1), 0) - valid_cross_sim_AB_sp_mean * pairAB_A_new.shape[0]) / (new_numA * new_numB - pairAB_A_new.shape[0] + eps)
                valid_cross_sim_BA_sp_mean = torch.mean(cross_sim_AB_sp[:, mask_pointB][match_maskBA.transpose(0, 1) == 1], dim=-1)
                novalid_cross_sim_BA_sp_mean = (torch.sum(torch.sum(cross_sim_AB_sp.detach(), 1), 0) - valid_cross_sim_BA_sp_mean * pairBA_B_new.shape[0]) / (new_numA * new_numB - pairBA_B_new.shape[0] + eps)

                valid_indexesA = torch.tensor(list(range(cross_sim_AB_sp.shape[0])), device=self.device)[mask_pointA][pairAB_A_new]
                # cross_sim_BA_sp = current_descB @ current_descA.transpose(0, 1)
                cross_sim_AB_out_sp = torch.cat((cross_sim_AB_sp, torch.ones((cross_sim_AB_sp.shape[0], 1), device=cross_sim_AB_sp.device) * 2), dim=-1)      # NA X (NB + 1)
                # cross_sim_BA_out_sp = torch.cat((cross_sim_BA_sp, torch.ones((numB, 1), device=cross_sim_BA_sp.device)), dim=-1)      # NB X (NA + 1)
                # valid_indexesB = torch.tensor(list(range(numB)), device=self.device)[mask_pointB][pairBA_B]
                # print('1_2')
                cross_sim_AB_out_sp[valid_indexesA, -1] = novalid_cross_sim_AB_sp_mean
                novalid_indexesA = torch.tensor(list(range(cross_sim_AB_sp.shape[0])), device=self.device)[cross_sim_AB_out_sp[:, -1]==2]
                cross_sim_AB_out_sp[novalid_indexesA, -1] = valid_cross_sim_AB_sp_mean

                soft_cross_sim_AtoB_sp = F.softmax((cross_sim_AB_out_sp - 1) / t_des, dim=-1)
                # soft_cross_sim_BtoA = F.softmax((cross_sim_BA_out - 1) / t_des, dim=-1)
                # print('1_3')
                soft_valid_cross_sim_AB_sp = soft_cross_sim_AtoB_sp[mask_pointA, :-1][match_maskAB==1]
                # soft_valid_cross_sim_BA = soft_cross_sim_BtoA[mask_pointB, :-1][pairBA_B, pairBA_A]
                soft_novalid_cross_sim_AB_sp = soft_cross_sim_AtoB_sp[novalid_indexesA, -1]
                # soft_novalid_cross_sim_BA = soft_cross_sim_BtoA[cross_sim_BA_out[:, -1]==1, -1]
                log_soft_valid_cross_sim_AB_sp = -torch.log(soft_valid_cross_sim_AB_sp + eps) * ori_maskATB[mask_pointA, :][match_maskAB==1] * (1 - bin_distAB[mask_pointA, :][match_maskAB==1] / current_binA.shape[-1])
                # log_soft_valid_cross_sim_BA = -torch.log(soft_valid_cross_sim_BA + eps)
                log_soft_novalid_cross_sim_AB_sp = -torch.log(soft_novalid_cross_sim_AB_sp + eps)
                # log_soft_novalid_cross_sim_BA = -torch.log(soft_novalid_cross_sim_BA + eps)
                dis_cross_sim_mean_sp = torch.sum(torch.cat((log_soft_valid_cross_sim_AB_sp, log_soft_novalid_cross_sim_AB_sp), dim=-1), dim=-1) / new_numA
                # print(2)
                # PA VS PAB
                # match_mask_A = copy.deepcopy(mask_pointA)
                # match_mask_B = copy.deepcopy(mask_pointB)
                match_mask_A = torch.zeros(cross_sim_AB_sp.shape[0], device=self.device)
                valid_match_indexesA = torch.tensor(list(range(cross_sim_AB_sp.shape[0])), device=self.device)[mask_pointA][vmaskAH]
                match_mask_A[valid_match_indexesA] = 1
                match_mask_B = torch.zeros(cross_sim_AB_sp.shape[1], device=self.device)
                valid_match_indexesB = torch.tensor(list(range(cross_sim_AB_sp.shape[1])), device=self.device)[mask_pointB][vmaskBH]
                match_mask_B[valid_match_indexesB] = 1
                # match_mask_A = copy.deepcopy(vmaskAH)
                # match_mask_B = copy.deepcopy(vmaskBH)

                cross_sim_AB = current_descA @ desc_mapB[idx, :, :, :].view(-1, H * W)
                # cross_sim_AB = cross_sim_AB[mask_pointA, :]
                cross_sim_AB_all = F.grid_sample(cross_sim_AB.view(-1, H, W).unsqueeze(0),
                                                pntA_H_normalized[vmaskAH, :].detach().view(1, 1, -1, 2),
                                                mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NA x repeatNA
                valid_cross_sim_AB_mean = torch.trace(cross_sim_AB_all[match_mask_A==1, :]) / cross_sim_AB_all[match_mask_A==1, :].shape[0]
                # novalid_cross_sim_AB_mean = (torch.sum(torch.sum(cross_sim_AB.detach(), 1), 1) - valid_cross_sim_AB_mean * pairAB_A.shape[0]) / (new_numA * H * W - pairAB_A.shape[0])

                cross_sim_BA = current_descB @ desc_mapA[idx, :, :, :].view(-1, H * W)   # M x H x W
                # cross_sim_BA = cross_sim_BA[mask_pointB, :]
                cross_sim_BA_all = F.grid_sample(cross_sim_BA.view(-1, H, W).unsqueeze(0),
                                                pntB_invH_normalized[vmaskBH, :].detach().view(1, 1, -1, 2),
                                                mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NB x match_nB
                valid_cross_sim_BA_mean = torch.trace(cross_sim_BA_all[match_mask_B==1, :]) / cross_sim_BA_all[match_mask_B==1, :].shape[0]
                # novalid_cross_sim_BA_mean = (torch.sum(torch.sum(cross_sim_BA.detach(), 1), 1) - valid_cross_sim_BA_mean * pairBA_B.shape[0]) / (new_numB * H * W - pairBA_B.shape[0])

                cross_sim_AB_out = torch.cat((cross_sim_AB, torch.ones((cross_sim_AB.shape[0], 1), device=cross_sim_AB.device)), dim=-1)      # NA X (H X W + 1)
                cross_sim_BA_out = torch.cat((cross_sim_BA, torch.ones((cross_sim_BA.shape[0], 1), device=cross_sim_BA.device)), dim=-1)      # NB X (H X W + 1)
                # print(3)
                # cross_sim_AB_out[mask_pointA, -1] -= 1
                # cross_sim_BA_out[mask_pointB, -1] -= 1
                # cross_sim_AB_out[match_mask_A, -1] -= 1
                cross_sim_AB_out[match_mask_A==1, -1] = novalid_cross_sim_AB_sp_mean
                cross_sim_AB_out[match_mask_A==0, -1] = valid_cross_sim_AB_mean

                cross_sim_BA_out[match_mask_B==1, -1] = novalid_cross_sim_BA_sp_mean
                cross_sim_BA_out[match_mask_B==0, -1] = valid_cross_sim_BA_mean

                soft_cross_sim_AtoB = F.softmax((cross_sim_AB_out - 1) / t_des, dim=-1)         # NA X (H X W + 1)
                soft_cross_sim_BtoA = F.softmax((cross_sim_BA_out - 1) / t_des, dim=-1)         # NB X (H X W + 1)
                soft_cross_sim_AB_all = F.grid_sample(soft_cross_sim_AtoB[:, :-1].view(-1, H, W).unsqueeze(0),
                                                    pntA_H_normalized[vmaskAH, :].detach().view(1, 1, -1, 2),
                                                    mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NA x match_nA
                
                soft_cross_sim_BA_all = F.grid_sample(soft_cross_sim_BtoA[:, :-1].view(-1, H, W).unsqueeze(0),
                                                    pntB_invH_normalized[vmaskBH, :].detach().view(1, 1, -1, 2),
                                                    mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NB x match_nB
                # soft_valid_cross_sim_AB_all = soft_cross_sim_AB_all[mask_pointA, :]             # repeat_nA x repeat_nA
                # soft_valid_cross_sim_BA_all = soft_cross_sim_BA_all[mask_pointB, :]             # repeat_nB x repeat_nB

                soft_valid_cross_sim_AB_all = soft_cross_sim_AB_all[match_mask_A==1, :]             # match_nA x match_nA
                soft_valid_cross_sim_BA_all = soft_cross_sim_BA_all[match_mask_B==1, :]             # match_nB x match_nB

                valid_mask_AB = torch.eye(soft_valid_cross_sim_AB_all.shape[0]) == 1
                valid_mask_BA = torch.eye(soft_valid_cross_sim_BA_all.shape[0]) == 1
                # print(4)
                # 取对角线
                soft_valid_cross_sim_AB = soft_valid_cross_sim_AB_all[valid_mask_AB]
                soft_valid_cross_sim_BA = soft_valid_cross_sim_BA_all[valid_mask_BA]

                # soft_novalid_cross_sim_AB = soft_cross_sim_AtoB[mask_pointA==False, -1]              # (NA-repeat_nA) x 1
                # soft_novalid_cross_sim_BA = soft_cross_sim_BtoA[mask_pointB==False, -1]
                soft_novalid_cross_sim_AB = soft_cross_sim_AtoB[match_mask_A==0, -1]               # (NA-match_nA) x 1
                soft_novalid_cross_sim_BA = soft_cross_sim_BtoA[match_mask_B==0, -1]
                # print(soft_novalid_cross_sim_AB, soft_novalid_cross_sim_BA)

                log_soft_valid_cross_sim_AB = -torch.log(soft_valid_cross_sim_AB + eps) * torch.diag(ori_maskATAB)[vmaskAH] * (1 - torch.diag(bin_distATAB[mask_pointA, :])[vmaskAH] / bin_kpAB_T.shape[0])
                log_soft_valid_cross_sim_BA = -torch.log(soft_valid_cross_sim_BA + eps) * torch.diag(ori_maskBTBA)[vmaskBH] * (1 - torch.diag(bin_distBTBA[mask_pointB, :])[vmaskBH] / bin_kpBA_T.shape[0])
                log_soft_novalid_cross_sim_AB = -torch.log(soft_novalid_cross_sim_AB + eps)
                log_soft_novalid_cross_sim_BA = -torch.log(soft_novalid_cross_sim_BA + eps)

                dis_cross_sim_mean = torch.sum(torch.cat((log_soft_valid_cross_sim_AB, log_soft_valid_cross_sim_BA, log_soft_novalid_cross_sim_AB, log_soft_novalid_cross_sim_BA), dim=-1), dim=-1) / (new_numA + new_numB)
                # print(5)
                valid_cross_sim_AB = cross_sim_AB[mask_pointA, :]   # repeat_nA x (H X W)
                valid_cross_sim_BA = cross_sim_BA[mask_pointB, :]   # repeat_nB x (H X W)
                exp_valid_cross_sim_AtoB = torch.exp((valid_cross_sim_AB - 1) / t_rel).view(-1, H, W)
                exp_valid_cross_sim_BtoA = torch.exp((valid_cross_sim_BA - 1) / t_rel).view(-1, H, W)
                exp_valid_cross_sim_AB_all = F.grid_sample(exp_valid_cross_sim_AtoB.unsqueeze(0),
                                                        pntA_H_normalized.detach().view(1, 1, -1, 2),
                                                        mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # repeat_nA x repeat_nA
                
                exp_valid_cross_sim_BA_all = F.grid_sample(exp_valid_cross_sim_BtoA.unsqueeze(0),
                                                        pntB_invH_normalized.detach().view(1, 1, -1, 2),
                                                        mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # repeat_nB x repeat_nB

                repeat_mask_AB = torch.eye(exp_valid_cross_sim_AB_all.shape[0]) == 1
                repeat_mask_BA = torch.eye(exp_valid_cross_sim_BA_all.shape[0]) == 1
                rel_valid_cross_sim_AB = exp_valid_cross_sim_AB_all[repeat_mask_AB]
                rel_valid_cross_sim_BA = exp_valid_cross_sim_BA_all[repeat_mask_BA]

                # pntA_H_normalized_new = copy.deepcopy(pntA_H_normalized.detach())
                # pntB_invH_normalized_new = copy.deepcopy(pntB_invH_normalized.detach())

                # pntA_H_normalized_new[:, 0] += 2
                # pntB_invH_normalized_new[:, 0] += 2

                scoresAB_all = F.grid_sample(scores_mapB[idx, :, :, :].unsqueeze(0),
                                            pntA_H_normalized_new.view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)      # 1 x repeat_nA

                scoresBA_all = F.grid_sample(scores_mapA[idx, :, :, :].unsqueeze(0),
                                            pntB_invH_normalized_new.view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)      # 1 x repeat_nB
                # print(6)
                scores_AAB = scoresA[idx][pmA][mask_pointA] * scoresAB_all
                scores_BBA = scoresB[idx][pmB][mask_pointB] * scoresBA_all
                scores_sum_AAB = torch.sum(scores_AAB, dim=-1)
                scores_sum_BBA = torch.sum(scores_BBA, dim=-1)
                scores_normalize_AAB = scores_AAB / (scores_sum_AAB + eps)
                scores_normalize_BBA = scores_BBA / (scores_sum_BBA + eps)
                rel_meanA = torch.sum(scores_normalize_AAB * (1 - rel_valid_cross_sim_AB), dim=-1) / pntA_H_normalized_new.shape[0]
                rel_meanB = torch.sum(scores_normalize_BBA * (1 - rel_valid_cross_sim_BA), dim=-1) / pntB_invH_normalized_new.shape[0]

                # # 熵loss
                # current_descA_std, current_descB_std = descA_std[countA:countA+new_numA], descB_std[countB:countB+new_numB]
                # desc_std += torch.mean(current_descA_std) + torch.mean(current_descB_std)

                countA += new_numA
                countB += new_numB
                # countA_T += numA_T
                # countB_T += numB_T

                dis_neighbor_mean_total += torch.mean(torch.sum(neighbor_dis_AB, dim=1)) + torch.mean(torch.sum(neighbor_dis_BA, dim=1))
                dis_desc += dis_cross_sim_mean_sp
                dis_desc += dis_cross_sim_mean

                dis_pair_meanAB = torch.mean(key_manhattandisAB[pairAB_A, pairAB_B])
                dis_pair_meanBA = torch.mean(key_manhattandisBA[pairBA_B, pairBA_A])

                dis_peak_mean = torch.mean(torch.cat((scoreddisA[idx][pmA], scoreddisB[idx][pmB]), dim=0))
                # dis_peak_meanB = torch.mean(scoreddisB[idx])
                
                dis_mean_total += dis_pair_meanAB + dis_pair_meanBA
                dis_peak_scored += dis_peak_mean

                dis_rel += rel_meanA + rel_meanB
                # # Penalty
                # scores_mean += (-torch.log(torch.mean(scoresA[idx], dim=-1) + eps) - torch.log(torch.mean(scoresB[idx], dim=-1) + eps)) 
                # print(scores_mean)
            except:
                # dis_mean_total += 0
                # dis_peak_scored += 0
                # dis_desc += 0
                # dis_rel += 0
                # print('Overlapping too small or Repeatable point pairs distance is greater than correspond(1.5):', pntA.shape[0], pntA_H.shape[0], pntB.shape[0], pntB_invH.shape[0], dis_pairAB.shape[0], dis_pairBA.shape[0])
                valid_batch_size -= 1
                countA += new_numA
                countB += new_numB
                # countA_T += numA_T
                # countB_T += numB_T

        valid_batch_size = valid_batch_size if valid_batch_size > 0 else eps
        # Reprojection Loss 
        reprojection_loss = dis_mean_total / (valid_batch_size * 2)
        # Dispersity Peak Loss
        dispersity_peak_loss = dis_peak_scored / valid_batch_size
        # NRE Loss
        descriptor_loss = dis_desc / (2 * valid_batch_size)
        # Reliability Loss
        reliability_loss = dis_rel / (valid_batch_size * 2)
        # SOSR Loss
        sosr_loss = dis_neighbor_mean_total / ((valid_batch_size * 2))
        # # Entropy loss
        # std_loss = (valid_batch_size * 2) / desc_std  
        # # Score Penalty
        # score_penalty = scores_mean / (valid_batch_size * 2)
        # FA Desc loss
        FA_des_loss = dis_desc_fa / valid_batch_size_FA if valid_batch_size_FA > 0 else 0

        loss_total = wrp * reprojection_loss + wpl * dispersity_peak_loss + wdl * descriptor_loss + wrl * reliability_loss + sosr_loss + FA_des_loss
        loss_group = {
            'reprojection_loss': reprojection_loss, 
            'dispersity_peak_loss': dispersity_peak_loss,
            'descriptor_loss': descriptor_loss,
            'reliability_loss': reliability_loss,
            'sosr_loss': sosr_loss,
            # 'std_loss': std_loss,
            'FA_des_loss': FA_des_loss,
            }
        return loss_total, loss_group

    def detector_selfsupervised_loss_dkd_patch_ext_restrict_modify_oriR_ratio_FA_bw_new_wg(self, kpA, kpB, pmaskA, pmaskB, descA, descB, desc_mapA, desc_mapB, scoreddisA, scoreddisB, scoresA, scoresB, scores_mapA, scores_mapB, Homo, inv_Homo, inv_Homo_en, ori_all_patchA, ori_all_patchB, ori_kp_patchA, ori_kp_patchB, bin_allA, bin_allB, bin_kpA, bin_kpB, FA_flag, H, W, wrp=1, wpl=1, wdl=1, wrl=1, t_des=0.02, t_rel=1):
        # pmaskA: (BxMax_num) 32x350=11200
        batch_size = len(kpA)
        max_num = pmaskA.shape[-1] // batch_size    # 350
        dis_mean_total = 0
        dis_neighbor_mean_total = 0
        dis_peak_scored = 0
        dis_desc = 0
        dis_rel = 0
        desc_std = 0
        eps = 1e-12
        valid_batch_size = batch_size
        valid_batch_size_FA = 0
        countA, countB = 0, 0
        dis_desc_fa = 0
        # countA_T, countB_T = 0, 0
        for idx in range(batch_size):
            pntA, pntB = kpA[idx], kpB[idx]     # M X 2 (x,y)
            # kmask_TA, kmask_TB = kmask_T_allA[idx], kmask_T_allB[idx]
            pntA = pntA.float()
            pntB = pntB.float()

            # 剔除部分按压区域的点,且保留在重叠区域的点
            numA, numB = pntA.shape[0], pntB.shape[0]
            # numA_T, numB_T = pntA[kmask_TA].shape[0], pntB[kmask_TB].shape[0]
            pmA, pmB = pmaskA[max_num * idx:max_num * idx + numA].bool(), pmaskB[max_num * idx:max_num * idx + numB].bool()
            pntA, pntB = pntA[pmA, :], pntB[pmB, :]
            new_numA, new_numB = pntA.shape[0], pntB.shape[0]       
            
            pntA = (pntA + 1) / 2 * pntA.new_tensor([[W + 3, H - 1]]).to(pntA.device)
            pntB = (pntB + 1) / 2 * pntB.new_tensor([[W + 3, H - 1]]).to(pntB.device)

            # [120, 40] -> [120, 36],实际只取中心118x32区域的点对
            pntA[:, 0] -= 2
            pntB[:, 0] -= 2
            
            pntA_normalized = pntA / pntA.new_tensor([W - 1, H - 1]).to(pntA.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)
            pntB_normalized = pntB / pntB.new_tensor([W - 1, H - 1]).to(pntB.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)

            pntA_H = warp_points(pntA[:, :2], Homo[idx].squeeze(), device=self.device)  # 利用变换矩阵变换坐标点
            pntA_H, mask_pointA = filter_points(pntA_H, torch.tensor([W, H], device=self.device), return_mask=True)
            pntB_invH = warp_points(pntB[:, :2], inv_Homo[idx].squeeze(), device=self.device)
            pntB_invH, mask_pointB = filter_points(pntB_invH, torch.tensor([W, H], device=self.device), return_mask=True)
            
            current_descA, current_descB = descA[countA:countA+new_numA], descB[countB:countB+new_numB]
            cross_sim_AB_sp = current_descA @ current_descB.transpose(0, 1)
            
            # 黑白相似度
            current_binA, current_binB = bin_kpA[countA:countA+new_numA], bin_kpB[countB:countB+new_numB]   # [NA, 256] [NB_256]
            bin_distAB = current_binA.shape[-1] - (current_binA @ current_binB.transpose(0, 1)) - ((1 - current_binA) @ (1 - current_binB.transpose(0, 1))) # [NA, NB]

            # Net FA余弦相似度小
            if FA_flag[idx] == 1:
                FA_bin_mask = bin_distAB >= (1 - self.FA_bin_thr) * current_binA.shape[-1] 
                # print(current_binA.shape, bin_distAB[0, :])
                # print(FA_bin_mask.shape, torch.sum(FA_bin_mask))
                dis_desc_fa += (2 - torch.mean(torch.sqrt(2 * (1 - cross_sim_AB_sp[FA_bin_mask]) + eps)))

                valid_batch_size -= 1
                valid_batch_size_FA += 1
                countA += new_numA
                countB += new_numB
                continue
            
            # 真匹配的trans
            try:
                assert pntA_H.shape[0] > 0 and pntB_invH.shape[0] > 0 
                
                # 点对欧氏距离
                key_disAB = self.get_dis(pntA_H[:, :2], pntB[:, :2])
                key_disBA = self.get_dis(pntB_invH[:, :2], pntA[:, :2])
                pairAB_A, pairAB_B, dis_pairAB, _ = self.get_point_pair(key_disAB, dis_thre=self.correspond)  # p -> k # NTA(<1.5), NTA(<1.5), NTA(<1.5), NTA        
                pairBA_B, pairBA_A, dis_pairBA, _  = self.get_point_pair(key_disBA, dis_thre=self.correspond)  # p -> k # NTB(<1.5), NTB(<1.5), NTB(<1.5), NTB 
                
                # 点距离mask
                nn_maskAB = torch.zeros((pntA_H.shape[0], pntB.shape[0]), device=self.device) 
                nn_maskAB[pairAB_A, pairAB_B] = 1

                nn_maskBA = torch.zeros((pntB_invH.shape[0], pntA.shape[0]), device=self.device) 
                nn_maskBA[pairBA_B, pairBA_A] = 1

                # 点对曼哈顿距离
                key_manhattandisAB = self.get_manhattan_dis(pntA_H[:, :2], pntB[:, :2])
                key_manhattandisBA = self.get_manhattan_dis(pntB_invH[:, :2], pntA[:, :2])
                # print('pdis:', dis_pairAB.shape[0], dis_pairBA.shape[0])
                assert dis_pairAB.shape[0] > 0 and dis_pairBA.shape[0] > 0     

                pntA_H_normalized = pntA_H / pntA_H.new_tensor([W - 1, H - 1]).to(pntA_H.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)
                pntB_invH_normalized = pntB_invH / pntB_invH.new_tensor([W - 1, H - 1]).to(pntB_invH.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)

                # 用于score_map
                pntA_H_new = copy.deepcopy(pntA_H.detach())
                pntB_invH_new = copy.deepcopy(pntB_invH.detach())
                pntA_H_new[:, 0] += 2
                pntB_invH_new[:, 0] += 2
                
                pntA_H_normalized_new = pntA_H_new / pntA_H_new.new_tensor([W + 3, H - 1]).to(pntA_H.device) * 2 - 1

                # pntB_invH_new = warp_points(pntB_invH_new[:, :2], inv_Homo_en[idx].squeeze(), device=self.device)       # 转到A上，而不是AT上
                
                pntB_invH_normalized_new = pntB_invH_new / pntB_invH_new.new_tensor([W + 3, H - 1]).to(pntB_invH.device) * 2 - 1 

                # # PA VS PB 有一定偏移
                # ori_kpA_ext = F.grid_sample(ori_allA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                #                             pntA_normalized.detach().view(1, 1, -1, 2),
                #                             mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  
                # ori_kpB_ext = F.grid_sample(ori_allB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                #                             pntB_normalized.detach().view(1, 1, -1, 2),
                #                             mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  

                # main_ori_maskATB = self.get_main_ori_consistence(ori_kpA[countA:countA+numA][pmA].unsqueeze(1), ori_kpB_ext)  # NTA x NTB 
                # main_ori_maskBTA = self.get_main_ori_consistence(ori_kpB[countB:countB+numB][pmB].unsqueeze(1), ori_kpA_ext)  # NTB x NTA 
                
                # print('1_2:', main_ori_maskATB.shape[0])
                # exit()
                # ori_kpA_patch_ext = F.grid_sample(ori_all_patchA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                #                             pntA_normalized.detach().view(1, 1, -1, 2),
                #                             mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  
                # ori_kpB_patch_ext = F.grid_sample(ori_all_patchB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                #                             pntB_normalized.detach().view(1, 1, -1, 2),
                #                             mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  
                # print('1_2_1:', pntB_invH_normalized_new.shape[0])
                ori_maskATB = self.get_ori_pattern(ori_kp_patchA[countA:countA+new_numA], ori_kp_patchB[countB:countB+new_numB])  # NTA x NTB
                # print('1_2_2:', ori_maskATB.shape)
                ori_maskBTA = ori_maskATB.transpose(0, 1)
                # print('1_2_2:', ori_maskATB.shape[0])
                # match_maskAB = (nn_maskAB == 1) * main_ori_maskATB
                # match_maskBA = (nn_maskBA == 1) * main_ori_maskBTA
                # print(nn_maskAB.shape, main_ori_maskATB.shape, ori_maskATB.shape)
                match_maskAB = (nn_maskAB == 1) * (ori_maskATB >= self.ori_ratio)[mask_pointA, :]           # repeatNA X NTB
                match_maskBA = (nn_maskBA == 1) * (ori_maskBTA >= self.ori_ratio)[mask_pointB, :]           # repeatNB X NTA
                # pairAB_A_new, pairAB_B_new = torch.where(match_maskAB == 1)
                # pairBA_B_new, pairBA_A_new = torch.where(match_maskBA == 1)
                # assert pairAB_A_new.shape[0] > 0 and pairBA_B_new.shape[0] > 0 

                # # PA VS PAB 没有中心点距离偏移
                # # 中心主方向一致性
                # ori_kpAB_ext = F.grid_sample(ori_allB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                #                             pntA_H_normalized.detach().view(1, 1, -1, 2),
                #                             mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  
                # ori_kpBA_ext = F.grid_sample(ori_allA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                #                             pntB_invH_normalized.detach().view(1, 1, -1, 2),
                #                             mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  
                # main_ori_maskATAB = self.get_main_ori_consistence(ori_kpA[countA:countA+new_numA].unsqueeze(1), ori_kpAB_ext)  # NTAxNTA 
                # main_ori_maskBTBA = self.get_main_ori_consistence(ori_kpB[countB:countB+new_numB].unsqueeze(1), ori_kpBA_ext)  # NTBxNTB 

                # 4x4邻域方向一致性
                ori_kpAB_patch_ext = F.grid_sample(ori_all_patchB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntA_H_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  
                ori_kpBA_patch_ext = F.grid_sample(ori_all_patchA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntB_invH_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  
                # print('1_2_4:', ori_kpAB_patch_ext.shape)
                ori_maskATAB = self.get_ori_pattern(ori_kp_patchA[countA:countA+new_numA], ori_kpAB_patch_ext.transpose(0, 1))  # NTA x repeatNA
                ori_maskBTBA = self.get_ori_pattern(ori_kp_patchB[countB:countB+new_numB], ori_kpBA_patch_ext.transpose(0, 1))  # NTB x repeatNB
                
                ori_maskATAB = ori_maskATAB[mask_pointA, :]         # repeatNA x repeatNA
                ori_maskBTBA = ori_maskBTBA[mask_pointB, :]
                # vmaskAH = torch.diag(main_ori_maskATAB) == 1
                # vmaskBH = torch.diag(main_ori_maskBTBA) == 1
                # vmaskAH = torch.diag(main_ori_maskATAB * (ori_maskATAB >= self.ori_ratio)) == 1
                # vmaskBH = torch.diag(main_ori_maskBTBA * (ori_maskBTBA >= self.ori_ratio)) == 1
                # assert torch.sum(vmaskAH) > 0 and torch.sum(vmaskBH) > 0
                
                # 黑白相似度
                bin_maskATB = bin_distAB <= (1 - self.FR_bin_thr) * current_binA.shape[-1]  
                bin_maskBTA = bin_maskATB.transpose(0, 1)  

                match_maskAB = match_maskAB * bin_maskATB[mask_pointA, :]               # repeatNA X NB
                match_maskBA = match_maskBA * bin_maskBTA[mask_pointB, :]               # repeatNB X NA

                pairAB_A_new, pairAB_B_new = torch.where(match_maskAB == 1)
                pairBA_B_new, pairBA_A_new = torch.where(match_maskBA == 1)
                # print('bin_mask:', pairAB_A_new.shape[0], pairBA_B_new.shape[0])
                assert pairAB_A_new.shape[0] > 0 and pairBA_B_new.shape[0] > 0 

                bin_kpAB_T = F.grid_sample(bin_allB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntA_H_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # [256, repeatNA]
                bin_kpBA_T = F.grid_sample(bin_allA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntB_invH_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # [256, repeatNB]
                bin_distATAB = bin_kpAB_T.shape[0] - (current_binA @ bin_kpAB_T) - ((1 - current_binA) @ (1 - bin_kpAB_T)) # [NTA, repeatNA]
                bin_distBTBA = bin_kpBA_T.shape[0] - (current_binB @ bin_kpBA_T) - ((1 - current_binB) @ (1 - bin_kpBA_T)) # [NTB, repeatNB]

                bin_maskATAB = bin_distATAB <= (1 - self.FR_bin_thr) * bin_kpAB_T.shape[0] 
                bin_maskBTBA = bin_distBTBA <= (1 - self.FR_bin_thr) * bin_kpBA_T.shape[0] 
                bin_maskATAB = bin_maskATAB[mask_pointA, :]
                bin_maskBTBA = bin_maskBTBA[mask_pointB, :]

                vmaskAH = torch.diag((ori_maskATAB >= self.ori_ratio) * bin_maskATAB) == 1      # [repeatNA, 1]
                vmaskBH = torch.diag((ori_maskBTBA >= self.ori_ratio) * bin_maskBTBA) == 1      # [repeatNB, 1]
                # print('main_ori:', torch.sum(vmaskAH), torch.sum(vmaskBH))
                assert torch.sum(vmaskAH) > 0 and torch.sum(vmaskBH) > 0

                # SOSR: 简化的self-attention
                k_neighbor = 3
                cross_sim_AA_sp = current_descA @ current_descA.transpose(0, 1)
                cross_sim_BB_sp = current_descB @ current_descB.transpose(0, 1)
                # print('SOSR:', pairAB_A_new.shape[0], pairBA_B_new.shape[0])
                assert pairAB_A_new.shape[0] >= k_neighbor and pairBA_B_new.shape[0] >= k_neighbor 

                match_sim_AB_AA = cross_sim_AA_sp[mask_pointA, :][:, mask_pointA][pairAB_A_new, :][:, pairAB_A_new]
                match_sim_BA_BB = cross_sim_BB_sp[mask_pointB, :][:, mask_pointB][pairBA_B_new, :][:, pairBA_B_new]
                match_sim_AB_BB = cross_sim_BB_sp[pairAB_B_new, :][:, pairAB_B_new]
                match_sim_BA_AA = cross_sim_AA_sp[pairBA_A_new, :][:, pairBA_A_new]
                match_values_AB_AA, match_indices_AB_AA = torch.topk(match_sim_AB_AA, dim=1, k=k_neighbor, largest=False)
                match_values_BA_BB, match_indices_BA_BB = torch.topk(match_sim_BA_BB, dim=1, k=k_neighbor, largest=False)
                match_values_AB_BB_all = match_sim_AB_BB[:, match_indices_AB_AA]
                match_values_BA_AA_all = match_sim_BA_AA[:, match_indices_BA_BB]
                match_values_AB_BB = torch.diagonal(match_values_AB_BB_all, 0, dim1=0, dim2=1).transpose(0, 1)
                match_values_BA_AA = torch.diagonal(match_values_BA_AA_all, 0, dim1=0, dim2=1).transpose(0, 1)
                neighbor_dis_AB = (match_values_AB_AA - match_values_AB_BB) * (match_values_AB_AA - match_values_AB_BB)
                neighbor_dis_BA = (match_values_BA_BB - match_values_BA_AA) * (match_values_BA_BB - match_values_BA_AA)
                # print('1_1')
                # PA VS PB
                valid_cross_sim_AB_sp_mean = torch.mean(cross_sim_AB_sp[mask_pointA, :][match_maskAB == 1], dim=-1)
                novalid_cross_sim_AB_sp_mean = (torch.sum(torch.sum(cross_sim_AB_sp.detach(), 1), 0) - valid_cross_sim_AB_sp_mean * pairAB_A_new.shape[0]) / (new_numA * new_numB - pairAB_A_new.shape[0] + eps)
                valid_cross_sim_BA_sp_mean = torch.mean(cross_sim_AB_sp[:, mask_pointB][match_maskBA.transpose(0, 1) == 1], dim=-1)
                novalid_cross_sim_BA_sp_mean = (torch.sum(torch.sum(cross_sim_AB_sp.detach(), 1), 0) - valid_cross_sim_BA_sp_mean * pairBA_B_new.shape[0]) / (new_numA * new_numB - pairBA_B_new.shape[0] + eps)

                valid_indexesA = torch.tensor(list(range(cross_sim_AB_sp.shape[0])), device=self.device)[mask_pointA][pairAB_A_new]
                # cross_sim_BA_sp = current_descB @ current_descA.transpose(0, 1)
                cross_sim_AB_out_sp = torch.cat((cross_sim_AB_sp, torch.ones((cross_sim_AB_sp.shape[0], 1), device=cross_sim_AB_sp.device) * 2), dim=-1)      # NA X (NB + 1)
                # cross_sim_BA_out_sp = torch.cat((cross_sim_BA_sp, torch.ones((numB, 1), device=cross_sim_BA_sp.device)), dim=-1)      # NB X (NA + 1)
                # valid_indexesB = torch.tensor(list(range(numB)), device=self.device)[mask_pointB][pairBA_B]
                # print('1_2')
                cross_sim_AB_out_sp[valid_indexesA, -1] = novalid_cross_sim_AB_sp_mean
                novalid_indexesA = torch.tensor(list(range(cross_sim_AB_sp.shape[0])), device=self.device)[cross_sim_AB_out_sp[:, -1]==2]
                cross_sim_AB_out_sp[novalid_indexesA, -1] = valid_cross_sim_AB_sp_mean

                soft_cross_sim_AtoB_sp = F.softmax((cross_sim_AB_out_sp - 1) / t_des, dim=-1)
                # soft_cross_sim_BtoA = F.softmax((cross_sim_BA_out - 1) / t_des, dim=-1)
                # print('1_3')
                soft_valid_cross_sim_AB_sp = soft_cross_sim_AtoB_sp[mask_pointA, :-1][match_maskAB==1]
                # soft_valid_cross_sim_BA = soft_cross_sim_BtoA[mask_pointB, :-1][pairBA_B, pairBA_A]
                soft_novalid_cross_sim_AB_sp = soft_cross_sim_AtoB_sp[novalid_indexesA, -1]
                # soft_novalid_cross_sim_BA = soft_cross_sim_BtoA[cross_sim_BA_out[:, -1]==1, -1]
                log_soft_valid_cross_sim_AB_sp = -torch.log(soft_valid_cross_sim_AB_sp + eps) * ori_maskATB[mask_pointA, :][match_maskAB==1] * (1 - bin_distAB[mask_pointA, :][match_maskAB==1] / current_binA.shape[-1]) * (1 - key_disAB[match_maskAB==1] / self.correspond)
                # log_soft_valid_cross_sim_BA = -torch.log(soft_valid_cross_sim_BA + eps)
                log_soft_novalid_cross_sim_AB_sp = -torch.log(soft_novalid_cross_sim_AB_sp + eps)
                # log_soft_novalid_cross_sim_BA = -torch.log(soft_novalid_cross_sim_BA + eps)
                dis_cross_sim_mean_sp = torch.sum(torch.cat((log_soft_valid_cross_sim_AB_sp, log_soft_novalid_cross_sim_AB_sp), dim=-1), dim=-1) / new_numA
                # print(2)
                # PA VS PAB
                # match_mask_A = copy.deepcopy(mask_pointA)
                # match_mask_B = copy.deepcopy(mask_pointB)
                match_mask_A = torch.zeros(cross_sim_AB_sp.shape[0], device=self.device)
                valid_match_indexesA = torch.tensor(list(range(cross_sim_AB_sp.shape[0])), device=self.device)[mask_pointA][vmaskAH]
                match_mask_A[valid_match_indexesA] = 1
                match_mask_B = torch.zeros(cross_sim_AB_sp.shape[1], device=self.device)
                valid_match_indexesB = torch.tensor(list(range(cross_sim_AB_sp.shape[1])), device=self.device)[mask_pointB][vmaskBH]
                match_mask_B[valid_match_indexesB] = 1
                # match_mask_A = copy.deepcopy(vmaskAH)
                # match_mask_B = copy.deepcopy(vmaskBH)

                cross_sim_AB = current_descA @ desc_mapB[idx, :, :, :].view(-1, H * W)
                # cross_sim_AB = cross_sim_AB[mask_pointA, :]
                cross_sim_AB_all = F.grid_sample(cross_sim_AB.view(-1, H, W).unsqueeze(0),
                                                pntA_H_normalized[vmaskAH, :].detach().view(1, 1, -1, 2),
                                                mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NA x repeatNA
                valid_cross_sim_AB_mean = torch.trace(cross_sim_AB_all[match_mask_A==1, :]) / cross_sim_AB_all[match_mask_A==1, :].shape[0]
                # novalid_cross_sim_AB_mean = (torch.sum(torch.sum(cross_sim_AB.detach(), 1), 1) - valid_cross_sim_AB_mean * pairAB_A.shape[0]) / (new_numA * H * W - pairAB_A.shape[0])

                cross_sim_BA = current_descB @ desc_mapA[idx, :, :, :].view(-1, H * W)   # M x H x W
                # cross_sim_BA = cross_sim_BA[mask_pointB, :]
                cross_sim_BA_all = F.grid_sample(cross_sim_BA.view(-1, H, W).unsqueeze(0),
                                                pntB_invH_normalized[vmaskBH, :].detach().view(1, 1, -1, 2),
                                                mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NB x match_nB
                valid_cross_sim_BA_mean = torch.trace(cross_sim_BA_all[match_mask_B==1, :]) / cross_sim_BA_all[match_mask_B==1, :].shape[0]
                # novalid_cross_sim_BA_mean = (torch.sum(torch.sum(cross_sim_BA.detach(), 1), 1) - valid_cross_sim_BA_mean * pairBA_B.shape[0]) / (new_numB * H * W - pairBA_B.shape[0])

                cross_sim_AB_out = torch.cat((cross_sim_AB, torch.ones((cross_sim_AB.shape[0], 1), device=cross_sim_AB.device)), dim=-1)      # NA X (H X W + 1)
                cross_sim_BA_out = torch.cat((cross_sim_BA, torch.ones((cross_sim_BA.shape[0], 1), device=cross_sim_BA.device)), dim=-1)      # NB X (H X W + 1)
                # print(3)
                # cross_sim_AB_out[mask_pointA, -1] -= 1
                # cross_sim_BA_out[mask_pointB, -1] -= 1
                # cross_sim_AB_out[match_mask_A, -1] -= 1
                cross_sim_AB_out[match_mask_A==1, -1] = novalid_cross_sim_AB_sp_mean
                cross_sim_AB_out[match_mask_A==0, -1] = valid_cross_sim_AB_mean

                cross_sim_BA_out[match_mask_B==1, -1] = novalid_cross_sim_BA_sp_mean
                cross_sim_BA_out[match_mask_B==0, -1] = valid_cross_sim_BA_mean

                soft_cross_sim_AtoB = F.softmax((cross_sim_AB_out - 1) / t_des, dim=-1)         # NA X (H X W + 1)
                soft_cross_sim_BtoA = F.softmax((cross_sim_BA_out - 1) / t_des, dim=-1)         # NB X (H X W + 1)
                soft_cross_sim_AB_all = F.grid_sample(soft_cross_sim_AtoB[:, :-1].view(-1, H, W).unsqueeze(0),
                                                    pntA_H_normalized[vmaskAH, :].detach().view(1, 1, -1, 2),
                                                    mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NA x match_nA
                
                soft_cross_sim_BA_all = F.grid_sample(soft_cross_sim_BtoA[:, :-1].view(-1, H, W).unsqueeze(0),
                                                    pntB_invH_normalized[vmaskBH, :].detach().view(1, 1, -1, 2),
                                                    mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NB x match_nB
                # soft_valid_cross_sim_AB_all = soft_cross_sim_AB_all[mask_pointA, :]             # repeat_nA x repeat_nA
                # soft_valid_cross_sim_BA_all = soft_cross_sim_BA_all[mask_pointB, :]             # repeat_nB x repeat_nB

                soft_valid_cross_sim_AB_all = soft_cross_sim_AB_all[match_mask_A==1, :]             # match_nA x match_nA
                soft_valid_cross_sim_BA_all = soft_cross_sim_BA_all[match_mask_B==1, :]             # match_nB x match_nB

                valid_mask_AB = torch.eye(soft_valid_cross_sim_AB_all.shape[0]) == 1
                valid_mask_BA = torch.eye(soft_valid_cross_sim_BA_all.shape[0]) == 1
                # print(4)
                # 取对角线
                soft_valid_cross_sim_AB = soft_valid_cross_sim_AB_all[valid_mask_AB]
                soft_valid_cross_sim_BA = soft_valid_cross_sim_BA_all[valid_mask_BA]

                # soft_novalid_cross_sim_AB = soft_cross_sim_AtoB[mask_pointA==False, -1]              # (NA-repeat_nA) x 1
                # soft_novalid_cross_sim_BA = soft_cross_sim_BtoA[mask_pointB==False, -1]
                soft_novalid_cross_sim_AB = soft_cross_sim_AtoB[match_mask_A==0, -1]               # (NA-match_nA) x 1
                soft_novalid_cross_sim_BA = soft_cross_sim_BtoA[match_mask_B==0, -1]
                # print(soft_novalid_cross_sim_AB, soft_novalid_cross_sim_BA)

                log_soft_valid_cross_sim_AB = -torch.log(soft_valid_cross_sim_AB + eps) * torch.diag(ori_maskATAB)[vmaskAH] * (1 - torch.diag(bin_distATAB[mask_pointA, :])[vmaskAH] / bin_kpAB_T.shape[0])
                log_soft_valid_cross_sim_BA = -torch.log(soft_valid_cross_sim_BA + eps) * torch.diag(ori_maskBTBA)[vmaskBH] * (1 - torch.diag(bin_distBTBA[mask_pointB, :])[vmaskBH] / bin_kpBA_T.shape[0])
                log_soft_novalid_cross_sim_AB = -torch.log(soft_novalid_cross_sim_AB + eps)
                log_soft_novalid_cross_sim_BA = -torch.log(soft_novalid_cross_sim_BA + eps)

                dis_cross_sim_mean = torch.sum(torch.cat((log_soft_valid_cross_sim_AB, log_soft_valid_cross_sim_BA, log_soft_novalid_cross_sim_AB, log_soft_novalid_cross_sim_BA), dim=-1), dim=-1) / (new_numA + new_numB)
                # print(5)
                valid_cross_sim_AB = cross_sim_AB[mask_pointA, :]   # repeat_nA x (H X W)
                valid_cross_sim_BA = cross_sim_BA[mask_pointB, :]   # repeat_nB x (H X W)
                exp_valid_cross_sim_AtoB = torch.exp((valid_cross_sim_AB - 1) / t_rel).view(-1, H, W)
                exp_valid_cross_sim_BtoA = torch.exp((valid_cross_sim_BA - 1) / t_rel).view(-1, H, W)
                exp_valid_cross_sim_AB_all = F.grid_sample(exp_valid_cross_sim_AtoB.unsqueeze(0),
                                                        pntA_H_normalized.detach().view(1, 1, -1, 2),
                                                        mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # repeat_nA x repeat_nA
                
                exp_valid_cross_sim_BA_all = F.grid_sample(exp_valid_cross_sim_BtoA.unsqueeze(0),
                                                        pntB_invH_normalized.detach().view(1, 1, -1, 2),
                                                        mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # repeat_nB x repeat_nB

                repeat_mask_AB = torch.eye(exp_valid_cross_sim_AB_all.shape[0]) == 1
                repeat_mask_BA = torch.eye(exp_valid_cross_sim_BA_all.shape[0]) == 1
                rel_valid_cross_sim_AB = exp_valid_cross_sim_AB_all[repeat_mask_AB]
                rel_valid_cross_sim_BA = exp_valid_cross_sim_BA_all[repeat_mask_BA]

                # pntA_H_normalized_new = copy.deepcopy(pntA_H_normalized.detach())
                # pntB_invH_normalized_new = copy.deepcopy(pntB_invH_normalized.detach())

                # pntA_H_normalized_new[:, 0] += 2
                # pntB_invH_normalized_new[:, 0] += 2

                scoresAB_all = F.grid_sample(scores_mapB[idx, :, :, :].unsqueeze(0),
                                            pntA_H_normalized_new.view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)      # 1 x repeat_nA

                scoresBA_all = F.grid_sample(scores_mapA[idx, :, :, :].unsqueeze(0),
                                            pntB_invH_normalized_new.view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)      # 1 x repeat_nB
                # print(6)
                scores_AAB = scoresA[idx][pmA][mask_pointA] * scoresAB_all
                scores_BBA = scoresB[idx][pmB][mask_pointB] * scoresBA_all
                scores_sum_AAB = torch.sum(scores_AAB, dim=-1)
                scores_sum_BBA = torch.sum(scores_BBA, dim=-1)
                scores_normalize_AAB = scores_AAB / (scores_sum_AAB + eps)
                scores_normalize_BBA = scores_BBA / (scores_sum_BBA + eps)
                rel_meanA = torch.sum(scores_normalize_AAB * (1 - rel_valid_cross_sim_AB), dim=-1) / pntA_H_normalized_new.shape[0]
                rel_meanB = torch.sum(scores_normalize_BBA * (1 - rel_valid_cross_sim_BA), dim=-1) / pntB_invH_normalized_new.shape[0]

                # # 熵loss
                # current_descA_std, current_descB_std = descA_std[countA:countA+new_numA], descB_std[countB:countB+new_numB]
                # desc_std += torch.mean(current_descA_std) + torch.mean(current_descB_std)

                countA += new_numA
                countB += new_numB
                # countA_T += numA_T
                # countB_T += numB_T

                dis_neighbor_mean_total += torch.mean(torch.sum(neighbor_dis_AB, dim=1)) + torch.mean(torch.sum(neighbor_dis_BA, dim=1))
                dis_desc += dis_cross_sim_mean_sp
                dis_desc += dis_cross_sim_mean

                dis_pair_meanAB = torch.mean(key_manhattandisAB[pairAB_A, pairAB_B])
                dis_pair_meanBA = torch.mean(key_manhattandisBA[pairBA_B, pairBA_A])

                dis_peak_mean = torch.mean(torch.cat((scoreddisA[idx][pmA], scoreddisB[idx][pmB]), dim=0))
                # dis_peak_meanB = torch.mean(scoreddisB[idx])
                
                dis_mean_total += dis_pair_meanAB + dis_pair_meanBA
                dis_peak_scored += dis_peak_mean

                dis_rel += rel_meanA + rel_meanB
                # # Penalty
                # scores_mean += (-torch.log(torch.mean(scoresA[idx], dim=-1) + eps) - torch.log(torch.mean(scoresB[idx], dim=-1) + eps)) 
                # print(scores_mean)
            except:
                # dis_mean_total += 0
                # dis_peak_scored += 0
                # dis_desc += 0
                # dis_rel += 0
                # print('Overlapping too small or Repeatable point pairs distance is greater than correspond(1.5):', pntA.shape[0], pntA_H.shape[0], pntB.shape[0], pntB_invH.shape[0], dis_pairAB.shape[0], dis_pairBA.shape[0])
                valid_batch_size -= 1
                countA += new_numA
                countB += new_numB
                # countA_T += numA_T
                # countB_T += numB_T

        valid_batch_size = valid_batch_size if valid_batch_size > 0 else eps
        # Reprojection Loss 
        reprojection_loss = dis_mean_total / (valid_batch_size * 2)
        # Dispersity Peak Loss
        dispersity_peak_loss = dis_peak_scored / valid_batch_size
        # NRE Loss
        descriptor_loss = dis_desc / (2 * valid_batch_size)
        # Reliability Loss
        reliability_loss = dis_rel / (valid_batch_size * 2)
        # SOSR Loss
        sosr_loss = dis_neighbor_mean_total / ((valid_batch_size * 2))
        # # Entropy loss
        # std_loss = (valid_batch_size * 2) / desc_std  
        # # Score Penalty
        # score_penalty = scores_mean / (valid_batch_size * 2)
        # FA Desc loss
        FA_des_loss = dis_desc_fa / valid_batch_size_FA if valid_batch_size_FA > 0 else 0

        loss_total = wrp * reprojection_loss + wpl * dispersity_peak_loss + wdl * descriptor_loss + wrl * reliability_loss + sosr_loss + FA_des_loss
        loss_group = {
            'reprojection_loss': reprojection_loss, 
            'dispersity_peak_loss': dispersity_peak_loss,
            'descriptor_loss': descriptor_loss,
            'reliability_loss': reliability_loss,
            'sosr_loss': sosr_loss,
            # 'std_loss': std_loss,
            'FA_des_loss': FA_des_loss,
            }
        return loss_total, loss_group

    def detector_selfsupervised_loss_dkd_patch_ext_restrict_modify_oriR_ratio_FA_bw_ns_wg(self, kpA, kpB, pmaskA, pmaskB, descA, descB, desc_mapA, desc_mapB, scoreddisA, scoreddisB, scoresA, scoresB, scores_mapA, scores_mapB, Homo, inv_Homo, inv_Homo_en, ori_all_patchA, ori_all_patchB, ori_kp_patchA, ori_kp_patchB, bin_allA, bin_allB, bin_kpA, bin_kpB, FA_flag, H, W, wrp=1, wpl=1, wdl=1, wrl=1, t_des=0.02, t_rel=1):
        # pmaskA: (BxMax_num) 32x350=11200
        batch_size = len(kpA)
        max_num = pmaskA.shape[-1] // batch_size    # 350
        dis_mean_total = 0
        dis_neighbor_mean_total = 0
        dis_peak_scored = 0
        dis_desc = 0
        dis_rel = 0
        desc_std = 0
        eps = 1e-12
        valid_batch_size = batch_size
        valid_batch_size_FA = 0
        countA, countB = 0, 0
        dis_desc_fa = 0
        # countA_T, countB_T = 0, 0
        for idx in range(batch_size):
            pntA, pntB = kpA[idx], kpB[idx]     # M X 2 (x,y)
            # kmask_TA, kmask_TB = kmask_T_allA[idx], kmask_T_allB[idx]
            pntA = pntA.float()
            pntB = pntB.float()

            # 剔除部分按压区域的点,且保留在重叠区域的点
            numA, numB = pntA.shape[0], pntB.shape[0]
            # numA_T, numB_T = pntA[kmask_TA].shape[0], pntB[kmask_TB].shape[0]
            pmA, pmB = pmaskA[max_num * idx:max_num * idx + numA].bool(), pmaskB[max_num * idx:max_num * idx + numB].bool()
            pntA, pntB = pntA[pmA, :], pntB[pmB, :]
            new_numA, new_numB = pntA.shape[0], pntB.shape[0]       
            
            pntA = (pntA + 1) / 2 * pntA.new_tensor([[W + 3, H - 1]]).to(pntA.device)
            pntB = (pntB + 1) / 2 * pntB.new_tensor([[W + 3, H - 1]]).to(pntB.device)

            # [120, 40] -> [120, 36],实际只取中心118x32区域的点对
            pntA[:, 0] -= 2
            pntB[:, 0] -= 2
            
            pntA_normalized = pntA / pntA.new_tensor([W - 1, H - 1]).to(pntA.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)
            pntB_normalized = pntB / pntB.new_tensor([W - 1, H - 1]).to(pntB.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)

            pntA_H = warp_points(pntA[:, :2], Homo[idx].squeeze(), device=self.device)  # 利用变换矩阵变换坐标点
            pntA_H, mask_pointA = filter_points(pntA_H, torch.tensor([W, H], device=self.device), return_mask=True)
            pntB_invH = warp_points(pntB[:, :2], inv_Homo[idx].squeeze(), device=self.device)
            pntB_invH, mask_pointB = filter_points(pntB_invH, torch.tensor([W, H], device=self.device), return_mask=True)
            
            current_descA, current_descB = descA[countA:countA+new_numA], descB[countB:countB+new_numB]
            cross_sim_AB_sp = current_descA @ current_descB.transpose(0, 1)     # NTA X NTB
            
            # 黑白相似度
            current_binA, current_binB = bin_kpA[countA:countA+new_numA], bin_kpB[countB:countB+new_numB]   # [NA, 256] [NB_256]
            bin_distAB = current_binA.shape[-1] - (current_binA @ current_binB.transpose(0, 1)) - ((1 - current_binA) @ (1 - current_binB.transpose(0, 1))) # [NA, NB]

            # Net FA余弦相似度小
            if FA_flag[idx] == 1:
                FA_bin_mask = bin_distAB >= (1 - self.FA_bin_thr) * current_binA.shape[-1] 
                # print(current_binA.shape, bin_distAB[0, :])
                # print(FA_bin_mask.shape, torch.sum(FA_bin_mask))
                dis_desc_fa += (2 - torch.mean(torch.sqrt(2 * (1 - cross_sim_AB_sp[FA_bin_mask]) + eps)))

                valid_batch_size -= 1
                valid_batch_size_FA += 1
                countA += new_numA
                countB += new_numB
                continue
            
            # 真匹配的trans
            try:
                assert pntA_H.shape[0] > 0 and pntB_invH.shape[0] > 0 
                
                # 点对欧氏距离
                key_disAB = self.get_dis(pntA_H[:, :2], pntB[:, :2])            # repeatNA x NB
                key_disBA = self.get_dis(pntB_invH[:, :2], pntA[:, :2])
                pairAB_A, pairAB_B, dis_pairAB, _ = self.get_point_pair(key_disAB, dis_thre=self.correspond)  # p -> k # NTA(<1.5), NTA(<1.5), NTA(<1.5), NTA        
                pairBA_B, pairBA_A, dis_pairBA, _  = self.get_point_pair(key_disBA, dis_thre=self.correspond)  # p -> k # NTB(<1.5), NTB(<1.5), NTB(<1.5), NTB 
                
                # 点距离mask
                nn_maskAB = torch.zeros((pntA_H.shape[0], pntB.shape[0]), device=self.device) 
                nn_maskAB[pairAB_A, pairAB_B] = 1

                nn_maskBA = torch.zeros((pntB_invH.shape[0], pntA.shape[0]), device=self.device) 
                nn_maskBA[pairBA_B, pairBA_A] = 1

                # 点对曼哈顿距离
                key_manhattandisAB = self.get_manhattan_dis(pntA_H[:, :2], pntB[:, :2])
                key_manhattandisBA = self.get_manhattan_dis(pntB_invH[:, :2], pntA[:, :2])
                # print('pdis:', dis_pairAB.shape[0], dis_pairBA.shape[0])
                assert dis_pairAB.shape[0] > 0 and dis_pairBA.shape[0] > 0     

                pntA_H_normalized = pntA_H / pntA_H.new_tensor([W - 1, H - 1]).to(pntA_H.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)
                pntB_invH_normalized = pntB_invH / pntB_invH.new_tensor([W - 1, H - 1]).to(pntB_invH.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)

                # 用于score_map
                pntA_H_new = copy.deepcopy(pntA_H.detach())
                pntB_invH_new = copy.deepcopy(pntB_invH.detach())
                pntA_H_new[:, 0] += 10                   # 120 x 36 -> 128 x 56
                pntA_H_new[:, 1] += 4 
                pntB_invH_new[:, 0] += 10
                pntB_invH_new[:, 1] += 4
                
                pntA_H_normalized_new = pntA_H_new / pntA_H_new.new_tensor([W + 19, H + 7]).to(pntA_H.device) * 2 - 1

                # pntB_invH_new = warp_points(pntB_invH_new[:, :2], inv_Homo_en[idx].squeeze(), device=self.device)       # 转到A上，而不是AT上
                
                pntB_invH_normalized_new = pntB_invH_new / pntB_invH_new.new_tensor([W + 19, H + 7]).to(pntB_invH.device) * 2 - 1 

                # # PA VS PB 有一定偏移
                # ori_kpA_ext = F.grid_sample(ori_allA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                #                             pntA_normalized.detach().view(1, 1, -1, 2),
                #                             mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  
                # ori_kpB_ext = F.grid_sample(ori_allB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                #                             pntB_normalized.detach().view(1, 1, -1, 2),
                #                             mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  

                # main_ori_maskATB = self.get_main_ori_consistence(ori_kpA[countA:countA+numA][pmA].unsqueeze(1), ori_kpB_ext)  # NTA x NTB 
                # main_ori_maskBTA = self.get_main_ori_consistence(ori_kpB[countB:countB+numB][pmB].unsqueeze(1), ori_kpA_ext)  # NTB x NTA 
                
                # print('1_2:', main_ori_maskATB.shape[0])
                # exit()
                # ori_kpA_patch_ext = F.grid_sample(ori_all_patchA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                #                             pntA_normalized.detach().view(1, 1, -1, 2),
                #                             mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  
                # ori_kpB_patch_ext = F.grid_sample(ori_all_patchB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                #                             pntB_normalized.detach().view(1, 1, -1, 2),
                #                             mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  
                # print('1_2_1:', pntB_invH_normalized_new.shape[0])
                ori_maskATB = self.get_ori_pattern(ori_kp_patchA[countA:countA+new_numA], ori_kp_patchB[countB:countB+new_numB])  # NTA x NTB
                # print('1_2_2:', ori_maskATB.shape)
                ori_maskBTA = ori_maskATB.transpose(0, 1)
                # print('1_2_2:', ori_maskATB.shape[0])
                # match_maskAB = (nn_maskAB == 1) * main_ori_maskATB
                # match_maskBA = (nn_maskBA == 1) * main_ori_maskBTA
                # print(nn_maskAB.shape, main_ori_maskATB.shape, ori_maskATB.shape)
                match_maskAB = (nn_maskAB == 1) * (ori_maskATB >= self.ori_ratio)[mask_pointA, :]           # repeatNA X NTB
                match_maskBA = (nn_maskBA == 1) * (ori_maskBTA >= self.ori_ratio)[mask_pointB, :]           # repeatNB X NTA
                # pairAB_A_new, pairAB_B_new = torch.where(match_maskAB == 1)
                # pairBA_B_new, pairBA_A_new = torch.where(match_maskBA == 1)
                # assert pairAB_A_new.shape[0] > 0 and pairBA_B_new.shape[0] > 0 

                # # PA VS PAB 没有中心点距离偏移
                # # 中心主方向一致性
                # ori_kpAB_ext = F.grid_sample(ori_allB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                #                             pntA_H_normalized.detach().view(1, 1, -1, 2),
                #                             mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  
                # ori_kpBA_ext = F.grid_sample(ori_allA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                #                             pntB_invH_normalized.detach().view(1, 1, -1, 2),
                #                             mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  
                # main_ori_maskATAB = self.get_main_ori_consistence(ori_kpA[countA:countA+new_numA].unsqueeze(1), ori_kpAB_ext)  # NTAxNTA 
                # main_ori_maskBTBA = self.get_main_ori_consistence(ori_kpB[countB:countB+new_numB].unsqueeze(1), ori_kpBA_ext)  # NTBxNTB 

                # 4x4邻域方向一致性
                ori_kpAB_patch_ext = F.grid_sample(ori_all_patchB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntA_H_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  
                ori_kpBA_patch_ext = F.grid_sample(ori_all_patchA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntB_invH_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  
                # print('1_2_4:', ori_kpAB_patch_ext.shape)
                ori_maskATAB = self.get_ori_pattern(ori_kp_patchA[countA:countA+new_numA], ori_kpAB_patch_ext.transpose(0, 1))  # NTA x repeatNA
                ori_maskBTBA = self.get_ori_pattern(ori_kp_patchB[countB:countB+new_numB], ori_kpBA_patch_ext.transpose(0, 1))  # NTB x repeatNB
                
                ori_maskATAB = ori_maskATAB[mask_pointA, :]         # repeatNA x repeatNA
                ori_maskBTBA = ori_maskBTBA[mask_pointB, :]
                # vmaskAH = torch.diag(main_ori_maskATAB) == 1
                # vmaskBH = torch.diag(main_ori_maskBTBA) == 1
                # vmaskAH = torch.diag(main_ori_maskATAB * (ori_maskATAB >= self.ori_ratio)) == 1
                # vmaskBH = torch.diag(main_ori_maskBTBA * (ori_maskBTBA >= self.ori_ratio)) == 1
                # assert torch.sum(vmaskAH) > 0 and torch.sum(vmaskBH) > 0
                
                # 黑白相似度
                bin_maskATB = bin_distAB <= (1 - self.FR_bin_thr) * current_binA.shape[-1]  
                bin_maskBTA = bin_maskATB.transpose(0, 1)  

                match_maskAB = match_maskAB * bin_maskATB[mask_pointA, :]               # repeatNA X NB
                match_maskBA = match_maskBA * bin_maskBTA[mask_pointB, :]               # repeatNB X NA

                pairAB_A_new, pairAB_B_new = torch.where(match_maskAB == 1)
                pairBA_B_new, pairBA_A_new = torch.where(match_maskBA == 1)
                # print('bin_mask:', pairAB_A_new.shape[0], pairBA_B_new.shape[0])
                assert pairAB_A_new.shape[0] > 0 and pairBA_B_new.shape[0] > 0 

                bin_kpAB_T = F.grid_sample(bin_allB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntA_H_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # [256, repeatNA]
                bin_kpBA_T = F.grid_sample(bin_allA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntB_invH_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # [256, repeatNB]
                bin_distATAB = bin_kpAB_T.shape[0] - (current_binA @ bin_kpAB_T) - ((1 - current_binA) @ (1 - bin_kpAB_T)) # [NTA, repeatNA]
                bin_distBTBA = bin_kpBA_T.shape[0] - (current_binB @ bin_kpBA_T) - ((1 - current_binB) @ (1 - bin_kpBA_T)) # [NTB, repeatNB]

                bin_maskATAB = bin_distATAB <= (1 - self.FR_bin_thr) * bin_kpAB_T.shape[0] 
                bin_maskBTBA = bin_distBTBA <= (1 - self.FR_bin_thr) * bin_kpBA_T.shape[0] 
                bin_maskATAB = bin_maskATAB[mask_pointA, :]
                bin_maskBTBA = bin_maskBTBA[mask_pointB, :]

                vmaskAH = torch.diag((ori_maskATAB >= self.ori_ratio) * bin_maskATAB) == 1      # [repeatNA, 1]
                vmaskBH = torch.diag((ori_maskBTBA >= self.ori_ratio) * bin_maskBTBA) == 1      # [repeatNB, 1]
                # print('main_ori:', torch.sum(vmaskAH), torch.sum(vmaskBH))
                assert torch.sum(vmaskAH) > 0 and torch.sum(vmaskBH) > 0

                # SOSR: 简化的self-attention
                k_neighbor = 3
                cross_sim_AA_sp = current_descA @ current_descA.transpose(0, 1)
                cross_sim_BB_sp = current_descB @ current_descB.transpose(0, 1)
                # print('SOSR:', pairAB_A_new.shape[0], pairBA_B_new.shape[0])
                assert pairAB_A_new.shape[0] >= k_neighbor and pairBA_B_new.shape[0] >= k_neighbor 

                match_sim_AB_AA = cross_sim_AA_sp[mask_pointA, :][:, mask_pointA][pairAB_A_new, :][:, pairAB_A_new]
                match_sim_BA_BB = cross_sim_BB_sp[mask_pointB, :][:, mask_pointB][pairBA_B_new, :][:, pairBA_B_new]
                match_sim_AB_BB = cross_sim_BB_sp[pairAB_B_new, :][:, pairAB_B_new]
                match_sim_BA_AA = cross_sim_AA_sp[pairBA_A_new, :][:, pairBA_A_new]
                match_values_AB_AA, match_indices_AB_AA = torch.topk(match_sim_AB_AA, dim=1, k=k_neighbor, largest=False)
                match_values_BA_BB, match_indices_BA_BB = torch.topk(match_sim_BA_BB, dim=1, k=k_neighbor, largest=False)
                match_values_AB_BB_all = match_sim_AB_BB[:, match_indices_AB_AA]
                match_values_BA_AA_all = match_sim_BA_AA[:, match_indices_BA_BB]
                match_values_AB_BB = torch.diagonal(match_values_AB_BB_all, 0, dim1=0, dim2=1).transpose(0, 1)
                match_values_BA_AA = torch.diagonal(match_values_BA_AA_all, 0, dim1=0, dim2=1).transpose(0, 1)
                neighbor_dis_AB = (match_values_AB_AA - match_values_AB_BB) * (match_values_AB_AA - match_values_AB_BB)
                neighbor_dis_BA = (match_values_BA_BB - match_values_BA_AA) * (match_values_BA_BB - match_values_BA_AA)
                # print('1_1')
                # PA VS PB
                valid_cross_sim_AB_sp_mean = torch.mean(cross_sim_AB_sp[mask_pointA, :][match_maskAB == 1], dim=-1)
                novalid_cross_sim_AB_sp_mean = (torch.sum(torch.sum(cross_sim_AB_sp.detach(), 1), 0) - valid_cross_sim_AB_sp_mean * pairAB_A_new.shape[0]) / (new_numA * new_numB - pairAB_A_new.shape[0] + eps)
                valid_cross_sim_BA_sp_mean = torch.mean(cross_sim_AB_sp[:, mask_pointB][match_maskBA.transpose(0, 1) == 1], dim=-1)
                novalid_cross_sim_BA_sp_mean = (torch.sum(torch.sum(cross_sim_AB_sp.detach(), 1), 0) - valid_cross_sim_BA_sp_mean * pairBA_B_new.shape[0]) / (new_numA * new_numB - pairBA_B_new.shape[0] + eps)

                valid_indexesA = torch.tensor(list(range(cross_sim_AB_sp.shape[0])), device=self.device)[mask_pointA][pairAB_A_new]
                # cross_sim_BA_sp = current_descB @ current_descA.transpose(0, 1)
                cross_sim_AB_out_sp = torch.cat((cross_sim_AB_sp, torch.ones((cross_sim_AB_sp.shape[0], 1), device=cross_sim_AB_sp.device) * 2), dim=-1)      # NA X (NB + 1)
                # cross_sim_BA_out_sp = torch.cat((cross_sim_BA_sp, torch.ones((numB, 1), device=cross_sim_BA_sp.device)), dim=-1)      # NB X (NA + 1)
                # valid_indexesB = torch.tensor(list(range(numB)), device=self.device)[mask_pointB][pairBA_B]
                # print('1_2')
                cross_sim_AB_out_sp[valid_indexesA, -1] = novalid_cross_sim_AB_sp_mean
                novalid_indexesA = torch.tensor(list(range(cross_sim_AB_sp.shape[0])), device=self.device)[cross_sim_AB_out_sp[:, -1]==2]
                cross_sim_AB_out_sp[novalid_indexesA, -1] = valid_cross_sim_AB_sp_mean

                soft_cross_sim_AtoB_sp = F.softmax((cross_sim_AB_out_sp - 1) / t_des, dim=-1)
                # soft_cross_sim_BtoA = F.softmax((cross_sim_BA_out - 1) / t_des, dim=-1)
                # print('1_3')
                soft_valid_cross_sim_AB_sp = soft_cross_sim_AtoB_sp[mask_pointA, :-1][match_maskAB==1]
                # soft_valid_cross_sim_BA = soft_cross_sim_BtoA[mask_pointB, :-1][pairBA_B, pairBA_A]
                soft_novalid_cross_sim_AB_sp = soft_cross_sim_AtoB_sp[novalid_indexesA, -1]
                # soft_novalid_cross_sim_BA = soft_cross_sim_BtoA[cross_sim_BA_out[:, -1]==1, -1]
                log_soft_valid_cross_sim_AB_sp = -torch.log(soft_valid_cross_sim_AB_sp + eps) * ori_maskATB[mask_pointA, :][match_maskAB==1] * (1 - bin_distAB[mask_pointA, :][match_maskAB==1] / current_binA.shape[-1]) * (1 - key_disAB[match_maskAB==1] / self.correspond)
                # log_soft_valid_cross_sim_BA = -torch.log(soft_valid_cross_sim_BA + eps)
                log_soft_novalid_cross_sim_AB_sp = -torch.log(soft_novalid_cross_sim_AB_sp + eps)
                # log_soft_novalid_cross_sim_BA = -torch.log(soft_novalid_cross_sim_BA + eps)
                dis_cross_sim_mean_sp = torch.sum(torch.cat((log_soft_valid_cross_sim_AB_sp, log_soft_novalid_cross_sim_AB_sp), dim=-1), dim=-1) / new_numA
                # print(2)
                # PA VS PAB
                # match_mask_A = copy.deepcopy(mask_pointA)
                # match_mask_B = copy.deepcopy(mask_pointB)
                match_mask_A = torch.zeros(cross_sim_AB_sp.shape[0], device=self.device)
                valid_match_indexesA = torch.tensor(list(range(cross_sim_AB_sp.shape[0])), device=self.device)[mask_pointA][vmaskAH]
                match_mask_A[valid_match_indexesA] = 1
                match_mask_B = torch.zeros(cross_sim_AB_sp.shape[1], device=self.device)
                valid_match_indexesB = torch.tensor(list(range(cross_sim_AB_sp.shape[1])), device=self.device)[mask_pointB][vmaskBH]
                match_mask_B[valid_match_indexesB] = 1
                # match_mask_A = copy.deepcopy(vmaskAH)
                # match_mask_B = copy.deepcopy(vmaskBH)

                cross_sim_AB = current_descA @ desc_mapB[idx, :, :, :].view(-1, H * W)
                # cross_sim_AB = cross_sim_AB[mask_pointA, :]
                cross_sim_AB_all = F.grid_sample(cross_sim_AB.view(-1, H, W).unsqueeze(0),
                                                pntA_H_normalized[vmaskAH, :].detach().view(1, 1, -1, 2),
                                                mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NA x repeatNA
                valid_cross_sim_AB_mean = torch.trace(cross_sim_AB_all[match_mask_A==1, :]) / cross_sim_AB_all[match_mask_A==1, :].shape[0]
                # novalid_cross_sim_AB_mean = (torch.sum(torch.sum(cross_sim_AB.detach(), 1), 1) - valid_cross_sim_AB_mean * pairAB_A.shape[0]) / (new_numA * H * W - pairAB_A.shape[0])

                cross_sim_BA = current_descB @ desc_mapA[idx, :, :, :].view(-1, H * W)   # M x H x W
                # cross_sim_BA = cross_sim_BA[mask_pointB, :]
                cross_sim_BA_all = F.grid_sample(cross_sim_BA.view(-1, H, W).unsqueeze(0),
                                                pntB_invH_normalized[vmaskBH, :].detach().view(1, 1, -1, 2),
                                                mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NB x match_nB
                valid_cross_sim_BA_mean = torch.trace(cross_sim_BA_all[match_mask_B==1, :]) / cross_sim_BA_all[match_mask_B==1, :].shape[0]
                # novalid_cross_sim_BA_mean = (torch.sum(torch.sum(cross_sim_BA.detach(), 1), 1) - valid_cross_sim_BA_mean * pairBA_B.shape[0]) / (new_numB * H * W - pairBA_B.shape[0])

                cross_sim_AB_out = torch.cat((cross_sim_AB, torch.ones((cross_sim_AB.shape[0], 1), device=cross_sim_AB.device)), dim=-1)      # NA X (H X W + 1)
                cross_sim_BA_out = torch.cat((cross_sim_BA, torch.ones((cross_sim_BA.shape[0], 1), device=cross_sim_BA.device)), dim=-1)      # NB X (H X W + 1)
                # print(3)
                # cross_sim_AB_out[mask_pointA, -1] -= 1
                # cross_sim_BA_out[mask_pointB, -1] -= 1
                # cross_sim_AB_out[match_mask_A, -1] -= 1
                cross_sim_AB_out[match_mask_A==1, -1] = novalid_cross_sim_AB_sp_mean
                cross_sim_AB_out[match_mask_A==0, -1] = valid_cross_sim_AB_mean

                cross_sim_BA_out[match_mask_B==1, -1] = novalid_cross_sim_BA_sp_mean
                cross_sim_BA_out[match_mask_B==0, -1] = valid_cross_sim_BA_mean

                soft_cross_sim_AtoB = F.softmax((cross_sim_AB_out - 1) / t_des, dim=-1)         # NA X (H X W + 1)
                soft_cross_sim_BtoA = F.softmax((cross_sim_BA_out - 1) / t_des, dim=-1)         # NB X (H X W + 1)
                soft_cross_sim_AB_all = F.grid_sample(soft_cross_sim_AtoB[:, :-1].view(-1, H, W).unsqueeze(0),
                                                    pntA_H_normalized[vmaskAH, :].detach().view(1, 1, -1, 2),
                                                    mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NA x match_nA
                
                soft_cross_sim_BA_all = F.grid_sample(soft_cross_sim_BtoA[:, :-1].view(-1, H, W).unsqueeze(0),
                                                    pntB_invH_normalized[vmaskBH, :].detach().view(1, 1, -1, 2),
                                                    mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NB x match_nB
                # soft_valid_cross_sim_AB_all = soft_cross_sim_AB_all[mask_pointA, :]             # repeat_nA x repeat_nA
                # soft_valid_cross_sim_BA_all = soft_cross_sim_BA_all[mask_pointB, :]             # repeat_nB x repeat_nB

                soft_valid_cross_sim_AB_all = soft_cross_sim_AB_all[match_mask_A==1, :]             # match_nA x match_nA
                soft_valid_cross_sim_BA_all = soft_cross_sim_BA_all[match_mask_B==1, :]             # match_nB x match_nB

                valid_mask_AB = torch.eye(soft_valid_cross_sim_AB_all.shape[0]) == 1
                valid_mask_BA = torch.eye(soft_valid_cross_sim_BA_all.shape[0]) == 1
                # print(4)
                # 取对角线
                soft_valid_cross_sim_AB = soft_valid_cross_sim_AB_all[valid_mask_AB]
                soft_valid_cross_sim_BA = soft_valid_cross_sim_BA_all[valid_mask_BA]

                # soft_novalid_cross_sim_AB = soft_cross_sim_AtoB[mask_pointA==False, -1]              # (NA-repeat_nA) x 1
                # soft_novalid_cross_sim_BA = soft_cross_sim_BtoA[mask_pointB==False, -1]
                soft_novalid_cross_sim_AB = soft_cross_sim_AtoB[match_mask_A==0, -1]               # (NA-match_nA) x 1
                soft_novalid_cross_sim_BA = soft_cross_sim_BtoA[match_mask_B==0, -1]
                # print(soft_novalid_cross_sim_AB, soft_novalid_cross_sim_BA)

                log_soft_valid_cross_sim_AB = -torch.log(soft_valid_cross_sim_AB + eps) * torch.diag(ori_maskATAB)[vmaskAH] * (1 - torch.diag(bin_distATAB[mask_pointA, :])[vmaskAH] / bin_kpAB_T.shape[0])
                log_soft_valid_cross_sim_BA = -torch.log(soft_valid_cross_sim_BA + eps) * torch.diag(ori_maskBTBA)[vmaskBH] * (1 - torch.diag(bin_distBTBA[mask_pointB, :])[vmaskBH] / bin_kpBA_T.shape[0])
                log_soft_novalid_cross_sim_AB = -torch.log(soft_novalid_cross_sim_AB + eps)
                log_soft_novalid_cross_sim_BA = -torch.log(soft_novalid_cross_sim_BA + eps)

                dis_cross_sim_mean = torch.sum(torch.cat((log_soft_valid_cross_sim_AB, log_soft_valid_cross_sim_BA, log_soft_novalid_cross_sim_AB, log_soft_novalid_cross_sim_BA), dim=-1), dim=-1) / (new_numA + new_numB)
                # print(5)
                valid_cross_sim_AB = cross_sim_AB[mask_pointA, :]   # repeat_nA x (H X W)
                valid_cross_sim_BA = cross_sim_BA[mask_pointB, :]   # repeat_nB x (H X W)
                exp_valid_cross_sim_AtoB = torch.exp((valid_cross_sim_AB - 1) / t_rel).view(-1, H, W)
                exp_valid_cross_sim_BtoA = torch.exp((valid_cross_sim_BA - 1) / t_rel).view(-1, H, W)
                exp_valid_cross_sim_AB_all = F.grid_sample(exp_valid_cross_sim_AtoB.unsqueeze(0),
                                                        pntA_H_normalized.detach().view(1, 1, -1, 2),
                                                        mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # repeat_nA x repeat_nA
                
                exp_valid_cross_sim_BA_all = F.grid_sample(exp_valid_cross_sim_BtoA.unsqueeze(0),
                                                        pntB_invH_normalized.detach().view(1, 1, -1, 2),
                                                        mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # repeat_nB x repeat_nB

                repeat_mask_AB = torch.eye(exp_valid_cross_sim_AB_all.shape[0]) == 1
                repeat_mask_BA = torch.eye(exp_valid_cross_sim_BA_all.shape[0]) == 1
                rel_valid_cross_sim_AB = exp_valid_cross_sim_AB_all[repeat_mask_AB]
                rel_valid_cross_sim_BA = exp_valid_cross_sim_BA_all[repeat_mask_BA]

                # pntA_H_normalized_new = copy.deepcopy(pntA_H_normalized.detach())
                # pntB_invH_normalized_new = copy.deepcopy(pntB_invH_normalized.detach())

                # pntA_H_normalized_new[:, 0] += 2
                # pntB_invH_normalized_new[:, 0] += 2

                scoresAB_all = F.grid_sample(scores_mapB[idx, :, :, :].unsqueeze(0),
                                            pntA_H_normalized_new.view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)      # 1 x repeat_nA

                scoresBA_all = F.grid_sample(scores_mapA[idx, :, :, :].unsqueeze(0),
                                            pntB_invH_normalized_new.view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)      # 1 x repeat_nB
                # print(6)
                scores_AAB = scoresA[idx][pmA][mask_pointA] * scoresAB_all
                scores_BBA = scoresB[idx][pmB][mask_pointB] * scoresBA_all
                scores_sum_AAB = torch.sum(scores_AAB, dim=-1)
                scores_sum_BBA = torch.sum(scores_BBA, dim=-1)
                scores_normalize_AAB = scores_AAB / (scores_sum_AAB + eps)
                scores_normalize_BBA = scores_BBA / (scores_sum_BBA + eps)
                rel_meanA = torch.sum(scores_normalize_AAB * (1 - rel_valid_cross_sim_AB), dim=-1) / pntA_H_normalized_new.shape[0]
                rel_meanB = torch.sum(scores_normalize_BBA * (1 - rel_valid_cross_sim_BA), dim=-1) / pntB_invH_normalized_new.shape[0]

                # # 熵loss
                # current_descA_std, current_descB_std = descA_std[countA:countA+new_numA], descB_std[countB:countB+new_numB]
                # desc_std += torch.mean(current_descA_std) + torch.mean(current_descB_std)

                countA += new_numA
                countB += new_numB
                # countA_T += numA_T
                # countB_T += numB_T

                dis_neighbor_mean_total += torch.mean(torch.sum(neighbor_dis_AB, dim=1)) + torch.mean(torch.sum(neighbor_dis_BA, dim=1))
                dis_desc += dis_cross_sim_mean_sp
                dis_desc += dis_cross_sim_mean

                dis_pair_meanAB = torch.mean(key_manhattandisAB[pairAB_A, pairAB_B])
                dis_pair_meanBA = torch.mean(key_manhattandisBA[pairBA_B, pairBA_A])

                dis_peak_mean = torch.mean(torch.cat((scoreddisA[idx][pmA], scoreddisB[idx][pmB]), dim=0))
                # dis_peak_meanB = torch.mean(scoreddisB[idx])
                
                dis_mean_total += dis_pair_meanAB + dis_pair_meanBA
                dis_peak_scored += dis_peak_mean

                dis_rel += rel_meanA + rel_meanB
                # # Penalty
                # scores_mean += (-torch.log(torch.mean(scoresA[idx], dim=-1) + eps) - torch.log(torch.mean(scoresB[idx], dim=-1) + eps)) 
                # print(scores_mean)
            except:
                # dis_mean_total += 0
                # dis_peak_scored += 0
                # dis_desc += 0
                # dis_rel += 0
                # print('Overlapping too small or Repeatable point pairs distance is greater than correspond(1.5):', pntA.shape[0], pntA_H.shape[0], pntB.shape[0], pntB_invH.shape[0], dis_pairAB.shape[0], dis_pairBA.shape[0])
                valid_batch_size -= 1
                countA += new_numA
                countB += new_numB
                # countA_T += numA_T
                # countB_T += numB_T

        valid_batch_size = valid_batch_size if valid_batch_size > 0 else eps
        # Reprojection Loss 
        reprojection_loss = dis_mean_total / (valid_batch_size * 2)
        # Dispersity Peak Loss
        dispersity_peak_loss = dis_peak_scored / valid_batch_size
        # NRE Loss
        descriptor_loss = dis_desc / (2 * valid_batch_size)
        # Reliability Loss
        reliability_loss = dis_rel / (valid_batch_size * 2)
        # SOSR Loss
        sosr_loss = dis_neighbor_mean_total / ((valid_batch_size * 2))
        # # Entropy loss
        # std_loss = (valid_batch_size * 2) / desc_std  
        # # Score Penalty
        # score_penalty = scores_mean / (valid_batch_size * 2)
        # FA Desc loss
        FA_des_loss = dis_desc_fa / valid_batch_size_FA if valid_batch_size_FA > 0 else 0

        loss_total = wrp * reprojection_loss + wpl * dispersity_peak_loss + wdl * descriptor_loss + wrl * reliability_loss + sosr_loss + FA_des_loss
        loss_group = {
            'reprojection_loss': reprojection_loss, 
            'dispersity_peak_loss': dispersity_peak_loss,
            'descriptor_loss': descriptor_loss,
            'reliability_loss': reliability_loss,
            'sosr_loss': sosr_loss,
            # 'std_loss': std_loss,
            'FA_des_loss': FA_des_loss,
            }
        return loss_total, loss_group


    # patch/dense
    def detector_selfsupervised_loss_dkd_patch_ext_restrict_modify_oriR_ratio_FA_bw_ns_wg_nori(self, kpA, kpB, pmaskA, pmaskB, descA, descB, desc_mapA, desc_mapB, scoreddisA, scoreddisB, scoresA, scoresB, scores_mapA, scores_mapB, Homo, inv_Homo, inv_Homo_en, ori_all_patchA, ori_all_patchB, ori_kp_patchA, ori_kp_patchB, bin_allA, bin_allB, bin_kpA, bin_kpB, trans_angle, FA_flag, H, W, wrp=1, wpl=1, wdl=1, wrl=1, t_des=0.02, t_rel=1):
        # pmaskA: (BxMax_num) 32x350=11200
        batch_size = len(kpA)
        max_num = pmaskA.shape[-1] // batch_size    # 350
        dis_mean_total = 0
        dis_neighbor_mean_total = 0
        dis_peak_scored = 0
        dis_desc = 0
        dis_rel = 0
        desc_std = 0
        eps = 1e-12
        valid_batch_size = batch_size
        valid_batch_size_FA = 0
        countA, countB = 0, 0
        dis_desc_fa = 0
        # countA_T, countB_T = 0, 0
        for idx in range(batch_size):
            pntA, pntB = kpA[idx], kpB[idx]     # M X 2 (x,y)
            # kmask_TA, kmask_TB = kmask_T_allA[idx], kmask_T_allB[idx]
            pntA = pntA.float()
            pntB = pntB.float()

            # 剔除部分按压区域的点,且保留在重叠区域的点
            numA, numB = pntA.shape[0], pntB.shape[0]
            # numA_T, numB_T = pntA[kmask_TA].shape[0], pntB[kmask_TB].shape[0]
            pmA, pmB = pmaskA[max_num * idx:max_num * idx + numA].bool(), pmaskB[max_num * idx:max_num * idx + numB].bool()
            pntA, pntB = pntA[pmA, :], pntB[pmB, :]
            new_numA, new_numB = pntA.shape[0], pntB.shape[0]       
            
            pntA = (pntA + 1) / 2 * pntA.new_tensor([[W + 3, H - 1]]).to(pntA.device)
            pntB = (pntB + 1) / 2 * pntB.new_tensor([[W + 3, H - 1]]).to(pntB.device)

            # [120, 40] -> [120, 36],实际只取中心118x32区域的点对
            pntA[:, 0] -= 2
            pntB[:, 0] -= 2
            
            pntA_normalized = pntA / pntA.new_tensor([W - 1, H - 1]).to(pntA.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)
            pntB_normalized = pntB / pntB.new_tensor([W - 1, H - 1]).to(pntB.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)

            pntA_H = warp_points(pntA[:, :2], Homo[idx].squeeze(), device=self.device)  # 利用变换矩阵变换坐标点
            pntA_H, mask_pointA = filter_points(pntA_H, torch.tensor([W, H], device=self.device), return_mask=True)
            pntB_invH = warp_points(pntB[:, :2], inv_Homo[idx].squeeze(), device=self.device)
            pntB_invH, mask_pointB = filter_points(pntB_invH, torch.tensor([W, H], device=self.device), return_mask=True)
            
            current_descA, current_descB = descA[countA:countA+new_numA], descB[countB:countB+new_numB]
            cross_sim_AB_sp = current_descA @ current_descB.transpose(0, 1)     # NTA X NTB
            
            # 黑白相似度
            current_binA, current_binB = bin_kpA[countA:countA+new_numA], bin_kpB[countB:countB+new_numB]   # [NA, 256] [NB_256]
            bin_distAB = current_binA.shape[-1] - (current_binA @ current_binB.transpose(0, 1)) - ((1 - current_binA) @ (1 - current_binB.transpose(0, 1))) # [NA, NB]

            # Net FA余弦相似度小
            if FA_flag[idx] == 1:
                FA_bin_mask = bin_distAB >= (1 - self.FA_bin_thr) * current_binA.shape[-1] 
                # print(current_binA.shape, bin_distAB[0, :])
                # print(FA_bin_mask.shape, torch.sum(FA_bin_mask))
                dis_desc_fa += (2 - torch.mean(torch.sqrt(2 * (1 - cross_sim_AB_sp[FA_bin_mask]) + eps)))

                valid_batch_size -= 1
                valid_batch_size_FA += 1
                countA += new_numA
                countB += new_numB
                continue
            
            # 真匹配的trans
            try:
                assert pntA_H.shape[0] > 0 and pntB_invH.shape[0] > 0 
                
                # 点对欧氏距离
                key_disAB = self.get_dis(pntA_H[:, :2], pntB[:, :2])            # repeatNA x NB
                key_disBA = self.get_dis(pntB_invH[:, :2], pntA[:, :2])
                pairAB_A, pairAB_B, dis_pairAB, _ = self.get_point_pair(key_disAB, dis_thre=self.correspond)  # p -> k # NTA(<1.5), NTA(<1.5), NTA(<1.5), NTA        
                pairBA_B, pairBA_A, dis_pairBA, _  = self.get_point_pair(key_disBA, dis_thre=self.correspond)  # p -> k # NTB(<1.5), NTB(<1.5), NTB(<1.5), NTB 
                
                # 点距离mask
                nn_maskAB = torch.zeros((pntA_H.shape[0], pntB.shape[0]), device=self.device) 
                nn_maskAB[pairAB_A, pairAB_B] = 1

                nn_maskBA = torch.zeros((pntB_invH.shape[0], pntA.shape[0]), device=self.device) 
                nn_maskBA[pairBA_B, pairBA_A] = 1

                # 点对曼哈顿距离
                key_manhattandisAB = self.get_manhattan_dis(pntA_H[:, :2], pntB[:, :2])
                key_manhattandisBA = self.get_manhattan_dis(pntB_invH[:, :2], pntA[:, :2])
                # print('pdis:', dis_pairAB.shape[0], dis_pairBA.shape[0])
                assert dis_pairAB.shape[0] > 0 and dis_pairBA.shape[0] > 0     

                pntA_H_normalized = pntA_H / pntA_H.new_tensor([W - 1, H - 1]).to(pntA_H.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)
                pntB_invH_normalized = pntB_invH / pntB_invH.new_tensor([W - 1, H - 1]).to(pntB_invH.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)

                # 用于score_map
                pntA_H_new = copy.deepcopy(pntA_H.detach())
                pntB_invH_new = copy.deepcopy(pntB_invH.detach())
                pntA_H_new[:, 0] += 10                   # 120 x 36 -> 128 x 56
                pntA_H_new[:, 1] += 4 
                pntB_invH_new[:, 0] += 10
                pntB_invH_new[:, 1] += 4
                
                pntA_H_normalized_new = pntA_H_new / pntA_H_new.new_tensor([W + 19, H + 7]).to(pntA_H.device) * 2 - 1

                # pntB_invH_new = warp_points(pntB_invH_new[:, :2], inv_Homo_en[idx].squeeze(), device=self.device)       # 转到A上，而不是AT上
                
                pntB_invH_normalized_new = pntB_invH_new / pntB_invH_new.new_tensor([W + 19, H + 7]).to(pntB_invH.device) * 2 - 1 

                # # PA VS PB 有一定偏移
                # ori_kpA_ext = F.grid_sample(ori_allA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                #                             pntA_normalized.detach().view(1, 1, -1, 2),
                #                             mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  
                # ori_kpB_ext = F.grid_sample(ori_allB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                #                             pntB_normalized.detach().view(1, 1, -1, 2),
                #                             mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  

                # main_ori_maskATB = self.get_main_ori_consistence(ori_kpA[countA:countA+numA][pmA].unsqueeze(1), ori_kpB_ext)  # NTA x NTB 
                # main_ori_maskBTA = self.get_main_ori_consistence(ori_kpB[countB:countB+numB][pmB].unsqueeze(1), ori_kpA_ext)  # NTB x NTA 
                
                # print('1_2:', main_ori_maskATB.shape[0])
                # exit()
                # ori_kpA_patch_ext = F.grid_sample(ori_all_patchA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                #                             pntA_normalized.detach().view(1, 1, -1, 2),
                #                             mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  
                # ori_kpB_patch_ext = F.grid_sample(ori_all_patchB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                #                             pntB_normalized.detach().view(1, 1, -1, 2),
                #                             mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  
                # print('1_2_1:', pntB_invH_normalized_new.shape[0])
                ori_maskATB, dis_oriATB = self.get_main_ori_consistence_caltrans(ori_kp_patchA[countA:countA+new_numA], ori_kp_patchB[countB:countB+new_numB], trans_angle[idx])  # NTA x NTB
                # print('1_2_2:', ori_maskATB.shape)
                ori_maskBTA = ori_maskATB.transpose(0, 1)
                # print('1_2_2:', ori_maskATB.shape[0])
                # match_maskAB = (nn_maskAB == 1) * main_ori_maskATB
                # match_maskBA = (nn_maskBA == 1) * main_ori_maskBTA
                # print(nn_maskAB.shape, main_ori_maskATB.shape, ori_maskATB.shape)
                match_maskAB_nb = (nn_maskAB == 1) * ori_maskATB[mask_pointA, :]           # repeatNA X NTB
                match_maskBA_nb = (nn_maskBA == 1) * ori_maskBTA[mask_pointB, :]           # repeatNB X NTA
                pairAB_A_nb_new, pairAB_B_nb_new = torch.where(match_maskAB_nb == 1)
                pairBA_B_nb_new, pairBA_A_nb_new = torch.where(match_maskBA_nb == 1)
                # assert pairAB_A_new.shape[0] > 0 and pairBA_B_new.shape[0] > 0 

                # # PA VS PAB 没有中心点距离偏移
                # # 中心主方向一致性
                # ori_kpAB_ext = F.grid_sample(ori_allB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                #                             pntA_H_normalized.detach().view(1, 1, -1, 2),
                #                             mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  
                # ori_kpBA_ext = F.grid_sample(ori_allA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                #                             pntB_invH_normalized.detach().view(1, 1, -1, 2),
                #                             mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  
                # main_ori_maskATAB = self.get_main_ori_consistence(ori_kpA[countA:countA+new_numA].unsqueeze(1), ori_kpAB_ext)  # NTAxNTA 
                # main_ori_maskBTBA = self.get_main_ori_consistence(ori_kpB[countB:countB+new_numB].unsqueeze(1), ori_kpBA_ext)  # NTBxNTB 

                # 4x4邻域方向一致性
                ori_kpAB_patch_ext = F.grid_sample(ori_all_patchB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntA_H_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  
                ori_kpBA_patch_ext = F.grid_sample(ori_all_patchA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntB_invH_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  
                # print('1_2_4:', ori_kpAB_patch_ext.shape)
                ori_maskATAB, dis_oriATAB = self.get_main_ori_consistence_caltrans(ori_kp_patchA[countA:countA+new_numA], ori_kpAB_patch_ext.transpose(0, 1), trans_angle[idx])  # NTA x repeatNA
                ori_maskBTBA, dis_oriBTBA = self.get_main_ori_consistence_caltrans(ori_kp_patchB[countB:countB+new_numB], ori_kpBA_patch_ext.transpose(0, 1), -trans_angle[idx])  # NTB x repeatNB
                
                ori_maskATAB = ori_maskATAB[mask_pointA, :]         # repeatNA x repeatNA
                ori_maskBTBA = ori_maskBTBA[mask_pointB, :]
                dis_oriATAB = dis_oriATAB[mask_pointA, :]         # repeatNA x repeatNA
                dis_oriBTBA = dis_oriBTBA[mask_pointB, :]
                # vmaskAH = torch.diag(main_ori_maskATAB) == 1
                # vmaskBH = torch.diag(main_ori_maskBTBA) == 1
                # vmaskAH = torch.diag(main_ori_maskATAB * (ori_maskATAB >= self.ori_ratio)) == 1
                # vmaskBH = torch.diag(main_ori_maskBTBA * (ori_maskBTBA >= self.ori_ratio)) == 1
                # assert torch.sum(vmaskAH) > 0 and torch.sum(vmaskBH) > 0
                
                # 黑白相似度
                bin_maskATB = bin_distAB <= (1 - self.FR_bin_thr) * current_binA.shape[-1]  
                bin_maskBTA = bin_maskATB.transpose(0, 1)  

                match_maskAB = match_maskAB_nb * bin_maskATB[mask_pointA, :]               # repeatNA X NB
                match_maskBA = match_maskBA_nb * bin_maskBTA[mask_pointB, :]               # repeatNB X NA

                pairAB_A_new, pairAB_B_new = torch.where(match_maskAB == 1)
                pairBA_B_new, pairBA_A_new = torch.where(match_maskBA == 1)
                # print('bin_mask:', pairAB_A_new.shape[0], pairBA_B_new.shape[0])
                assert pairAB_A_new.shape[0] > 0 and pairBA_B_new.shape[0] > 0 

                bin_kpAB_T = F.grid_sample(bin_allB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntA_H_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # [256, repeatNA]
                bin_kpBA_T = F.grid_sample(bin_allA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntB_invH_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # [256, repeatNB]
                bin_distATAB = bin_kpAB_T.shape[0] - (current_binA @ bin_kpAB_T) - ((1 - current_binA) @ (1 - bin_kpAB_T)) # [NTA, repeatNA]
                bin_distBTBA = bin_kpBA_T.shape[0] - (current_binB @ bin_kpBA_T) - ((1 - current_binB) @ (1 - bin_kpBA_T)) # [NTB, repeatNB]

                bin_maskATAB = bin_distATAB <= (1 - self.FR_bin_thr) * bin_kpAB_T.shape[0] 
                bin_maskBTBA = bin_distBTBA <= (1 - self.FR_bin_thr) * bin_kpBA_T.shape[0] 
                bin_maskATAB = bin_maskATAB[mask_pointA, :]
                bin_maskBTBA = bin_maskBTBA[mask_pointB, :]

                vmaskAH_nb = torch.diag(ori_maskATAB)
                vmaskBH_nb = torch.diag(ori_maskBTBA)
                vmaskAH = torch.diag(ori_maskATAB * bin_maskATAB) == 1      # [repeatNA, 1]
                vmaskBH = torch.diag(ori_maskBTBA * bin_maskBTBA) == 1      # [repeatNB, 1]

                # print('main_ori:', torch.sum(vmaskAH), torch.sum(vmaskBH))
                assert torch.sum(vmaskAH) > 0 and torch.sum(vmaskBH) > 0

                # SOSR: 简化的self-attention
                k_neighbor = 3
                cross_sim_AA_sp = current_descA @ current_descA.transpose(0, 1)
                cross_sim_BB_sp = current_descB @ current_descB.transpose(0, 1)
                # print('SOSR:', pairAB_A_new.shape[0], pairBA_B_new.shape[0])
                assert pairAB_A_new.shape[0] >= k_neighbor and pairBA_B_new.shape[0] >= k_neighbor 

                match_sim_AB_AA = cross_sim_AA_sp[mask_pointA, :][:, mask_pointA][pairAB_A_new, :][:, pairAB_A_new]
                match_sim_BA_BB = cross_sim_BB_sp[mask_pointB, :][:, mask_pointB][pairBA_B_new, :][:, pairBA_B_new]
                match_sim_AB_BB = cross_sim_BB_sp[pairAB_B_new, :][:, pairAB_B_new]
                match_sim_BA_AA = cross_sim_AA_sp[pairBA_A_new, :][:, pairBA_A_new]
                match_values_AB_AA, match_indices_AB_AA = torch.topk(match_sim_AB_AA, dim=1, k=k_neighbor, largest=False)
                match_values_BA_BB, match_indices_BA_BB = torch.topk(match_sim_BA_BB, dim=1, k=k_neighbor, largest=False)
                match_values_AB_BB_all = match_sim_AB_BB[:, match_indices_AB_AA]
                match_values_BA_AA_all = match_sim_BA_AA[:, match_indices_BA_BB]
                match_values_AB_BB = torch.diagonal(match_values_AB_BB_all, 0, dim1=0, dim2=1).transpose(0, 1)
                match_values_BA_AA = torch.diagonal(match_values_BA_AA_all, 0, dim1=0, dim2=1).transpose(0, 1)
                neighbor_dis_AB = (match_values_AB_AA - match_values_AB_BB) * (match_values_AB_AA - match_values_AB_BB)
                neighbor_dis_BA = (match_values_BA_BB - match_values_BA_AA) * (match_values_BA_BB - match_values_BA_AA)
                # print('1_1')
                # PA VS PB
                valid_cross_sim_AB_sp_mean = torch.mean(cross_sim_AB_sp[mask_pointA, :][match_maskAB == 1], dim=-1)
                valid_cross_sim_AB_sp_nb_mean = torch.mean(cross_sim_AB_sp[mask_pointA, :][match_maskAB_nb == 1], dim=-1)
                novalid_cross_sim_AB_sp_mean = (torch.sum(torch.sum(cross_sim_AB_sp.detach(), 1), 0) - valid_cross_sim_AB_sp_nb_mean * pairAB_A_nb_new.shape[0]) / (new_numA * new_numB - pairAB_A_nb_new.shape[0] + eps)
                valid_cross_sim_BA_sp_mean = torch.mean(cross_sim_AB_sp[:, mask_pointB][match_maskBA.transpose(0, 1) == 1], dim=-1)
                valid_cross_sim_BA_sp_nb_mean = torch.mean(cross_sim_AB_sp[:, mask_pointB][match_maskBA_nb.transpose(0, 1) == 1], dim=-1)
                novalid_cross_sim_BA_sp_mean = (torch.sum(torch.sum(cross_sim_AB_sp.detach(), 1), 0) - valid_cross_sim_BA_sp_nb_mean * pairBA_B_nb_new.shape[0]) / (new_numA * new_numB - pairBA_B_nb_new.shape[0] + eps)

                valid_indexesA = torch.tensor(list(range(cross_sim_AB_sp.shape[0])), device=self.device)[mask_pointA][pairAB_A_new]
                valid_indexesA_nb = torch.tensor(list(range(cross_sim_AB_sp.shape[0])), device=self.device)[mask_pointA][pairAB_A_nb_new]
                # cross_sim_BA_sp = current_descB @ current_descA.transpose(0, 1)
                cross_sim_AB_out_sp = torch.cat((cross_sim_AB_sp, torch.ones((cross_sim_AB_sp.shape[0], 1), device=cross_sim_AB_sp.device) * 2), dim=-1)      # NA X (NB + 1)
                cross_sim_AB_out_nb_sp = torch.cat((cross_sim_AB_sp, torch.ones((cross_sim_AB_sp.shape[0], 1), device=cross_sim_AB_sp.device) * 2), dim=-1)      # NA X (NB + 1)
                # cross_sim_BA_out_sp = torch.cat((cross_sim_BA_sp, torch.ones((numB, 1), device=cross_sim_BA_sp.device)), dim=-1)      # NB X (NA + 1)
                # valid_indexesB = torch.tensor(list(range(numB)), device=self.device)[mask_pointB][pairBA_B]
                # print('1_2')
                cross_sim_AB_out_sp[valid_indexesA, -1] = novalid_cross_sim_AB_sp_mean
                cross_sim_AB_out_nb_sp[valid_indexesA_nb, -1] = novalid_cross_sim_AB_sp_mean
                novalid_indexesA = torch.tensor(list(range(cross_sim_AB_sp.shape[0])), device=self.device)[cross_sim_AB_out_nb_sp[:, -1]==2]
                cross_sim_AB_out_sp[novalid_indexesA, -1] = valid_cross_sim_AB_sp_mean

                soft_cross_sim_AtoB_sp = F.softmax((cross_sim_AB_out_sp - 1) / t_des, dim=-1)
                # soft_cross_sim_BtoA = F.softmax((cross_sim_BA_out - 1) / t_des, dim=-1)
                # print('1_3')
                soft_valid_cross_sim_AB_sp = soft_cross_sim_AtoB_sp[mask_pointA, :-1][match_maskAB==1]
                # soft_valid_cross_sim_BA = soft_cross_sim_BtoA[mask_pointB, :-1][pairBA_B, pairBA_A]
                soft_novalid_cross_sim_AB_sp = soft_cross_sim_AtoB_sp[novalid_indexesA, -1]
                # soft_novalid_cross_sim_BA = soft_cross_sim_BtoA[cross_sim_BA_out[:, -1]==1, -1]
                log_soft_valid_cross_sim_AB_sp = -torch.log(soft_valid_cross_sim_AB_sp + eps) * (1 - dis_oriATB[mask_pointA, :][match_maskAB==1] / self.ori_diff) * (1 - bin_distAB[mask_pointA, :][match_maskAB==1] / current_binA.shape[-1]) * (1 - key_disAB[match_maskAB==1].detach() / self.correspond)
                # log_soft_valid_cross_sim_BA = -torch.log(soft_valid_cross_sim_BA + eps)
                log_soft_novalid_cross_sim_AB_sp = -torch.log(soft_novalid_cross_sim_AB_sp + eps)
                # log_soft_novalid_cross_sim_BA = -torch.log(soft_novalid_cross_sim_BA + eps)
                dis_cross_sim_mean_sp = torch.sum(torch.cat((4*log_soft_valid_cross_sim_AB_sp, log_soft_novalid_cross_sim_AB_sp), dim=-1), dim=-1) / new_numA
                # print(2)
                # PA VS PAB
                # match_mask_A = copy.deepcopy(mask_pointA)
                # match_mask_B = copy.deepcopy(mask_pointB)
                match_mask_A = torch.zeros(cross_sim_AB_sp.shape[0], device=self.device)
                match_mask_nb_A = torch.zeros(cross_sim_AB_sp.shape[0], device=self.device)
                valid_match_indexesA = torch.tensor(list(range(cross_sim_AB_sp.shape[0])), device=self.device)[mask_pointA][vmaskAH]
                valid_match_indexesA_nb = torch.tensor(list(range(cross_sim_AB_sp.shape[0])), device=self.device)[mask_pointA][vmaskAH_nb]
                match_mask_A[valid_match_indexesA] = 1
                match_mask_nb_A[valid_match_indexesA_nb] = 1

                match_mask_B = torch.zeros(cross_sim_AB_sp.shape[1], device=self.device)
                match_mask_nb_B = torch.zeros(cross_sim_AB_sp.shape[1], device=self.device)
                valid_match_indexesB = torch.tensor(list(range(cross_sim_AB_sp.shape[1])), device=self.device)[mask_pointB][vmaskBH]
                valid_match_indexesB_nb = torch.tensor(list(range(cross_sim_AB_sp.shape[1])), device=self.device)[mask_pointB][vmaskBH_nb]
                match_mask_B[valid_match_indexesB] = 1
                match_mask_nb_B[valid_match_indexesB_nb] = 1
                # match_mask_A = copy.deepcopy(vmaskAH)
                # match_mask_B = copy.deepcopy(vmaskBH)

                cross_sim_AB = current_descA @ desc_mapB[idx, :, :, :].view(-1, H * W)
                # cross_sim_AB = cross_sim_AB[mask_pointA, :]
                cross_sim_AB_all = F.grid_sample(cross_sim_AB.view(-1, H, W).unsqueeze(0),
                                                pntA_H_normalized[vmaskAH, :].detach().view(1, 1, -1, 2),
                                                mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NA x repeatNA
                valid_cross_sim_AB_mean = torch.trace(cross_sim_AB_all[match_mask_A==1, :]) / cross_sim_AB_all[match_mask_A==1, :].shape[0]
                # novalid_cross_sim_AB_mean = (torch.sum(torch.sum(cross_sim_AB.detach(), 1), 1) - valid_cross_sim_AB_mean * pairAB_A.shape[0]) / (new_numA * H * W - pairAB_A.shape[0])

                cross_sim_BA = current_descB @ desc_mapA[idx, :, :, :].view(-1, H * W)   # M x H x W
                # cross_sim_BA = cross_sim_BA[mask_pointB, :]
                cross_sim_BA_all = F.grid_sample(cross_sim_BA.view(-1, H, W).unsqueeze(0),
                                                pntB_invH_normalized[vmaskBH, :].detach().view(1, 1, -1, 2),
                                                mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NB x match_nB
                valid_cross_sim_BA_mean = torch.trace(cross_sim_BA_all[match_mask_B==1, :]) / cross_sim_BA_all[match_mask_B==1, :].shape[0]
                # novalid_cross_sim_BA_mean = (torch.sum(torch.sum(cross_sim_BA.detach(), 1), 1) - valid_cross_sim_BA_mean * pairBA_B.shape[0]) / (new_numB * H * W - pairBA_B.shape[0])

                cross_sim_AB_out = torch.cat((cross_sim_AB, torch.ones((cross_sim_AB.shape[0], 1), device=cross_sim_AB.device)), dim=-1)      # NA X (H X W + 1)
                cross_sim_BA_out = torch.cat((cross_sim_BA, torch.ones((cross_sim_BA.shape[0], 1), device=cross_sim_BA.device)), dim=-1)      # NB X (H X W + 1)
                # print(3)
                # cross_sim_AB_out[mask_pointA, -1] -= 1
                # cross_sim_BA_out[mask_pointB, -1] -= 1
                # cross_sim_AB_out[match_mask_A, -1] -= 1
                cross_sim_AB_out[match_mask_A==1, -1] = novalid_cross_sim_AB_sp_mean
                cross_sim_AB_out[match_mask_nb_A==0, -1] = valid_cross_sim_AB_mean

                cross_sim_BA_out[match_mask_B==1, -1] = novalid_cross_sim_BA_sp_mean
                cross_sim_BA_out[match_mask_nb_B==0, -1] = valid_cross_sim_BA_mean

                soft_cross_sim_AtoB = F.softmax((cross_sim_AB_out - 1) / t_des, dim=-1)         # NA X (H X W + 1)
                soft_cross_sim_BtoA = F.softmax((cross_sim_BA_out - 1) / t_des, dim=-1)         # NB X (H X W + 1)
                soft_cross_sim_AB_all = F.grid_sample(soft_cross_sim_AtoB[:, :-1].view(-1, H, W).unsqueeze(0),
                                                    pntA_H_normalized[vmaskAH, :].detach().view(1, 1, -1, 2),
                                                    mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NA x match_nA
                
                soft_cross_sim_BA_all = F.grid_sample(soft_cross_sim_BtoA[:, :-1].view(-1, H, W).unsqueeze(0),
                                                    pntB_invH_normalized[vmaskBH, :].detach().view(1, 1, -1, 2),
                                                    mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NB x match_nB
                # soft_valid_cross_sim_AB_all = soft_cross_sim_AB_all[mask_pointA, :]             # repeat_nA x repeat_nA
                # soft_valid_cross_sim_BA_all = soft_cross_sim_BA_all[mask_pointB, :]             # repeat_nB x repeat_nB

                soft_valid_cross_sim_AB_all = soft_cross_sim_AB_all[match_mask_A==1, :]             # match_nA x match_nA
                soft_valid_cross_sim_BA_all = soft_cross_sim_BA_all[match_mask_B==1, :]             # match_nB x match_nB

                valid_mask_AB = torch.eye(soft_valid_cross_sim_AB_all.shape[0]) == 1
                valid_mask_BA = torch.eye(soft_valid_cross_sim_BA_all.shape[0]) == 1
                # print(4)
                # 取对角线
                soft_valid_cross_sim_AB = soft_valid_cross_sim_AB_all[valid_mask_AB]
                soft_valid_cross_sim_BA = soft_valid_cross_sim_BA_all[valid_mask_BA]

                # soft_novalid_cross_sim_AB = soft_cross_sim_AtoB[mask_pointA==False, -1]              # (NA-repeat_nA) x 1
                # soft_novalid_cross_sim_BA = soft_cross_sim_BtoA[mask_pointB==False, -1]
                soft_novalid_cross_sim_AB = soft_cross_sim_AtoB[match_mask_nb_A==0, -1]               # (NA-match_nA) x 1
                soft_novalid_cross_sim_BA = soft_cross_sim_BtoA[match_mask_nb_B==0, -1]
                # print(soft_novalid_cross_sim_AB, soft_novalid_cross_sim_BA)

                log_soft_valid_cross_sim_AB = -torch.log(soft_valid_cross_sim_AB + eps) * (1 - torch.diag(dis_oriATAB)[vmaskAH] / self.ori_diff) * (1 - torch.diag(bin_distATAB[mask_pointA, :])[vmaskAH] / bin_kpAB_T.shape[0])
                log_soft_valid_cross_sim_BA = -torch.log(soft_valid_cross_sim_BA + eps) * (1 - torch.diag(dis_oriBTBA)[vmaskBH] / self.ori_diff) * (1 - torch.diag(bin_distBTBA[mask_pointB, :])[vmaskBH] / bin_kpBA_T.shape[0])
                log_soft_novalid_cross_sim_AB = -torch.log(soft_novalid_cross_sim_AB + eps)
                log_soft_novalid_cross_sim_BA = -torch.log(soft_novalid_cross_sim_BA + eps)

                dis_cross_sim_mean = torch.sum(torch.cat((4*log_soft_valid_cross_sim_AB, 4*log_soft_valid_cross_sim_BA, log_soft_novalid_cross_sim_AB, log_soft_novalid_cross_sim_BA), dim=-1), dim=-1) / (new_numA + new_numB)
                # print(5)
                valid_cross_sim_AB = cross_sim_AB[mask_pointA, :]   # repeat_nA x (H X W)
                valid_cross_sim_BA = cross_sim_BA[mask_pointB, :]   # repeat_nB x (H X W)
                exp_valid_cross_sim_AtoB = torch.exp((valid_cross_sim_AB - 1) / t_rel).view(-1, H, W)
                exp_valid_cross_sim_BtoA = torch.exp((valid_cross_sim_BA - 1) / t_rel).view(-1, H, W)
                exp_valid_cross_sim_AB_all = F.grid_sample(exp_valid_cross_sim_AtoB.unsqueeze(0),
                                                        pntA_H_normalized.detach().view(1, 1, -1, 2),
                                                        mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # repeat_nA x repeat_nA
                
                exp_valid_cross_sim_BA_all = F.grid_sample(exp_valid_cross_sim_BtoA.unsqueeze(0),
                                                        pntB_invH_normalized.detach().view(1, 1, -1, 2),
                                                        mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # repeat_nB x repeat_nB

                repeat_mask_AB = torch.eye(exp_valid_cross_sim_AB_all.shape[0]) == 1
                repeat_mask_BA = torch.eye(exp_valid_cross_sim_BA_all.shape[0]) == 1
                rel_valid_cross_sim_AB = exp_valid_cross_sim_AB_all[repeat_mask_AB]
                rel_valid_cross_sim_BA = exp_valid_cross_sim_BA_all[repeat_mask_BA]

                # pntA_H_normalized_new = copy.deepcopy(pntA_H_normalized.detach())
                # pntB_invH_normalized_new = copy.deepcopy(pntB_invH_normalized.detach())

                # pntA_H_normalized_new[:, 0] += 2
                # pntB_invH_normalized_new[:, 0] += 2

                scoresAB_all = F.grid_sample(scores_mapB[idx, :, :, :].unsqueeze(0),
                                            pntA_H_normalized_new.view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)      # 1 x repeat_nA

                scoresBA_all = F.grid_sample(scores_mapA[idx, :, :, :].unsqueeze(0),
                                            pntB_invH_normalized_new.view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)      # 1 x repeat_nB
                # print(6)
                scores_AAB = scoresA[idx][pmA][mask_pointA] * scoresAB_all
                scores_BBA = scoresB[idx][pmB][mask_pointB] * scoresBA_all
                scores_sum_AAB = torch.sum(scores_AAB, dim=-1)
                scores_sum_BBA = torch.sum(scores_BBA, dim=-1)
                scores_normalize_AAB = scores_AAB / (scores_sum_AAB + eps)
                scores_normalize_BBA = scores_BBA / (scores_sum_BBA + eps)
                rel_meanA = torch.sum(scores_normalize_AAB * (1 - rel_valid_cross_sim_AB), dim=-1) / pntA_H_normalized_new.shape[0]
                rel_meanB = torch.sum(scores_normalize_BBA * (1 - rel_valid_cross_sim_BA), dim=-1) / pntB_invH_normalized_new.shape[0]

                # # 熵loss
                # current_descA_std, current_descB_std = descA_std[countA:countA+new_numA], descB_std[countB:countB+new_numB]
                # desc_std += torch.mean(current_descA_std) + torch.mean(current_descB_std)

                countA += new_numA
                countB += new_numB
                # countA_T += numA_T
                # countB_T += numB_T

                dis_neighbor_mean_total += torch.mean(torch.sum(neighbor_dis_AB, dim=1)) + torch.mean(torch.sum(neighbor_dis_BA, dim=1))
                dis_desc += dis_cross_sim_mean_sp
                dis_desc += dis_cross_sim_mean

                dis_pair_meanAB = torch.mean(key_manhattandisAB[pairAB_A, pairAB_B])
                dis_pair_meanBA = torch.mean(key_manhattandisBA[pairBA_B, pairBA_A])

                dis_peak_mean = torch.mean(torch.cat((scoreddisA[idx][pmA], scoreddisB[idx][pmB]), dim=0))
                # dis_peak_meanB = torch.mean(scoreddisB[idx])
                
                dis_mean_total += dis_pair_meanAB + dis_pair_meanBA
                dis_peak_scored += dis_peak_mean

                dis_rel += rel_meanA + rel_meanB
                # # Penalty
                # scores_mean += (-torch.log(torch.mean(scoresA[idx], dim=-1) + eps) - torch.log(torch.mean(scoresB[idx], dim=-1) + eps)) 
                # print(scores_mean)
            except:
                # dis_mean_total += 0
                # dis_peak_scored += 0
                # dis_desc += 0
                # dis_rel += 0
                # print('Overlapping too small or Repeatable point pairs distance is greater than correspond(1.5):', pntA.shape[0], pntA_H.shape[0], pntB.shape[0], pntB_invH.shape[0], dis_pairAB.shape[0], dis_pairBA.shape[0])
                valid_batch_size -= 1
                countA += new_numA
                countB += new_numB
                # countA_T += numA_T
                # countB_T += numB_T

        valid_batch_size = valid_batch_size if valid_batch_size > 0 else eps
        # Reprojection Loss 
        reprojection_loss = dis_mean_total / (valid_batch_size * 2)
        # Dispersity Peak Loss
        dispersity_peak_loss = dis_peak_scored / valid_batch_size
        # NRE Loss
        descriptor_loss = dis_desc / (2 * valid_batch_size)
        # Reliability Loss
        reliability_loss = dis_rel / (valid_batch_size * 2)
        # SOSR Loss
        sosr_loss = dis_neighbor_mean_total / ((valid_batch_size * 2))
        # # Entropy loss
        # std_loss = (valid_batch_size * 2) / desc_std  
        # # Score Penalty
        # score_penalty = scores_mean / (valid_batch_size * 2)
        # FA Desc loss
        FA_des_loss = dis_desc_fa / valid_batch_size_FA if valid_batch_size_FA > 0 else 0

        loss_total = wrp * reprojection_loss + wpl * dispersity_peak_loss + wdl * descriptor_loss + wrl * reliability_loss + sosr_loss + FA_des_loss
        loss_group = {
            'reprojection_loss': reprojection_loss, 
            'dispersity_peak_loss': dispersity_peak_loss,
            'descriptor_loss': descriptor_loss,
            'reliability_loss': reliability_loss,
            'sosr_loss': sosr_loss,
            # 'std_loss': std_loss,
            'FA_des_loss': FA_des_loss,
            }
        return loss_total, loss_group
    
    # patch/dense AT角度
    def detector_selfsupervised_loss_dkd_patch_ext_restrict_modify_oriR_ratio_FA_bw_ns_wg_nori_AT(self, kpA, kpB, pmaskA, pmaskB, descA, descB, desc_mapA, desc_mapB, scoreddisA, scoreddisB, scoresA, scoresB, scores_mapA, scores_mapB, Homo, inv_Homo, inv_Homo_en, ori_all_patchA, ori_all_patchB, ori_kp_patchA, ori_kp_patchB, bin_allA, bin_allB, bin_kpA, bin_kpB, trans_angle, FA_flag, H, W, wrp=1, wpl=1, wdl=1, wrl=1, t_des=0.02, t_rel=1):
        # pmaskA: (BxMax_num) 32x350=11200
        batch_size = len(kpA)
        max_num = pmaskA.shape[-1] // batch_size    # 350
        dis_mean_total = 0
        dis_neighbor_mean_total = 0
        dis_peak_scored = 0
        dis_desc = 0
        dis_rel = 0
        desc_std = 0
        eps = 1e-12
        valid_batch_size = batch_size
        valid_batch_size_FA = 0
        countA, countB = 0, 0
        dis_desc_fa = 0
        # countA_T, countB_T = 0, 0
        for idx in range(batch_size):
            pntA, pntB = kpA[idx], kpB[idx]     # M X 2 (x,y)
            # kmask_TA, kmask_TB = kmask_T_allA[idx], kmask_T_allB[idx]
            pntA = pntA.float()
            pntB = pntB.float()

            # 剔除部分按压区域的点,且保留在重叠区域的点
            numA, numB = pntA.shape[0], pntB.shape[0]
            # numA_T, numB_T = pntA[kmask_TA].shape[0], pntB[kmask_TB].shape[0]
            pmA, pmB = pmaskA[max_num * idx:max_num * idx + numA].bool(), pmaskB[max_num * idx:max_num * idx + numB].bool()
            pntA, pntB = pntA[pmA, :], pntB[pmB, :]
            new_numA, new_numB = pntA.shape[0], pntB.shape[0]       
            
            pntA = (pntA + 1) / 2 * pntA.new_tensor([[W + 3, H - 1]]).to(pntA.device)
            pntB = (pntB + 1) / 2 * pntB.new_tensor([[W + 3, H - 1]]).to(pntB.device)

            # [120, 40] -> [120, 36],实际只取中心118x32区域的点对
            pntA[:, 0] -= 2
            pntB[:, 0] -= 2
            
            pntA_normalized = pntA / pntA.new_tensor([W - 1, H - 1]).to(pntA.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)
            pntB_normalized = pntB / pntB.new_tensor([W - 1, H - 1]).to(pntB.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)

            pntA_H = warp_points(pntA[:, :2], Homo[idx].squeeze(), device=self.device)  # 利用变换矩阵变换坐标点
            pntA_H, mask_pointA = filter_points(pntA_H, torch.tensor([W, H], device=self.device), return_mask=True)
            pntB_invH = warp_points(pntB[:, :2], inv_Homo[idx].squeeze(), device=self.device)
            pntB_invH, mask_pointB = filter_points(pntB_invH, torch.tensor([W, H], device=self.device), return_mask=True)
            
            current_descA, current_descB = descA[countA:countA+new_numA], descB[countB:countB+new_numB]
            cross_sim_AB_sp = current_descA @ current_descB.transpose(0, 1)     # NTA X NTB
            
            # 黑白相似度
            current_binA, current_binB = bin_kpA[countA:countA+new_numA], bin_kpB[countB:countB+new_numB]   # [NA, 256] [NB_256]
            bin_distAB = current_binA.shape[-1] - (current_binA @ current_binB.transpose(0, 1)) - ((1 - current_binA) @ (1 - current_binB.transpose(0, 1))) # [NA, NB]

            # Net FA余弦相似度小
            if FA_flag[idx] == 1:
                FA_bin_mask = bin_distAB >= (1 - self.FA_bin_thr) * current_binA.shape[-1] 
                # print(current_binA.shape, bin_distAB[0, :])
                # print(FA_bin_mask.shape, torch.sum(FA_bin_mask))
                dis_desc_fa += (2 - torch.mean(torch.sqrt(2 * (1 - cross_sim_AB_sp[FA_bin_mask]) + eps)))

                valid_batch_size -= 1
                valid_batch_size_FA += 1
                countA += new_numA
                countB += new_numB
                continue
            
            # 真匹配的trans
            try:
                assert pntA_H.shape[0] > 0 and pntB_invH.shape[0] > 0 
                
                # 点对欧氏距离
                key_disAB = self.get_dis(pntA_H[:, :2], pntB[:, :2])            # repeatNA x NB
                key_disBA = self.get_dis(pntB_invH[:, :2], pntA[:, :2])
                pairAB_A, pairAB_B, dis_pairAB, _ = self.get_point_pair(key_disAB, dis_thre=self.correspond)  # p -> k # NTA(<1.5), NTA(<1.5), NTA(<1.5), NTA        
                pairBA_B, pairBA_A, dis_pairBA, _  = self.get_point_pair(key_disBA, dis_thre=self.correspond)  # p -> k # NTB(<1.5), NTB(<1.5), NTB(<1.5), NTB 
                
                # 点距离mask
                nn_maskAB = torch.zeros((pntA_H.shape[0], pntB.shape[0]), device=self.device) 
                nn_maskAB[pairAB_A, pairAB_B] = 1

                nn_maskBA = torch.zeros((pntB_invH.shape[0], pntA.shape[0]), device=self.device) 
                nn_maskBA[pairBA_B, pairBA_A] = 1

                # 点对曼哈顿距离
                key_manhattandisAB = self.get_manhattan_dis(pntA_H[:, :2], pntB[:, :2])
                key_manhattandisBA = self.get_manhattan_dis(pntB_invH[:, :2], pntA[:, :2])
                # print('pdis:', dis_pairAB.shape[0], dis_pairBA.shape[0])
                assert dis_pairAB.shape[0] > 0 and dis_pairBA.shape[0] > 0     

                pntA_H_normalized = pntA_H / pntA_H.new_tensor([W - 1, H - 1]).to(pntA_H.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)
                pntB_invH_normalized = pntB_invH / pntB_invH.new_tensor([W - 1, H - 1]).to(pntB_invH.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)

                # 用于score_map
                pntA_H_new = copy.deepcopy(pntA_H.detach())
                pntB_invH_new = copy.deepcopy(pntB_invH.detach())
                pntA_H_new[:, 0] += 10                   # 120 x 36 -> 128 x 56
                pntA_H_new[:, 1] += 4 
                pntB_invH_new[:, 0] += 10
                pntB_invH_new[:, 1] += 4
                
                pntA_H_normalized_new = pntA_H_new / pntA_H_new.new_tensor([W + 19, H + 7]).to(pntA_H.device) * 2 - 1

                # pntB_invH_new = warp_points(pntB_invH_new[:, :2], inv_Homo_en[idx].squeeze(), device=self.device)       # 转到A上，而不是AT上
                
                pntB_invH_normalized_new = pntB_invH_new / pntB_invH_new.new_tensor([W + 19, H + 7]).to(pntB_invH.device) * 2 - 1 

                # # PA VS PB 有一定偏移
                # ori_kpA_ext = F.grid_sample(ori_allA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                #                             pntA_normalized.detach().view(1, 1, -1, 2),
                #                             mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  
                # ori_kpB_ext = F.grid_sample(ori_allB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                #                             pntB_normalized.detach().view(1, 1, -1, 2),
                #                             mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  

                # main_ori_maskATB = self.get_main_ori_consistence(ori_kpA[countA:countA+numA][pmA].unsqueeze(1), ori_kpB_ext)  # NTA x NTB 
                # main_ori_maskBTA = self.get_main_ori_consistence(ori_kpB[countB:countB+numB][pmB].unsqueeze(1), ori_kpA_ext)  # NTB x NTA 
                
                # print('1_2:', main_ori_maskATB.shape[0])
                # exit()
                ori_kpAT_patch_ext = F.grid_sample(ori_kp_patchA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntA_H_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0).transpose(0, 1)          # repeatNA x 1
                ori_kpB_patch_ext = F.grid_sample(ori_all_patchB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntB_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0).transpose(0, 1)          # NTB x 1
                ori_kpA_patch_ext = F.grid_sample(ori_all_patchA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntA_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0).transpose(0, 1)          # NTA x 1
                ori_kpBT_patch_ext = F.grid_sample(ori_kp_patchB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntB_invH_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0).transpose(0, 1)          # repeatNB x 1
                # print('1_2_1:', pntB_invH_normalized_new.shape[0])
                ori_maskATB, dis_oriATB = self.get_main_ori_consistence_AT(ori_kpAT_patch_ext, ori_kpB_patch_ext)  # repeatNA x NTB
                # print('1_2_2:', ori_maskATB.shape)
                ori_maskBTA, dis_oriBTA = self.get_main_ori_consistence_AT(ori_kpBT_patch_ext, ori_kpA_patch_ext)  # repeatNB x NTA
                # print('1_2_2:', ori_maskATB.shape[0])
                # match_maskAB = (nn_maskAB == 1) * main_ori_maskATB
                # match_maskBA = (nn_maskBA == 1) * main_ori_maskBTA
                # print(nn_maskAB.shape, main_ori_maskATB.shape, ori_maskATB.shape)
                match_maskAB_nb = (nn_maskAB == 1) * ori_maskATB           # repeatNA X NTB
                match_maskBA_nb = (nn_maskBA == 1) * ori_maskBTA          # repeatNB X NTA
                pairAB_A_nb_new, pairAB_B_nb_new = torch.where(match_maskAB_nb == 1)
                pairBA_B_nb_new, pairBA_A_nb_new = torch.where(match_maskBA_nb == 1)
                # assert pairAB_A_new.shape[0] > 0 and pairBA_B_new.shape[0] > 0 

                # # PA VS PAB 没有中心点距离偏移
                # # 中心主方向一致性
                # ori_kpAB_ext = F.grid_sample(ori_allB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                #                             pntA_H_normalized.detach().view(1, 1, -1, 2),
                #                             mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  
                # ori_kpBA_ext = F.grid_sample(ori_allA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                #                             pntB_invH_normalized.detach().view(1, 1, -1, 2),
                #                             mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  
                # main_ori_maskATAB = self.get_main_ori_consistence(ori_kpA[countA:countA+new_numA].unsqueeze(1), ori_kpAB_ext)  # NTAxNTA 
                # main_ori_maskBTBA = self.get_main_ori_consistence(ori_kpB[countB:countB+new_numB].unsqueeze(1), ori_kpBA_ext)  # NTBxNTB 

                # 4x4邻域方向一致性
                ori_kpAB_patch_ext = F.grid_sample(ori_all_patchB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntA_H_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0).transpose(0, 1)  
                ori_kpBA_patch_ext = F.grid_sample(ori_all_patchA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntB_invH_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0).transpose(0, 1)  
                # print('1_2_4:', ori_kpAB_patch_ext.shape)
                ori_maskATAB, dis_oriATAB = self.get_main_ori_consistence_AT(ori_kpAT_patch_ext, ori_kpAB_patch_ext)  # repeatNA x repeatNA
                ori_maskBTBA, dis_oriBTBA = self.get_main_ori_consistence_AT(ori_kpBT_patch_ext, ori_kpBA_patch_ext)  # repeatNB x repeatNB
                
                # ori_maskATAB = ori_maskATAB[mask_pointA, :]         # repeatNA x repeatNA
                # ori_maskBTBA = ori_maskBTBA[mask_pointB, :]
                # dis_oriATAB = dis_oriATAB[mask_pointA, :]         # repeatNA x repeatNA
                # dis_oriBTBA = dis_oriBTBA[mask_pointB, :]

                # vmaskAH = torch.diag(main_ori_maskATAB) == 1
                # vmaskBH = torch.diag(main_ori_maskBTBA) == 1
                # vmaskAH = torch.diag(main_ori_maskATAB * (ori_maskATAB >= self.ori_ratio)) == 1
                # vmaskBH = torch.diag(main_ori_maskBTBA * (ori_maskBTBA >= self.ori_ratio)) == 1
                # assert torch.sum(vmaskAH) > 0 and torch.sum(vmaskBH) > 0
                
                # 黑白相似度
                bin_maskATB = bin_distAB <= (1 - self.FR_bin_thr) * current_binA.shape[-1]  
                bin_maskBTA = bin_maskATB.transpose(0, 1)  

                match_maskAB = match_maskAB_nb * bin_maskATB[mask_pointA, :]               # repeatNA X NB
                match_maskBA = match_maskBA_nb * bin_maskBTA[mask_pointB, :]               # repeatNB X NA

                pairAB_A_new, pairAB_B_new = torch.where(match_maskAB == 1)
                pairBA_B_new, pairBA_A_new = torch.where(match_maskBA == 1)
                # print('bin_mask:', pairAB_A_new.shape[0], pairBA_B_new.shape[0])
                assert pairAB_A_new.shape[0] > 0 and pairBA_B_new.shape[0] > 0 

                bin_kpAB_T = F.grid_sample(bin_allB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntA_H_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # [256, repeatNA]
                bin_kpBA_T = F.grid_sample(bin_allA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntB_invH_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # [256, repeatNB]
                bin_distATAB = bin_kpAB_T.shape[0] - (current_binA @ bin_kpAB_T) - ((1 - current_binA) @ (1 - bin_kpAB_T)) # [NTA, repeatNA]
                bin_distBTBA = bin_kpBA_T.shape[0] - (current_binB @ bin_kpBA_T) - ((1 - current_binB) @ (1 - bin_kpBA_T)) # [NTB, repeatNB]

                bin_maskATAB = bin_distATAB <= (1 - self.FR_bin_thr) * bin_kpAB_T.shape[0] 
                bin_maskBTBA = bin_distBTBA <= (1 - self.FR_bin_thr) * bin_kpBA_T.shape[0] 
                bin_maskATAB = bin_maskATAB[mask_pointA, :]
                bin_maskBTBA = bin_maskBTBA[mask_pointB, :]

                vmaskAH_nb = torch.diag(ori_maskATAB)
                vmaskBH_nb = torch.diag(ori_maskBTBA)
                vmaskAH = torch.diag(ori_maskATAB * bin_maskATAB) == 1      # [repeatNA, 1]
                vmaskBH = torch.diag(ori_maskBTBA * bin_maskBTBA) == 1      # [repeatNB, 1]

                # print('main_ori:', torch.sum(vmaskAH), torch.sum(vmaskBH))
                assert torch.sum(vmaskAH) > 0 and torch.sum(vmaskBH) > 0

                # SOSR: 简化的self-attention
                k_neighbor = 3
                cross_sim_AA_sp = current_descA @ current_descA.transpose(0, 1)
                cross_sim_BB_sp = current_descB @ current_descB.transpose(0, 1)
                # print('SOSR:', pairAB_A_new.shape[0], pairBA_B_new.shape[0])
                assert pairAB_A_new.shape[0] >= k_neighbor and pairBA_B_new.shape[0] >= k_neighbor 

                match_sim_AB_AA = cross_sim_AA_sp[mask_pointA, :][:, mask_pointA][pairAB_A_new, :][:, pairAB_A_new]
                match_sim_BA_BB = cross_sim_BB_sp[mask_pointB, :][:, mask_pointB][pairBA_B_new, :][:, pairBA_B_new]
                match_sim_AB_BB = cross_sim_BB_sp[pairAB_B_new, :][:, pairAB_B_new]
                match_sim_BA_AA = cross_sim_AA_sp[pairBA_A_new, :][:, pairBA_A_new]
                match_values_AB_AA, match_indices_AB_AA = torch.topk(match_sim_AB_AA, dim=1, k=k_neighbor, largest=False)
                match_values_BA_BB, match_indices_BA_BB = torch.topk(match_sim_BA_BB, dim=1, k=k_neighbor, largest=False)
                match_values_AB_BB_all = match_sim_AB_BB[:, match_indices_AB_AA]
                match_values_BA_AA_all = match_sim_BA_AA[:, match_indices_BA_BB]
                match_values_AB_BB = torch.diagonal(match_values_AB_BB_all, 0, dim1=0, dim2=1).transpose(0, 1)
                match_values_BA_AA = torch.diagonal(match_values_BA_AA_all, 0, dim1=0, dim2=1).transpose(0, 1)
                neighbor_dis_AB = (match_values_AB_AA - match_values_AB_BB) * (match_values_AB_AA - match_values_AB_BB)
                neighbor_dis_BA = (match_values_BA_BB - match_values_BA_AA) * (match_values_BA_BB - match_values_BA_AA)
                # print('1_1')
                # PA VS PB
                valid_cross_sim_AB_sp_mean = torch.mean(cross_sim_AB_sp[mask_pointA, :][match_maskAB == 1], dim=-1)
                valid_cross_sim_AB_sp_nb_mean = torch.mean(cross_sim_AB_sp[mask_pointA, :][match_maskAB_nb == 1], dim=-1)
                novalid_cross_sim_AB_sp_mean = (torch.sum(torch.sum(cross_sim_AB_sp.detach(), 1), 0) - valid_cross_sim_AB_sp_nb_mean * pairAB_A_nb_new.shape[0]) / (new_numA * new_numB - pairAB_A_nb_new.shape[0] + eps)
                valid_cross_sim_BA_sp_mean = torch.mean(cross_sim_AB_sp[:, mask_pointB][match_maskBA.transpose(0, 1) == 1], dim=-1)
                valid_cross_sim_BA_sp_nb_mean = torch.mean(cross_sim_AB_sp[:, mask_pointB][match_maskBA_nb.transpose(0, 1) == 1], dim=-1)
                novalid_cross_sim_BA_sp_mean = (torch.sum(torch.sum(cross_sim_AB_sp.detach(), 1), 0) - valid_cross_sim_BA_sp_nb_mean * pairBA_B_nb_new.shape[0]) / (new_numA * new_numB - pairBA_B_nb_new.shape[0] + eps)

                valid_indexesA = torch.tensor(list(range(cross_sim_AB_sp.shape[0])), device=self.device)[mask_pointA][pairAB_A_new]
                valid_indexesA_nb = torch.tensor(list(range(cross_sim_AB_sp.shape[0])), device=self.device)[mask_pointA][pairAB_A_nb_new]
                # cross_sim_BA_sp = current_descB @ current_descA.transpose(0, 1)
                cross_sim_AB_out_sp = torch.cat((cross_sim_AB_sp, torch.ones((cross_sim_AB_sp.shape[0], 1), device=cross_sim_AB_sp.device) * 2), dim=-1)      # NA X (NB + 1)
                cross_sim_AB_out_nb_sp = torch.cat((cross_sim_AB_sp, torch.ones((cross_sim_AB_sp.shape[0], 1), device=cross_sim_AB_sp.device) * 2), dim=-1)      # NA X (NB + 1)
                # cross_sim_BA_out_sp = torch.cat((cross_sim_BA_sp, torch.ones((numB, 1), device=cross_sim_BA_sp.device)), dim=-1)      # NB X (NA + 1)
                # valid_indexesB = torch.tensor(list(range(numB)), device=self.device)[mask_pointB][pairBA_B]
                # print('1_2')
                cross_sim_AB_out_sp[valid_indexesA, -1] = novalid_cross_sim_AB_sp_mean
                cross_sim_AB_out_nb_sp[valid_indexesA_nb, -1] = novalid_cross_sim_AB_sp_mean
                novalid_indexesA = torch.tensor(list(range(cross_sim_AB_sp.shape[0])), device=self.device)[cross_sim_AB_out_nb_sp[:, -1]==2]
                cross_sim_AB_out_sp[novalid_indexesA, -1] = valid_cross_sim_AB_sp_mean

                soft_cross_sim_AtoB_sp = F.softmax((cross_sim_AB_out_sp - 1) / t_des, dim=-1)
                # soft_cross_sim_BtoA = F.softmax((cross_sim_BA_out - 1) / t_des, dim=-1)
                # print('1_3')
                soft_valid_cross_sim_AB_sp = soft_cross_sim_AtoB_sp[mask_pointA, :-1][match_maskAB==1]
                # soft_valid_cross_sim_BA = soft_cross_sim_BtoA[mask_pointB, :-1][pairBA_B, pairBA_A]
                soft_novalid_cross_sim_AB_sp = soft_cross_sim_AtoB_sp[novalid_indexesA, -1]
                # soft_novalid_cross_sim_BA = soft_cross_sim_BtoA[cross_sim_BA_out[:, -1]==1, -1]
                log_soft_valid_cross_sim_AB_sp = -torch.log(soft_valid_cross_sim_AB_sp + eps) * (1 - dis_oriATB[match_maskAB==1] / self.ori_diff) * (1 - bin_distAB[mask_pointA, :][match_maskAB==1] / current_binA.shape[-1]) * (1 - key_disAB[match_maskAB==1].detach() / self.correspond)
                # log_soft_valid_cross_sim_BA = -torch.log(soft_valid_cross_sim_BA + eps)
                log_soft_novalid_cross_sim_AB_sp = -torch.log(soft_novalid_cross_sim_AB_sp + eps)
                # log_soft_novalid_cross_sim_BA = -torch.log(soft_novalid_cross_sim_BA + eps)
                dis_cross_sim_mean_sp = torch.sum(torch.cat((4*log_soft_valid_cross_sim_AB_sp, log_soft_novalid_cross_sim_AB_sp), dim=-1), dim=-1) / new_numA
                # print(2)
                # PA VS PAB
                # match_mask_A = copy.deepcopy(mask_pointA)
                # match_mask_B = copy.deepcopy(mask_pointB)
                match_mask_A = torch.zeros(cross_sim_AB_sp.shape[0], device=self.device)
                match_mask_nb_A = torch.zeros(cross_sim_AB_sp.shape[0], device=self.device)
                valid_match_indexesA = torch.tensor(list(range(cross_sim_AB_sp.shape[0])), device=self.device)[mask_pointA][vmaskAH]
                valid_match_indexesA_nb = torch.tensor(list(range(cross_sim_AB_sp.shape[0])), device=self.device)[mask_pointA][vmaskAH_nb]
                match_mask_A[valid_match_indexesA] = 1
                match_mask_nb_A[valid_match_indexesA_nb] = 1

                match_mask_B = torch.zeros(cross_sim_AB_sp.shape[1], device=self.device)
                match_mask_nb_B = torch.zeros(cross_sim_AB_sp.shape[1], device=self.device)
                valid_match_indexesB = torch.tensor(list(range(cross_sim_AB_sp.shape[1])), device=self.device)[mask_pointB][vmaskBH]
                valid_match_indexesB_nb = torch.tensor(list(range(cross_sim_AB_sp.shape[1])), device=self.device)[mask_pointB][vmaskBH_nb]
                match_mask_B[valid_match_indexesB] = 1
                match_mask_nb_B[valid_match_indexesB_nb] = 1
                # match_mask_A = copy.deepcopy(vmaskAH)
                # match_mask_B = copy.deepcopy(vmaskBH)

                cross_sim_AB = current_descA @ desc_mapB[idx, :, :, :].view(-1, H * W)
                # cross_sim_AB = cross_sim_AB[mask_pointA, :]
                cross_sim_AB_all = F.grid_sample(cross_sim_AB.view(-1, H, W).unsqueeze(0),
                                                pntA_H_normalized[vmaskAH, :].detach().view(1, 1, -1, 2),
                                                mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NA x repeatNA
                valid_cross_sim_AB_mean = torch.trace(cross_sim_AB_all[match_mask_A==1, :]) / cross_sim_AB_all[match_mask_A==1, :].shape[0]
                # novalid_cross_sim_AB_mean = (torch.sum(torch.sum(cross_sim_AB.detach(), 1), 1) - valid_cross_sim_AB_mean * pairAB_A.shape[0]) / (new_numA * H * W - pairAB_A.shape[0])

                cross_sim_BA = current_descB @ desc_mapA[idx, :, :, :].view(-1, H * W)   # M x H x W
                # cross_sim_BA = cross_sim_BA[mask_pointB, :]
                cross_sim_BA_all = F.grid_sample(cross_sim_BA.view(-1, H, W).unsqueeze(0),
                                                pntB_invH_normalized[vmaskBH, :].detach().view(1, 1, -1, 2),
                                                mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NB x match_nB
                valid_cross_sim_BA_mean = torch.trace(cross_sim_BA_all[match_mask_B==1, :]) / cross_sim_BA_all[match_mask_B==1, :].shape[0]
                # novalid_cross_sim_BA_mean = (torch.sum(torch.sum(cross_sim_BA.detach(), 1), 1) - valid_cross_sim_BA_mean * pairBA_B.shape[0]) / (new_numB * H * W - pairBA_B.shape[0])

                cross_sim_AB_out = torch.cat((cross_sim_AB, torch.ones((cross_sim_AB.shape[0], 1), device=cross_sim_AB.device)), dim=-1)      # NA X (H X W + 1)
                cross_sim_BA_out = torch.cat((cross_sim_BA, torch.ones((cross_sim_BA.shape[0], 1), device=cross_sim_BA.device)), dim=-1)      # NB X (H X W + 1)
                # print(3)
                # cross_sim_AB_out[mask_pointA, -1] -= 1
                # cross_sim_BA_out[mask_pointB, -1] -= 1
                # cross_sim_AB_out[match_mask_A, -1] -= 1
                cross_sim_AB_out[match_mask_A==1, -1] = novalid_cross_sim_AB_sp_mean
                cross_sim_AB_out[match_mask_nb_A==0, -1] = valid_cross_sim_AB_mean

                cross_sim_BA_out[match_mask_B==1, -1] = novalid_cross_sim_BA_sp_mean
                cross_sim_BA_out[match_mask_nb_B==0, -1] = valid_cross_sim_BA_mean

                soft_cross_sim_AtoB = F.softmax((cross_sim_AB_out - 1) / t_des, dim=-1)         # NA X (H X W + 1)
                soft_cross_sim_BtoA = F.softmax((cross_sim_BA_out - 1) / t_des, dim=-1)         # NB X (H X W + 1)
                soft_cross_sim_AB_all = F.grid_sample(soft_cross_sim_AtoB[:, :-1].view(-1, H, W).unsqueeze(0),
                                                    pntA_H_normalized[vmaskAH, :].detach().view(1, 1, -1, 2),
                                                    mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NA x match_nA
                
                soft_cross_sim_BA_all = F.grid_sample(soft_cross_sim_BtoA[:, :-1].view(-1, H, W).unsqueeze(0),
                                                    pntB_invH_normalized[vmaskBH, :].detach().view(1, 1, -1, 2),
                                                    mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NB x match_nB
                # soft_valid_cross_sim_AB_all = soft_cross_sim_AB_all[mask_pointA, :]             # repeat_nA x repeat_nA
                # soft_valid_cross_sim_BA_all = soft_cross_sim_BA_all[mask_pointB, :]             # repeat_nB x repeat_nB

                soft_valid_cross_sim_AB_all = soft_cross_sim_AB_all[match_mask_A==1, :]             # match_nA x match_nA
                soft_valid_cross_sim_BA_all = soft_cross_sim_BA_all[match_mask_B==1, :]             # match_nB x match_nB

                valid_mask_AB = torch.eye(soft_valid_cross_sim_AB_all.shape[0]) == 1
                valid_mask_BA = torch.eye(soft_valid_cross_sim_BA_all.shape[0]) == 1
                # print(4)
                # 取对角线
                soft_valid_cross_sim_AB = soft_valid_cross_sim_AB_all[valid_mask_AB]
                soft_valid_cross_sim_BA = soft_valid_cross_sim_BA_all[valid_mask_BA]

                # soft_novalid_cross_sim_AB = soft_cross_sim_AtoB[mask_pointA==False, -1]              # (NA-repeat_nA) x 1
                # soft_novalid_cross_sim_BA = soft_cross_sim_BtoA[mask_pointB==False, -1]
                soft_novalid_cross_sim_AB = soft_cross_sim_AtoB[match_mask_nb_A==0, -1]               # (NA-match_nA) x 1
                soft_novalid_cross_sim_BA = soft_cross_sim_BtoA[match_mask_nb_B==0, -1]
                # print(soft_novalid_cross_sim_AB, soft_novalid_cross_sim_BA)

                log_soft_valid_cross_sim_AB = -torch.log(soft_valid_cross_sim_AB + eps) * (1 - torch.diag(dis_oriATAB)[vmaskAH] / self.ori_diff) * (1 - torch.diag(bin_distATAB[mask_pointA, :])[vmaskAH] / bin_kpAB_T.shape[0])
                log_soft_valid_cross_sim_BA = -torch.log(soft_valid_cross_sim_BA + eps) * (1 - torch.diag(dis_oriBTBA)[vmaskBH] / self.ori_diff) * (1 - torch.diag(bin_distBTBA[mask_pointB, :])[vmaskBH] / bin_kpBA_T.shape[0])
                log_soft_novalid_cross_sim_AB = -torch.log(soft_novalid_cross_sim_AB + eps)
                log_soft_novalid_cross_sim_BA = -torch.log(soft_novalid_cross_sim_BA + eps)

                dis_cross_sim_mean = torch.sum(torch.cat((4*log_soft_valid_cross_sim_AB, 4*log_soft_valid_cross_sim_BA, log_soft_novalid_cross_sim_AB, log_soft_novalid_cross_sim_BA), dim=-1), dim=-1) / (new_numA + new_numB)
                # print(5)
                valid_cross_sim_AB = cross_sim_AB[mask_pointA, :]   # repeat_nA x (H X W)
                valid_cross_sim_BA = cross_sim_BA[mask_pointB, :]   # repeat_nB x (H X W)
                exp_valid_cross_sim_AtoB = torch.exp((valid_cross_sim_AB - 1) / t_rel).view(-1, H, W)
                exp_valid_cross_sim_BtoA = torch.exp((valid_cross_sim_BA - 1) / t_rel).view(-1, H, W)
                exp_valid_cross_sim_AB_all = F.grid_sample(exp_valid_cross_sim_AtoB.unsqueeze(0),
                                                        pntA_H_normalized.detach().view(1, 1, -1, 2),
                                                        mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # repeat_nA x repeat_nA
                
                exp_valid_cross_sim_BA_all = F.grid_sample(exp_valid_cross_sim_BtoA.unsqueeze(0),
                                                        pntB_invH_normalized.detach().view(1, 1, -1, 2),
                                                        mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # repeat_nB x repeat_nB

                repeat_mask_AB = torch.eye(exp_valid_cross_sim_AB_all.shape[0]) == 1
                repeat_mask_BA = torch.eye(exp_valid_cross_sim_BA_all.shape[0]) == 1
                rel_valid_cross_sim_AB = exp_valid_cross_sim_AB_all[repeat_mask_AB]
                rel_valid_cross_sim_BA = exp_valid_cross_sim_BA_all[repeat_mask_BA]

                # pntA_H_normalized_new = copy.deepcopy(pntA_H_normalized.detach())
                # pntB_invH_normalized_new = copy.deepcopy(pntB_invH_normalized.detach())

                # pntA_H_normalized_new[:, 0] += 2
                # pntB_invH_normalized_new[:, 0] += 2

                scoresAB_all = F.grid_sample(scores_mapB[idx, :, :, :].unsqueeze(0),
                                            pntA_H_normalized_new.view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)      # 1 x repeat_nA

                scoresBA_all = F.grid_sample(scores_mapA[idx, :, :, :].unsqueeze(0),
                                            pntB_invH_normalized_new.view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)      # 1 x repeat_nB
                # print(6)
                scores_AAB = scoresA[idx][pmA][mask_pointA] * scoresAB_all
                scores_BBA = scoresB[idx][pmB][mask_pointB] * scoresBA_all
                scores_sum_AAB = torch.sum(scores_AAB, dim=-1)
                scores_sum_BBA = torch.sum(scores_BBA, dim=-1)
                scores_normalize_AAB = scores_AAB / (scores_sum_AAB + eps)
                scores_normalize_BBA = scores_BBA / (scores_sum_BBA + eps)
                rel_meanA = torch.sum(scores_normalize_AAB * (1 - rel_valid_cross_sim_AB), dim=-1) / pntA_H_normalized_new.shape[0]
                rel_meanB = torch.sum(scores_normalize_BBA * (1 - rel_valid_cross_sim_BA), dim=-1) / pntB_invH_normalized_new.shape[0]

                # # 熵loss
                # current_descA_std, current_descB_std = descA_std[countA:countA+new_numA], descB_std[countB:countB+new_numB]
                # desc_std += torch.mean(current_descA_std) + torch.mean(current_descB_std)

                countA += new_numA
                countB += new_numB
                # countA_T += numA_T
                # countB_T += numB_T

                dis_neighbor_mean_total += torch.mean(torch.sum(neighbor_dis_AB, dim=1)) + torch.mean(torch.sum(neighbor_dis_BA, dim=1))
                dis_desc += dis_cross_sim_mean_sp
                dis_desc += dis_cross_sim_mean

                dis_pair_meanAB = torch.mean(key_manhattandisAB[pairAB_A, pairAB_B])
                dis_pair_meanBA = torch.mean(key_manhattandisBA[pairBA_B, pairBA_A])

                dis_peak_mean = torch.mean(torch.cat((scoreddisA[idx][pmA], scoreddisB[idx][pmB]), dim=0))
                # dis_peak_meanB = torch.mean(scoreddisB[idx])
                
                dis_mean_total += dis_pair_meanAB + dis_pair_meanBA
                dis_peak_scored += dis_peak_mean

                dis_rel += rel_meanA + rel_meanB
                # # Penalty
                # scores_mean += (-torch.log(torch.mean(scoresA[idx], dim=-1) + eps) - torch.log(torch.mean(scoresB[idx], dim=-1) + eps)) 
                # print(scores_mean)
            except:
                # dis_mean_total += 0
                # dis_peak_scored += 0
                # dis_desc += 0
                # dis_rel += 0
                # print('Overlapping too small or Repeatable point pairs distance is greater than correspond(1.5):', pntA.shape[0], pntA_H.shape[0], pntB.shape[0], pntB_invH.shape[0], dis_pairAB.shape[0], dis_pairBA.shape[0])
                valid_batch_size -= 1
                countA += new_numA
                countB += new_numB
                # countA_T += numA_T
                # countB_T += numB_T

        valid_batch_size = valid_batch_size if valid_batch_size > 0 else eps
        # Reprojection Loss 
        reprojection_loss = dis_mean_total / (valid_batch_size * 2)
        # Dispersity Peak Loss
        dispersity_peak_loss = dis_peak_scored / valid_batch_size
        # NRE Loss
        descriptor_loss = dis_desc / (2 * valid_batch_size)
        # Reliability Loss
        reliability_loss = dis_rel / (valid_batch_size * 2)
        # SOSR Loss
        sosr_loss = dis_neighbor_mean_total / ((valid_batch_size * 2))
        # # Entropy loss
        # std_loss = (valid_batch_size * 2) / desc_std  
        # # Score Penalty
        # score_penalty = scores_mean / (valid_batch_size * 2)
        # FA Desc loss
        FA_des_loss = dis_desc_fa / valid_batch_size_FA if valid_batch_size_FA > 0 else 0

        loss_total = wrp * reprojection_loss + wpl * dispersity_peak_loss + wdl * descriptor_loss + wrl * reliability_loss + sosr_loss + FA_des_loss
        loss_group = {
            'reprojection_loss': reprojection_loss, 
            'dispersity_peak_loss': dispersity_peak_loss,
            'descriptor_loss': descriptor_loss,
            'reliability_loss': reliability_loss,
            'sosr_loss': sosr_loss,
            # 'std_loss': std_loss,
            'FA_des_loss': FA_des_loss,
            }
        return loss_total, loss_group

    # patch/dense AT角度 黑白相似度加量化
    def detector_selfsupervised_loss_dkd_patch_ext_restrict_modify_oriR_ratio_FA_qtbw_ns_wg_nori_AT(self, kpA, kpB, pmaskA, pmaskB, descA, descB, desc_mapA, desc_mapB, scoreddisA, scoreddisB, scoresA, scoresB, scores_mapA, scores_mapB, Homo, inv_Homo, inv_Homo_en, ori_all_patchA, ori_all_patchB, ori_kp_patchA, ori_kp_patchB, bin_allA, bin_allB, bin_kpA, bin_kpB, trans_angle, FA_flag, H, W, wrp=1, wpl=1, wdl=1, wrl=1, t_des=0.02, t_rel=1):
        # pmaskA: (BxMax_num) 32x350=11200
        batch_size = len(kpA)
        max_num = pmaskA.shape[-1] // batch_size    # 350
        dis_mean_total = 0
        dis_neighbor_mean_total = 0
        dis_peak_scored = 0
        dis_desc = 0
        dis_rel = 0
        desc_std = 0
        eps = 1e-12
        valid_batch_size = batch_size
        valid_batch_size_FA = 0
        countA, countB = 0, 0
        dis_desc_fa = 0
        # countA_T, countB_T = 0, 0
        for idx in range(batch_size):
            pntA, pntB = kpA[idx], kpB[idx]     # M X 2 (x,y)
            # kmask_TA, kmask_TB = kmask_T_allA[idx], kmask_T_allB[idx]
            pntA = pntA.float()
            pntB = pntB.float()

            # 剔除部分按压区域的点,且保留在重叠区域的点
            numA, numB = pntA.shape[0], pntB.shape[0]
            # numA_T, numB_T = pntA[kmask_TA].shape[0], pntB[kmask_TB].shape[0]
            pmA, pmB = pmaskA[max_num * idx:max_num * idx + numA].bool(), pmaskB[max_num * idx:max_num * idx + numB].bool()
            pntA, pntB = pntA[pmA, :], pntB[pmB, :]
            new_numA, new_numB = pntA.shape[0], pntB.shape[0]       
            
            pntA = (pntA + 1) / 2 * pntA.new_tensor([[W + 3, H - 1]]).to(pntA.device)
            pntB = (pntB + 1) / 2 * pntB.new_tensor([[W + 3, H - 1]]).to(pntB.device)

            # [120, 40] -> [120, 36],实际只取中心118x32区域的点对
            pntA[:, 0] -= 2
            pntB[:, 0] -= 2
            
            pntA_normalized = pntA / pntA.new_tensor([W - 1, H - 1]).to(pntA.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)
            pntB_normalized = pntB / pntB.new_tensor([W - 1, H - 1]).to(pntB.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)

            pntA_H = warp_points(pntA[:, :2], Homo[idx].squeeze(), device=self.device)  # 利用变换矩阵变换坐标点
            pntA_H, mask_pointA = filter_points(pntA_H, torch.tensor([W, H], device=self.device), return_mask=True)
            pntB_invH = warp_points(pntB[:, :2], inv_Homo[idx].squeeze(), device=self.device)
            pntB_invH, mask_pointB = filter_points(pntB_invH, torch.tensor([W, H], device=self.device), return_mask=True)
            
            current_descA, current_descB = descA[countA:countA+new_numA], descB[countB:countB+new_numB]
            cross_sim_AB_sp = current_descA @ current_descB.transpose(0, 1)     # NTA X NTB
            
            # 黑白相似度
            current_binA, current_binB = (bin_kpA[countA:countA+new_numA] >= 0.5).float(), (bin_kpB[countB:countB+new_numB] >= 0.5).float()   # [NA, 256] [NB_256]
            bin_distAB = current_binA.shape[-1] - (current_binA @ current_binB.transpose(0, 1)) - ((1 - current_binA) @ (1 - current_binB.transpose(0, 1))) # [NA, NB]

            # Net FA余弦相似度小
            if FA_flag[idx] == 1:
                FA_bin_mask = bin_distAB >= (1 - self.FA_bin_thr) * current_binA.shape[-1] 
                # print(torch.sum(FA_bin_mask), FA_bin_mask.shape[0]*FA_bin_mask.shape[1])
                dis_desc_fa += (2 - torch.mean(torch.sqrt(2 * (1 - cross_sim_AB_sp[FA_bin_mask]) + eps)))

                valid_batch_size -= 1
                valid_batch_size_FA += 1
                countA += new_numA
                countB += new_numB
                continue
            
            # 真匹配的trans
            try:
                assert pntA_H.shape[0] > 0 and pntB_invH.shape[0] > 0 
                
                # 点对欧氏距离
                key_disAB = self.get_dis(pntA_H[:, :2], pntB[:, :2])            # repeatNA x NB
                key_disBA = self.get_dis(pntB_invH[:, :2], pntA[:, :2])
                pairAB_A, pairAB_B, dis_pairAB, _ = self.get_point_pair(key_disAB, dis_thre=self.correspond)  # p -> k # NTA(<1.5), NTA(<1.5), NTA(<1.5), NTA        
                pairBA_B, pairBA_A, dis_pairBA, _  = self.get_point_pair(key_disBA, dis_thre=self.correspond)  # p -> k # NTB(<1.5), NTB(<1.5), NTB(<1.5), NTB 
                
                # 点距离mask
                nn_maskAB = torch.zeros((pntA_H.shape[0], pntB.shape[0]), device=self.device) 
                nn_maskAB[pairAB_A, pairAB_B] = 1

                nn_maskBA = torch.zeros((pntB_invH.shape[0], pntA.shape[0]), device=self.device) 
                nn_maskBA[pairBA_B, pairBA_A] = 1

                # 点对曼哈顿距离
                key_manhattandisAB = self.get_manhattan_dis(pntA_H[:, :2], pntB[:, :2])
                key_manhattandisBA = self.get_manhattan_dis(pntB_invH[:, :2], pntA[:, :2])
                # print('pdis:', dis_pairAB.shape[0], dis_pairBA.shape[0])
                assert dis_pairAB.shape[0] > 0 and dis_pairBA.shape[0] > 0     

                pntA_H_normalized = pntA_H / pntA_H.new_tensor([W - 1, H - 1]).to(pntA_H.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)
                pntB_invH_normalized = pntB_invH / pntB_invH.new_tensor([W - 1, H - 1]).to(pntB_invH.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)

                # 用于score_map
                pntA_H_new = copy.deepcopy(pntA_H.detach())
                pntB_invH_new = copy.deepcopy(pntB_invH.detach())
                pntA_H_new[:, 0] += 10                   # 120 x 36 -> 128 x 56
                pntA_H_new[:, 1] += 4 
                pntB_invH_new[:, 0] += 10
                pntB_invH_new[:, 1] += 4
                
                pntA_H_normalized_new = pntA_H_new / pntA_H_new.new_tensor([W + 19, H + 7]).to(pntA_H.device) * 2 - 1

                # pntB_invH_new = warp_points(pntB_invH_new[:, :2], inv_Homo_en[idx].squeeze(), device=self.device)       # 转到A上，而不是AT上
                
                pntB_invH_normalized_new = pntB_invH_new / pntB_invH_new.new_tensor([W + 19, H + 7]).to(pntB_invH.device) * 2 - 1 

                # # PA VS PB 有一定偏移
                # ori_kpA_ext = F.grid_sample(ori_allA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                #                             pntA_normalized.detach().view(1, 1, -1, 2),
                #                             mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  
                # ori_kpB_ext = F.grid_sample(ori_allB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                #                             pntB_normalized.detach().view(1, 1, -1, 2),
                #                             mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  

                # main_ori_maskATB = self.get_main_ori_consistence(ori_kpA[countA:countA+numA][pmA].unsqueeze(1), ori_kpB_ext)  # NTA x NTB 
                # main_ori_maskBTA = self.get_main_ori_consistence(ori_kpB[countB:countB+numB][pmB].unsqueeze(1), ori_kpA_ext)  # NTB x NTA 
                
                # print('1_2:', main_ori_maskATB.shape[0])
                # exit()
                ori_kpAT_patch_ext = F.grid_sample(ori_kp_patchA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntA_H_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0).transpose(0, 1)          # repeatNA x 1
                ori_kpB_patch_ext = F.grid_sample(ori_all_patchB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntB_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0).transpose(0, 1)          # NTB x 1
                ori_kpA_patch_ext = F.grid_sample(ori_all_patchA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntA_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0).transpose(0, 1)          # NTA x 1
                ori_kpBT_patch_ext = F.grid_sample(ori_kp_patchB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntB_invH_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0).transpose(0, 1)          # repeatNB x 1
                # print('1_2_1:', pntB_invH_normalized_new.shape[0])
                ori_maskATB, dis_oriATB = self.get_main_ori_consistence_AT(ori_kpAT_patch_ext, ori_kpB_patch_ext)  # repeatNA x NTB
                # print('1_2_2:', ori_maskATB.shape)
                ori_maskBTA, dis_oriBTA = self.get_main_ori_consistence_AT(ori_kpBT_patch_ext, ori_kpA_patch_ext)  # repeatNB x NTA
                # print('1_2_2:', ori_maskATB.shape[0])
                # match_maskAB = (nn_maskAB == 1) * main_ori_maskATB
                # match_maskBA = (nn_maskBA == 1) * main_ori_maskBTA
                # print(nn_maskAB.shape, main_ori_maskATB.shape, ori_maskATB.shape)
                match_maskAB_nb = (nn_maskAB == 1) * ori_maskATB           # repeatNA X NTB
                match_maskBA_nb = (nn_maskBA == 1) * ori_maskBTA          # repeatNB X NTA
                pairAB_A_nb_new, pairAB_B_nb_new = torch.where(match_maskAB_nb == 1)
                pairBA_B_nb_new, pairBA_A_nb_new = torch.where(match_maskBA_nb == 1)
                # assert pairAB_A_new.shape[0] > 0 and pairBA_B_new.shape[0] > 0 

                # # PA VS PAB 没有中心点距离偏移
                # # 中心主方向一致性
                # ori_kpAB_ext = F.grid_sample(ori_allB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                #                             pntA_H_normalized.detach().view(1, 1, -1, 2),
                #                             mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  
                # ori_kpBA_ext = F.grid_sample(ori_allA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                #                             pntB_invH_normalized.detach().view(1, 1, -1, 2),
                #                             mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  
                # main_ori_maskATAB = self.get_main_ori_consistence(ori_kpA[countA:countA+new_numA].unsqueeze(1), ori_kpAB_ext)  # NTAxNTA 
                # main_ori_maskBTBA = self.get_main_ori_consistence(ori_kpB[countB:countB+new_numB].unsqueeze(1), ori_kpBA_ext)  # NTBxNTB 

                # 4x4邻域方向一致性
                ori_kpAB_patch_ext = F.grid_sample(ori_all_patchB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntA_H_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0).transpose(0, 1)  
                ori_kpBA_patch_ext = F.grid_sample(ori_all_patchA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntB_invH_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0).transpose(0, 1)  
                # print('1_2_4:', ori_kpAB_patch_ext.shape)
                ori_maskATAB, dis_oriATAB = self.get_main_ori_consistence_AT(ori_kpAT_patch_ext, ori_kpAB_patch_ext)  # repeatNA x repeatNA
                ori_maskBTBA, dis_oriBTBA = self.get_main_ori_consistence_AT(ori_kpBT_patch_ext, ori_kpBA_patch_ext)  # repeatNB x repeatNB
                
                # ori_maskATAB = ori_maskATAB[mask_pointA, :]         # repeatNA x repeatNA
                # ori_maskBTBA = ori_maskBTBA[mask_pointB, :]
                # dis_oriATAB = dis_oriATAB[mask_pointA, :]         # repeatNA x repeatNA
                # dis_oriBTBA = dis_oriBTBA[mask_pointB, :]

                # vmaskAH = torch.diag(main_ori_maskATAB) == 1
                # vmaskBH = torch.diag(main_ori_maskBTBA) == 1
                # vmaskAH = torch.diag(main_ori_maskATAB * (ori_maskATAB >= self.ori_ratio)) == 1
                # vmaskBH = torch.diag(main_ori_maskBTBA * (ori_maskBTBA >= self.ori_ratio)) == 1
                # assert torch.sum(vmaskAH) > 0 and torch.sum(vmaskBH) > 0
                
                # 黑白相似度
                bin_maskATB = bin_distAB <= (1 - self.FR_bin_thr) * current_binA.shape[-1]  
                bin_maskBTA = bin_maskATB.transpose(0, 1)  

                match_maskAB = match_maskAB_nb * bin_maskATB[mask_pointA, :]               # repeatNA X NB
                match_maskBA = match_maskBA_nb * bin_maskBTA[mask_pointB, :]               # repeatNB X NA

                pairAB_A_new, pairAB_B_new = torch.where(match_maskAB == 1)
                pairBA_B_new, pairBA_A_new = torch.where(match_maskBA == 1)
                # print('bin_mask:', pairAB_A_new.shape[0], pairBA_B_new.shape[0])
                assert pairAB_A_new.shape[0] > 0 and pairBA_B_new.shape[0] > 0 

                bin_kpAB_T = (F.grid_sample(bin_allB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntA_H_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0) >= 0.5).float()  # [256, repeatNA]
                bin_kpBA_T = (F.grid_sample(bin_allA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntB_invH_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0) >= 0.5).float()  # [256, repeatNB]
                bin_distATAB = bin_kpAB_T.shape[0] - (current_binA @ bin_kpAB_T) - ((1 - current_binA) @ (1 - bin_kpAB_T)) # [NTA, repeatNA]
                bin_distBTBA = bin_kpBA_T.shape[0] - (current_binB @ bin_kpBA_T) - ((1 - current_binB) @ (1 - bin_kpBA_T)) # [NTB, repeatNB]

                bin_maskATAB = bin_distATAB <= (1 - self.FR_bin_thr) * bin_kpAB_T.shape[0] 
                bin_maskBTBA = bin_distBTBA <= (1 - self.FR_bin_thr) * bin_kpBA_T.shape[0] 
                bin_maskATAB = bin_maskATAB[mask_pointA, :]
                bin_maskBTBA = bin_maskBTBA[mask_pointB, :]

                vmaskAH_nb = torch.diag(ori_maskATAB)
                vmaskBH_nb = torch.diag(ori_maskBTBA)
                vmaskAH = torch.diag(ori_maskATAB * bin_maskATAB) == 1      # [repeatNA, 1]
                vmaskBH = torch.diag(ori_maskBTBA * bin_maskBTBA) == 1      # [repeatNB, 1]

                # print('main_ori:', torch.sum(vmaskAH), torch.sum(vmaskBH))
                assert torch.sum(vmaskAH) > 0 and torch.sum(vmaskBH) > 0

                # SOSR: 简化的self-attention
                k_neighbor = 3
                cross_sim_AA_sp = current_descA @ current_descA.transpose(0, 1)
                cross_sim_BB_sp = current_descB @ current_descB.transpose(0, 1)
                # print('SOSR:', pairAB_A_new.shape[0], pairBA_B_new.shape[0])
                assert pairAB_A_new.shape[0] >= k_neighbor and pairBA_B_new.shape[0] >= k_neighbor 

                match_sim_AB_AA = cross_sim_AA_sp[mask_pointA, :][:, mask_pointA][pairAB_A_new, :][:, pairAB_A_new]
                match_sim_BA_BB = cross_sim_BB_sp[mask_pointB, :][:, mask_pointB][pairBA_B_new, :][:, pairBA_B_new]
                match_sim_AB_BB = cross_sim_BB_sp[pairAB_B_new, :][:, pairAB_B_new]
                match_sim_BA_AA = cross_sim_AA_sp[pairBA_A_new, :][:, pairBA_A_new]
                match_values_AB_AA, match_indices_AB_AA = torch.topk(match_sim_AB_AA, dim=1, k=k_neighbor, largest=False)
                match_values_BA_BB, match_indices_BA_BB = torch.topk(match_sim_BA_BB, dim=1, k=k_neighbor, largest=False)
                match_values_AB_BB_all = match_sim_AB_BB[:, match_indices_AB_AA]
                match_values_BA_AA_all = match_sim_BA_AA[:, match_indices_BA_BB]
                match_values_AB_BB = torch.diagonal(match_values_AB_BB_all, 0, dim1=0, dim2=1).transpose(0, 1)
                match_values_BA_AA = torch.diagonal(match_values_BA_AA_all, 0, dim1=0, dim2=1).transpose(0, 1)
                neighbor_dis_AB = (match_values_AB_AA - match_values_AB_BB) * (match_values_AB_AA - match_values_AB_BB)
                neighbor_dis_BA = (match_values_BA_BB - match_values_BA_AA) * (match_values_BA_BB - match_values_BA_AA)
                # print('1_1')
                # PA VS PB
                valid_cross_sim_AB_sp_mean = torch.mean(cross_sim_AB_sp[mask_pointA, :][match_maskAB == 1], dim=-1)
                valid_cross_sim_AB_sp_nb_mean = torch.mean(cross_sim_AB_sp[mask_pointA, :][match_maskAB_nb == 1], dim=-1)
                novalid_cross_sim_AB_sp_mean = (torch.sum(torch.sum(cross_sim_AB_sp.detach(), 1), 0) - valid_cross_sim_AB_sp_nb_mean * pairAB_A_nb_new.shape[0]) / (new_numA * new_numB - pairAB_A_nb_new.shape[0] + eps)
                valid_cross_sim_BA_sp_mean = torch.mean(cross_sim_AB_sp[:, mask_pointB][match_maskBA.transpose(0, 1) == 1], dim=-1)
                valid_cross_sim_BA_sp_nb_mean = torch.mean(cross_sim_AB_sp[:, mask_pointB][match_maskBA_nb.transpose(0, 1) == 1], dim=-1)
                novalid_cross_sim_BA_sp_mean = (torch.sum(torch.sum(cross_sim_AB_sp.detach(), 1), 0) - valid_cross_sim_BA_sp_nb_mean * pairBA_B_nb_new.shape[0]) / (new_numA * new_numB - pairBA_B_nb_new.shape[0] + eps)

                valid_indexesA = torch.tensor(list(range(cross_sim_AB_sp.shape[0])), device=self.device)[mask_pointA][pairAB_A_new]
                valid_indexesA_nb = torch.tensor(list(range(cross_sim_AB_sp.shape[0])), device=self.device)[mask_pointA][pairAB_A_nb_new]
                # cross_sim_BA_sp = current_descB @ current_descA.transpose(0, 1)
                cross_sim_AB_out_sp = torch.cat((cross_sim_AB_sp, torch.ones((cross_sim_AB_sp.shape[0], 1), device=cross_sim_AB_sp.device) * 2), dim=-1)      # NA X (NB + 1)
                cross_sim_AB_out_nb_sp = torch.cat((cross_sim_AB_sp, torch.ones((cross_sim_AB_sp.shape[0], 1), device=cross_sim_AB_sp.device) * 2), dim=-1)      # NA X (NB + 1)
                # cross_sim_BA_out_sp = torch.cat((cross_sim_BA_sp, torch.ones((numB, 1), device=cross_sim_BA_sp.device)), dim=-1)      # NB X (NA + 1)
                # valid_indexesB = torch.tensor(list(range(numB)), device=self.device)[mask_pointB][pairBA_B]
                # print('1_2')
                cross_sim_AB_out_sp[valid_indexesA, -1] = novalid_cross_sim_AB_sp_mean
                cross_sim_AB_out_nb_sp[valid_indexesA_nb, -1] = novalid_cross_sim_AB_sp_mean
                novalid_indexesA = torch.tensor(list(range(cross_sim_AB_sp.shape[0])), device=self.device)[cross_sim_AB_out_nb_sp[:, -1]==2]
                cross_sim_AB_out_sp[novalid_indexesA, -1] = valid_cross_sim_AB_sp_mean

                soft_cross_sim_AtoB_sp = F.softmax((cross_sim_AB_out_sp - 1) / t_des, dim=-1)
                # soft_cross_sim_BtoA = F.softmax((cross_sim_BA_out - 1) / t_des, dim=-1)
                # print('1_3')
                soft_valid_cross_sim_AB_sp = soft_cross_sim_AtoB_sp[mask_pointA, :-1][match_maskAB==1]
                # soft_valid_cross_sim_BA = soft_cross_sim_BtoA[mask_pointB, :-1][pairBA_B, pairBA_A]
                soft_novalid_cross_sim_AB_sp = soft_cross_sim_AtoB_sp[novalid_indexesA, -1]
                # soft_novalid_cross_sim_BA = soft_cross_sim_BtoA[cross_sim_BA_out[:, -1]==1, -1]
                log_soft_valid_cross_sim_AB_sp = -torch.log(soft_valid_cross_sim_AB_sp + eps) * (1 - dis_oriATB[match_maskAB==1] / self.ori_diff) * (1 - bin_distAB[mask_pointA, :][match_maskAB==1] / current_binA.shape[-1]) * (1 - key_disAB[match_maskAB==1].detach() / self.correspond)
                # log_soft_valid_cross_sim_BA = -torch.log(soft_valid_cross_sim_BA + eps)
                log_soft_novalid_cross_sim_AB_sp = -torch.log(soft_novalid_cross_sim_AB_sp + eps)
                # log_soft_novalid_cross_sim_BA = -torch.log(soft_novalid_cross_sim_BA + eps)
                dis_cross_sim_mean_sp = torch.sum(torch.cat((4*log_soft_valid_cross_sim_AB_sp, log_soft_novalid_cross_sim_AB_sp), dim=-1), dim=-1) / new_numA
                # print(2)
                # PA VS PAB
                # match_mask_A = copy.deepcopy(mask_pointA)
                # match_mask_B = copy.deepcopy(mask_pointB)
                match_mask_A = torch.zeros(cross_sim_AB_sp.shape[0], device=self.device)
                match_mask_nb_A = torch.zeros(cross_sim_AB_sp.shape[0], device=self.device)
                valid_match_indexesA = torch.tensor(list(range(cross_sim_AB_sp.shape[0])), device=self.device)[mask_pointA][vmaskAH]
                valid_match_indexesA_nb = torch.tensor(list(range(cross_sim_AB_sp.shape[0])), device=self.device)[mask_pointA][vmaskAH_nb]
                match_mask_A[valid_match_indexesA] = 1
                match_mask_nb_A[valid_match_indexesA_nb] = 1

                match_mask_B = torch.zeros(cross_sim_AB_sp.shape[1], device=self.device)
                match_mask_nb_B = torch.zeros(cross_sim_AB_sp.shape[1], device=self.device)
                valid_match_indexesB = torch.tensor(list(range(cross_sim_AB_sp.shape[1])), device=self.device)[mask_pointB][vmaskBH]
                valid_match_indexesB_nb = torch.tensor(list(range(cross_sim_AB_sp.shape[1])), device=self.device)[mask_pointB][vmaskBH_nb]
                match_mask_B[valid_match_indexesB] = 1
                match_mask_nb_B[valid_match_indexesB_nb] = 1
                # match_mask_A = copy.deepcopy(vmaskAH)
                # match_mask_B = copy.deepcopy(vmaskBH)

                cross_sim_AB = current_descA @ desc_mapB[idx, :, :, :].view(-1, H * W)
                # cross_sim_AB = cross_sim_AB[mask_pointA, :]
                cross_sim_AB_all = F.grid_sample(cross_sim_AB.view(-1, H, W).unsqueeze(0),
                                                pntA_H_normalized[vmaskAH, :].detach().view(1, 1, -1, 2),
                                                mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NA x repeatNA
                valid_cross_sim_AB_mean = torch.trace(cross_sim_AB_all[match_mask_A==1, :]) / cross_sim_AB_all[match_mask_A==1, :].shape[0]
                # novalid_cross_sim_AB_mean = (torch.sum(torch.sum(cross_sim_AB.detach(), 1), 1) - valid_cross_sim_AB_mean * pairAB_A.shape[0]) / (new_numA * H * W - pairAB_A.shape[0])

                cross_sim_BA = current_descB @ desc_mapA[idx, :, :, :].view(-1, H * W)   # M x H x W
                # cross_sim_BA = cross_sim_BA[mask_pointB, :]
                cross_sim_BA_all = F.grid_sample(cross_sim_BA.view(-1, H, W).unsqueeze(0),
                                                pntB_invH_normalized[vmaskBH, :].detach().view(1, 1, -1, 2),
                                                mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NB x match_nB
                valid_cross_sim_BA_mean = torch.trace(cross_sim_BA_all[match_mask_B==1, :]) / cross_sim_BA_all[match_mask_B==1, :].shape[0]
                # novalid_cross_sim_BA_mean = (torch.sum(torch.sum(cross_sim_BA.detach(), 1), 1) - valid_cross_sim_BA_mean * pairBA_B.shape[0]) / (new_numB * H * W - pairBA_B.shape[0])

                cross_sim_AB_out = torch.cat((cross_sim_AB, torch.ones((cross_sim_AB.shape[0], 1), device=cross_sim_AB.device)), dim=-1)      # NA X (H X W + 1)
                cross_sim_BA_out = torch.cat((cross_sim_BA, torch.ones((cross_sim_BA.shape[0], 1), device=cross_sim_BA.device)), dim=-1)      # NB X (H X W + 1)
                # print(3)
                # cross_sim_AB_out[mask_pointA, -1] -= 1
                # cross_sim_BA_out[mask_pointB, -1] -= 1
                # cross_sim_AB_out[match_mask_A, -1] -= 1
                cross_sim_AB_out[match_mask_A==1, -1] = novalid_cross_sim_AB_sp_mean
                cross_sim_AB_out[match_mask_nb_A==0, -1] = valid_cross_sim_AB_mean

                cross_sim_BA_out[match_mask_B==1, -1] = novalid_cross_sim_BA_sp_mean
                cross_sim_BA_out[match_mask_nb_B==0, -1] = valid_cross_sim_BA_mean

                soft_cross_sim_AtoB = F.softmax((cross_sim_AB_out - 1) / t_des, dim=-1)         # NA X (H X W + 1)
                soft_cross_sim_BtoA = F.softmax((cross_sim_BA_out - 1) / t_des, dim=-1)         # NB X (H X W + 1)
                soft_cross_sim_AB_all = F.grid_sample(soft_cross_sim_AtoB[:, :-1].view(-1, H, W).unsqueeze(0),
                                                    pntA_H_normalized[vmaskAH, :].detach().view(1, 1, -1, 2),
                                                    mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NA x match_nA
                
                soft_cross_sim_BA_all = F.grid_sample(soft_cross_sim_BtoA[:, :-1].view(-1, H, W).unsqueeze(0),
                                                    pntB_invH_normalized[vmaskBH, :].detach().view(1, 1, -1, 2),
                                                    mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NB x match_nB
                # soft_valid_cross_sim_AB_all = soft_cross_sim_AB_all[mask_pointA, :]             # repeat_nA x repeat_nA
                # soft_valid_cross_sim_BA_all = soft_cross_sim_BA_all[mask_pointB, :]             # repeat_nB x repeat_nB

                soft_valid_cross_sim_AB_all = soft_cross_sim_AB_all[match_mask_A==1, :]             # match_nA x match_nA
                soft_valid_cross_sim_BA_all = soft_cross_sim_BA_all[match_mask_B==1, :]             # match_nB x match_nB

                valid_mask_AB = torch.eye(soft_valid_cross_sim_AB_all.shape[0]) == 1
                valid_mask_BA = torch.eye(soft_valid_cross_sim_BA_all.shape[0]) == 1
                # print(4)
                # 取对角线
                soft_valid_cross_sim_AB = soft_valid_cross_sim_AB_all[valid_mask_AB]
                soft_valid_cross_sim_BA = soft_valid_cross_sim_BA_all[valid_mask_BA]

                # soft_novalid_cross_sim_AB = soft_cross_sim_AtoB[mask_pointA==False, -1]              # (NA-repeat_nA) x 1
                # soft_novalid_cross_sim_BA = soft_cross_sim_BtoA[mask_pointB==False, -1]
                soft_novalid_cross_sim_AB = soft_cross_sim_AtoB[match_mask_nb_A==0, -1]               # (NA-match_nA) x 1
                soft_novalid_cross_sim_BA = soft_cross_sim_BtoA[match_mask_nb_B==0, -1]
                # print(soft_novalid_cross_sim_AB, soft_novalid_cross_sim_BA)

                log_soft_valid_cross_sim_AB = -torch.log(soft_valid_cross_sim_AB + eps) * (1 - torch.diag(dis_oriATAB)[vmaskAH] / self.ori_diff) * (1 - torch.diag(bin_distATAB[mask_pointA, :])[vmaskAH] / bin_kpAB_T.shape[0])
                log_soft_valid_cross_sim_BA = -torch.log(soft_valid_cross_sim_BA + eps) * (1 - torch.diag(dis_oriBTBA)[vmaskBH] / self.ori_diff) * (1 - torch.diag(bin_distBTBA[mask_pointB, :])[vmaskBH] / bin_kpBA_T.shape[0])
                log_soft_novalid_cross_sim_AB = -torch.log(soft_novalid_cross_sim_AB + eps)
                log_soft_novalid_cross_sim_BA = -torch.log(soft_novalid_cross_sim_BA + eps)

                dis_cross_sim_mean = torch.sum(torch.cat((4*log_soft_valid_cross_sim_AB, 4*log_soft_valid_cross_sim_BA, log_soft_novalid_cross_sim_AB, log_soft_novalid_cross_sim_BA), dim=-1), dim=-1) / (new_numA + new_numB)
                # print(5)
                valid_cross_sim_AB = cross_sim_AB[mask_pointA, :]   # repeat_nA x (H X W)
                valid_cross_sim_BA = cross_sim_BA[mask_pointB, :]   # repeat_nB x (H X W)
                exp_valid_cross_sim_AtoB = torch.exp((valid_cross_sim_AB - 1) / t_rel).view(-1, H, W)
                exp_valid_cross_sim_BtoA = torch.exp((valid_cross_sim_BA - 1) / t_rel).view(-1, H, W)
                exp_valid_cross_sim_AB_all = F.grid_sample(exp_valid_cross_sim_AtoB.unsqueeze(0),
                                                        pntA_H_normalized.detach().view(1, 1, -1, 2),
                                                        mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # repeat_nA x repeat_nA
                
                exp_valid_cross_sim_BA_all = F.grid_sample(exp_valid_cross_sim_BtoA.unsqueeze(0),
                                                        pntB_invH_normalized.detach().view(1, 1, -1, 2),
                                                        mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # repeat_nB x repeat_nB

                repeat_mask_AB = torch.eye(exp_valid_cross_sim_AB_all.shape[0]) == 1
                repeat_mask_BA = torch.eye(exp_valid_cross_sim_BA_all.shape[0]) == 1
                rel_valid_cross_sim_AB = exp_valid_cross_sim_AB_all[repeat_mask_AB]
                rel_valid_cross_sim_BA = exp_valid_cross_sim_BA_all[repeat_mask_BA]

                # pntA_H_normalized_new = copy.deepcopy(pntA_H_normalized.detach())
                # pntB_invH_normalized_new = copy.deepcopy(pntB_invH_normalized.detach())

                # pntA_H_normalized_new[:, 0] += 2
                # pntB_invH_normalized_new[:, 0] += 2

                scoresAB_all = F.grid_sample(scores_mapB[idx, :, :, :].unsqueeze(0),
                                            pntA_H_normalized_new.view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)      # 1 x repeat_nA

                scoresBA_all = F.grid_sample(scores_mapA[idx, :, :, :].unsqueeze(0),
                                            pntB_invH_normalized_new.view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)      # 1 x repeat_nB
                # print(6)
                scores_AAB = scoresA[idx][pmA][mask_pointA] * scoresAB_all
                scores_BBA = scoresB[idx][pmB][mask_pointB] * scoresBA_all
                scores_sum_AAB = torch.sum(scores_AAB, dim=-1)
                scores_sum_BBA = torch.sum(scores_BBA, dim=-1)
                scores_normalize_AAB = scores_AAB / (scores_sum_AAB + eps)
                scores_normalize_BBA = scores_BBA / (scores_sum_BBA + eps)
                rel_meanA = torch.sum(scores_normalize_AAB * (1 - rel_valid_cross_sim_AB), dim=-1) / pntA_H_normalized_new.shape[0]
                rel_meanB = torch.sum(scores_normalize_BBA * (1 - rel_valid_cross_sim_BA), dim=-1) / pntB_invH_normalized_new.shape[0]

                # # 熵loss
                # current_descA_std, current_descB_std = descA_std[countA:countA+new_numA], descB_std[countB:countB+new_numB]
                # desc_std += torch.mean(current_descA_std) + torch.mean(current_descB_std)
                # countA_T += numA_T
                # countB_T += numB_T

                dis_neighbor_mean_total += torch.mean(torch.sum(neighbor_dis_AB, dim=1)) + torch.mean(torch.sum(neighbor_dis_BA, dim=1))
                dis_desc += dis_cross_sim_mean_sp
                dis_desc += dis_cross_sim_mean

                dis_pair_meanAB = torch.mean(key_manhattandisAB[pairAB_A, pairAB_B])
                dis_pair_meanBA = torch.mean(key_manhattandisBA[pairBA_B, pairBA_A])

                dis_peak_mean = torch.mean(torch.cat((scoreddisA[idx][pmA], scoreddisB[idx][pmB]), dim=0))
                # dis_peak_meanB = torch.mean(scoreddisB[idx])
                
                dis_mean_total += dis_pair_meanAB + dis_pair_meanBA
                dis_peak_scored += dis_peak_mean

                dis_rel += rel_meanA + rel_meanB
                
                countA += new_numA
                countB += new_numB
                # # Penalty
                # scores_mean += (-torch.log(torch.mean(scoresA[idx], dim=-1) + eps) - torch.log(torch.mean(scoresB[idx], dim=-1) + eps)) 
                # print(scores_mean)
            except:
                # dis_mean_total += 0
                # dis_peak_scored += 0
                # dis_desc += 0
                # dis_rel += 0
                # print('Overlapping too small or Repeatable point pairs distance is greater than correspond(1.5):', pntA.shape[0], pntA_H.shape[0], pntB.shape[0], pntB_invH.shape[0], dis_pairAB.shape[0], dis_pairBA.shape[0])
                valid_batch_size -= 1
                countA += new_numA
                countB += new_numB
                # countA_T += numA_T
                # countB_T += numB_T

        valid_batch_size = valid_batch_size if valid_batch_size > 0 else eps
        # Reprojection Loss 
        reprojection_loss = dis_mean_total / (valid_batch_size * 2)
        # Dispersity Peak Loss
        dispersity_peak_loss = dis_peak_scored / valid_batch_size
        # NRE Loss
        descriptor_loss = dis_desc / (2 * valid_batch_size)
        # Reliability Loss
        reliability_loss = dis_rel / (valid_batch_size * 2)
        # SOSR Loss
        sosr_loss = dis_neighbor_mean_total / ((valid_batch_size * 2))
        # # Entropy loss
        # std_loss = (valid_batch_size * 2) / desc_std  
        # # Score Penalty
        # score_penalty = scores_mean / (valid_batch_size * 2)
        # FA Desc loss
        FA_des_loss = dis_desc_fa / valid_batch_size_FA if valid_batch_size_FA > 0 else 0

        loss_total = wrp * reprojection_loss + wpl * dispersity_peak_loss + wdl * descriptor_loss + wrl * reliability_loss + sosr_loss + FA_des_loss
        loss_group = {
            'reprojection_loss': reprojection_loss, 
            'dispersity_peak_loss': dispersity_peak_loss,
            'descriptor_loss': descriptor_loss,
            'reliability_loss': reliability_loss,
            'sosr_loss': sosr_loss,
            # 'std_loss': std_loss,
            'FA_des_loss': FA_des_loss,
            }
        return loss_total, loss_group

    # patch/dense AT角度 黑白相似度加量化 NFA
    def detector_selfsupervised_loss_dkd_patch_ext_restrict_modify_oriR_ratio_NFA_qtbw_ns_wg_nori_AT(self, kpA, kpB, pmaskA, pmaskB, descA, descB, desc_mapA, desc_mapB, scoreddisA, scoreddisB, scoresA, scoresB, scores_mapA, scores_mapB, Homo, inv_Homo, inv_Homo_en, ori_all_patchA, ori_all_patchB, ori_kp_patchA, ori_kp_patchB, bin_allA, bin_allB, bin_kpA, bin_kpB, trans_angle, FA_flag, H, W, wrp=1, wpl=1, wdl=1, wrl=1, t_des=0.02, t_rel=1):
        # pmaskA: (BxMax_num) 32x350=11200
        batch_size = len(kpA)
        max_num = pmaskA.shape[-1] // batch_size    # 350
        dis_mean_total = 0
        dis_neighbor_mean_total = 0
        dis_peak_scored = 0
        dis_desc = 0
        dis_rel = 0
        desc_std = 0
        eps = 1e-12
        valid_batch_size = batch_size
        # valid_batch_size_FA = 0
        countA, countB = 0, 0
        # dis_desc_fa = 0
        # countA_T, countB_T = 0, 0
        for idx in range(batch_size):
            pntA, pntB = kpA[idx], kpB[idx]     # M X 2 (x,y)
            # kmask_TA, kmask_TB = kmask_T_allA[idx], kmask_T_allB[idx]
            pntA = pntA.float()
            pntB = pntB.float()

            # 剔除部分按压区域的点,且保留在重叠区域的点
            numA, numB = pntA.shape[0], pntB.shape[0]
            # numA_T, numB_T = pntA[kmask_TA].shape[0], pntB[kmask_TB].shape[0]
            pmA, pmB = pmaskA[max_num * idx:max_num * idx + numA].bool(), pmaskB[max_num * idx:max_num * idx + numB].bool()
            pntA, pntB = pntA[pmA, :], pntB[pmB, :]
            new_numA, new_numB = pntA.shape[0], pntB.shape[0]       
            
            pntA = (pntA + 1) / 2 * pntA.new_tensor([[W + 3, H - 1]]).to(pntA.device)
            pntB = (pntB + 1) / 2 * pntB.new_tensor([[W + 3, H - 1]]).to(pntB.device)

            # [120, 40] -> [120, 36],实际只取中心118x32区域的点对
            pntA[:, 0] -= 2
            pntB[:, 0] -= 2
            
            pntA_normalized = pntA / pntA.new_tensor([W - 1, H - 1]).to(pntA.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)
            pntB_normalized = pntB / pntB.new_tensor([W - 1, H - 1]).to(pntB.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)

            pntA_H = warp_points(pntA[:, :2], Homo[idx].squeeze(), device=self.device)  # 利用变换矩阵变换坐标点
            pntA_H, mask_pointA = filter_points(pntA_H, torch.tensor([W, H], device=self.device), return_mask=True)
            pntB_invH = warp_points(pntB[:, :2], inv_Homo[idx].squeeze(), device=self.device)
            pntB_invH, mask_pointB = filter_points(pntB_invH, torch.tensor([W, H], device=self.device), return_mask=True)
            
            current_descA, current_descB = descA[countA:countA+new_numA], descB[countB:countB+new_numB]
            cross_sim_AB_sp = current_descA @ current_descB.transpose(0, 1)     # NTA X NTB
            
            # 黑白相似度
            current_binA, current_binB = (bin_kpA[countA:countA+new_numA] >= 0.5).float(), (bin_kpB[countB:countB+new_numB] >= 0.5).float()   # [NA, 256] [NB_256]
            bin_distAB = current_binA.shape[-1] - (current_binA @ current_binB.transpose(0, 1)) - ((1 - current_binA) @ (1 - current_binB.transpose(0, 1))) # [NA, NB]
            
            # 真匹配的trans
            try:
                assert pntA_H.shape[0] > 0 and pntB_invH.shape[0] > 0 
                
                # 点对欧氏距离
                key_disAB = self.get_dis(pntA_H[:, :2], pntB[:, :2])            # repeatNA x NB
                key_disBA = self.get_dis(pntB_invH[:, :2], pntA[:, :2])
                pairAB_A, pairAB_B, dis_pairAB, _ = self.get_point_pair(key_disAB, dis_thre=self.correspond)  # p -> k # NTA(<1.5), NTA(<1.5), NTA(<1.5), NTA        
                pairBA_B, pairBA_A, dis_pairBA, _  = self.get_point_pair(key_disBA, dis_thre=self.correspond)  # p -> k # NTB(<1.5), NTB(<1.5), NTB(<1.5), NTB 
                
                # 点距离mask
                nn_maskAB = torch.zeros((pntA_H.shape[0], pntB.shape[0]), device=self.device) 
                nn_maskAB[pairAB_A, pairAB_B] = 1

                nn_maskBA = torch.zeros((pntB_invH.shape[0], pntA.shape[0]), device=self.device) 
                nn_maskBA[pairBA_B, pairBA_A] = 1

                # 点对曼哈顿距离
                key_manhattandisAB = self.get_manhattan_dis(pntA_H[:, :2], pntB[:, :2])
                key_manhattandisBA = self.get_manhattan_dis(pntB_invH[:, :2], pntA[:, :2])
                # print('pdis:', dis_pairAB.shape[0], dis_pairBA.shape[0])
                assert dis_pairAB.shape[0] > 0 and dis_pairBA.shape[0] > 0     

                pntA_H_normalized = pntA_H / pntA_H.new_tensor([W - 1, H - 1]).to(pntA_H.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)
                pntB_invH_normalized = pntB_invH / pntB_invH.new_tensor([W - 1, H - 1]).to(pntB_invH.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)

                # 用于score_map
                pntA_H_new = copy.deepcopy(pntA_H.detach())
                pntB_invH_new = copy.deepcopy(pntB_invH.detach())
                pntA_H_new[:, 0] += 10                   # 120 x 36 -> 128 x 56
                pntA_H_new[:, 1] += 4 
                pntB_invH_new[:, 0] += 10
                pntB_invH_new[:, 1] += 4
                
                pntA_H_normalized_new = pntA_H_new / pntA_H_new.new_tensor([W + 19, H + 7]).to(pntA_H.device) * 2 - 1

                # pntB_invH_new = warp_points(pntB_invH_new[:, :2], inv_Homo_en[idx].squeeze(), device=self.device)       # 转到A上，而不是AT上
                
                pntB_invH_normalized_new = pntB_invH_new / pntB_invH_new.new_tensor([W + 19, H + 7]).to(pntB_invH.device) * 2 - 1 

                ori_kpAT_patch_ext = F.grid_sample(ori_kp_patchA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntA_H_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0).transpose(0, 1)          # repeatNA x 1
                ori_kpB_patch_ext = F.grid_sample(ori_all_patchB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntB_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0).transpose(0, 1)          # NTB x 1
                ori_kpA_patch_ext = F.grid_sample(ori_all_patchA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntA_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0).transpose(0, 1)          # NTA x 1
                ori_kpBT_patch_ext = F.grid_sample(ori_kp_patchB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntB_invH_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0).transpose(0, 1)          # repeatNB x 1
                # print('1_2_1:', pntB_invH_normalized_new.shape[0])
                ori_maskATB, dis_oriATB = self.get_main_ori_consistence_AT(ori_kpAT_patch_ext, ori_kpB_patch_ext)  # repeatNA x NTB
                # print('1_2_2:', ori_maskATB.shape)
                ori_maskBTA, dis_oriBTA = self.get_main_ori_consistence_AT(ori_kpBT_patch_ext, ori_kpA_patch_ext)  # repeatNB x NTA
                # print('1_2_2:', ori_maskATB.shape[0])
                # match_maskAB = (nn_maskAB == 1) * main_ori_maskATB
                # match_maskBA = (nn_maskBA == 1) * main_ori_maskBTA
                # print(nn_maskAB.shape, main_ori_maskATB.shape, ori_maskATB.shape)
                match_maskAB_nb = (nn_maskAB == 1) * ori_maskATB           # repeatNA X NTB
                match_maskBA_nb = (nn_maskBA == 1) * ori_maskBTA          # repeatNB X NTA
                pairAB_A_nb_new, pairAB_B_nb_new = torch.where(match_maskAB_nb == 1)
                pairBA_B_nb_new, pairBA_A_nb_new = torch.where(match_maskBA_nb == 1)
                # assert pairAB_A_new.shape[0] > 0 and pairBA_B_new.shape[0] > 0 

                # # PA VS PAB 没有中心点距离偏移
                # 4x4邻域方向一致性
                ori_kpAB_patch_ext = F.grid_sample(ori_all_patchB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntA_H_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0).transpose(0, 1)  
                ori_kpBA_patch_ext = F.grid_sample(ori_all_patchA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntB_invH_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0).transpose(0, 1)  
                # print('1_2_4:', ori_kpAB_patch_ext.shape)
                ori_maskATAB, dis_oriATAB = self.get_main_ori_consistence_AT(ori_kpAT_patch_ext, ori_kpAB_patch_ext)  # repeatNA x repeatNA
                ori_maskBTBA, dis_oriBTBA = self.get_main_ori_consistence_AT(ori_kpBT_patch_ext, ori_kpBA_patch_ext)  # repeatNB x repeatNB
                
                # 黑白相似度
                bin_maskATB = bin_distAB <= (1 - self.FR_bin_thr) * current_binA.shape[-1]  
                bin_maskBTA = bin_maskATB.transpose(0, 1)  

                match_maskAB = match_maskAB_nb * bin_maskATB[mask_pointA, :]               # repeatNA X NB
                match_maskBA = match_maskBA_nb * bin_maskBTA[mask_pointB, :]               # repeatNB X NA

                pairAB_A_new, pairAB_B_new = torch.where(match_maskAB == 1)
                pairBA_B_new, pairBA_A_new = torch.where(match_maskBA == 1)
                # print('bin_mask:', pairAB_A_new.shape[0], pairBA_B_new.shape[0])
                assert pairAB_A_new.shape[0] > 0 and pairBA_B_new.shape[0] > 0 

                bin_kpAB_T = (F.grid_sample(bin_allB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntA_H_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0) >= 0.5).float()  # [256, repeatNA]
                bin_kpBA_T = (F.grid_sample(bin_allA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntB_invH_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0) >= 0.5).float()  # [256, repeatNB]
                bin_distATAB = bin_kpAB_T.shape[0] - (current_binA @ bin_kpAB_T) - ((1 - current_binA) @ (1 - bin_kpAB_T)) # [NTA, repeatNA]
                bin_distBTBA = bin_kpBA_T.shape[0] - (current_binB @ bin_kpBA_T) - ((1 - current_binB) @ (1 - bin_kpBA_T)) # [NTB, repeatNB]

                bin_maskATAB = bin_distATAB <= (1 - self.FR_bin_thr) * bin_kpAB_T.shape[0] 
                bin_maskBTBA = bin_distBTBA <= (1 - self.FR_bin_thr) * bin_kpBA_T.shape[0] 
                bin_maskATAB = bin_maskATAB[mask_pointA, :]
                bin_maskBTBA = bin_maskBTBA[mask_pointB, :]

                vmaskAH_nb = torch.diag(ori_maskATAB)
                vmaskBH_nb = torch.diag(ori_maskBTBA)
                vmaskAH = torch.diag(ori_maskATAB * bin_maskATAB) == 1      # [repeatNA, 1]
                vmaskBH = torch.diag(ori_maskBTBA * bin_maskBTBA) == 1      # [repeatNB, 1]

                # print('main_ori:', torch.sum(vmaskAH), torch.sum(vmaskBH))
                assert torch.sum(vmaskAH) > 0 and torch.sum(vmaskBH) > 0

                # SOSR: 简化的self-attention
                k_neighbor = 3
                cross_sim_AA_sp = current_descA @ current_descA.transpose(0, 1)
                cross_sim_BB_sp = current_descB @ current_descB.transpose(0, 1)
                # print('SOSR:', pairAB_A_new.shape[0], pairBA_B_new.shape[0])
                assert pairAB_A_new.shape[0] >= k_neighbor and pairBA_B_new.shape[0] >= k_neighbor 

                match_sim_AB_AA = cross_sim_AA_sp[mask_pointA, :][:, mask_pointA][pairAB_A_new, :][:, pairAB_A_new]
                match_sim_BA_BB = cross_sim_BB_sp[mask_pointB, :][:, mask_pointB][pairBA_B_new, :][:, pairBA_B_new]
                match_sim_AB_BB = cross_sim_BB_sp[pairAB_B_new, :][:, pairAB_B_new]
                match_sim_BA_AA = cross_sim_AA_sp[pairBA_A_new, :][:, pairBA_A_new]
                match_values_AB_AA, match_indices_AB_AA = torch.topk(match_sim_AB_AA, dim=1, k=k_neighbor, largest=False)
                match_values_BA_BB, match_indices_BA_BB = torch.topk(match_sim_BA_BB, dim=1, k=k_neighbor, largest=False)
                match_values_AB_BB_all = match_sim_AB_BB[:, match_indices_AB_AA]
                match_values_BA_AA_all = match_sim_BA_AA[:, match_indices_BA_BB]
                match_values_AB_BB = torch.diagonal(match_values_AB_BB_all, 0, dim1=0, dim2=1).transpose(0, 1)
                match_values_BA_AA = torch.diagonal(match_values_BA_AA_all, 0, dim1=0, dim2=1).transpose(0, 1)
                neighbor_dis_AB = (match_values_AB_AA - match_values_AB_BB) * (match_values_AB_AA - match_values_AB_BB)
                neighbor_dis_BA = (match_values_BA_BB - match_values_BA_AA) * (match_values_BA_BB - match_values_BA_AA)
                # print('1_1')
                # PA VS PB
                valid_cross_sim_AB_sp_mean = torch.mean(cross_sim_AB_sp[mask_pointA, :][match_maskAB == 1], dim=-1)
                valid_cross_sim_AB_sp_nb_mean = torch.mean(cross_sim_AB_sp[mask_pointA, :][match_maskAB_nb == 1], dim=-1)
                novalid_cross_sim_AB_sp_mean = (torch.sum(torch.sum(cross_sim_AB_sp.detach(), 1), 0) - valid_cross_sim_AB_sp_nb_mean * pairAB_A_nb_new.shape[0]) / (new_numA * new_numB - pairAB_A_nb_new.shape[0] + eps)
                valid_cross_sim_BA_sp_mean = torch.mean(cross_sim_AB_sp[:, mask_pointB][match_maskBA.transpose(0, 1) == 1], dim=-1)
                valid_cross_sim_BA_sp_nb_mean = torch.mean(cross_sim_AB_sp[:, mask_pointB][match_maskBA_nb.transpose(0, 1) == 1], dim=-1)
                novalid_cross_sim_BA_sp_mean = (torch.sum(torch.sum(cross_sim_AB_sp.detach(), 1), 0) - valid_cross_sim_BA_sp_nb_mean * pairBA_B_nb_new.shape[0]) / (new_numA * new_numB - pairBA_B_nb_new.shape[0] + eps)

                valid_indexesA = torch.tensor(list(range(cross_sim_AB_sp.shape[0])), device=self.device)[mask_pointA][pairAB_A_new]
                valid_indexesA_nb = torch.tensor(list(range(cross_sim_AB_sp.shape[0])), device=self.device)[mask_pointA][pairAB_A_nb_new]
                # cross_sim_BA_sp = current_descB @ current_descA.transpose(0, 1)
                cross_sim_AB_out_sp = torch.cat((cross_sim_AB_sp, torch.ones((cross_sim_AB_sp.shape[0], 1), device=cross_sim_AB_sp.device) * 2), dim=-1)      # NA X (NB + 1)
                cross_sim_AB_out_nb_sp = torch.cat((cross_sim_AB_sp, torch.ones((cross_sim_AB_sp.shape[0], 1), device=cross_sim_AB_sp.device) * 2), dim=-1)      # NA X (NB + 1)
                # cross_sim_BA_out_sp = torch.cat((cross_sim_BA_sp, torch.ones((numB, 1), device=cross_sim_BA_sp.device)), dim=-1)      # NB X (NA + 1)
                # valid_indexesB = torch.tensor(list(range(numB)), device=self.device)[mask_pointB][pairBA_B]
                # print('1_2')
                cross_sim_AB_out_sp[valid_indexesA, -1] = novalid_cross_sim_AB_sp_mean
                cross_sim_AB_out_nb_sp[valid_indexesA_nb, -1] = novalid_cross_sim_AB_sp_mean
                novalid_indexesA = torch.tensor(list(range(cross_sim_AB_sp.shape[0])), device=self.device)[cross_sim_AB_out_nb_sp[:, -1]==2]
                cross_sim_AB_out_sp[novalid_indexesA, -1] = valid_cross_sim_AB_sp_mean

                soft_cross_sim_AtoB_sp = F.softmax((cross_sim_AB_out_sp - 1) / t_des, dim=-1)
                # soft_cross_sim_BtoA = F.softmax((cross_sim_BA_out - 1) / t_des, dim=-1)
                # print('1_3')
                soft_valid_cross_sim_AB_sp = soft_cross_sim_AtoB_sp[mask_pointA, :-1][match_maskAB==1]
                # soft_valid_cross_sim_BA = soft_cross_sim_BtoA[mask_pointB, :-1][pairBA_B, pairBA_A]
                soft_novalid_cross_sim_AB_sp = soft_cross_sim_AtoB_sp[novalid_indexesA, -1]
                # soft_novalid_cross_sim_BA = soft_cross_sim_BtoA[cross_sim_BA_out[:, -1]==1, -1]
                log_soft_valid_cross_sim_AB_sp = -torch.log(soft_valid_cross_sim_AB_sp + eps) * (1 - dis_oriATB[match_maskAB==1] / self.ori_diff) * (1 - bin_distAB[mask_pointA, :][match_maskAB==1] / current_binA.shape[-1]) * (1 - key_disAB[match_maskAB==1].detach() / self.correspond)
                # log_soft_valid_cross_sim_BA = -torch.log(soft_valid_cross_sim_BA + eps)
                log_soft_novalid_cross_sim_AB_sp = -torch.log(soft_novalid_cross_sim_AB_sp + eps)
                # log_soft_novalid_cross_sim_BA = -torch.log(soft_novalid_cross_sim_BA + eps)
                dis_cross_sim_mean_sp = torch.sum(torch.cat((4*log_soft_valid_cross_sim_AB_sp, log_soft_novalid_cross_sim_AB_sp), dim=-1), dim=-1) / new_numA
                # print(2)
                # PA VS PAB
                # match_mask_A = copy.deepcopy(mask_pointA)
                # match_mask_B = copy.deepcopy(mask_pointB)
                match_mask_A = torch.zeros(cross_sim_AB_sp.shape[0], device=self.device)
                match_mask_nb_A = torch.zeros(cross_sim_AB_sp.shape[0], device=self.device)
                valid_match_indexesA = torch.tensor(list(range(cross_sim_AB_sp.shape[0])), device=self.device)[mask_pointA][vmaskAH]
                valid_match_indexesA_nb = torch.tensor(list(range(cross_sim_AB_sp.shape[0])), device=self.device)[mask_pointA][vmaskAH_nb]
                match_mask_A[valid_match_indexesA] = 1
                match_mask_nb_A[valid_match_indexesA_nb] = 1

                match_mask_B = torch.zeros(cross_sim_AB_sp.shape[1], device=self.device)
                match_mask_nb_B = torch.zeros(cross_sim_AB_sp.shape[1], device=self.device)
                valid_match_indexesB = torch.tensor(list(range(cross_sim_AB_sp.shape[1])), device=self.device)[mask_pointB][vmaskBH]
                valid_match_indexesB_nb = torch.tensor(list(range(cross_sim_AB_sp.shape[1])), device=self.device)[mask_pointB][vmaskBH_nb]
                match_mask_B[valid_match_indexesB] = 1
                match_mask_nb_B[valid_match_indexesB_nb] = 1
                # match_mask_A = copy.deepcopy(vmaskAH)
                # match_mask_B = copy.deepcopy(vmaskBH)

                cross_sim_AB = current_descA @ desc_mapB[idx, :, :, :].view(-1, H * W)
                # cross_sim_AB = cross_sim_AB[mask_pointA, :]
                cross_sim_AB_all = F.grid_sample(cross_sim_AB.view(-1, H, W).unsqueeze(0),
                                                pntA_H_normalized[vmaskAH, :].detach().view(1, 1, -1, 2),
                                                mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NA x repeatNA
                valid_cross_sim_AB_mean = torch.trace(cross_sim_AB_all[match_mask_A==1, :]) / cross_sim_AB_all[match_mask_A==1, :].shape[0]
                # novalid_cross_sim_AB_mean = (torch.sum(torch.sum(cross_sim_AB.detach(), 1), 1) - valid_cross_sim_AB_mean * pairAB_A.shape[0]) / (new_numA * H * W - pairAB_A.shape[0])

                cross_sim_BA = current_descB @ desc_mapA[idx, :, :, :].view(-1, H * W)   # M x H x W
                # cross_sim_BA = cross_sim_BA[mask_pointB, :]
                cross_sim_BA_all = F.grid_sample(cross_sim_BA.view(-1, H, W).unsqueeze(0),
                                                pntB_invH_normalized[vmaskBH, :].detach().view(1, 1, -1, 2),
                                                mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NB x match_nB
                valid_cross_sim_BA_mean = torch.trace(cross_sim_BA_all[match_mask_B==1, :]) / cross_sim_BA_all[match_mask_B==1, :].shape[0]
                # novalid_cross_sim_BA_mean = (torch.sum(torch.sum(cross_sim_BA.detach(), 1), 1) - valid_cross_sim_BA_mean * pairBA_B.shape[0]) / (new_numB * H * W - pairBA_B.shape[0])

                cross_sim_AB_out = torch.cat((cross_sim_AB, torch.ones((cross_sim_AB.shape[0], 1), device=cross_sim_AB.device)), dim=-1)      # NA X (H X W + 1)
                cross_sim_BA_out = torch.cat((cross_sim_BA, torch.ones((cross_sim_BA.shape[0], 1), device=cross_sim_BA.device)), dim=-1)      # NB X (H X W + 1)
                # print(3)
                # cross_sim_AB_out[mask_pointA, -1] -= 1
                # cross_sim_BA_out[mask_pointB, -1] -= 1
                # cross_sim_AB_out[match_mask_A, -1] -= 1
                cross_sim_AB_out[match_mask_A==1, -1] = novalid_cross_sim_AB_sp_mean
                cross_sim_AB_out[match_mask_nb_A==0, -1] = valid_cross_sim_AB_mean

                cross_sim_BA_out[match_mask_B==1, -1] = novalid_cross_sim_BA_sp_mean
                cross_sim_BA_out[match_mask_nb_B==0, -1] = valid_cross_sim_BA_mean

                soft_cross_sim_AtoB = F.softmax((cross_sim_AB_out - 1) / t_des, dim=-1)         # NA X (H X W + 1)
                soft_cross_sim_BtoA = F.softmax((cross_sim_BA_out - 1) / t_des, dim=-1)         # NB X (H X W + 1)
                soft_cross_sim_AB_all = F.grid_sample(soft_cross_sim_AtoB[:, :-1].view(-1, H, W).unsqueeze(0),
                                                    pntA_H_normalized[vmaskAH, :].detach().view(1, 1, -1, 2),
                                                    mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NA x match_nA
                
                soft_cross_sim_BA_all = F.grid_sample(soft_cross_sim_BtoA[:, :-1].view(-1, H, W).unsqueeze(0),
                                                    pntB_invH_normalized[vmaskBH, :].detach().view(1, 1, -1, 2),
                                                    mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NB x match_nB
                # soft_valid_cross_sim_AB_all = soft_cross_sim_AB_all[mask_pointA, :]             # repeat_nA x repeat_nA
                # soft_valid_cross_sim_BA_all = soft_cross_sim_BA_all[mask_pointB, :]             # repeat_nB x repeat_nB

                soft_valid_cross_sim_AB_all = soft_cross_sim_AB_all[match_mask_A==1, :]             # match_nA x match_nA
                soft_valid_cross_sim_BA_all = soft_cross_sim_BA_all[match_mask_B==1, :]             # match_nB x match_nB

                valid_mask_AB = torch.eye(soft_valid_cross_sim_AB_all.shape[0]) == 1
                valid_mask_BA = torch.eye(soft_valid_cross_sim_BA_all.shape[0]) == 1
                # print(4)
                # 取对角线
                soft_valid_cross_sim_AB = soft_valid_cross_sim_AB_all[valid_mask_AB]
                soft_valid_cross_sim_BA = soft_valid_cross_sim_BA_all[valid_mask_BA]

                # soft_novalid_cross_sim_AB = soft_cross_sim_AtoB[mask_pointA==False, -1]              # (NA-repeat_nA) x 1
                # soft_novalid_cross_sim_BA = soft_cross_sim_BtoA[mask_pointB==False, -1]
                soft_novalid_cross_sim_AB = soft_cross_sim_AtoB[match_mask_nb_A==0, -1]               # (NA-match_nA) x 1
                soft_novalid_cross_sim_BA = soft_cross_sim_BtoA[match_mask_nb_B==0, -1]
                # print(soft_novalid_cross_sim_AB, soft_novalid_cross_sim_BA)

                log_soft_valid_cross_sim_AB = -torch.log(soft_valid_cross_sim_AB + eps) * (1 - torch.diag(dis_oriATAB)[vmaskAH] / self.ori_diff) * (1 - torch.diag(bin_distATAB[mask_pointA, :])[vmaskAH] / bin_kpAB_T.shape[0])
                log_soft_valid_cross_sim_BA = -torch.log(soft_valid_cross_sim_BA + eps) * (1 - torch.diag(dis_oriBTBA)[vmaskBH] / self.ori_diff) * (1 - torch.diag(bin_distBTBA[mask_pointB, :])[vmaskBH] / bin_kpBA_T.shape[0])
                log_soft_novalid_cross_sim_AB = -torch.log(soft_novalid_cross_sim_AB + eps)
                log_soft_novalid_cross_sim_BA = -torch.log(soft_novalid_cross_sim_BA + eps)

                dis_cross_sim_mean = torch.sum(torch.cat((4*log_soft_valid_cross_sim_AB, 4*log_soft_valid_cross_sim_BA, log_soft_novalid_cross_sim_AB, log_soft_novalid_cross_sim_BA), dim=-1), dim=-1) / (new_numA + new_numB)
                # print(5)
                valid_cross_sim_AB = cross_sim_AB[mask_pointA, :]   # repeat_nA x (H X W)
                valid_cross_sim_BA = cross_sim_BA[mask_pointB, :]   # repeat_nB x (H X W)
                exp_valid_cross_sim_AtoB = torch.exp((valid_cross_sim_AB - 1) / t_rel).view(-1, H, W)
                exp_valid_cross_sim_BtoA = torch.exp((valid_cross_sim_BA - 1) / t_rel).view(-1, H, W)
                exp_valid_cross_sim_AB_all = F.grid_sample(exp_valid_cross_sim_AtoB.unsqueeze(0),
                                                        pntA_H_normalized.detach().view(1, 1, -1, 2),
                                                        mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # repeat_nA x repeat_nA
                
                exp_valid_cross_sim_BA_all = F.grid_sample(exp_valid_cross_sim_BtoA.unsqueeze(0),
                                                        pntB_invH_normalized.detach().view(1, 1, -1, 2),
                                                        mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # repeat_nB x repeat_nB

                repeat_mask_AB = torch.eye(exp_valid_cross_sim_AB_all.shape[0]) == 1
                repeat_mask_BA = torch.eye(exp_valid_cross_sim_BA_all.shape[0]) == 1
                rel_valid_cross_sim_AB = exp_valid_cross_sim_AB_all[repeat_mask_AB]
                rel_valid_cross_sim_BA = exp_valid_cross_sim_BA_all[repeat_mask_BA]

                # pntA_H_normalized_new = copy.deepcopy(pntA_H_normalized.detach())
                # pntB_invH_normalized_new = copy.deepcopy(pntB_invH_normalized.detach())

                # pntA_H_normalized_new[:, 0] += 2
                # pntB_invH_normalized_new[:, 0] += 2

                scoresAB_all = F.grid_sample(scores_mapB[idx, :, :, :].unsqueeze(0),
                                            pntA_H_normalized_new.view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)      # 1 x repeat_nA

                scoresBA_all = F.grid_sample(scores_mapA[idx, :, :, :].unsqueeze(0),
                                            pntB_invH_normalized_new.view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)      # 1 x repeat_nB
                # print(6)
                scores_AAB = scoresA[idx][pmA][mask_pointA] * scoresAB_all
                scores_BBA = scoresB[idx][pmB][mask_pointB] * scoresBA_all
                scores_sum_AAB = torch.sum(scores_AAB, dim=-1)
                scores_sum_BBA = torch.sum(scores_BBA, dim=-1)
                scores_normalize_AAB = scores_AAB / (scores_sum_AAB + eps)
                scores_normalize_BBA = scores_BBA / (scores_sum_BBA + eps)
                rel_meanA = torch.sum(scores_normalize_AAB * (1 - rel_valid_cross_sim_AB), dim=-1) / pntA_H_normalized_new.shape[0]
                rel_meanB = torch.sum(scores_normalize_BBA * (1 - rel_valid_cross_sim_BA), dim=-1) / pntB_invH_normalized_new.shape[0]

                # # 熵loss
                # current_descA_std, current_descB_std = descA_std[countA:countA+new_numA], descB_std[countB:countB+new_numB]
                # desc_std += torch.mean(current_descA_std) + torch.mean(current_descB_std)
                # countA_T += numA_T
                # countB_T += numB_T

                dis_neighbor_mean_total += torch.mean(torch.sum(neighbor_dis_AB, dim=1)) + torch.mean(torch.sum(neighbor_dis_BA, dim=1))
                dis_desc += dis_cross_sim_mean_sp
                dis_desc += dis_cross_sim_mean

                dis_pair_meanAB = torch.mean(key_manhattandisAB[pairAB_A, pairAB_B])
                dis_pair_meanBA = torch.mean(key_manhattandisBA[pairBA_B, pairBA_A])

                dis_peak_mean = torch.mean(torch.cat((scoreddisA[idx][pmA], scoreddisB[idx][pmB]), dim=0))
                # dis_peak_meanB = torch.mean(scoreddisB[idx])
                
                dis_mean_total += dis_pair_meanAB + dis_pair_meanBA
                dis_peak_scored += dis_peak_mean

                dis_rel += rel_meanA + rel_meanB
                
                countA += new_numA
                countB += new_numB
                # # Penalty
                # scores_mean += (-torch.log(torch.mean(scoresA[idx], dim=-1) + eps) - torch.log(torch.mean(scoresB[idx], dim=-1) + eps)) 
                # print(scores_mean)
            except:
                # dis_mean_total += 0
                # dis_peak_scored += 0
                # dis_desc += 0
                # dis_rel += 0
                # print('Overlapping too small or Repeatable point pairs distance is greater than correspond(1.5):', pntA.shape[0], pntA_H.shape[0], pntB.shape[0], pntB_invH.shape[0], dis_pairAB.shape[0], dis_pairBA.shape[0])
                valid_batch_size -= 1
                countA += new_numA
                countB += new_numB
                # countA_T += numA_T
                # countB_T += numB_T

        valid_batch_size = valid_batch_size if valid_batch_size > 0 else eps
        # Reprojection Loss 
        reprojection_loss = dis_mean_total / (valid_batch_size * 2)
        # Dispersity Peak Loss
        dispersity_peak_loss = dis_peak_scored / valid_batch_size
        # NRE Loss
        descriptor_loss = dis_desc / (2 * valid_batch_size)
        # Reliability Loss
        reliability_loss = dis_rel / (valid_batch_size * 2)
        # SOSR Loss
        sosr_loss = dis_neighbor_mean_total / ((valid_batch_size * 2))
        # # Entropy loss
        # std_loss = (valid_batch_size * 2) / desc_std  
        # # Score Penalty
        # score_penalty = scores_mean / (valid_batch_size * 2)
        # # FA Desc loss
        # FA_des_loss = dis_desc_fa / valid_batch_size_FA if valid_batch_size_FA > 0 else 0

        loss_total = wrp * reprojection_loss + wpl * dispersity_peak_loss + wdl * descriptor_loss + wrl * reliability_loss + sosr_loss
        loss_group = {
            'reprojection_loss': reprojection_loss, 
            'dispersity_peak_loss': dispersity_peak_loss,
            'descriptor_loss': descriptor_loss,
            'reliability_loss': reliability_loss,
            'sosr_loss': sosr_loss,
            # 'std_loss': std_loss,
            # 'FA_des_loss': FA_des_loss,
            }
        return loss_total, loss_group


    # patch/dense AT角度 黑白相似度加量化 NFA negtives
    def detector_selfsupervised_loss_dkd_patch_ext_restrict_modify_oriR_ratio_NFA_qtbw_ns_wg_nori_AT_NE(self, kpA, kpB, pmaskA, pmaskB, descA, descB, desc_mapA, desc_mapB, scoreddisA, scoreddisB, scoresA, scoresB, scores_mapA, scores_mapB, Homo, inv_Homo, inv_Homo_en, ori_all_patchA, ori_all_patchB, ori_kp_patchA, ori_kp_patchB, bin_allA, bin_allB, bin_kpA, bin_kpB, kp_ne, pmask_ne, desc_ne, bin_kp_ne, trans_angle, FA_flag, H, W, wrp=1, wpl=1, wdl=1, wrl=1, t_des=0.02, t_rel=1):
        # pmaskA: (BxMax_num) 32x350=11200
        batch_size = len(kpA)
        max_num = pmaskA.shape[-1] // batch_size    # 350
        dis_mean_total = 0
        dis_neighbor_mean_total = 0
        dis_peak_scored = 0
        dis_desc = 0
        dis_rel = 0
        desc_std = 0
        eps = 1e-12
        valid_batch_size = batch_size
        # valid_batch_size_FA = 0
        countA, countB, count_ne = 0, 0, 0
        # dis_desc_fa = 0
        # countA_T, countB_T = 0, 0
        for idx in range(batch_size):
            pntA, pntB, pnt_ne = kpA[idx], kpB[idx], kp_ne[idx]     # M X 2 (x,y)
            # kmask_TA, kmask_TB = kmask_T_allA[idx], kmask_T_allB[idx]
            pntA = pntA.float()
            pntB = pntB.float()
            pnt_ne = pnt_ne.float()

            # 剔除部分按压区域的点,且保留在重叠区域的点
            numA, numB, num_ne = pntA.shape[0], pntB.shape[0], pnt_ne.shape[0]
            # numA_T, numB_T = pntA[kmask_TA].shape[0], pntB[kmask_TB].shape[0]
            pmA, pmB, pm_ne = pmaskA[max_num * idx:max_num * idx + numA].bool(), pmaskB[max_num * idx:max_num * idx + numB].bool(), pmask_ne[max_num * idx:max_num * idx + num_ne].bool()
            pntA, pntB, pnt_ne = pntA[pmA, :], pntB[pmB, :], pnt_ne[pm_ne, :]
            new_numA, new_numB, new_num_ne = pntA.shape[0], pntB.shape[0], pnt_ne.shape[0]       
            
            pntA = (pntA + 1) / 2 * pntA.new_tensor([[W + 3, H - 1]]).to(pntA.device)
            pntB = (pntB + 1) / 2 * pntB.new_tensor([[W + 3, H - 1]]).to(pntB.device)

            # [120, 40] -> [120, 36],实际只取中心118x32区域的点对
            pntA[:, 0] -= 2
            pntB[:, 0] -= 2
            
            pntA_normalized = pntA / pntA.new_tensor([W - 1, H - 1]).to(pntA.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)
            pntB_normalized = pntB / pntB.new_tensor([W - 1, H - 1]).to(pntB.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)

            pntA_H = warp_points(pntA[:, :2], Homo[idx].squeeze(), device=self.device)  # 利用变换矩阵变换坐标点
            pntA_H, mask_pointA = filter_points(pntA_H, torch.tensor([W, H], device=self.device), return_mask=True)
            pntB_invH = warp_points(pntB[:, :2], inv_Homo[idx].squeeze(), device=self.device)
            pntB_invH, mask_pointB = filter_points(pntB_invH, torch.tensor([W, H], device=self.device), return_mask=True)
            
            current_descA, current_descB = descA[countA:countA+new_numA], descB[countB:countB+new_numB]
            current_desc_ne = desc_ne[count_ne:count_ne+new_num_ne]
            cross_sim_AB_sp = current_descA @ current_descB.transpose(0, 1)     # NTA X NTB
            
            cross_sim_AN_sp = current_descA @ current_desc_ne.transpose(0, 1)
            cross_sim_BN_sp = current_descB @ current_desc_ne.transpose(0, 1)
            
            # 黑白相似度
            current_binA, current_binB = (bin_kpA[countA:countA+new_numA] >= 0.5).float(), (bin_kpB[countB:countB+new_numB] >= 0.5).float()   # [NA, 256] [NB_256]
            current_bin_ne = (bin_kp_ne[count_ne:count_ne+new_num_ne] >= 0.5).float()
            bin_distAB = current_binA.shape[-1] - (current_binA @ current_binB.transpose(0, 1)) - ((1 - current_binA) @ (1 - current_binB.transpose(0, 1))) # [NA, NB]
            
            bin_distAN = current_binA.shape[-1] - (current_binA @ current_bin_ne.transpose(0, 1)) - ((1 - current_binA) @ (1 - current_bin_ne.transpose(0, 1))) # [NA, NE]
            bin_distBN = current_binB.shape[-1] - (current_binB @ current_bin_ne.transpose(0, 1)) - ((1 - current_binB) @ (1 - current_bin_ne.transpose(0, 1))) # [NA, NE]
            
            # 真匹配的trans
            try:
                FAN_bin_mask = bin_distAN >= (1 - self.FA_bin_thr) * current_binA.shape[-1] 
                FBN_bin_mask = bin_distBN >= (1 - self.FA_bin_thr) * current_binB.shape[-1] 
                # topk ?
                crossAN_mean = torch.mean(cross_sim_AN_sp[FAN_bin_mask])
                crossBN_mean = torch.mean(cross_sim_BN_sp[FBN_bin_mask])

                assert pntA_H.shape[0] > 0 and pntB_invH.shape[0] > 0 
                
                # 点对欧氏距离
                key_disAB = self.get_dis(pntA_H[:, :2], pntB[:, :2])            # repeatNA x NB
                key_disBA = self.get_dis(pntB_invH[:, :2], pntA[:, :2])
                pairAB_A, pairAB_B, dis_pairAB, _ = self.get_point_pair(key_disAB, dis_thre=self.correspond)  # p -> k # NTA(<1.5), NTA(<1.5), NTA(<1.5), NTA        
                pairBA_B, pairBA_A, dis_pairBA, _  = self.get_point_pair(key_disBA, dis_thre=self.correspond)  # p -> k # NTB(<1.5), NTB(<1.5), NTB(<1.5), NTB 
                
                # 点距离mask
                nn_maskAB = torch.zeros((pntA_H.shape[0], pntB.shape[0]), device=self.device) 
                nn_maskAB[pairAB_A, pairAB_B] = 1

                nn_maskBA = torch.zeros((pntB_invH.shape[0], pntA.shape[0]), device=self.device) 
                nn_maskBA[pairBA_B, pairBA_A] = 1

                # 点对曼哈顿距离
                key_manhattandisAB = self.get_manhattan_dis(pntA_H[:, :2], pntB[:, :2])
                key_manhattandisBA = self.get_manhattan_dis(pntB_invH[:, :2], pntA[:, :2])
                # print('pdis:', dis_pairAB.shape[0], dis_pairBA.shape[0])
                assert dis_pairAB.shape[0] > 0 and dis_pairBA.shape[0] > 0     

                pntA_H_normalized = pntA_H / pntA_H.new_tensor([W - 1, H - 1]).to(pntA_H.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)
                pntB_invH_normalized = pntB_invH / pntB_invH.new_tensor([W - 1, H - 1]).to(pntB_invH.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)

                # 用于score_map
                pntA_H_new = copy.deepcopy(pntA_H.detach())
                pntB_invH_new = copy.deepcopy(pntB_invH.detach())
                pntA_H_new[:, 0] += 10                   # 120 x 36 -> 128 x 56
                pntA_H_new[:, 1] += 4 
                pntB_invH_new[:, 0] += 10
                pntB_invH_new[:, 1] += 4
                
                pntA_H_normalized_new = pntA_H_new / pntA_H_new.new_tensor([W + 19, H + 7]).to(pntA_H.device) * 2 - 1

                # pntB_invH_new = warp_points(pntB_invH_new[:, :2], inv_Homo_en[idx].squeeze(), device=self.device)       # 转到A上，而不是AT上
                
                pntB_invH_normalized_new = pntB_invH_new / pntB_invH_new.new_tensor([W + 19, H + 7]).to(pntB_invH.device) * 2 - 1 
                
                # print('1_2:', main_ori_maskATB.shape[0])
                # exit()
                ori_kpAT_patch_ext = F.grid_sample(ori_kp_patchA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntA_H_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0).transpose(0, 1)          # repeatNA x 1
                ori_kpB_patch_ext = F.grid_sample(ori_all_patchB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntB_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0).transpose(0, 1)          # NTB x 1
                ori_kpA_patch_ext = F.grid_sample(ori_all_patchA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntA_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0).transpose(0, 1)          # NTA x 1
                ori_kpBT_patch_ext = F.grid_sample(ori_kp_patchB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntB_invH_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0).transpose(0, 1)          # repeatNB x 1
                # print('1_2_1:', pntB_invH_normalized_new.shape[0])
                ori_maskATB, dis_oriATB = self.get_main_ori_consistence_AT(ori_kpAT_patch_ext, ori_kpB_patch_ext)  # repeatNA x NTB
                # print('1_2_2:', ori_maskATB.shape)
                ori_maskBTA, dis_oriBTA = self.get_main_ori_consistence_AT(ori_kpBT_patch_ext, ori_kpA_patch_ext)  # repeatNB x NTA

                match_maskAB_nb = (nn_maskAB == 1) * ori_maskATB           # repeatNA X NTB
                match_maskBA_nb = (nn_maskBA == 1) * ori_maskBTA          # repeatNB X NTA
                pairAB_A_nb_new, pairAB_B_nb_new = torch.where(match_maskAB_nb == 1)
                pairBA_B_nb_new, pairBA_A_nb_new = torch.where(match_maskBA_nb == 1)
                # assert pairAB_A_new.shape[0] > 0 and pairBA_B_new.shape[0] > 0 

                # 4x4邻域方向一致性
                ori_kpAB_patch_ext = F.grid_sample(ori_all_patchB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntA_H_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0).transpose(0, 1)  
                ori_kpBA_patch_ext = F.grid_sample(ori_all_patchA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntB_invH_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0).transpose(0, 1)  
                # print('1_2_4:', ori_kpAB_patch_ext.shape)
                ori_maskATAB, dis_oriATAB = self.get_main_ori_consistence_AT(ori_kpAT_patch_ext, ori_kpAB_patch_ext)  # repeatNA x repeatNA
                ori_maskBTBA, dis_oriBTBA = self.get_main_ori_consistence_AT(ori_kpBT_patch_ext, ori_kpBA_patch_ext)  # repeatNB x repeatNB
                
                # 黑白相似度
                bin_maskATB = bin_distAB <= (1 - self.FR_bin_thr) * current_binA.shape[-1]  
                bin_maskBTA = bin_maskATB.transpose(0, 1)  

                match_maskAB = match_maskAB_nb * bin_maskATB[mask_pointA, :]               # repeatNA X NB
                match_maskBA = match_maskBA_nb * bin_maskBTA[mask_pointB, :]               # repeatNB X NA

                pairAB_A_new, pairAB_B_new = torch.where(match_maskAB == 1)
                pairBA_B_new, pairBA_A_new = torch.where(match_maskBA == 1)
                # print('bin_mask:', pairAB_A_new.shape[0], pairBA_B_new.shape[0])
                assert pairAB_A_new.shape[0] > 0 and pairBA_B_new.shape[0] > 0 

                bin_kpAB_T = (F.grid_sample(bin_allB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntA_H_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0) >= 0.5).float()  # [256, repeatNA]
                bin_kpBA_T = (F.grid_sample(bin_allA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntB_invH_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0) >= 0.5).float()  # [256, repeatNB]
                bin_distATAB = bin_kpAB_T.shape[0] - (current_binA @ bin_kpAB_T) - ((1 - current_binA) @ (1 - bin_kpAB_T)) # [NTA, repeatNA]
                bin_distBTBA = bin_kpBA_T.shape[0] - (current_binB @ bin_kpBA_T) - ((1 - current_binB) @ (1 - bin_kpBA_T)) # [NTB, repeatNB]

                bin_maskATAB = bin_distATAB <= (1 - self.FR_bin_thr) * bin_kpAB_T.shape[0] 
                bin_maskBTBA = bin_distBTBA <= (1 - self.FR_bin_thr) * bin_kpBA_T.shape[0] 
                bin_maskATAB = bin_maskATAB[mask_pointA, :]
                bin_maskBTBA = bin_maskBTBA[mask_pointB, :]

                vmaskAH_nb = torch.diag(ori_maskATAB)
                vmaskBH_nb = torch.diag(ori_maskBTBA)
                vmaskAH = torch.diag(ori_maskATAB * bin_maskATAB) == 1      # [repeatNA, 1]
                vmaskBH = torch.diag(ori_maskBTBA * bin_maskBTBA) == 1      # [repeatNB, 1]

                # print('main_ori:', torch.sum(vmaskAH), torch.sum(vmaskBH))
                assert torch.sum(vmaskAH) > 0 and torch.sum(vmaskBH) > 0

                # SOSR: 简化的self-attention
                k_neighbor = 3
                cross_sim_AA_sp = current_descA @ current_descA.transpose(0, 1)
                cross_sim_BB_sp = current_descB @ current_descB.transpose(0, 1)
                # print('SOSR:', pairAB_A_new.shape[0], pairBA_B_new.shape[0])
                assert pairAB_A_new.shape[0] >= k_neighbor and pairBA_B_new.shape[0] >= k_neighbor 

                match_sim_AB_AA = cross_sim_AA_sp[mask_pointA, :][:, mask_pointA][pairAB_A_new, :][:, pairAB_A_new]
                match_sim_BA_BB = cross_sim_BB_sp[mask_pointB, :][:, mask_pointB][pairBA_B_new, :][:, pairBA_B_new]
                match_sim_AB_BB = cross_sim_BB_sp[pairAB_B_new, :][:, pairAB_B_new]
                match_sim_BA_AA = cross_sim_AA_sp[pairBA_A_new, :][:, pairBA_A_new]
                match_values_AB_AA, match_indices_AB_AA = torch.topk(match_sim_AB_AA, dim=1, k=k_neighbor, largest=False)
                match_values_BA_BB, match_indices_BA_BB = torch.topk(match_sim_BA_BB, dim=1, k=k_neighbor, largest=False)
                match_values_AB_BB_all = match_sim_AB_BB[:, match_indices_AB_AA]
                match_values_BA_AA_all = match_sim_BA_AA[:, match_indices_BA_BB]
                match_values_AB_BB = torch.diagonal(match_values_AB_BB_all, 0, dim1=0, dim2=1).transpose(0, 1)
                match_values_BA_AA = torch.diagonal(match_values_BA_AA_all, 0, dim1=0, dim2=1).transpose(0, 1)
                neighbor_dis_AB = (match_values_AB_AA - match_values_AB_BB) * (match_values_AB_AA - match_values_AB_BB)
                neighbor_dis_BA = (match_values_BA_BB - match_values_BA_AA) * (match_values_BA_BB - match_values_BA_AA)

                # PA VS PB
                # 计算bin值
                valid_cross_sim_AB_sp_mean = torch.mean(cross_sim_AB_sp[mask_pointA, :][match_maskAB == 1], dim=-1)
                valid_cross_sim_AB_sp_nb_mean = torch.mean(cross_sim_AB_sp[mask_pointA, :][match_maskAB_nb == 1], dim=-1)
                novalid_cross_sim_AB_sp_mean = (torch.sum(torch.sum(cross_sim_AB_sp.detach(), 1), 0) - valid_cross_sim_AB_sp_nb_mean * pairAB_A_nb_new.shape[0]) / (new_numA * new_numB - pairAB_A_nb_new.shape[0] + eps)
                valid_cross_sim_BA_sp_mean = torch.mean(cross_sim_AB_sp[:, mask_pointB][match_maskBA.transpose(0, 1) == 1], dim=-1)
                valid_cross_sim_BA_sp_nb_mean = torch.mean(cross_sim_AB_sp[:, mask_pointB][match_maskBA_nb.transpose(0, 1) == 1], dim=-1)
                novalid_cross_sim_BA_sp_mean = (torch.sum(torch.sum(cross_sim_AB_sp.detach(), 1), 0) - valid_cross_sim_BA_sp_nb_mean * pairBA_B_nb_new.shape[0]) / (new_numA * new_numB - pairBA_B_nb_new.shape[0] + eps)

                valid_indexesA = torch.tensor(list(range(cross_sim_AB_sp.shape[0])), device=self.device)[mask_pointA][pairAB_A_new]
                valid_indexesA_nb = torch.tensor(list(range(cross_sim_AB_sp.shape[0])), device=self.device)[mask_pointA][pairAB_A_nb_new]
                # cross_sim_BA_sp = current_descB @ current_descA.transpose(0, 1)
                cross_sim_AB_out_sp = torch.cat((cross_sim_AB_sp, torch.ones((cross_sim_AB_sp.shape[0], 2), device=cross_sim_AB_sp.device) * 2), dim=-1)      # NA X (NB + 2)
                cross_sim_AB_out_nb_sp = torch.cat((cross_sim_AB_sp, torch.ones((cross_sim_AB_sp.shape[0], 2), device=cross_sim_AB_sp.device) * 2), dim=-1)      # NA X (NB + 2)
                # cross_sim_BA_out_sp = torch.cat((cross_sim_BA_sp, torch.ones((numB, 1), device=cross_sim_BA_sp.device)), dim=-1)      # NB X (NA + 1)
                # valid_indexesB = torch.tensor(list(range(numB)), device=self.device)[mask_pointB][pairBA_B]
                # print('1_2')
                cross_sim_AB_out_sp[valid_indexesA, -1] = novalid_cross_sim_AB_sp_mean
                cross_sim_AB_out_sp[valid_indexesA, -2] = crossAN_mean
                cross_sim_AB_out_nb_sp[valid_indexesA_nb, -1] = novalid_cross_sim_AB_sp_mean
                novalid_indexesA = torch.tensor(list(range(cross_sim_AB_sp.shape[0])), device=self.device)[cross_sim_AB_out_nb_sp[:, -1]==2]
                cross_sim_AB_out_sp[novalid_indexesA, -1] = valid_cross_sim_AB_sp_mean
                # nomatch对不增加negtives的均值bin
                cross_sim_AB_out_sp[novalid_indexesA, -2] = -1 # crossAN_mean # -1

                soft_cross_sim_AtoB_sp = F.softmax((cross_sim_AB_out_sp - 1) / t_des, dim=-1)
                # soft_cross_sim_BtoA = F.softmax((cross_sim_BA_out - 1) / t_des, dim=-1)
                # print('1_3')
                soft_valid_cross_sim_AB_sp = soft_cross_sim_AtoB_sp[mask_pointA, :-2][match_maskAB==1]
                # soft_valid_cross_sim_BA = soft_cross_sim_BtoA[mask_pointB, :-1][pairBA_B, pairBA_A]
                soft_novalid_cross_sim_AB_sp = soft_cross_sim_AtoB_sp[novalid_indexesA, -1]
                # soft_novalid_cross_sim_BA = soft_cross_sim_BtoA[cross_sim_BA_out[:, -1]==1, -1]
                log_soft_valid_cross_sim_AB_sp = -torch.log(soft_valid_cross_sim_AB_sp + eps) * (1 - dis_oriATB[match_maskAB==1] / self.ori_diff) * (1 - bin_distAB[mask_pointA, :][match_maskAB==1] / current_binA.shape[-1]) * (1 - key_disAB[match_maskAB==1].detach() / self.correspond)
                # log_soft_valid_cross_sim_BA = -torch.log(soft_valid_cross_sim_BA + eps)
                log_soft_novalid_cross_sim_AB_sp = -torch.log(soft_novalid_cross_sim_AB_sp + eps)
                # log_soft_novalid_cross_sim_BA = -torch.log(soft_novalid_cross_sim_BA + eps)
                dis_cross_sim_mean_sp = torch.sum(torch.cat((4*log_soft_valid_cross_sim_AB_sp, log_soft_novalid_cross_sim_AB_sp), dim=-1), dim=-1) / new_numA
                
                # PA VS PAB
                # match_mask_A = copy.deepcopy(mask_pointA)
                # match_mask_B = copy.deepcopy(mask_pointB)
                match_mask_A = torch.zeros(cross_sim_AB_sp.shape[0], device=self.device)
                match_mask_nb_A = torch.zeros(cross_sim_AB_sp.shape[0], device=self.device)
                valid_match_indexesA = torch.tensor(list(range(cross_sim_AB_sp.shape[0])), device=self.device)[mask_pointA][vmaskAH]
                valid_match_indexesA_nb = torch.tensor(list(range(cross_sim_AB_sp.shape[0])), device=self.device)[mask_pointA][vmaskAH_nb]
                match_mask_A[valid_match_indexesA] = 1
                match_mask_nb_A[valid_match_indexesA_nb] = 1

                match_mask_B = torch.zeros(cross_sim_AB_sp.shape[1], device=self.device)
                match_mask_nb_B = torch.zeros(cross_sim_AB_sp.shape[1], device=self.device)
                valid_match_indexesB = torch.tensor(list(range(cross_sim_AB_sp.shape[1])), device=self.device)[mask_pointB][vmaskBH]
                valid_match_indexesB_nb = torch.tensor(list(range(cross_sim_AB_sp.shape[1])), device=self.device)[mask_pointB][vmaskBH_nb]
                match_mask_B[valid_match_indexesB] = 1
                match_mask_nb_B[valid_match_indexesB_nb] = 1

                cross_sim_AB = current_descA @ desc_mapB[idx, :, :, :].view(-1, H * W)
                # cross_sim_AB = cross_sim_AB[mask_pointA, :]
                cross_sim_AB_all = F.grid_sample(cross_sim_AB.view(-1, H, W).unsqueeze(0),
                                                pntA_H_normalized[vmaskAH, :].detach().view(1, 1, -1, 2),
                                                mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NA x repeatNA
                valid_cross_sim_AB_mean = torch.trace(cross_sim_AB_all[match_mask_A==1, :]) / cross_sim_AB_all[match_mask_A==1, :].shape[0]
                # novalid_cross_sim_AB_mean = (torch.sum(torch.sum(cross_sim_AB.detach(), 1), 1) - valid_cross_sim_AB_mean * pairAB_A.shape[0]) / (new_numA * H * W - pairAB_A.shape[0])

                cross_sim_BA = current_descB @ desc_mapA[idx, :, :, :].view(-1, H * W)   # M x H x W
                # cross_sim_BA = cross_sim_BA[mask_pointB, :]
                cross_sim_BA_all = F.grid_sample(cross_sim_BA.view(-1, H, W).unsqueeze(0),
                                                pntB_invH_normalized[vmaskBH, :].detach().view(1, 1, -1, 2),
                                                mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NB x match_nB
                valid_cross_sim_BA_mean = torch.trace(cross_sim_BA_all[match_mask_B==1, :]) / cross_sim_BA_all[match_mask_B==1, :].shape[0]
                # novalid_cross_sim_BA_mean = (torch.sum(torch.sum(cross_sim_BA.detach(), 1), 1) - valid_cross_sim_BA_mean * pairBA_B.shape[0]) / (new_numB * H * W - pairBA_B.shape[0])

                cross_sim_AB_out = torch.cat((cross_sim_AB, torch.ones((cross_sim_AB.shape[0], 2), device=cross_sim_AB.device)), dim=-1)      # NA X (H X W + 2)
                cross_sim_BA_out = torch.cat((cross_sim_BA, torch.ones((cross_sim_BA.shape[0], 2), device=cross_sim_BA.device)), dim=-1)      # NB X (H X W + 2)
                # print(3)
                # cross_sim_AB_out[mask_pointA, -1] -= 1
                # cross_sim_BA_out[mask_pointB, -1] -= 1
                # cross_sim_AB_out[match_mask_A, -1] -= 1
                cross_sim_AB_out[match_mask_A==1, -1] = novalid_cross_sim_AB_sp_mean
                cross_sim_AB_out[match_mask_A==1, -2] = crossAN_mean
                cross_sim_AB_out[match_mask_nb_A==0, -1] = valid_cross_sim_AB_mean
                cross_sim_AB_out[match_mask_nb_A==0, -2] = -1 # crossAN_mean # -1

                cross_sim_BA_out[match_mask_B==1, -1] = novalid_cross_sim_BA_sp_mean
                cross_sim_BA_out[match_mask_B==1, -2] = crossBN_mean
                cross_sim_BA_out[match_mask_nb_B==0, -1] = valid_cross_sim_BA_mean
                cross_sim_BA_out[match_mask_nb_B==0, -2] = -1 # crossBN_mean # -1

                soft_cross_sim_AtoB = F.softmax((cross_sim_AB_out - 1) / t_des, dim=-1)         # NA X (H X W + 1)
                soft_cross_sim_BtoA = F.softmax((cross_sim_BA_out - 1) / t_des, dim=-1)         # NB X (H X W + 1)
                soft_cross_sim_AB_all = F.grid_sample(soft_cross_sim_AtoB[:, :-2].view(-1, H, W).unsqueeze(0),
                                                    pntA_H_normalized[vmaskAH, :].detach().view(1, 1, -1, 2),
                                                    mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NA x match_nA
                
                soft_cross_sim_BA_all = F.grid_sample(soft_cross_sim_BtoA[:, :-2].view(-1, H, W).unsqueeze(0),
                                                    pntB_invH_normalized[vmaskBH, :].detach().view(1, 1, -1, 2),
                                                    mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NB x match_nB
                # soft_valid_cross_sim_AB_all = soft_cross_sim_AB_all[mask_pointA, :]             # repeat_nA x repeat_nA
                # soft_valid_cross_sim_BA_all = soft_cross_sim_BA_all[mask_pointB, :]             # repeat_nB x repeat_nB

                soft_valid_cross_sim_AB_all = soft_cross_sim_AB_all[match_mask_A==1, :]             # match_nA x match_nA
                soft_valid_cross_sim_BA_all = soft_cross_sim_BA_all[match_mask_B==1, :]             # match_nB x match_nB

                valid_mask_AB = torch.eye(soft_valid_cross_sim_AB_all.shape[0]) == 1
                valid_mask_BA = torch.eye(soft_valid_cross_sim_BA_all.shape[0]) == 1
                # print(4)
                # 取对角线
                soft_valid_cross_sim_AB = soft_valid_cross_sim_AB_all[valid_mask_AB]
                soft_valid_cross_sim_BA = soft_valid_cross_sim_BA_all[valid_mask_BA]

                # soft_novalid_cross_sim_AB = soft_cross_sim_AtoB[mask_pointA==False, -1]              # (NA-repeat_nA) x 1
                # soft_novalid_cross_sim_BA = soft_cross_sim_BtoA[mask_pointB==False, -1]
                soft_novalid_cross_sim_AB = soft_cross_sim_AtoB[match_mask_nb_A==0, -1]               # (NA-match_nA) x 1
                soft_novalid_cross_sim_BA = soft_cross_sim_BtoA[match_mask_nb_B==0, -1]
                # print(soft_novalid_cross_sim_AB, soft_novalid_cross_sim_BA)

                log_soft_valid_cross_sim_AB = -torch.log(soft_valid_cross_sim_AB + eps) * (1 - torch.diag(dis_oriATAB)[vmaskAH] / self.ori_diff) * (1 - torch.diag(bin_distATAB[mask_pointA, :])[vmaskAH] / bin_kpAB_T.shape[0])
                log_soft_valid_cross_sim_BA = -torch.log(soft_valid_cross_sim_BA + eps) * (1 - torch.diag(dis_oriBTBA)[vmaskBH] / self.ori_diff) * (1 - torch.diag(bin_distBTBA[mask_pointB, :])[vmaskBH] / bin_kpBA_T.shape[0])
                log_soft_novalid_cross_sim_AB = -torch.log(soft_novalid_cross_sim_AB + eps)
                log_soft_novalid_cross_sim_BA = -torch.log(soft_novalid_cross_sim_BA + eps)

                dis_cross_sim_mean = torch.sum(torch.cat((4*log_soft_valid_cross_sim_AB, 4*log_soft_valid_cross_sim_BA, log_soft_novalid_cross_sim_AB, log_soft_novalid_cross_sim_BA), dim=-1), dim=-1) / (new_numA + new_numB)
                
                # print(5)
                valid_cross_sim_AB = cross_sim_AB[mask_pointA, :]   # repeat_nA x (H X W)
                valid_cross_sim_BA = cross_sim_BA[mask_pointB, :]   # repeat_nB x (H X W)
                exp_valid_cross_sim_AtoB = torch.exp((valid_cross_sim_AB - 1) / t_rel).view(-1, H, W)
                exp_valid_cross_sim_BtoA = torch.exp((valid_cross_sim_BA - 1) / t_rel).view(-1, H, W)
                exp_valid_cross_sim_AB_all = F.grid_sample(exp_valid_cross_sim_AtoB.unsqueeze(0),
                                                        pntA_H_normalized.detach().view(1, 1, -1, 2),
                                                        mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # repeat_nA x repeat_nA
                
                exp_valid_cross_sim_BA_all = F.grid_sample(exp_valid_cross_sim_BtoA.unsqueeze(0),
                                                        pntB_invH_normalized.detach().view(1, 1, -1, 2),
                                                        mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # repeat_nB x repeat_nB

                repeat_mask_AB = torch.eye(exp_valid_cross_sim_AB_all.shape[0]) == 1
                repeat_mask_BA = torch.eye(exp_valid_cross_sim_BA_all.shape[0]) == 1
                rel_valid_cross_sim_AB = exp_valid_cross_sim_AB_all[repeat_mask_AB]
                rel_valid_cross_sim_BA = exp_valid_cross_sim_BA_all[repeat_mask_BA]

                # pntA_H_normalized_new = copy.deepcopy(pntA_H_normalized.detach())
                # pntB_invH_normalized_new = copy.deepcopy(pntB_invH_normalized.detach())

                # pntA_H_normalized_new[:, 0] += 2
                # pntB_invH_normalized_new[:, 0] += 2

                scoresAB_all = F.grid_sample(scores_mapB[idx, :, :, :].unsqueeze(0),
                                            pntA_H_normalized_new.view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)      # 1 x repeat_nA

                scoresBA_all = F.grid_sample(scores_mapA[idx, :, :, :].unsqueeze(0),
                                            pntB_invH_normalized_new.view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)      # 1 x repeat_nB
                # print(6)
                scores_AAB = scoresA[idx][pmA][mask_pointA] * scoresAB_all
                scores_BBA = scoresB[idx][pmB][mask_pointB] * scoresBA_all
                scores_sum_AAB = torch.sum(scores_AAB, dim=-1)
                scores_sum_BBA = torch.sum(scores_BBA, dim=-1)
                scores_normalize_AAB = scores_AAB / (scores_sum_AAB + eps)
                scores_normalize_BBA = scores_BBA / (scores_sum_BBA + eps)
                rel_meanA = torch.sum(scores_normalize_AAB * (1 - rel_valid_cross_sim_AB), dim=-1) / pntA_H_normalized_new.shape[0]
                rel_meanB = torch.sum(scores_normalize_BBA * (1 - rel_valid_cross_sim_BA), dim=-1) / pntB_invH_normalized_new.shape[0]

                # # 熵loss
                # current_descA_std, current_descB_std = descA_std[countA:countA+new_numA], descB_std[countB:countB+new_numB]
                # desc_std += torch.mean(current_descA_std) + torch.mean(current_descB_std)
                # countA_T += numA_T
                # countB_T += numB_T

                dis_neighbor_mean_total += torch.mean(torch.sum(neighbor_dis_AB, dim=1)) + torch.mean(torch.sum(neighbor_dis_BA, dim=1))
                dis_desc += dis_cross_sim_mean_sp
                dis_desc += dis_cross_sim_mean

                dis_pair_meanAB = torch.mean(key_manhattandisAB[pairAB_A, pairAB_B])
                dis_pair_meanBA = torch.mean(key_manhattandisBA[pairBA_B, pairBA_A])

                dis_peak_mean = torch.mean(torch.cat((scoreddisA[idx][pmA], scoreddisB[idx][pmB]), dim=0))
                # dis_peak_meanB = torch.mean(scoreddisB[idx])
                
                dis_mean_total += dis_pair_meanAB + dis_pair_meanBA
                dis_peak_scored += dis_peak_mean

                dis_rel += rel_meanA + rel_meanB
                
                countA += new_numA
                countB += new_numB
                count_ne += new_num_ne
                # # Penalty
                # scores_mean += (-torch.log(torch.mean(scoresA[idx], dim=-1) + eps) - torch.log(torch.mean(scoresB[idx], dim=-1) + eps)) 
                # print(scores_mean)
            except:
                # dis_mean_total += 0
                # dis_peak_scored += 0
                # dis_desc += 0
                # dis_rel += 0
                # print('Overlapping too small or Repeatable point pairs distance is greater than correspond(1.5):', pntA.shape[0], pntA_H.shape[0], pntB.shape[0], pntB_invH.shape[0], dis_pairAB.shape[0], dis_pairBA.shape[0])
                valid_batch_size -= 1
                countA += new_numA
                countB += new_numB
                count_ne += new_num_ne
                # countA_T += numA_T
                # countB_T += numB_T

        valid_batch_size = valid_batch_size if valid_batch_size > 0 else eps
        # Reprojection Loss 
        reprojection_loss = dis_mean_total / (valid_batch_size * 2)
        # Dispersity Peak Loss
        dispersity_peak_loss = dis_peak_scored / valid_batch_size
        # NRE Loss
        descriptor_loss = dis_desc / (2 * valid_batch_size)
        # Reliability Loss
        reliability_loss = dis_rel / (valid_batch_size * 2)
        # SOSR Loss
        sosr_loss = dis_neighbor_mean_total / ((valid_batch_size * 2))
        # # Entropy loss
        # std_loss = (valid_batch_size * 2) / desc_std  
        # # Score Penalty
        # score_penalty = scores_mean / (valid_batch_size * 2)
        # # FA Desc loss
        # FA_des_loss = dis_desc_fa / valid_batch_size_FA if valid_batch_size_FA > 0 else 0

        loss_total = wrp * reprojection_loss + wpl * dispersity_peak_loss + wdl * descriptor_loss + wrl * reliability_loss + sosr_loss
        loss_group = {
            'reprojection_loss': reprojection_loss, 
            'dispersity_peak_loss': dispersity_peak_loss,
            'descriptor_loss': descriptor_loss,
            'reliability_loss': reliability_loss,
            'sosr_loss': sosr_loss,
            # 'std_loss': std_loss,
            # 'FA_des_loss': FA_des_loss,
            }
        return loss_total, loss_group

    # patch/dense AT角度 黑白相似度加量化 NFA negtives KD(Softmax 知识蒸馏)
    def detector_selfsupervised_loss_dkd_patch_ext_restrict_modify_oriR_ratio_NFA_qtbw_ns_wg_nori_AT_NE_KD(self, kpA, kpB, pmaskA, pmaskB, descA, descA_tea, descB, descB_tea, desc_mapA, desc_mapB, scoreddisA, scoreddisB, scoresA, scoresB, scores_mapA, scores_mapB, Homo, inv_Homo, inv_Homo_en, ori_all_patchA, ori_all_patchB, ori_kp_patchA, ori_kp_patchB, bin_allA, bin_allB, bin_kpA, bin_kpB, kp_ne, pmask_ne, desc_ne, bin_kp_ne, trans_angle, FA_flag, H, W, wrp=1, wpl=1, wdl=1, wrl=1, t_des=0.02, t_rel=1, t_kd=0.04):
        # pmaskA: (BxMax_num) 32x350=11200
        batch_size = len(kpA)
        max_num = pmaskA.shape[-1] // batch_size    # 350
        dis_mean_total = 0
        dis_neighbor_mean_total = 0
        dis_peak_scored = 0
        dis_desc = 0
        dis_rel = 0
        desc_std = 0
        dis_cross_sim_KD = 0
        eps = 1e-12
        valid_batch_size = batch_size
        # valid_batch_size_FA = 0
        countA, countB, count_ne = 0, 0, 0
        # dis_desc_fa = 0
        # countA_T, countB_T = 0, 0
        for idx in range(batch_size):
            pntA, pntB, pnt_ne = kpA[idx], kpB[idx], kp_ne[idx]     # M X 2 (x,y)
            # kmask_TA, kmask_TB = kmask_T_allA[idx], kmask_T_allB[idx]
            pntA = pntA.float()
            pntB = pntB.float()
            pnt_ne = pnt_ne.float()

            # 剔除部分按压区域的点,且保留在重叠区域的点
            numA, numB, num_ne = pntA.shape[0], pntB.shape[0], pnt_ne.shape[0]
            # numA_T, numB_T = pntA[kmask_TA].shape[0], pntB[kmask_TB].shape[0]
            pmA, pmB, pm_ne = pmaskA[max_num * idx:max_num * idx + numA].bool(), pmaskB[max_num * idx:max_num * idx + numB].bool(), pmask_ne[max_num * idx:max_num * idx + num_ne].bool()
            pntA, pntB, pnt_ne = pntA[pmA, :], pntB[pmB, :], pnt_ne[pm_ne, :]
            new_numA, new_numB, new_num_ne = pntA.shape[0], pntB.shape[0], pnt_ne.shape[0]       
            
            pntA = (pntA + 1) / 2 * pntA.new_tensor([[W + 3, H - 1]]).to(pntA.device)
            pntB = (pntB + 1) / 2 * pntB.new_tensor([[W + 3, H - 1]]).to(pntB.device)

            # [120, 40] -> [120, 36],实际只取中心118x32区域的点对
            pntA[:, 0] -= 2
            pntB[:, 0] -= 2
            
            pntA_normalized = pntA / pntA.new_tensor([W - 1, H - 1]).to(pntA.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)
            pntB_normalized = pntB / pntB.new_tensor([W - 1, H - 1]).to(pntB.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)

            pntA_H = warp_points(pntA[:, :2], Homo[idx].squeeze(), device=self.device)  # 利用变换矩阵变换坐标点
            pntA_H, mask_pointA = filter_points(pntA_H, torch.tensor([W, H], device=self.device), return_mask=True)
            pntB_invH = warp_points(pntB[:, :2], inv_Homo[idx].squeeze(), device=self.device)
            pntB_invH, mask_pointB = filter_points(pntB_invH, torch.tensor([W, H], device=self.device), return_mask=True)
            
            current_descA, current_descB = descA[countA:countA+new_numA], descB[countB:countB+new_numB]
            current_descA_tea, current_descB_tea = descA_tea[countA:countA+new_numA], descB_tea[countB:countB+new_numB]
            current_desc_ne = desc_ne[count_ne:count_ne+new_num_ne]

            cross_sim_AB_sp = current_descA @ current_descB.transpose(0, 1)     # NTA X NTB
            cross_sim_KDA_sp = current_descA @ current_descA_tea.transpose(0, 1) 
            cross_sim_KDB_sp = current_descB @ current_descB_tea.transpose(0, 1) 

            cross_sim_AN_sp = current_descA @ current_desc_ne.transpose(0, 1)
            cross_sim_BN_sp = current_descB @ current_desc_ne.transpose(0, 1)
            
            # 黑白相似度
            current_binA, current_binB = (bin_kpA[countA:countA+new_numA] >= 0.5).float(), (bin_kpB[countB:countB+new_numB] >= 0.5).float()   # [NA, 256] [NB_256]
            current_bin_ne = (bin_kp_ne[count_ne:count_ne+new_num_ne] >= 0.5).float()
            bin_distAB = current_binA.shape[-1] - (current_binA @ current_binB.transpose(0, 1)) - ((1 - current_binA) @ (1 - current_binB.transpose(0, 1))) # [NA, NB]
            
            bin_distAN = current_binA.shape[-1] - (current_binA @ current_bin_ne.transpose(0, 1)) - ((1 - current_binA) @ (1 - current_bin_ne.transpose(0, 1))) # [NA, NE]
            bin_distBN = current_binB.shape[-1] - (current_binB @ current_bin_ne.transpose(0, 1)) - ((1 - current_binB) @ (1 - current_bin_ne.transpose(0, 1))) # [NA, NE]
            
            # 真匹配的trans
            try:
                FAN_bin_mask = bin_distAN >= (1 - self.FA_bin_thr) * current_binA.shape[-1] 
                FBN_bin_mask = bin_distBN >= (1 - self.FA_bin_thr) * current_binB.shape[-1] 
                # topk ?
                crossAN_mean = torch.mean(cross_sim_AN_sp[FAN_bin_mask])
                crossBN_mean = torch.mean(cross_sim_BN_sp[FBN_bin_mask])

                assert pntA_H.shape[0] > 0 and pntB_invH.shape[0] > 0 
                
                # 点对欧氏距离
                key_disAB = self.get_dis(pntA_H[:, :2], pntB[:, :2])            # repeatNA x NB
                key_disBA = self.get_dis(pntB_invH[:, :2], pntA[:, :2])
                pairAB_A, pairAB_B, dis_pairAB, _ = self.get_point_pair(key_disAB, dis_thre=self.correspond)  # p -> k # NTA(<1.5), NTA(<1.5), NTA(<1.5), NTA        
                pairBA_B, pairBA_A, dis_pairBA, _  = self.get_point_pair(key_disBA, dis_thre=self.correspond)  # p -> k # NTB(<1.5), NTB(<1.5), NTB(<1.5), NTB 
                
                # 点距离mask
                nn_maskAB = torch.zeros((pntA_H.shape[0], pntB.shape[0]), device=self.device) 
                nn_maskAB[pairAB_A, pairAB_B] = 1

                nn_maskBA = torch.zeros((pntB_invH.shape[0], pntA.shape[0]), device=self.device) 
                nn_maskBA[pairBA_B, pairBA_A] = 1

                # 点对曼哈顿距离
                key_manhattandisAB = self.get_manhattan_dis(pntA_H[:, :2], pntB[:, :2])
                key_manhattandisBA = self.get_manhattan_dis(pntB_invH[:, :2], pntA[:, :2])
                # print('pdis:', dis_pairAB.shape[0], dis_pairBA.shape[0])
                assert dis_pairAB.shape[0] > 0 and dis_pairBA.shape[0] > 0     

                pntA_H_normalized = pntA_H / pntA_H.new_tensor([W - 1, H - 1]).to(pntA_H.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)
                pntB_invH_normalized = pntB_invH / pntB_invH.new_tensor([W - 1, H - 1]).to(pntB_invH.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)

                # 用于score_map
                pntA_H_new = copy.deepcopy(pntA_H.detach())
                pntB_invH_new = copy.deepcopy(pntB_invH.detach())
                pntA_H_new[:, 0] += 10                   # 120 x 36 -> 128 x 56
                pntA_H_new[:, 1] += 4 
                pntB_invH_new[:, 0] += 10
                pntB_invH_new[:, 1] += 4
                
                pntA_H_normalized_new = pntA_H_new / pntA_H_new.new_tensor([W + 19, H + 7]).to(pntA_H.device) * 2 - 1

                # pntB_invH_new = warp_points(pntB_invH_new[:, :2], inv_Homo_en[idx].squeeze(), device=self.device)       # 转到A上，而不是AT上
                
                pntB_invH_normalized_new = pntB_invH_new / pntB_invH_new.new_tensor([W + 19, H + 7]).to(pntB_invH.device) * 2 - 1 
                
                # print('1_2:', main_ori_maskATB.shape[0])
                # exit()
                ori_kpAT_patch_ext = F.grid_sample(ori_kp_patchA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntA_H_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0).transpose(0, 1)          # repeatNA x 1
                ori_kpB_patch_ext = F.grid_sample(ori_all_patchB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntB_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0).transpose(0, 1)          # NTB x 1
                ori_kpA_patch_ext = F.grid_sample(ori_all_patchA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntA_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0).transpose(0, 1)          # NTA x 1
                ori_kpBT_patch_ext = F.grid_sample(ori_kp_patchB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntB_invH_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0).transpose(0, 1)          # repeatNB x 1
                # print('1_2_1:', pntB_invH_normalized_new.shape[0])
                ori_maskATB, dis_oriATB = self.get_main_ori_consistence_AT(ori_kpAT_patch_ext, ori_kpB_patch_ext)  # repeatNA x NTB
                # print('1_2_2:', ori_maskATB.shape)
                ori_maskBTA, dis_oriBTA = self.get_main_ori_consistence_AT(ori_kpBT_patch_ext, ori_kpA_patch_ext)  # repeatNB x NTA

                match_maskAB_nb = (nn_maskAB == 1) * ori_maskATB           # repeatNA X NTB
                match_maskBA_nb = (nn_maskBA == 1) * ori_maskBTA          # repeatNB X NTA
                pairAB_A_nb_new, pairAB_B_nb_new = torch.where(match_maskAB_nb == 1)
                pairBA_B_nb_new, pairBA_A_nb_new = torch.where(match_maskBA_nb == 1)
                # assert pairAB_A_new.shape[0] > 0 and pairBA_B_new.shape[0] > 0 

                # 4x4邻域方向一致性
                ori_kpAB_patch_ext = F.grid_sample(ori_all_patchB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntA_H_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0).transpose(0, 1)  
                ori_kpBA_patch_ext = F.grid_sample(ori_all_patchA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntB_invH_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0).transpose(0, 1)  
                # print('1_2_4:', ori_kpAB_patch_ext.shape)
                ori_maskATAB, dis_oriATAB = self.get_main_ori_consistence_AT(ori_kpAT_patch_ext, ori_kpAB_patch_ext)  # repeatNA x repeatNA
                ori_maskBTBA, dis_oriBTBA = self.get_main_ori_consistence_AT(ori_kpBT_patch_ext, ori_kpBA_patch_ext)  # repeatNB x repeatNB
                
                # 黑白相似度
                bin_maskATB = bin_distAB <= (1 - self.FR_bin_thr) * current_binA.shape[-1]  
                bin_maskBTA = bin_maskATB.transpose(0, 1)  

                match_maskAB = match_maskAB_nb * bin_maskATB[mask_pointA, :]               # repeatNA X NB
                match_maskBA = match_maskBA_nb * bin_maskBTA[mask_pointB, :]               # repeatNB X NA

                pairAB_A_new, pairAB_B_new = torch.where(match_maskAB == 1)
                pairBA_B_new, pairBA_A_new = torch.where(match_maskBA == 1)
                # print('bin_mask:', pairAB_A_new.shape[0], pairBA_B_new.shape[0])
                assert pairAB_A_new.shape[0] > 0 and pairBA_B_new.shape[0] > 0 

                bin_kpAB_T = (F.grid_sample(bin_allB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntA_H_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0) >= 0.5).float()  # [256, repeatNA]
                bin_kpBA_T = (F.grid_sample(bin_allA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntB_invH_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0) >= 0.5).float()  # [256, repeatNB]
                bin_distATAB = bin_kpAB_T.shape[0] - (current_binA @ bin_kpAB_T) - ((1 - current_binA) @ (1 - bin_kpAB_T)) # [NTA, repeatNA]
                bin_distBTBA = bin_kpBA_T.shape[0] - (current_binB @ bin_kpBA_T) - ((1 - current_binB) @ (1 - bin_kpBA_T)) # [NTB, repeatNB]

                bin_maskATAB = bin_distATAB <= (1 - self.FR_bin_thr) * bin_kpAB_T.shape[0] 
                bin_maskBTBA = bin_distBTBA <= (1 - self.FR_bin_thr) * bin_kpBA_T.shape[0] 
                bin_maskATAB = bin_maskATAB[mask_pointA, :]
                bin_maskBTBA = bin_maskBTBA[mask_pointB, :]

                vmaskAH_nb = torch.diag(ori_maskATAB)
                vmaskBH_nb = torch.diag(ori_maskBTBA)
                vmaskAH = torch.diag(ori_maskATAB * bin_maskATAB) == 1      # [repeatNA, 1]
                vmaskBH = torch.diag(ori_maskBTBA * bin_maskBTBA) == 1      # [repeatNB, 1]

                # print('main_ori:', torch.sum(vmaskAH), torch.sum(vmaskBH))
                assert torch.sum(vmaskAH) > 0 and torch.sum(vmaskBH) > 0

                # SOSR: 简化的self-attention
                k_neighbor = 3
                cross_sim_AA_sp = current_descA @ current_descA.transpose(0, 1)
                cross_sim_BB_sp = current_descB @ current_descB.transpose(0, 1)
                # print('SOSR:', pairAB_A_new.shape[0], pairBA_B_new.shape[0])
                assert pairAB_A_new.shape[0] >= k_neighbor and pairBA_B_new.shape[0] >= k_neighbor 

                match_sim_AB_AA = cross_sim_AA_sp[mask_pointA, :][:, mask_pointA][pairAB_A_new, :][:, pairAB_A_new]
                match_sim_BA_BB = cross_sim_BB_sp[mask_pointB, :][:, mask_pointB][pairBA_B_new, :][:, pairBA_B_new]
                match_sim_AB_BB = cross_sim_BB_sp[pairAB_B_new, :][:, pairAB_B_new]
                match_sim_BA_AA = cross_sim_AA_sp[pairBA_A_new, :][:, pairBA_A_new]
                match_values_AB_AA, match_indices_AB_AA = torch.topk(match_sim_AB_AA, dim=1, k=k_neighbor, largest=False)
                match_values_BA_BB, match_indices_BA_BB = torch.topk(match_sim_BA_BB, dim=1, k=k_neighbor, largest=False)
                match_values_AB_BB_all = match_sim_AB_BB[:, match_indices_AB_AA]
                match_values_BA_AA_all = match_sim_BA_AA[:, match_indices_BA_BB]
                match_values_AB_BB = torch.diagonal(match_values_AB_BB_all, 0, dim1=0, dim2=1).transpose(0, 1)
                match_values_BA_AA = torch.diagonal(match_values_BA_AA_all, 0, dim1=0, dim2=1).transpose(0, 1)
                neighbor_dis_AB = (match_values_AB_AA - match_values_AB_BB) * (match_values_AB_AA - match_values_AB_BB)
                neighbor_dis_BA = (match_values_BA_BB - match_values_BA_AA) * (match_values_BA_BB - match_values_BA_AA)

                # PA VS PB
                # 计算bin值
                valid_cross_sim_AB_sp_mean = torch.mean(cross_sim_AB_sp[mask_pointA, :][match_maskAB == 1], dim=-1)
                valid_cross_sim_AB_sp_nb_mean = torch.mean(cross_sim_AB_sp[mask_pointA, :][match_maskAB_nb == 1], dim=-1)
                novalid_cross_sim_AB_sp_mean = (torch.sum(torch.sum(cross_sim_AB_sp.detach(), 1), 0) - valid_cross_sim_AB_sp_nb_mean * pairAB_A_nb_new.shape[0]) / (new_numA * new_numB - pairAB_A_nb_new.shape[0] + eps)
                valid_cross_sim_BA_sp_mean = torch.mean(cross_sim_AB_sp[:, mask_pointB][match_maskBA.transpose(0, 1) == 1], dim=-1)
                valid_cross_sim_BA_sp_nb_mean = torch.mean(cross_sim_AB_sp[:, mask_pointB][match_maskBA_nb.transpose(0, 1) == 1], dim=-1)
                novalid_cross_sim_BA_sp_mean = (torch.sum(torch.sum(cross_sim_AB_sp.detach(), 1), 0) - valid_cross_sim_BA_sp_nb_mean * pairBA_B_nb_new.shape[0]) / (new_numA * new_numB - pairBA_B_nb_new.shape[0] + eps)

                valid_indexesA = torch.tensor(list(range(cross_sim_AB_sp.shape[0])), device=self.device)[mask_pointA][pairAB_A_new]
                valid_indexesA_nb = torch.tensor(list(range(cross_sim_AB_sp.shape[0])), device=self.device)[mask_pointA][pairAB_A_nb_new]
                # cross_sim_BA_sp = current_descB @ current_descA.transpose(0, 1)
                cross_sim_AB_out_sp = torch.cat((cross_sim_AB_sp, torch.ones((cross_sim_AB_sp.shape[0], 2), device=cross_sim_AB_sp.device) * 2), dim=-1)      # NA X (NB + 2)
                cross_sim_AB_out_nb_sp = torch.cat((cross_sim_AB_sp, torch.ones((cross_sim_AB_sp.shape[0], 2), device=cross_sim_AB_sp.device) * 2), dim=-1)      # NA X (NB + 2)
                # cross_sim_BA_out_sp = torch.cat((cross_sim_BA_sp, torch.ones((numB, 1), device=cross_sim_BA_sp.device)), dim=-1)      # NB X (NA + 1)
                # valid_indexesB = torch.tensor(list(range(numB)), device=self.device)[mask_pointB][pairBA_B]
                # print('1_2')
                cross_sim_AB_out_sp[valid_indexesA, -1] = novalid_cross_sim_AB_sp_mean
                cross_sim_AB_out_sp[valid_indexesA, -2] = crossAN_mean
                cross_sim_AB_out_nb_sp[valid_indexesA_nb, -1] = novalid_cross_sim_AB_sp_mean
                novalid_indexesA = torch.tensor(list(range(cross_sim_AB_sp.shape[0])), device=self.device)[cross_sim_AB_out_nb_sp[:, -1]==2]
                cross_sim_AB_out_sp[novalid_indexesA, -1] = valid_cross_sim_AB_sp_mean
                # nomatch对不增加negtives的均值bin
                cross_sim_AB_out_sp[novalid_indexesA, -2] = -1 # crossAN_mean # -1

                soft_cross_sim_AtoB_sp = F.softmax((cross_sim_AB_out_sp - 1) / t_des, dim=-1)
                # soft_cross_sim_BtoA = F.softmax((cross_sim_BA_out - 1) / t_des, dim=-1)
                # print('1_3')
                soft_valid_cross_sim_AB_sp = soft_cross_sim_AtoB_sp[mask_pointA, :-2][match_maskAB==1]
                # soft_valid_cross_sim_BA = soft_cross_sim_BtoA[mask_pointB, :-1][pairBA_B, pairBA_A]
                soft_novalid_cross_sim_AB_sp = soft_cross_sim_AtoB_sp[novalid_indexesA, -1]
                # soft_novalid_cross_sim_BA = soft_cross_sim_BtoA[cross_sim_BA_out[:, -1]==1, -1]
                log_soft_valid_cross_sim_AB_sp = -torch.log(soft_valid_cross_sim_AB_sp + eps) * (1 - dis_oriATB[match_maskAB==1] / self.ori_diff) * (1 - bin_distAB[mask_pointA, :][match_maskAB==1] / current_binA.shape[-1]) * (1 - key_disAB[match_maskAB==1].detach() / self.correspond)
                # log_soft_valid_cross_sim_BA = -torch.log(soft_valid_cross_sim_BA + eps)
                log_soft_novalid_cross_sim_AB_sp = -torch.log(soft_novalid_cross_sim_AB_sp + eps)
                # log_soft_novalid_cross_sim_BA = -torch.log(soft_novalid_cross_sim_BA + eps)
                dis_cross_sim_mean_sp = torch.sum(torch.cat((4*log_soft_valid_cross_sim_AB_sp, log_soft_novalid_cross_sim_AB_sp), dim=-1), dim=-1) / new_numA
                
                # PA VS PAB
                # match_mask_A = copy.deepcopy(mask_pointA)
                # match_mask_B = copy.deepcopy(mask_pointB)
                match_mask_A = torch.zeros(cross_sim_AB_sp.shape[0], device=self.device)
                match_mask_nb_A = torch.zeros(cross_sim_AB_sp.shape[0], device=self.device)
                valid_match_indexesA = torch.tensor(list(range(cross_sim_AB_sp.shape[0])), device=self.device)[mask_pointA][vmaskAH]
                valid_match_indexesA_nb = torch.tensor(list(range(cross_sim_AB_sp.shape[0])), device=self.device)[mask_pointA][vmaskAH_nb]
                match_mask_A[valid_match_indexesA] = 1
                match_mask_nb_A[valid_match_indexesA_nb] = 1

                match_mask_B = torch.zeros(cross_sim_AB_sp.shape[1], device=self.device)
                match_mask_nb_B = torch.zeros(cross_sim_AB_sp.shape[1], device=self.device)
                valid_match_indexesB = torch.tensor(list(range(cross_sim_AB_sp.shape[1])), device=self.device)[mask_pointB][vmaskBH]
                valid_match_indexesB_nb = torch.tensor(list(range(cross_sim_AB_sp.shape[1])), device=self.device)[mask_pointB][vmaskBH_nb]
                match_mask_B[valid_match_indexesB] = 1
                match_mask_nb_B[valid_match_indexesB_nb] = 1

                cross_sim_AB = current_descA @ desc_mapB[idx, :, :, :].view(-1, H * W)
                # cross_sim_AB = cross_sim_AB[mask_pointA, :]
                cross_sim_AB_all = F.grid_sample(cross_sim_AB.view(-1, H, W).unsqueeze(0),
                                                pntA_H_normalized[vmaskAH, :].detach().view(1, 1, -1, 2),
                                                mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NA x repeatNA
                valid_cross_sim_AB_mean = torch.trace(cross_sim_AB_all[match_mask_A==1, :]) / cross_sim_AB_all[match_mask_A==1, :].shape[0]
                # novalid_cross_sim_AB_mean = (torch.sum(torch.sum(cross_sim_AB.detach(), 1), 1) - valid_cross_sim_AB_mean * pairAB_A.shape[0]) / (new_numA * H * W - pairAB_A.shape[0])

                cross_sim_BA = current_descB @ desc_mapA[idx, :, :, :].view(-1, H * W)   # M x H x W
                # cross_sim_BA = cross_sim_BA[mask_pointB, :]
                cross_sim_BA_all = F.grid_sample(cross_sim_BA.view(-1, H, W).unsqueeze(0),
                                                pntB_invH_normalized[vmaskBH, :].detach().view(1, 1, -1, 2),
                                                mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NB x match_nB
                valid_cross_sim_BA_mean = torch.trace(cross_sim_BA_all[match_mask_B==1, :]) / cross_sim_BA_all[match_mask_B==1, :].shape[0]
                # novalid_cross_sim_BA_mean = (torch.sum(torch.sum(cross_sim_BA.detach(), 1), 1) - valid_cross_sim_BA_mean * pairBA_B.shape[0]) / (new_numB * H * W - pairBA_B.shape[0])

                cross_sim_AB_out = torch.cat((cross_sim_AB, torch.ones((cross_sim_AB.shape[0], 2), device=cross_sim_AB.device)), dim=-1)      # NA X (H X W + 2)
                cross_sim_BA_out = torch.cat((cross_sim_BA, torch.ones((cross_sim_BA.shape[0], 2), device=cross_sim_BA.device)), dim=-1)      # NB X (H X W + 2)
                # print(3)
                # cross_sim_AB_out[mask_pointA, -1] -= 1
                # cross_sim_BA_out[mask_pointB, -1] -= 1
                # cross_sim_AB_out[match_mask_A, -1] -= 1
                cross_sim_AB_out[match_mask_A==1, -1] = novalid_cross_sim_AB_sp_mean
                cross_sim_AB_out[match_mask_A==1, -2] = crossAN_mean
                cross_sim_AB_out[match_mask_nb_A==0, -1] = valid_cross_sim_AB_mean
                cross_sim_AB_out[match_mask_nb_A==0, -2] = -1 # crossAN_mean # -1

                cross_sim_BA_out[match_mask_B==1, -1] = novalid_cross_sim_BA_sp_mean
                cross_sim_BA_out[match_mask_B==1, -2] = crossBN_mean
                cross_sim_BA_out[match_mask_nb_B==0, -1] = valid_cross_sim_BA_mean
                cross_sim_BA_out[match_mask_nb_B==0, -2] = -1 # crossBN_mean # -1

                soft_cross_sim_AtoB = F.softmax((cross_sim_AB_out - 1) / t_des, dim=-1)         # NA X (H X W + 1)
                soft_cross_sim_BtoA = F.softmax((cross_sim_BA_out - 1) / t_des, dim=-1)         # NB X (H X W + 1)
                soft_cross_sim_AB_all = F.grid_sample(soft_cross_sim_AtoB[:, :-2].view(-1, H, W).unsqueeze(0),
                                                    pntA_H_normalized[vmaskAH, :].detach().view(1, 1, -1, 2),
                                                    mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NA x match_nA
                
                soft_cross_sim_BA_all = F.grid_sample(soft_cross_sim_BtoA[:, :-2].view(-1, H, W).unsqueeze(0),
                                                    pntB_invH_normalized[vmaskBH, :].detach().view(1, 1, -1, 2),
                                                    mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NB x match_nB
                # soft_valid_cross_sim_AB_all = soft_cross_sim_AB_all[mask_pointA, :]             # repeat_nA x repeat_nA
                # soft_valid_cross_sim_BA_all = soft_cross_sim_BA_all[mask_pointB, :]             # repeat_nB x repeat_nB

                soft_valid_cross_sim_AB_all = soft_cross_sim_AB_all[match_mask_A==1, :]             # match_nA x match_nA
                soft_valid_cross_sim_BA_all = soft_cross_sim_BA_all[match_mask_B==1, :]             # match_nB x match_nB

                valid_mask_AB = torch.eye(soft_valid_cross_sim_AB_all.shape[0]) == 1
                valid_mask_BA = torch.eye(soft_valid_cross_sim_BA_all.shape[0]) == 1
                # print(4)
                # 取对角线
                soft_valid_cross_sim_AB = soft_valid_cross_sim_AB_all[valid_mask_AB]
                soft_valid_cross_sim_BA = soft_valid_cross_sim_BA_all[valid_mask_BA]

                # soft_novalid_cross_sim_AB = soft_cross_sim_AtoB[mask_pointA==False, -1]              # (NA-repeat_nA) x 1
                # soft_novalid_cross_sim_BA = soft_cross_sim_BtoA[mask_pointB==False, -1]
                soft_novalid_cross_sim_AB = soft_cross_sim_AtoB[match_mask_nb_A==0, -1]               # (NA-match_nA) x 1
                soft_novalid_cross_sim_BA = soft_cross_sim_BtoA[match_mask_nb_B==0, -1]
                # print(soft_novalid_cross_sim_AB, soft_novalid_cross_sim_BA)

                log_soft_valid_cross_sim_AB = -torch.log(soft_valid_cross_sim_AB + eps) * (1 - torch.diag(dis_oriATAB)[vmaskAH] / self.ori_diff) * (1 - torch.diag(bin_distATAB[mask_pointA, :])[vmaskAH] / bin_kpAB_T.shape[0])
                log_soft_valid_cross_sim_BA = -torch.log(soft_valid_cross_sim_BA + eps) * (1 - torch.diag(dis_oriBTBA)[vmaskBH] / self.ori_diff) * (1 - torch.diag(bin_distBTBA[mask_pointB, :])[vmaskBH] / bin_kpBA_T.shape[0])
                log_soft_novalid_cross_sim_AB = -torch.log(soft_novalid_cross_sim_AB + eps)
                log_soft_novalid_cross_sim_BA = -torch.log(soft_novalid_cross_sim_BA + eps)

                dis_cross_sim_mean = torch.sum(torch.cat((4*log_soft_valid_cross_sim_AB, 4*log_soft_valid_cross_sim_BA, log_soft_novalid_cross_sim_AB, log_soft_novalid_cross_sim_BA), dim=-1), dim=-1) / (new_numA + new_numB)
                
                # print(5)
                valid_cross_sim_AB = cross_sim_AB[mask_pointA, :]   # repeat_nA x (H X W)
                valid_cross_sim_BA = cross_sim_BA[mask_pointB, :]   # repeat_nB x (H X W)
                exp_valid_cross_sim_AtoB = torch.exp((valid_cross_sim_AB - 1) / t_rel).view(-1, H, W)
                exp_valid_cross_sim_BtoA = torch.exp((valid_cross_sim_BA - 1) / t_rel).view(-1, H, W)
                exp_valid_cross_sim_AB_all = F.grid_sample(exp_valid_cross_sim_AtoB.unsqueeze(0),
                                                        pntA_H_normalized.detach().view(1, 1, -1, 2),
                                                        mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # repeat_nA x repeat_nA
                
                exp_valid_cross_sim_BA_all = F.grid_sample(exp_valid_cross_sim_BtoA.unsqueeze(0),
                                                        pntB_invH_normalized.detach().view(1, 1, -1, 2),
                                                        mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # repeat_nB x repeat_nB

                repeat_mask_AB = torch.eye(exp_valid_cross_sim_AB_all.shape[0]) == 1
                repeat_mask_BA = torch.eye(exp_valid_cross_sim_BA_all.shape[0]) == 1
                rel_valid_cross_sim_AB = exp_valid_cross_sim_AB_all[repeat_mask_AB]
                rel_valid_cross_sim_BA = exp_valid_cross_sim_BA_all[repeat_mask_BA]

                # pntA_H_normalized_new = copy.deepcopy(pntA_H_normalized.detach())
                # pntB_invH_normalized_new = copy.deepcopy(pntB_invH_normalized.detach())

                # pntA_H_normalized_new[:, 0] += 2
                # pntB_invH_normalized_new[:, 0] += 2

                scoresAB_all = F.grid_sample(scores_mapB[idx, :, :, :].unsqueeze(0),
                                            pntA_H_normalized_new.view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)      # 1 x repeat_nA

                scoresBA_all = F.grid_sample(scores_mapA[idx, :, :, :].unsqueeze(0),
                                            pntB_invH_normalized_new.view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)      # 1 x repeat_nB
                # print(6)
                scores_AAB = scoresA[idx][pmA][mask_pointA] * scoresAB_all
                scores_BBA = scoresB[idx][pmB][mask_pointB] * scoresBA_all
                scores_sum_AAB = torch.sum(scores_AAB, dim=-1)
                scores_sum_BBA = torch.sum(scores_BBA, dim=-1)
                scores_normalize_AAB = scores_AAB / (scores_sum_AAB + eps)
                scores_normalize_BBA = scores_BBA / (scores_sum_BBA + eps)
                rel_meanA = torch.sum(scores_normalize_AAB * (1 - rel_valid_cross_sim_AB), dim=-1) / pntA_H_normalized_new.shape[0]
                rel_meanB = torch.sum(scores_normalize_BBA * (1 - rel_valid_cross_sim_BA), dim=-1) / pntB_invH_normalized_new.shape[0]

                # # 熵loss
                # current_descA_std, current_descB_std = descA_std[countA:countA+new_numA], descB_std[countB:countB+new_numB]
                # desc_std += torch.mean(current_descA_std) + torch.mean(current_descB_std)
                # countA_T += numA_T
                # countB_T += numB_T

                # KD_loss
                soft_cross_sim_KDA_sp = F.softmax((cross_sim_KDA_sp - 1) / t_kd, dim=-1)   # NTA X NTA
                soft_cross_sim_KDB_sp = F.softmax((cross_sim_KDB_sp - 1) / t_kd, dim=-1)   # NTB X NTB
                log_soft_valid_cross_sim_KDA = -torch.log(soft_cross_sim_KDA_sp + eps)
                log_soft_valid_cross_sim_KDB = -torch.log(soft_cross_sim_KDB_sp + eps)
                dis_cross_sim_KD += (torch.trace(log_soft_valid_cross_sim_KDA) + torch.trace(log_soft_valid_cross_sim_KDB)) / (new_numA + new_numB)


                dis_neighbor_mean_total += torch.mean(torch.sum(neighbor_dis_AB, dim=1)) + torch.mean(torch.sum(neighbor_dis_BA, dim=1))
                dis_desc += dis_cross_sim_mean_sp
                dis_desc += dis_cross_sim_mean

                dis_pair_meanAB = torch.mean(key_manhattandisAB[pairAB_A, pairAB_B])
                dis_pair_meanBA = torch.mean(key_manhattandisBA[pairBA_B, pairBA_A])

                dis_peak_mean = torch.mean(torch.cat((scoreddisA[idx][pmA], scoreddisB[idx][pmB]), dim=0))
                # dis_peak_meanB = torch.mean(scoreddisB[idx])
                
                dis_mean_total += dis_pair_meanAB + dis_pair_meanBA
                dis_peak_scored += dis_peak_mean

                dis_rel += rel_meanA + rel_meanB
                
                countA += new_numA
                countB += new_numB
                count_ne += new_num_ne
                # # Penalty
                # scores_mean += (-torch.log(torch.mean(scoresA[idx], dim=-1) + eps) - torch.log(torch.mean(scoresB[idx], dim=-1) + eps)) 
                # print(scores_mean)
            except:
                # dis_mean_total += 0
                # dis_peak_scored += 0
                # dis_desc += 0
                # dis_rel += 0
                # print('Overlapping too small or Repeatable point pairs distance is greater than correspond(1.5):', pntA.shape[0], pntA_H.shape[0], pntB.shape[0], pntB_invH.shape[0], dis_pairAB.shape[0], dis_pairBA.shape[0])
                valid_batch_size -= 1
                countA += new_numA
                countB += new_numB
                count_ne += new_num_ne
                # countA_T += numA_T
                # countB_T += numB_T

        valid_batch_size = valid_batch_size if valid_batch_size > 0 else eps
        # Reprojection Loss 
        reprojection_loss = dis_mean_total / (valid_batch_size * 2)
        # Dispersity Peak Loss
        dispersity_peak_loss = dis_peak_scored / valid_batch_size
        # NRE Loss
        descriptor_loss = dis_desc / (2 * valid_batch_size)
        # Reliability Loss
        reliability_loss = dis_rel / (valid_batch_size * 2)
        # SOSR Loss
        sosr_loss = dis_neighbor_mean_total / ((valid_batch_size * 2))
        # # Entropy loss
        # std_loss = (valid_batch_size * 2) / desc_std  
        # # Score Penalty
        # score_penalty = scores_mean / (valid_batch_size * 2)
        # # FA Desc loss
        # FA_des_loss = dis_desc_fa / valid_batch_size_FA if valid_batch_size_FA > 0 else 0
        # KD_loss
        KD_loss = dis_cross_sim_KD / valid_batch_size

        loss_total = wrp * reprojection_loss + wpl * dispersity_peak_loss + wdl * descriptor_loss + wrl * reliability_loss + sosr_loss + KD_loss
        loss_group = {
            'reprojection_loss': reprojection_loss, 
            'dispersity_peak_loss': dispersity_peak_loss,
            'descriptor_loss': descriptor_loss,
            'reliability_loss': reliability_loss,
            'sosr_loss': sosr_loss,
            # 'std_loss': std_loss,
            # 'FA_des_loss': FA_des_loss,
            'KD_loss': KD_loss,
            }
        return loss_total, loss_group

    # patch/dense AT角度 黑白相似度加量化 NFA negtives SKKD(Sinkhorn 知识蒸馏)
    def detector_selfsupervised_loss_dkd_patch_ext_restrict_modify_oriR_ratio_NFA_qtbw_ns_wg_nori_AT_NE_SKKD(self, kpA, kpB, pmaskA, pmaskB, descA, descA_tea, descB, descB_tea, desc_mapA, desc_mapB, scoreddisA, scoreddisB, scoresA, scoresB, scores_mapA, scores_mapB, Homo, inv_Homo, inv_Homo_en, ori_all_patchA, ori_all_patchB, ori_kp_patchA, ori_kp_patchB, bin_allA, bin_allB, bin_kpA, bin_kpB, kp_ne, pmask_ne, desc_ne, bin_kp_ne, trans_angle, FA_flag, H, W, wrp=1, wpl=1, wdl=1, wrl=1, t_des=0.02, t_rel=1, t_kd=0.04):
        # pmaskA: (BxMax_num) 32x350=11200
        batch_size = len(kpA)
        max_num = pmaskA.shape[-1] // batch_size    # 350
        dis_mean_total = 0
        dis_neighbor_mean_total = 0
        dis_peak_scored = 0
        dis_desc = 0
        dis_rel = 0
        desc_std = 0
        dis_cross_sim_KD = 0
        eps = 1e-12
        valid_batch_size = batch_size
        # valid_batch_size_FA = 0
        countA, countB, count_ne = 0, 0, 0
        # dis_desc_fa = 0
        # countA_T, countB_T = 0, 0
        for idx in range(batch_size):
            pntA, pntB, pnt_ne = kpA[idx], kpB[idx], kp_ne[idx]     # M X 2 (x,y)
            # kmask_TA, kmask_TB = kmask_T_allA[idx], kmask_T_allB[idx]
            pntA = pntA.float()
            pntB = pntB.float()
            pnt_ne = pnt_ne.float()

            # 剔除部分按压区域的点,且保留在重叠区域的点
            numA, numB, num_ne = pntA.shape[0], pntB.shape[0], pnt_ne.shape[0]
            # numA_T, numB_T = pntA[kmask_TA].shape[0], pntB[kmask_TB].shape[0]
            pmA, pmB, pm_ne = pmaskA[max_num * idx:max_num * idx + numA].bool(), pmaskB[max_num * idx:max_num * idx + numB].bool(), pmask_ne[max_num * idx:max_num * idx + num_ne].bool()
            pntA, pntB, pnt_ne = pntA[pmA, :], pntB[pmB, :], pnt_ne[pm_ne, :]
            new_numA, new_numB, new_num_ne = pntA.shape[0], pntB.shape[0], pnt_ne.shape[0]       
            
            pntA = (pntA + 1) / 2 * pntA.new_tensor([[W + 3, H - 1]]).to(pntA.device)
            pntB = (pntB + 1) / 2 * pntB.new_tensor([[W + 3, H - 1]]).to(pntB.device)

            # [120, 40] -> [120, 36],实际只取中心118x32区域的点对
            pntA[:, 0] -= 2
            pntB[:, 0] -= 2
            
            pntA_normalized = pntA / pntA.new_tensor([W - 1, H - 1]).to(pntA.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)
            pntB_normalized = pntB / pntB.new_tensor([W - 1, H - 1]).to(pntB.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)

            pntA_H = warp_points(pntA[:, :2], Homo[idx].squeeze(), device=self.device)  # 利用变换矩阵变换坐标点
            pntA_H, mask_pointA = filter_points(pntA_H, torch.tensor([W, H], device=self.device), return_mask=True)
            pntB_invH = warp_points(pntB[:, :2], inv_Homo[idx].squeeze(), device=self.device)
            pntB_invH, mask_pointB = filter_points(pntB_invH, torch.tensor([W, H], device=self.device), return_mask=True)
            
            current_descA, current_descB = descA[countA:countA+new_numA], descB[countB:countB+new_numB]
            current_descA_tea, current_descB_tea = descA_tea[countA:countA+new_numA], descB_tea[countB:countB+new_numB]
            current_desc_ne = desc_ne[count_ne:count_ne+new_num_ne]

            cross_sim_AB_sp = current_descA @ current_descB.transpose(0, 1)     # NTA X NTB
            cross_sim_KDA_sp = current_descA @ current_descA_tea.transpose(0, 1)  # NTA x NTA
            cross_sim_KDB_sp = current_descB @ current_descB_tea.transpose(0, 1)  # NTB x NTB

            cross_sim_AN_sp = current_descA @ current_desc_ne.transpose(0, 1)
            cross_sim_BN_sp = current_descB @ current_desc_ne.transpose(0, 1)
            
            # 黑白相似度
            current_binA, current_binB = (bin_kpA[countA:countA+new_numA] >= 0.5).float(), (bin_kpB[countB:countB+new_numB] >= 0.5).float()   # [NA, 256] [NB_256]
            current_bin_ne = (bin_kp_ne[count_ne:count_ne+new_num_ne] >= 0.5).float()
            bin_distAB = current_binA.shape[-1] - (current_binA @ current_binB.transpose(0, 1)) - ((1 - current_binA) @ (1 - current_binB.transpose(0, 1))) # [NA, NB]
            
            bin_distAN = current_binA.shape[-1] - (current_binA @ current_bin_ne.transpose(0, 1)) - ((1 - current_binA) @ (1 - current_bin_ne.transpose(0, 1))) # [NA, NE]
            bin_distBN = current_binB.shape[-1] - (current_binB @ current_bin_ne.transpose(0, 1)) - ((1 - current_binB) @ (1 - current_bin_ne.transpose(0, 1))) # [NA, NE]
            
            # 真匹配的trans
            try:
                FAN_bin_mask = bin_distAN >= (1 - self.FA_bin_thr) * current_binA.shape[-1] 
                FBN_bin_mask = bin_distBN >= (1 - self.FA_bin_thr) * current_binB.shape[-1] 
                # topk ?
                crossAN_mean = torch.mean(cross_sim_AN_sp[FAN_bin_mask])
                crossBN_mean = torch.mean(cross_sim_BN_sp[FBN_bin_mask])

                assert pntA_H.shape[0] > 0 and pntB_invH.shape[0] > 0 
                
                # 点对欧氏距离
                key_disAB = self.get_dis(pntA_H[:, :2], pntB[:, :2])            # repeatNA x NB
                key_disBA = self.get_dis(pntB_invH[:, :2], pntA[:, :2])
                pairAB_A, pairAB_B, dis_pairAB, _ = self.get_point_pair(key_disAB, dis_thre=self.correspond)  # p -> k # NTA(<1.5), NTA(<1.5), NTA(<1.5), NTA        
                pairBA_B, pairBA_A, dis_pairBA, _  = self.get_point_pair(key_disBA, dis_thre=self.correspond)  # p -> k # NTB(<1.5), NTB(<1.5), NTB(<1.5), NTB 
                
                # 点距离mask
                nn_maskAB = torch.zeros((pntA_H.shape[0], pntB.shape[0]), device=self.device) 
                nn_maskAB[pairAB_A, pairAB_B] = 1

                nn_maskBA = torch.zeros((pntB_invH.shape[0], pntA.shape[0]), device=self.device) 
                nn_maskBA[pairBA_B, pairBA_A] = 1

                # 点对曼哈顿距离
                key_manhattandisAB = self.get_manhattan_dis(pntA_H[:, :2], pntB[:, :2])
                key_manhattandisBA = self.get_manhattan_dis(pntB_invH[:, :2], pntA[:, :2])
                # print('pdis:', dis_pairAB.shape[0], dis_pairBA.shape[0])
                assert dis_pairAB.shape[0] > 0 and dis_pairBA.shape[0] > 0     

                pntA_H_normalized = pntA_H / pntA_H.new_tensor([W - 1, H - 1]).to(pntA_H.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)
                pntB_invH_normalized = pntB_invH / pntB_invH.new_tensor([W - 1, H - 1]).to(pntB_invH.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)

                # 用于score_map
                pntA_H_new = copy.deepcopy(pntA_H.detach())
                pntB_invH_new = copy.deepcopy(pntB_invH.detach())
                pntA_H_new[:, 0] += 10                   # 120 x 36 -> 128 x 56
                pntA_H_new[:, 1] += 4 
                pntB_invH_new[:, 0] += 10
                pntB_invH_new[:, 1] += 4
                
                pntA_H_normalized_new = pntA_H_new / pntA_H_new.new_tensor([W + 19, H + 7]).to(pntA_H.device) * 2 - 1

                # pntB_invH_new = warp_points(pntB_invH_new[:, :2], inv_Homo_en[idx].squeeze(), device=self.device)       # 转到A上，而不是AT上
                
                pntB_invH_normalized_new = pntB_invH_new / pntB_invH_new.new_tensor([W + 19, H + 7]).to(pntB_invH.device) * 2 - 1 
                
                # print('1_2:', main_ori_maskATB.shape[0])
                # exit()
                ori_kpAT_patch_ext = F.grid_sample(ori_kp_patchA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntA_H_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0).transpose(0, 1)          # repeatNA x 1
                ori_kpB_patch_ext = F.grid_sample(ori_all_patchB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntB_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0).transpose(0, 1)          # NTB x 1
                ori_kpA_patch_ext = F.grid_sample(ori_all_patchA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntA_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0).transpose(0, 1)          # NTA x 1
                ori_kpBT_patch_ext = F.grid_sample(ori_kp_patchB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntB_invH_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0).transpose(0, 1)          # repeatNB x 1
                # print('1_2_1:', pntB_invH_normalized_new.shape[0])
                ori_maskATB, dis_oriATB = self.get_main_ori_consistence_AT(ori_kpAT_patch_ext, ori_kpB_patch_ext)  # repeatNA x NTB
                # print('1_2_2:', ori_maskATB.shape)
                ori_maskBTA, dis_oriBTA = self.get_main_ori_consistence_AT(ori_kpBT_patch_ext, ori_kpA_patch_ext)  # repeatNB x NTA

                match_maskAB_nb = (nn_maskAB == 1) * ori_maskATB           # repeatNA X NTB
                match_maskBA_nb = (nn_maskBA == 1) * ori_maskBTA          # repeatNB X NTA
                pairAB_A_nb_new, pairAB_B_nb_new = torch.where(match_maskAB_nb == 1)
                pairBA_B_nb_new, pairBA_A_nb_new = torch.where(match_maskBA_nb == 1)
                # assert pairAB_A_new.shape[0] > 0 and pairBA_B_new.shape[0] > 0 

                # 4x4邻域方向一致性
                ori_kpAB_patch_ext = F.grid_sample(ori_all_patchB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntA_H_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0).transpose(0, 1)  
                ori_kpBA_patch_ext = F.grid_sample(ori_all_patchA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntB_invH_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0).transpose(0, 1)  
                # print('1_2_4:', ori_kpAB_patch_ext.shape)
                ori_maskATAB, dis_oriATAB = self.get_main_ori_consistence_AT(ori_kpAT_patch_ext, ori_kpAB_patch_ext)  # repeatNA x repeatNA
                ori_maskBTBA, dis_oriBTBA = self.get_main_ori_consistence_AT(ori_kpBT_patch_ext, ori_kpBA_patch_ext)  # repeatNB x repeatNB
                
                # 黑白相似度
                bin_maskATB = bin_distAB <= (1 - self.FR_bin_thr) * current_binA.shape[-1]  
                bin_maskBTA = bin_maskATB.transpose(0, 1)  

                match_maskAB = match_maskAB_nb * bin_maskATB[mask_pointA, :]               # repeatNA X NB
                match_maskBA = match_maskBA_nb * bin_maskBTA[mask_pointB, :]               # repeatNB X NA

                pairAB_A_new, pairAB_B_new = torch.where(match_maskAB == 1)
                pairBA_B_new, pairBA_A_new = torch.where(match_maskBA == 1)
                # print('bin_mask:', pairAB_A_new.shape[0], pairBA_B_new.shape[0])
                assert pairAB_A_new.shape[0] > 0 and pairBA_B_new.shape[0] > 0 

                bin_kpAB_T = (F.grid_sample(bin_allB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntA_H_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0) >= 0.5).float()  # [256, repeatNA]
                bin_kpBA_T = (F.grid_sample(bin_allA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntB_invH_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0) >= 0.5).float()  # [256, repeatNB]
                bin_distATAB = bin_kpAB_T.shape[0] - (current_binA @ bin_kpAB_T) - ((1 - current_binA) @ (1 - bin_kpAB_T)) # [NTA, repeatNA]
                bin_distBTBA = bin_kpBA_T.shape[0] - (current_binB @ bin_kpBA_T) - ((1 - current_binB) @ (1 - bin_kpBA_T)) # [NTB, repeatNB]

                bin_maskATAB = bin_distATAB <= (1 - self.FR_bin_thr) * bin_kpAB_T.shape[0] 
                bin_maskBTBA = bin_distBTBA <= (1 - self.FR_bin_thr) * bin_kpBA_T.shape[0] 
                bin_maskATAB = bin_maskATAB[mask_pointA, :]
                bin_maskBTBA = bin_maskBTBA[mask_pointB, :]

                vmaskAH_nb = torch.diag(ori_maskATAB)
                vmaskBH_nb = torch.diag(ori_maskBTBA)
                vmaskAH = torch.diag(ori_maskATAB * bin_maskATAB) == 1      # [repeatNA, 1]
                vmaskBH = torch.diag(ori_maskBTBA * bin_maskBTBA) == 1      # [repeatNB, 1]

                # print('main_ori:', torch.sum(vmaskAH), torch.sum(vmaskBH))
                assert torch.sum(vmaskAH) > 0 and torch.sum(vmaskBH) > 0

                # SOSR: 简化的self-attention
                k_neighbor = 3
                cross_sim_AA_sp = current_descA @ current_descA.transpose(0, 1)
                cross_sim_BB_sp = current_descB @ current_descB.transpose(0, 1)
                # print('SOSR:', pairAB_A_new.shape[0], pairBA_B_new.shape[0])
                assert pairAB_A_new.shape[0] >= k_neighbor and pairBA_B_new.shape[0] >= k_neighbor 

                match_sim_AB_AA = cross_sim_AA_sp[mask_pointA, :][:, mask_pointA][pairAB_A_new, :][:, pairAB_A_new]
                match_sim_BA_BB = cross_sim_BB_sp[mask_pointB, :][:, mask_pointB][pairBA_B_new, :][:, pairBA_B_new]
                match_sim_AB_BB = cross_sim_BB_sp[pairAB_B_new, :][:, pairAB_B_new]
                match_sim_BA_AA = cross_sim_AA_sp[pairBA_A_new, :][:, pairBA_A_new]
                match_values_AB_AA, match_indices_AB_AA = torch.topk(match_sim_AB_AA, dim=1, k=k_neighbor, largest=False)
                match_values_BA_BB, match_indices_BA_BB = torch.topk(match_sim_BA_BB, dim=1, k=k_neighbor, largest=False)
                match_values_AB_BB_all = match_sim_AB_BB[:, match_indices_AB_AA]
                match_values_BA_AA_all = match_sim_BA_AA[:, match_indices_BA_BB]
                match_values_AB_BB = torch.diagonal(match_values_AB_BB_all, 0, dim1=0, dim2=1).transpose(0, 1)
                match_values_BA_AA = torch.diagonal(match_values_BA_AA_all, 0, dim1=0, dim2=1).transpose(0, 1)
                neighbor_dis_AB = (match_values_AB_AA - match_values_AB_BB) * (match_values_AB_AA - match_values_AB_BB)
                neighbor_dis_BA = (match_values_BA_BB - match_values_BA_AA) * (match_values_BA_BB - match_values_BA_AA)

                # PA VS PB
                # 计算bin值
                valid_cross_sim_AB_sp_mean = torch.mean(cross_sim_AB_sp[mask_pointA, :][match_maskAB == 1], dim=-1)
                valid_cross_sim_AB_sp_nb_mean = torch.mean(cross_sim_AB_sp[mask_pointA, :][match_maskAB_nb == 1], dim=-1)
                novalid_cross_sim_AB_sp_mean = (torch.sum(torch.sum(cross_sim_AB_sp.detach(), 1), 0) - valid_cross_sim_AB_sp_nb_mean * pairAB_A_nb_new.shape[0]) / (new_numA * new_numB - pairAB_A_nb_new.shape[0] + eps)
                valid_cross_sim_BA_sp_mean = torch.mean(cross_sim_AB_sp[:, mask_pointB][match_maskBA.transpose(0, 1) == 1], dim=-1)
                valid_cross_sim_BA_sp_nb_mean = torch.mean(cross_sim_AB_sp[:, mask_pointB][match_maskBA_nb.transpose(0, 1) == 1], dim=-1)
                novalid_cross_sim_BA_sp_mean = (torch.sum(torch.sum(cross_sim_AB_sp.detach(), 1), 0) - valid_cross_sim_BA_sp_nb_mean * pairBA_B_nb_new.shape[0]) / (new_numA * new_numB - pairBA_B_nb_new.shape[0] + eps)

                valid_indexesA = torch.tensor(list(range(cross_sim_AB_sp.shape[0])), device=self.device)[mask_pointA][pairAB_A_new]
                valid_indexesA_nb = torch.tensor(list(range(cross_sim_AB_sp.shape[0])), device=self.device)[mask_pointA][pairAB_A_nb_new]
                # cross_sim_BA_sp = current_descB @ current_descA.transpose(0, 1)
                cross_sim_AB_out_sp = torch.cat((cross_sim_AB_sp, torch.ones((cross_sim_AB_sp.shape[0], 2), device=cross_sim_AB_sp.device) * 2), dim=-1)      # NA X (NB + 2)
                cross_sim_AB_out_nb_sp = torch.cat((cross_sim_AB_sp, torch.ones((cross_sim_AB_sp.shape[0], 2), device=cross_sim_AB_sp.device) * 2), dim=-1)      # NA X (NB + 2)
                # cross_sim_BA_out_sp = torch.cat((cross_sim_BA_sp, torch.ones((numB, 1), device=cross_sim_BA_sp.device)), dim=-1)      # NB X (NA + 1)
                # valid_indexesB = torch.tensor(list(range(numB)), device=self.device)[mask_pointB][pairBA_B]
                # print('1_2')
                cross_sim_AB_out_sp[valid_indexesA, -1] = novalid_cross_sim_AB_sp_mean
                cross_sim_AB_out_sp[valid_indexesA, -2] = crossAN_mean
                cross_sim_AB_out_nb_sp[valid_indexesA_nb, -1] = novalid_cross_sim_AB_sp_mean
                novalid_indexesA = torch.tensor(list(range(cross_sim_AB_sp.shape[0])), device=self.device)[cross_sim_AB_out_nb_sp[:, -1]==2]
                cross_sim_AB_out_sp[novalid_indexesA, -1] = valid_cross_sim_AB_sp_mean
                # nomatch对不增加negtives的均值bin
                cross_sim_AB_out_sp[novalid_indexesA, -2] = -1 # crossAN_mean # -1

                soft_cross_sim_AtoB_sp = F.softmax((cross_sim_AB_out_sp - 1) / t_des, dim=-1)
                # soft_cross_sim_BtoA = F.softmax((cross_sim_BA_out - 1) / t_des, dim=-1)
                # print('1_3')
                soft_valid_cross_sim_AB_sp = soft_cross_sim_AtoB_sp[mask_pointA, :-2][match_maskAB==1]
                # soft_valid_cross_sim_BA = soft_cross_sim_BtoA[mask_pointB, :-1][pairBA_B, pairBA_A]
                soft_novalid_cross_sim_AB_sp = soft_cross_sim_AtoB_sp[novalid_indexesA, -1]
                # soft_novalid_cross_sim_BA = soft_cross_sim_BtoA[cross_sim_BA_out[:, -1]==1, -1]
                log_soft_valid_cross_sim_AB_sp = -torch.log(soft_valid_cross_sim_AB_sp + eps) * (1 - dis_oriATB[match_maskAB==1] / self.ori_diff) * (1 - bin_distAB[mask_pointA, :][match_maskAB==1] / current_binA.shape[-1]) * (1 - key_disAB[match_maskAB==1].detach() / self.correspond)
                # log_soft_valid_cross_sim_BA = -torch.log(soft_valid_cross_sim_BA + eps)
                log_soft_novalid_cross_sim_AB_sp = -torch.log(soft_novalid_cross_sim_AB_sp + eps)
                # log_soft_novalid_cross_sim_BA = -torch.log(soft_novalid_cross_sim_BA + eps)
                dis_cross_sim_mean_sp = torch.sum(torch.cat((4*log_soft_valid_cross_sim_AB_sp, log_soft_novalid_cross_sim_AB_sp), dim=-1), dim=-1) / new_numA
                
                # PA VS PAB
                # match_mask_A = copy.deepcopy(mask_pointA)
                # match_mask_B = copy.deepcopy(mask_pointB)
                match_mask_A = torch.zeros(cross_sim_AB_sp.shape[0], device=self.device)
                match_mask_nb_A = torch.zeros(cross_sim_AB_sp.shape[0], device=self.device)
                valid_match_indexesA = torch.tensor(list(range(cross_sim_AB_sp.shape[0])), device=self.device)[mask_pointA][vmaskAH]
                valid_match_indexesA_nb = torch.tensor(list(range(cross_sim_AB_sp.shape[0])), device=self.device)[mask_pointA][vmaskAH_nb]
                match_mask_A[valid_match_indexesA] = 1
                match_mask_nb_A[valid_match_indexesA_nb] = 1

                match_mask_B = torch.zeros(cross_sim_AB_sp.shape[1], device=self.device)
                match_mask_nb_B = torch.zeros(cross_sim_AB_sp.shape[1], device=self.device)
                valid_match_indexesB = torch.tensor(list(range(cross_sim_AB_sp.shape[1])), device=self.device)[mask_pointB][vmaskBH]
                valid_match_indexesB_nb = torch.tensor(list(range(cross_sim_AB_sp.shape[1])), device=self.device)[mask_pointB][vmaskBH_nb]
                match_mask_B[valid_match_indexesB] = 1
                match_mask_nb_B[valid_match_indexesB_nb] = 1

                cross_sim_AB = current_descA @ desc_mapB[idx, :, :, :].view(-1, H * W)
                # cross_sim_AB = cross_sim_AB[mask_pointA, :]
                cross_sim_AB_all = F.grid_sample(cross_sim_AB.view(-1, H, W).unsqueeze(0),
                                                pntA_H_normalized[vmaskAH, :].detach().view(1, 1, -1, 2),
                                                mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NA x repeatNA
                valid_cross_sim_AB_mean = torch.trace(cross_sim_AB_all[match_mask_A==1, :]) / cross_sim_AB_all[match_mask_A==1, :].shape[0]
                # novalid_cross_sim_AB_mean = (torch.sum(torch.sum(cross_sim_AB.detach(), 1), 1) - valid_cross_sim_AB_mean * pairAB_A.shape[0]) / (new_numA * H * W - pairAB_A.shape[0])

                cross_sim_BA = current_descB @ desc_mapA[idx, :, :, :].view(-1, H * W)   # M x H x W
                # cross_sim_BA = cross_sim_BA[mask_pointB, :]
                cross_sim_BA_all = F.grid_sample(cross_sim_BA.view(-1, H, W).unsqueeze(0),
                                                pntB_invH_normalized[vmaskBH, :].detach().view(1, 1, -1, 2),
                                                mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NB x match_nB
                valid_cross_sim_BA_mean = torch.trace(cross_sim_BA_all[match_mask_B==1, :]) / cross_sim_BA_all[match_mask_B==1, :].shape[0]
                # novalid_cross_sim_BA_mean = (torch.sum(torch.sum(cross_sim_BA.detach(), 1), 1) - valid_cross_sim_BA_mean * pairBA_B.shape[0]) / (new_numB * H * W - pairBA_B.shape[0])

                cross_sim_AB_out = torch.cat((cross_sim_AB, torch.ones((cross_sim_AB.shape[0], 2), device=cross_sim_AB.device)), dim=-1)      # NA X (H X W + 2)
                cross_sim_BA_out = torch.cat((cross_sim_BA, torch.ones((cross_sim_BA.shape[0], 2), device=cross_sim_BA.device)), dim=-1)      # NB X (H X W + 2)
                # print(3)
                # cross_sim_AB_out[mask_pointA, -1] -= 1
                # cross_sim_BA_out[mask_pointB, -1] -= 1
                # cross_sim_AB_out[match_mask_A, -1] -= 1
                cross_sim_AB_out[match_mask_A==1, -1] = novalid_cross_sim_AB_sp_mean
                cross_sim_AB_out[match_mask_A==1, -2] = crossAN_mean
                cross_sim_AB_out[match_mask_nb_A==0, -1] = valid_cross_sim_AB_mean
                cross_sim_AB_out[match_mask_nb_A==0, -2] = -1 # crossAN_mean # -1

                cross_sim_BA_out[match_mask_B==1, -1] = novalid_cross_sim_BA_sp_mean
                cross_sim_BA_out[match_mask_B==1, -2] = crossBN_mean
                cross_sim_BA_out[match_mask_nb_B==0, -1] = valid_cross_sim_BA_mean
                cross_sim_BA_out[match_mask_nb_B==0, -2] = -1 # crossBN_mean # -1

                soft_cross_sim_AtoB = F.softmax((cross_sim_AB_out - 1) / t_des, dim=-1)         # NA X (H X W + 1)
                soft_cross_sim_BtoA = F.softmax((cross_sim_BA_out - 1) / t_des, dim=-1)         # NB X (H X W + 1)
                soft_cross_sim_AB_all = F.grid_sample(soft_cross_sim_AtoB[:, :-2].view(-1, H, W).unsqueeze(0),
                                                    pntA_H_normalized[vmaskAH, :].detach().view(1, 1, -1, 2),
                                                    mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NA x match_nA
                
                soft_cross_sim_BA_all = F.grid_sample(soft_cross_sim_BtoA[:, :-2].view(-1, H, W).unsqueeze(0),
                                                    pntB_invH_normalized[vmaskBH, :].detach().view(1, 1, -1, 2),
                                                    mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NB x match_nB
                # soft_valid_cross_sim_AB_all = soft_cross_sim_AB_all[mask_pointA, :]             # repeat_nA x repeat_nA
                # soft_valid_cross_sim_BA_all = soft_cross_sim_BA_all[mask_pointB, :]             # repeat_nB x repeat_nB

                soft_valid_cross_sim_AB_all = soft_cross_sim_AB_all[match_mask_A==1, :]             # match_nA x match_nA
                soft_valid_cross_sim_BA_all = soft_cross_sim_BA_all[match_mask_B==1, :]             # match_nB x match_nB

                valid_mask_AB = torch.eye(soft_valid_cross_sim_AB_all.shape[0]) == 1
                valid_mask_BA = torch.eye(soft_valid_cross_sim_BA_all.shape[0]) == 1
                # print(4)
                # 取对角线
                soft_valid_cross_sim_AB = soft_valid_cross_sim_AB_all[valid_mask_AB]
                soft_valid_cross_sim_BA = soft_valid_cross_sim_BA_all[valid_mask_BA]

                # soft_novalid_cross_sim_AB = soft_cross_sim_AtoB[mask_pointA==False, -1]              # (NA-repeat_nA) x 1
                # soft_novalid_cross_sim_BA = soft_cross_sim_BtoA[mask_pointB==False, -1]
                soft_novalid_cross_sim_AB = soft_cross_sim_AtoB[match_mask_nb_A==0, -1]               # (NA-match_nA) x 1
                soft_novalid_cross_sim_BA = soft_cross_sim_BtoA[match_mask_nb_B==0, -1]
                # print(soft_novalid_cross_sim_AB, soft_novalid_cross_sim_BA)

                log_soft_valid_cross_sim_AB = -torch.log(soft_valid_cross_sim_AB + eps) * (1 - torch.diag(dis_oriATAB)[vmaskAH] / self.ori_diff) * (1 - torch.diag(bin_distATAB[mask_pointA, :])[vmaskAH] / bin_kpAB_T.shape[0])
                log_soft_valid_cross_sim_BA = -torch.log(soft_valid_cross_sim_BA + eps) * (1 - torch.diag(dis_oriBTBA)[vmaskBH] / self.ori_diff) * (1 - torch.diag(bin_distBTBA[mask_pointB, :])[vmaskBH] / bin_kpBA_T.shape[0])
                log_soft_novalid_cross_sim_AB = -torch.log(soft_novalid_cross_sim_AB + eps)
                log_soft_novalid_cross_sim_BA = -torch.log(soft_novalid_cross_sim_BA + eps)

                dis_cross_sim_mean = torch.sum(torch.cat((4*log_soft_valid_cross_sim_AB, 4*log_soft_valid_cross_sim_BA, log_soft_novalid_cross_sim_AB, log_soft_novalid_cross_sim_BA), dim=-1), dim=-1) / (new_numA + new_numB)
                
                # print(5)
                valid_cross_sim_AB = cross_sim_AB[mask_pointA, :]   # repeat_nA x (H X W)
                valid_cross_sim_BA = cross_sim_BA[mask_pointB, :]   # repeat_nB x (H X W)
                exp_valid_cross_sim_AtoB = torch.exp((valid_cross_sim_AB - 1) / t_rel).view(-1, H, W)
                exp_valid_cross_sim_BtoA = torch.exp((valid_cross_sim_BA - 1) / t_rel).view(-1, H, W)
                exp_valid_cross_sim_AB_all = F.grid_sample(exp_valid_cross_sim_AtoB.unsqueeze(0),
                                                        pntA_H_normalized.detach().view(1, 1, -1, 2),
                                                        mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # repeat_nA x repeat_nA
                
                exp_valid_cross_sim_BA_all = F.grid_sample(exp_valid_cross_sim_BtoA.unsqueeze(0),
                                                        pntB_invH_normalized.detach().view(1, 1, -1, 2),
                                                        mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # repeat_nB x repeat_nB

                repeat_mask_AB = torch.eye(exp_valid_cross_sim_AB_all.shape[0]) == 1
                repeat_mask_BA = torch.eye(exp_valid_cross_sim_BA_all.shape[0]) == 1
                rel_valid_cross_sim_AB = exp_valid_cross_sim_AB_all[repeat_mask_AB]
                rel_valid_cross_sim_BA = exp_valid_cross_sim_BA_all[repeat_mask_BA]

                # pntA_H_normalized_new = copy.deepcopy(pntA_H_normalized.detach())
                # pntB_invH_normalized_new = copy.deepcopy(pntB_invH_normalized.detach())

                # pntA_H_normalized_new[:, 0] += 2
                # pntB_invH_normalized_new[:, 0] += 2

                scoresAB_all = F.grid_sample(scores_mapB[idx, :, :, :].unsqueeze(0),
                                            pntA_H_normalized_new.view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)      # 1 x repeat_nA

                scoresBA_all = F.grid_sample(scores_mapA[idx, :, :, :].unsqueeze(0),
                                            pntB_invH_normalized_new.view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)      # 1 x repeat_nB
                # print(6)
                scores_AAB = scoresA[idx][pmA][mask_pointA] * scoresAB_all
                scores_BBA = scoresB[idx][pmB][mask_pointB] * scoresBA_all
                scores_sum_AAB = torch.sum(scores_AAB, dim=-1)
                scores_sum_BBA = torch.sum(scores_BBA, dim=-1)
                scores_normalize_AAB = scores_AAB / (scores_sum_AAB + eps)
                scores_normalize_BBA = scores_BBA / (scores_sum_BBA + eps)
                rel_meanA = torch.sum(scores_normalize_AAB * (1 - rel_valid_cross_sim_AB), dim=-1) / pntA_H_normalized_new.shape[0]
                rel_meanB = torch.sum(scores_normalize_BBA * (1 - rel_valid_cross_sim_BA), dim=-1) / pntB_invH_normalized_new.shape[0]

                # # 熵loss
                # current_descA_std, current_descB_std = descA_std[countA:countA+new_numA], descB_std[countB:countB+new_numB]
                # desc_std += torch.mean(current_descA_std) + torch.mean(current_descB_std)
                # countA_T += numA_T
                # countB_T += numB_T

                # KD_loss

                # softmax 
                # soft_cross_sim_KDA_sp = F.softmax((cross_sim_KDA_sp - 1) / t_kd, dim=-1)   # NTA X NTA
                # soft_cross_sim_KDB_sp = F.softmax((cross_sim_KDB_sp - 1) / t_kd, dim=-1)   # NTB X NTB
                # log_soft_valid_cross_sim_KDA = -torch.log(soft_cross_sim_KDA_sp + eps)
                # log_soft_valid_cross_sim_KDB = -torch.log(soft_cross_sim_KDB_sp + eps)

                # Sinkhorn
                SK_scores_KDA = log_optimal_transport(cross_sim_KDA_sp.unsqueeze(0), 3).squeeze(0)  
                SK_scores_KDB = log_optimal_transport(cross_sim_KDB_sp.unsqueeze(0), 3).squeeze(0)

                dis_cross_sim_KD += (-(torch.trace(SK_scores_KDA) + torch.trace(SK_scores_KDB)) / (new_numA + new_numB))


                dis_neighbor_mean_total += torch.mean(torch.sum(neighbor_dis_AB, dim=1)) + torch.mean(torch.sum(neighbor_dis_BA, dim=1))
                dis_desc += dis_cross_sim_mean_sp
                dis_desc += dis_cross_sim_mean

                dis_pair_meanAB = torch.mean(key_manhattandisAB[pairAB_A, pairAB_B])
                dis_pair_meanBA = torch.mean(key_manhattandisBA[pairBA_B, pairBA_A])

                dis_peak_mean = torch.mean(torch.cat((scoreddisA[idx][pmA], scoreddisB[idx][pmB]), dim=0))
                # dis_peak_meanB = torch.mean(scoreddisB[idx])
                
                dis_mean_total += dis_pair_meanAB + dis_pair_meanBA
                dis_peak_scored += dis_peak_mean

                dis_rel += rel_meanA + rel_meanB
                
                countA += new_numA
                countB += new_numB
                count_ne += new_num_ne
                # # Penalty
                # scores_mean += (-torch.log(torch.mean(scoresA[idx], dim=-1) + eps) - torch.log(torch.mean(scoresB[idx], dim=-1) + eps)) 
                # print(scores_mean)
            except:
                # dis_mean_total += 0
                # dis_peak_scored += 0
                # dis_desc += 0
                # dis_rel += 0
                # print('Overlapping too small or Repeatable point pairs distance is greater than correspond(1.5):', pntA.shape[0], pntA_H.shape[0], pntB.shape[0], pntB_invH.shape[0], dis_pairAB.shape[0], dis_pairBA.shape[0])
                valid_batch_size -= 1
                countA += new_numA
                countB += new_numB
                count_ne += new_num_ne
                # countA_T += numA_T
                # countB_T += numB_T

        valid_batch_size = valid_batch_size if valid_batch_size > 0 else eps
        # Reprojection Loss 
        reprojection_loss = dis_mean_total / (valid_batch_size * 2)
        # Dispersity Peak Loss
        dispersity_peak_loss = dis_peak_scored / valid_batch_size
        # NRE Loss
        descriptor_loss = dis_desc / (2 * valid_batch_size)
        # Reliability Loss
        reliability_loss = dis_rel / (valid_batch_size * 2)
        # SOSR Loss
        sosr_loss = dis_neighbor_mean_total / ((valid_batch_size * 2))
        # # Entropy loss
        # std_loss = (valid_batch_size * 2) / desc_std  
        # # Score Penalty
        # score_penalty = scores_mean / (valid_batch_size * 2)
        # # FA Desc loss
        # FA_des_loss = dis_desc_fa / valid_batch_size_FA if valid_batch_size_FA > 0 else 0
        # KD_loss
        KD_loss = dis_cross_sim_KD / valid_batch_size

        loss_total = wrp * reprojection_loss + wpl * dispersity_peak_loss + wdl * descriptor_loss + wrl * reliability_loss + sosr_loss + KD_loss
        loss_group = {
            'reprojection_loss': reprojection_loss, 
            'dispersity_peak_loss': dispersity_peak_loss,
            'descriptor_loss': descriptor_loss,
            'reliability_loss': reliability_loss,
            'sosr_loss': sosr_loss,
            # 'std_loss': std_loss,
            # 'FA_des_loss': FA_des_loss,
            'KD_loss': KD_loss,
            }
        return loss_total, loss_group

    # patch/dense AT角度 黑白相似度加量化 NFA negtives DSKD(Dual-Softmax 知识蒸馏)
    def detector_selfsupervised_loss_dkd_patch_ext_restrict_modify_oriR_ratio_NFA_qtbw_ns_wg_nori_AT_NE_DSKD(self, kpA, kpB, pmaskA, pmaskB, descA, descA_tea, descB, descB_tea, desc_mapA, desc_mapB, scoreddisA, scoreddisB, scoresA, scoresB, scores_mapA, scores_mapB, Homo, inv_Homo, inv_Homo_en, ori_all_patchA, ori_all_patchB, ori_kp_patchA, ori_kp_patchB, bin_allA, bin_allB, bin_kpA, bin_kpB, kp_ne, pmask_ne, desc_ne, bin_kp_ne, trans_angle, FA_flag, H, W, wrp=1, wpl=1, wdl=1, wrl=1, t_des=0.02, t_rel=1, t_kd=0.04):
        # pmaskA: (BxMax_num) 32x350=11200
        batch_size = len(kpA)
        max_num = pmaskA.shape[-1] // batch_size    # 350
        dis_mean_total = 0
        dis_neighbor_mean_total = 0
        dis_peak_scored = 0
        dis_desc = 0
        dis_rel = 0
        desc_std = 0
        dis_cross_sim_KD = 0
        eps = 1e-12
        valid_batch_size = batch_size
        # valid_batch_size_FA = 0
        countA, countB, count_ne = 0, 0, 0
        # dis_desc_fa = 0
        # countA_T, countB_T = 0, 0
        for idx in range(batch_size):
            pntA, pntB, pnt_ne = kpA[idx], kpB[idx], kp_ne[idx]     # M X 2 (x,y)
            # kmask_TA, kmask_TB = kmask_T_allA[idx], kmask_T_allB[idx]
            pntA = pntA.float()
            pntB = pntB.float()
            pnt_ne = pnt_ne.float()

            # 剔除部分按压区域的点,且保留在重叠区域的点
            numA, numB, num_ne = pntA.shape[0], pntB.shape[0], pnt_ne.shape[0]
            # numA_T, numB_T = pntA[kmask_TA].shape[0], pntB[kmask_TB].shape[0]
            pmA, pmB, pm_ne = pmaskA[max_num * idx:max_num * idx + numA].bool(), pmaskB[max_num * idx:max_num * idx + numB].bool(), pmask_ne[max_num * idx:max_num * idx + num_ne].bool()
            pntA, pntB, pnt_ne = pntA[pmA, :], pntB[pmB, :], pnt_ne[pm_ne, :]
            new_numA, new_numB, new_num_ne = pntA.shape[0], pntB.shape[0], pnt_ne.shape[0]       
            
            pntA = (pntA + 1) / 2 * pntA.new_tensor([[W + 3, H - 1]]).to(pntA.device)
            pntB = (pntB + 1) / 2 * pntB.new_tensor([[W + 3, H - 1]]).to(pntB.device)

            # [120, 40] -> [120, 36],实际只取中心118x32区域的点对
            pntA[:, 0] -= 2
            pntB[:, 0] -= 2
            
            pntA_normalized = pntA / pntA.new_tensor([W - 1, H - 1]).to(pntA.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)
            pntB_normalized = pntB / pntB.new_tensor([W - 1, H - 1]).to(pntB.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)

            pntA_H = warp_points(pntA[:, :2], Homo[idx].squeeze(), device=self.device)  # 利用变换矩阵变换坐标点
            pntA_H, mask_pointA = filter_points(pntA_H, torch.tensor([W, H], device=self.device), return_mask=True)
            pntB_invH = warp_points(pntB[:, :2], inv_Homo[idx].squeeze(), device=self.device)
            pntB_invH, mask_pointB = filter_points(pntB_invH, torch.tensor([W, H], device=self.device), return_mask=True)
            
            current_descA, current_descB = descA[countA:countA+new_numA], descB[countB:countB+new_numB]
            current_descA_tea, current_descB_tea = descA_tea[countA:countA+new_numA], descB_tea[countB:countB+new_numB]
            current_desc_ne = desc_ne[count_ne:count_ne+new_num_ne]

            cross_sim_AB_sp = current_descA @ current_descB.transpose(0, 1)     # NTA X NTB
            cross_sim_KDA_sp = current_descA @ current_descA_tea.transpose(0, 1) 
            cross_sim_KDB_sp = current_descB @ current_descB_tea.transpose(0, 1) 

            cross_sim_AN_sp = current_descA @ current_desc_ne.transpose(0, 1)
            cross_sim_BN_sp = current_descB @ current_desc_ne.transpose(0, 1)
            
            # 黑白相似度
            current_binA, current_binB = (bin_kpA[countA:countA+new_numA] >= 0.5).float(), (bin_kpB[countB:countB+new_numB] >= 0.5).float()   # [NA, 256] [NB_256]
            current_bin_ne = (bin_kp_ne[count_ne:count_ne+new_num_ne] >= 0.5).float()
            bin_distAB = current_binA.shape[-1] - (current_binA @ current_binB.transpose(0, 1)) - ((1 - current_binA) @ (1 - current_binB.transpose(0, 1))) # [NA, NB]
            
            bin_distAN = current_binA.shape[-1] - (current_binA @ current_bin_ne.transpose(0, 1)) - ((1 - current_binA) @ (1 - current_bin_ne.transpose(0, 1))) # [NA, NE]
            bin_distBN = current_binB.shape[-1] - (current_binB @ current_bin_ne.transpose(0, 1)) - ((1 - current_binB) @ (1 - current_bin_ne.transpose(0, 1))) # [NA, NE]
            
            # 真匹配的trans
            try:
                FAN_bin_mask = bin_distAN >= (1 - self.FA_bin_thr) * current_binA.shape[-1] 
                FBN_bin_mask = bin_distBN >= (1 - self.FA_bin_thr) * current_binB.shape[-1] 
                # topk ?
                crossAN_mean = torch.mean(cross_sim_AN_sp[FAN_bin_mask])
                crossBN_mean = torch.mean(cross_sim_BN_sp[FBN_bin_mask])

                assert pntA_H.shape[0] > 0 and pntB_invH.shape[0] > 0 
                
                # 点对欧氏距离
                key_disAB = self.get_dis(pntA_H[:, :2], pntB[:, :2])            # repeatNA x NB
                key_disBA = self.get_dis(pntB_invH[:, :2], pntA[:, :2])
                pairAB_A, pairAB_B, dis_pairAB, _ = self.get_point_pair(key_disAB, dis_thre=self.correspond)  # p -> k # NTA(<1.5), NTA(<1.5), NTA(<1.5), NTA        
                pairBA_B, pairBA_A, dis_pairBA, _  = self.get_point_pair(key_disBA, dis_thre=self.correspond)  # p -> k # NTB(<1.5), NTB(<1.5), NTB(<1.5), NTB 
                
                # 点距离mask
                nn_maskAB = torch.zeros((pntA_H.shape[0], pntB.shape[0]), device=self.device) 
                nn_maskAB[pairAB_A, pairAB_B] = 1

                nn_maskBA = torch.zeros((pntB_invH.shape[0], pntA.shape[0]), device=self.device) 
                nn_maskBA[pairBA_B, pairBA_A] = 1

                # 点对曼哈顿距离
                key_manhattandisAB = self.get_manhattan_dis(pntA_H[:, :2], pntB[:, :2])
                key_manhattandisBA = self.get_manhattan_dis(pntB_invH[:, :2], pntA[:, :2])
                # print('pdis:', dis_pairAB.shape[0], dis_pairBA.shape[0])
                assert dis_pairAB.shape[0] > 0 and dis_pairBA.shape[0] > 0     

                pntA_H_normalized = pntA_H / pntA_H.new_tensor([W - 1, H - 1]).to(pntA_H.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)
                pntB_invH_normalized = pntB_invH / pntB_invH.new_tensor([W - 1, H - 1]).to(pntB_invH.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)

                # 用于score_map
                pntA_H_new = copy.deepcopy(pntA_H.detach())
                pntB_invH_new = copy.deepcopy(pntB_invH.detach())
                pntA_H_new[:, 0] += 10                   # 120 x 36 -> 128 x 56
                pntA_H_new[:, 1] += 4 
                pntB_invH_new[:, 0] += 10
                pntB_invH_new[:, 1] += 4
                
                pntA_H_normalized_new = pntA_H_new / pntA_H_new.new_tensor([W + 19, H + 7]).to(pntA_H.device) * 2 - 1

                # pntB_invH_new = warp_points(pntB_invH_new[:, :2], inv_Homo_en[idx].squeeze(), device=self.device)       # 转到A上，而不是AT上
                
                pntB_invH_normalized_new = pntB_invH_new / pntB_invH_new.new_tensor([W + 19, H + 7]).to(pntB_invH.device) * 2 - 1 
                
                # print('1_2:', main_ori_maskATB.shape[0])
                # exit()
                ori_kpAT_patch_ext = F.grid_sample(ori_kp_patchA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntA_H_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0).transpose(0, 1)          # repeatNA x 1
                ori_kpB_patch_ext = F.grid_sample(ori_all_patchB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntB_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0).transpose(0, 1)          # NTB x 1
                ori_kpA_patch_ext = F.grid_sample(ori_all_patchA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntA_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0).transpose(0, 1)          # NTA x 1
                ori_kpBT_patch_ext = F.grid_sample(ori_kp_patchB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntB_invH_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0).transpose(0, 1)          # repeatNB x 1
                # print('1_2_1:', pntB_invH_normalized_new.shape[0])
                ori_maskATB, dis_oriATB = self.get_main_ori_consistence_AT(ori_kpAT_patch_ext, ori_kpB_patch_ext)  # repeatNA x NTB
                # print('1_2_2:', ori_maskATB.shape)
                ori_maskBTA, dis_oriBTA = self.get_main_ori_consistence_AT(ori_kpBT_patch_ext, ori_kpA_patch_ext)  # repeatNB x NTA

                match_maskAB_nb = (nn_maskAB == 1) * ori_maskATB           # repeatNA X NTB
                match_maskBA_nb = (nn_maskBA == 1) * ori_maskBTA          # repeatNB X NTA
                pairAB_A_nb_new, pairAB_B_nb_new = torch.where(match_maskAB_nb == 1)
                pairBA_B_nb_new, pairBA_A_nb_new = torch.where(match_maskBA_nb == 1)
                # assert pairAB_A_new.shape[0] > 0 and pairBA_B_new.shape[0] > 0 

                # 4x4邻域方向一致性
                ori_kpAB_patch_ext = F.grid_sample(ori_all_patchB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntA_H_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0).transpose(0, 1)  
                ori_kpBA_patch_ext = F.grid_sample(ori_all_patchA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntB_invH_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0).transpose(0, 1)  
                # print('1_2_4:', ori_kpAB_patch_ext.shape)
                ori_maskATAB, dis_oriATAB = self.get_main_ori_consistence_AT(ori_kpAT_patch_ext, ori_kpAB_patch_ext)  # repeatNA x repeatNA
                ori_maskBTBA, dis_oriBTBA = self.get_main_ori_consistence_AT(ori_kpBT_patch_ext, ori_kpBA_patch_ext)  # repeatNB x repeatNB
                
                # 黑白相似度
                bin_maskATB = bin_distAB <= (1 - self.FR_bin_thr) * current_binA.shape[-1]  
                bin_maskBTA = bin_maskATB.transpose(0, 1)  

                match_maskAB = match_maskAB_nb * bin_maskATB[mask_pointA, :]               # repeatNA X NB
                match_maskBA = match_maskBA_nb * bin_maskBTA[mask_pointB, :]               # repeatNB X NA

                pairAB_A_new, pairAB_B_new = torch.where(match_maskAB == 1)
                pairBA_B_new, pairBA_A_new = torch.where(match_maskBA == 1)
                # print('bin_mask:', pairAB_A_new.shape[0], pairBA_B_new.shape[0])
                assert pairAB_A_new.shape[0] > 0 and pairBA_B_new.shape[0] > 0 

                bin_kpAB_T = (F.grid_sample(bin_allB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntA_H_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0) >= 0.5).float()  # [256, repeatNA]
                bin_kpBA_T = (F.grid_sample(bin_allA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntB_invH_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0) >= 0.5).float()  # [256, repeatNB]
                bin_distATAB = bin_kpAB_T.shape[0] - (current_binA @ bin_kpAB_T) - ((1 - current_binA) @ (1 - bin_kpAB_T)) # [NTA, repeatNA]
                bin_distBTBA = bin_kpBA_T.shape[0] - (current_binB @ bin_kpBA_T) - ((1 - current_binB) @ (1 - bin_kpBA_T)) # [NTB, repeatNB]

                bin_maskATAB = bin_distATAB <= (1 - self.FR_bin_thr) * bin_kpAB_T.shape[0] 
                bin_maskBTBA = bin_distBTBA <= (1 - self.FR_bin_thr) * bin_kpBA_T.shape[0] 
                bin_maskATAB = bin_maskATAB[mask_pointA, :]
                bin_maskBTBA = bin_maskBTBA[mask_pointB, :]

                vmaskAH_nb = torch.diag(ori_maskATAB)
                vmaskBH_nb = torch.diag(ori_maskBTBA)
                vmaskAH = torch.diag(ori_maskATAB * bin_maskATAB) == 1      # [repeatNA, 1]
                vmaskBH = torch.diag(ori_maskBTBA * bin_maskBTBA) == 1      # [repeatNB, 1]

                # print('main_ori:', torch.sum(vmaskAH), torch.sum(vmaskBH))
                assert torch.sum(vmaskAH) > 0 and torch.sum(vmaskBH) > 0

                # SOSR: 简化的self-attention
                k_neighbor = 3
                cross_sim_AA_sp = current_descA @ current_descA.transpose(0, 1)
                cross_sim_BB_sp = current_descB @ current_descB.transpose(0, 1)
                # print('SOSR:', pairAB_A_new.shape[0], pairBA_B_new.shape[0])
                assert pairAB_A_new.shape[0] >= k_neighbor and pairBA_B_new.shape[0] >= k_neighbor 

                match_sim_AB_AA = cross_sim_AA_sp[mask_pointA, :][:, mask_pointA][pairAB_A_new, :][:, pairAB_A_new]
                match_sim_BA_BB = cross_sim_BB_sp[mask_pointB, :][:, mask_pointB][pairBA_B_new, :][:, pairBA_B_new]
                match_sim_AB_BB = cross_sim_BB_sp[pairAB_B_new, :][:, pairAB_B_new]
                match_sim_BA_AA = cross_sim_AA_sp[pairBA_A_new, :][:, pairBA_A_new]
                match_values_AB_AA, match_indices_AB_AA = torch.topk(match_sim_AB_AA, dim=1, k=k_neighbor, largest=False)
                match_values_BA_BB, match_indices_BA_BB = torch.topk(match_sim_BA_BB, dim=1, k=k_neighbor, largest=False)
                match_values_AB_BB_all = match_sim_AB_BB[:, match_indices_AB_AA]
                match_values_BA_AA_all = match_sim_BA_AA[:, match_indices_BA_BB]
                match_values_AB_BB = torch.diagonal(match_values_AB_BB_all, 0, dim1=0, dim2=1).transpose(0, 1)
                match_values_BA_AA = torch.diagonal(match_values_BA_AA_all, 0, dim1=0, dim2=1).transpose(0, 1)
                neighbor_dis_AB = (match_values_AB_AA - match_values_AB_BB) * (match_values_AB_AA - match_values_AB_BB)
                neighbor_dis_BA = (match_values_BA_BB - match_values_BA_AA) * (match_values_BA_BB - match_values_BA_AA)

                # PA VS PB
                # 计算bin值
                valid_cross_sim_AB_sp_mean = torch.mean(cross_sim_AB_sp[mask_pointA, :][match_maskAB == 1], dim=-1)
                valid_cross_sim_AB_sp_nb_mean = torch.mean(cross_sim_AB_sp[mask_pointA, :][match_maskAB_nb == 1], dim=-1)
                novalid_cross_sim_AB_sp_mean = (torch.sum(torch.sum(cross_sim_AB_sp.detach(), 1), 0) - valid_cross_sim_AB_sp_nb_mean * pairAB_A_nb_new.shape[0]) / (new_numA * new_numB - pairAB_A_nb_new.shape[0] + eps)
                valid_cross_sim_BA_sp_mean = torch.mean(cross_sim_AB_sp[:, mask_pointB][match_maskBA.transpose(0, 1) == 1], dim=-1)
                valid_cross_sim_BA_sp_nb_mean = torch.mean(cross_sim_AB_sp[:, mask_pointB][match_maskBA_nb.transpose(0, 1) == 1], dim=-1)
                novalid_cross_sim_BA_sp_mean = (torch.sum(torch.sum(cross_sim_AB_sp.detach(), 1), 0) - valid_cross_sim_BA_sp_nb_mean * pairBA_B_nb_new.shape[0]) / (new_numA * new_numB - pairBA_B_nb_new.shape[0] + eps)

                valid_indexesA = torch.tensor(list(range(cross_sim_AB_sp.shape[0])), device=self.device)[mask_pointA][pairAB_A_new]
                valid_indexesA_nb = torch.tensor(list(range(cross_sim_AB_sp.shape[0])), device=self.device)[mask_pointA][pairAB_A_nb_new]
                # cross_sim_BA_sp = current_descB @ current_descA.transpose(0, 1)
                cross_sim_AB_out_sp = torch.cat((cross_sim_AB_sp, torch.ones((cross_sim_AB_sp.shape[0], 2), device=cross_sim_AB_sp.device) * 2), dim=-1)      # NA X (NB + 2)
                cross_sim_AB_out_nb_sp = torch.cat((cross_sim_AB_sp, torch.ones((cross_sim_AB_sp.shape[0], 2), device=cross_sim_AB_sp.device) * 2), dim=-1)      # NA X (NB + 2)
                # cross_sim_BA_out_sp = torch.cat((cross_sim_BA_sp, torch.ones((numB, 1), device=cross_sim_BA_sp.device)), dim=-1)      # NB X (NA + 1)
                # valid_indexesB = torch.tensor(list(range(numB)), device=self.device)[mask_pointB][pairBA_B]
                # print('1_2')
                cross_sim_AB_out_sp[valid_indexesA, -1] = novalid_cross_sim_AB_sp_mean
                cross_sim_AB_out_sp[valid_indexesA, -2] = crossAN_mean
                cross_sim_AB_out_nb_sp[valid_indexesA_nb, -1] = novalid_cross_sim_AB_sp_mean
                novalid_indexesA = torch.tensor(list(range(cross_sim_AB_sp.shape[0])), device=self.device)[cross_sim_AB_out_nb_sp[:, -1]==2]
                cross_sim_AB_out_sp[novalid_indexesA, -1] = valid_cross_sim_AB_sp_mean
                # nomatch对不增加negtives的均值bin
                cross_sim_AB_out_sp[novalid_indexesA, -2] = -1 # crossAN_mean # -1

                soft_cross_sim_AtoB_sp = F.softmax((cross_sim_AB_out_sp - 1) / t_des, dim=-1)
                # soft_cross_sim_BtoA = F.softmax((cross_sim_BA_out - 1) / t_des, dim=-1)
                # print('1_3')
                soft_valid_cross_sim_AB_sp = soft_cross_sim_AtoB_sp[mask_pointA, :-2][match_maskAB==1]
                # soft_valid_cross_sim_BA = soft_cross_sim_BtoA[mask_pointB, :-1][pairBA_B, pairBA_A]
                soft_novalid_cross_sim_AB_sp = soft_cross_sim_AtoB_sp[novalid_indexesA, -1]
                # soft_novalid_cross_sim_BA = soft_cross_sim_BtoA[cross_sim_BA_out[:, -1]==1, -1]
                log_soft_valid_cross_sim_AB_sp = -torch.log(soft_valid_cross_sim_AB_sp + eps) * (1 - dis_oriATB[match_maskAB==1] / self.ori_diff) * (1 - bin_distAB[mask_pointA, :][match_maskAB==1] / current_binA.shape[-1]) * (1 - key_disAB[match_maskAB==1].detach() / self.correspond)
                # log_soft_valid_cross_sim_BA = -torch.log(soft_valid_cross_sim_BA + eps)
                log_soft_novalid_cross_sim_AB_sp = -torch.log(soft_novalid_cross_sim_AB_sp + eps)
                # log_soft_novalid_cross_sim_BA = -torch.log(soft_novalid_cross_sim_BA + eps)
                dis_cross_sim_mean_sp = torch.sum(torch.cat((4*log_soft_valid_cross_sim_AB_sp, log_soft_novalid_cross_sim_AB_sp), dim=-1), dim=-1) / new_numA
                
                # PA VS PAB
                # match_mask_A = copy.deepcopy(mask_pointA)
                # match_mask_B = copy.deepcopy(mask_pointB)
                match_mask_A = torch.zeros(cross_sim_AB_sp.shape[0], device=self.device)
                match_mask_nb_A = torch.zeros(cross_sim_AB_sp.shape[0], device=self.device)
                valid_match_indexesA = torch.tensor(list(range(cross_sim_AB_sp.shape[0])), device=self.device)[mask_pointA][vmaskAH]
                valid_match_indexesA_nb = torch.tensor(list(range(cross_sim_AB_sp.shape[0])), device=self.device)[mask_pointA][vmaskAH_nb]
                match_mask_A[valid_match_indexesA] = 1
                match_mask_nb_A[valid_match_indexesA_nb] = 1

                match_mask_B = torch.zeros(cross_sim_AB_sp.shape[1], device=self.device)
                match_mask_nb_B = torch.zeros(cross_sim_AB_sp.shape[1], device=self.device)
                valid_match_indexesB = torch.tensor(list(range(cross_sim_AB_sp.shape[1])), device=self.device)[mask_pointB][vmaskBH]
                valid_match_indexesB_nb = torch.tensor(list(range(cross_sim_AB_sp.shape[1])), device=self.device)[mask_pointB][vmaskBH_nb]
                match_mask_B[valid_match_indexesB] = 1
                match_mask_nb_B[valid_match_indexesB_nb] = 1

                cross_sim_AB = current_descA @ desc_mapB[idx, :, :, :].view(-1, H * W)
                # cross_sim_AB = cross_sim_AB[mask_pointA, :]
                cross_sim_AB_all = F.grid_sample(cross_sim_AB.view(-1, H, W).unsqueeze(0),
                                                pntA_H_normalized[vmaskAH, :].detach().view(1, 1, -1, 2),
                                                mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NA x repeatNA
                valid_cross_sim_AB_mean = torch.trace(cross_sim_AB_all[match_mask_A==1, :]) / cross_sim_AB_all[match_mask_A==1, :].shape[0]
                # novalid_cross_sim_AB_mean = (torch.sum(torch.sum(cross_sim_AB.detach(), 1), 1) - valid_cross_sim_AB_mean * pairAB_A.shape[0]) / (new_numA * H * W - pairAB_A.shape[0])

                cross_sim_BA = current_descB @ desc_mapA[idx, :, :, :].view(-1, H * W)   # M x H x W
                # cross_sim_BA = cross_sim_BA[mask_pointB, :]
                cross_sim_BA_all = F.grid_sample(cross_sim_BA.view(-1, H, W).unsqueeze(0),
                                                pntB_invH_normalized[vmaskBH, :].detach().view(1, 1, -1, 2),
                                                mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NB x match_nB
                valid_cross_sim_BA_mean = torch.trace(cross_sim_BA_all[match_mask_B==1, :]) / cross_sim_BA_all[match_mask_B==1, :].shape[0]
                # novalid_cross_sim_BA_mean = (torch.sum(torch.sum(cross_sim_BA.detach(), 1), 1) - valid_cross_sim_BA_mean * pairBA_B.shape[0]) / (new_numB * H * W - pairBA_B.shape[0])

                cross_sim_AB_out = torch.cat((cross_sim_AB, torch.ones((cross_sim_AB.shape[0], 2), device=cross_sim_AB.device)), dim=-1)      # NA X (H X W + 2)
                cross_sim_BA_out = torch.cat((cross_sim_BA, torch.ones((cross_sim_BA.shape[0], 2), device=cross_sim_BA.device)), dim=-1)      # NB X (H X W + 2)
                # print(3)
                # cross_sim_AB_out[mask_pointA, -1] -= 1
                # cross_sim_BA_out[mask_pointB, -1] -= 1
                # cross_sim_AB_out[match_mask_A, -1] -= 1
                cross_sim_AB_out[match_mask_A==1, -1] = novalid_cross_sim_AB_sp_mean
                cross_sim_AB_out[match_mask_A==1, -2] = crossAN_mean
                cross_sim_AB_out[match_mask_nb_A==0, -1] = valid_cross_sim_AB_mean
                cross_sim_AB_out[match_mask_nb_A==0, -2] = -1 # crossAN_mean # -1

                cross_sim_BA_out[match_mask_B==1, -1] = novalid_cross_sim_BA_sp_mean
                cross_sim_BA_out[match_mask_B==1, -2] = crossBN_mean
                cross_sim_BA_out[match_mask_nb_B==0, -1] = valid_cross_sim_BA_mean
                cross_sim_BA_out[match_mask_nb_B==0, -2] = -1 # crossBN_mean # -1

                soft_cross_sim_AtoB = F.softmax((cross_sim_AB_out - 1) / t_des, dim=-1)         # NA X (H X W + 1)
                soft_cross_sim_BtoA = F.softmax((cross_sim_BA_out - 1) / t_des, dim=-1)         # NB X (H X W + 1)
                soft_cross_sim_AB_all = F.grid_sample(soft_cross_sim_AtoB[:, :-2].view(-1, H, W).unsqueeze(0),
                                                    pntA_H_normalized[vmaskAH, :].detach().view(1, 1, -1, 2),
                                                    mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NA x match_nA
                
                soft_cross_sim_BA_all = F.grid_sample(soft_cross_sim_BtoA[:, :-2].view(-1, H, W).unsqueeze(0),
                                                    pntB_invH_normalized[vmaskBH, :].detach().view(1, 1, -1, 2),
                                                    mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NB x match_nB
                # soft_valid_cross_sim_AB_all = soft_cross_sim_AB_all[mask_pointA, :]             # repeat_nA x repeat_nA
                # soft_valid_cross_sim_BA_all = soft_cross_sim_BA_all[mask_pointB, :]             # repeat_nB x repeat_nB

                soft_valid_cross_sim_AB_all = soft_cross_sim_AB_all[match_mask_A==1, :]             # match_nA x match_nA
                soft_valid_cross_sim_BA_all = soft_cross_sim_BA_all[match_mask_B==1, :]             # match_nB x match_nB

                valid_mask_AB = torch.eye(soft_valid_cross_sim_AB_all.shape[0]) == 1
                valid_mask_BA = torch.eye(soft_valid_cross_sim_BA_all.shape[0]) == 1
                # print(4)
                # 取对角线
                soft_valid_cross_sim_AB = soft_valid_cross_sim_AB_all[valid_mask_AB]
                soft_valid_cross_sim_BA = soft_valid_cross_sim_BA_all[valid_mask_BA]

                # soft_novalid_cross_sim_AB = soft_cross_sim_AtoB[mask_pointA==False, -1]              # (NA-repeat_nA) x 1
                # soft_novalid_cross_sim_BA = soft_cross_sim_BtoA[mask_pointB==False, -1]
                soft_novalid_cross_sim_AB = soft_cross_sim_AtoB[match_mask_nb_A==0, -1]               # (NA-match_nA) x 1
                soft_novalid_cross_sim_BA = soft_cross_sim_BtoA[match_mask_nb_B==0, -1]
                # print(soft_novalid_cross_sim_AB, soft_novalid_cross_sim_BA)

                log_soft_valid_cross_sim_AB = -torch.log(soft_valid_cross_sim_AB + eps) * (1 - torch.diag(dis_oriATAB)[vmaskAH] / self.ori_diff) * (1 - torch.diag(bin_distATAB[mask_pointA, :])[vmaskAH] / bin_kpAB_T.shape[0])
                log_soft_valid_cross_sim_BA = -torch.log(soft_valid_cross_sim_BA + eps) * (1 - torch.diag(dis_oriBTBA)[vmaskBH] / self.ori_diff) * (1 - torch.diag(bin_distBTBA[mask_pointB, :])[vmaskBH] / bin_kpBA_T.shape[0])
                log_soft_novalid_cross_sim_AB = -torch.log(soft_novalid_cross_sim_AB + eps)
                log_soft_novalid_cross_sim_BA = -torch.log(soft_novalid_cross_sim_BA + eps)

                dis_cross_sim_mean = torch.sum(torch.cat((4*log_soft_valid_cross_sim_AB, 4*log_soft_valid_cross_sim_BA, log_soft_novalid_cross_sim_AB, log_soft_novalid_cross_sim_BA), dim=-1), dim=-1) / (new_numA + new_numB)
                
                # print(5)
                valid_cross_sim_AB = cross_sim_AB[mask_pointA, :]   # repeat_nA x (H X W)
                valid_cross_sim_BA = cross_sim_BA[mask_pointB, :]   # repeat_nB x (H X W)
                exp_valid_cross_sim_AtoB = torch.exp((valid_cross_sim_AB - 1) / t_rel).view(-1, H, W)
                exp_valid_cross_sim_BtoA = torch.exp((valid_cross_sim_BA - 1) / t_rel).view(-1, H, W)
                exp_valid_cross_sim_AB_all = F.grid_sample(exp_valid_cross_sim_AtoB.unsqueeze(0),
                                                        pntA_H_normalized.detach().view(1, 1, -1, 2),
                                                        mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # repeat_nA x repeat_nA
                
                exp_valid_cross_sim_BA_all = F.grid_sample(exp_valid_cross_sim_BtoA.unsqueeze(0),
                                                        pntB_invH_normalized.detach().view(1, 1, -1, 2),
                                                        mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # repeat_nB x repeat_nB

                repeat_mask_AB = torch.eye(exp_valid_cross_sim_AB_all.shape[0]) == 1
                repeat_mask_BA = torch.eye(exp_valid_cross_sim_BA_all.shape[0]) == 1
                rel_valid_cross_sim_AB = exp_valid_cross_sim_AB_all[repeat_mask_AB]
                rel_valid_cross_sim_BA = exp_valid_cross_sim_BA_all[repeat_mask_BA]

                # pntA_H_normalized_new = copy.deepcopy(pntA_H_normalized.detach())
                # pntB_invH_normalized_new = copy.deepcopy(pntB_invH_normalized.detach())

                # pntA_H_normalized_new[:, 0] += 2
                # pntB_invH_normalized_new[:, 0] += 2

                scoresAB_all = F.grid_sample(scores_mapB[idx, :, :, :].unsqueeze(0),
                                            pntA_H_normalized_new.view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)      # 1 x repeat_nA

                scoresBA_all = F.grid_sample(scores_mapA[idx, :, :, :].unsqueeze(0),
                                            pntB_invH_normalized_new.view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)      # 1 x repeat_nB
                # print(6)
                scores_AAB = scoresA[idx][pmA][mask_pointA] * scoresAB_all
                scores_BBA = scoresB[idx][pmB][mask_pointB] * scoresBA_all
                scores_sum_AAB = torch.sum(scores_AAB, dim=-1)
                scores_sum_BBA = torch.sum(scores_BBA, dim=-1)
                scores_normalize_AAB = scores_AAB / (scores_sum_AAB + eps)
                scores_normalize_BBA = scores_BBA / (scores_sum_BBA + eps)
                rel_meanA = torch.sum(scores_normalize_AAB * (1 - rel_valid_cross_sim_AB), dim=-1) / pntA_H_normalized_new.shape[0]
                rel_meanB = torch.sum(scores_normalize_BBA * (1 - rel_valid_cross_sim_BA), dim=-1) / pntB_invH_normalized_new.shape[0]

                # # 熵loss
                # current_descA_std, current_descB_std = descA_std[countA:countA+new_numA], descB_std[countB:countB+new_numB]
                # desc_std += torch.mean(current_descA_std) + torch.mean(current_descB_std)
                # countA_T += numA_T
                # countB_T += numB_T

                # KD_loss

                # soft_cross_sim_KDA_sp = F.softmax((cross_sim_KDA_sp - 1) / t_kd, dim=-1)   # NTA X NTA
                # soft_cross_sim_KDB_sp = F.softmax((cross_sim_KDB_sp - 1) / t_kd, dim=-1)   # NTB X NTB
                # log_soft_valid_cross_sim_KDA = -torch.log(soft_cross_sim_KDA_sp + eps)
                # log_soft_valid_cross_sim_KDB = -torch.log(soft_cross_sim_KDB_sp + eps)

                # Dual-Softmax
                DS_scores_KDA = dual_softmax(cross_sim_KDA_sp.unsqueeze(0)).squeeze(0)
                DS_scores_KDB = dual_softmax(cross_sim_KDB_sp.unsqueeze(0)).squeeze(0)
                dis_cross_sim_KD += -(torch.trace(DS_scores_KDA) + torch.trace(DS_scores_KDB)) / (new_numA + new_numB)


                dis_neighbor_mean_total += torch.mean(torch.sum(neighbor_dis_AB, dim=1)) + torch.mean(torch.sum(neighbor_dis_BA, dim=1))
                dis_desc += dis_cross_sim_mean_sp
                dis_desc += dis_cross_sim_mean

                dis_pair_meanAB = torch.mean(key_manhattandisAB[pairAB_A, pairAB_B])
                dis_pair_meanBA = torch.mean(key_manhattandisBA[pairBA_B, pairBA_A])

                dis_peak_mean = torch.mean(torch.cat((scoreddisA[idx][pmA], scoreddisB[idx][pmB]), dim=0))
                # dis_peak_meanB = torch.mean(scoreddisB[idx])
                
                dis_mean_total += dis_pair_meanAB + dis_pair_meanBA
                dis_peak_scored += dis_peak_mean

                dis_rel += rel_meanA + rel_meanB
                
                countA += new_numA
                countB += new_numB
                count_ne += new_num_ne
                # # Penalty
                # scores_mean += (-torch.log(torch.mean(scoresA[idx], dim=-1) + eps) - torch.log(torch.mean(scoresB[idx], dim=-1) + eps)) 
                # print(scores_mean)
            except:
                # dis_mean_total += 0
                # dis_peak_scored += 0
                # dis_desc += 0
                # dis_rel += 0
                # print('Overlapping too small or Repeatable point pairs distance is greater than correspond(1.5):', pntA.shape[0], pntA_H.shape[0], pntB.shape[0], pntB_invH.shape[0], dis_pairAB.shape[0], dis_pairBA.shape[0])
                valid_batch_size -= 1
                countA += new_numA
                countB += new_numB
                count_ne += new_num_ne
                # countA_T += numA_T
                # countB_T += numB_T

        valid_batch_size = valid_batch_size if valid_batch_size > 0 else eps
        # Reprojection Loss 
        reprojection_loss = dis_mean_total / (valid_batch_size * 2)
        # Dispersity Peak Loss
        dispersity_peak_loss = dis_peak_scored / valid_batch_size
        # NRE Loss
        descriptor_loss = dis_desc / (2 * valid_batch_size)
        # Reliability Loss
        reliability_loss = dis_rel / (valid_batch_size * 2)
        # SOSR Loss
        sosr_loss = dis_neighbor_mean_total / ((valid_batch_size * 2))
        # # Entropy loss
        # std_loss = (valid_batch_size * 2) / desc_std  
        # # Score Penalty
        # score_penalty = scores_mean / (valid_batch_size * 2)
        # # FA Desc loss
        # FA_des_loss = dis_desc_fa / valid_batch_size_FA if valid_batch_size_FA > 0 else 0
        # KD_loss
        KD_loss = dis_cross_sim_KD / valid_batch_size

        loss_total = wrp * reprojection_loss + wpl * dispersity_peak_loss + wdl * descriptor_loss + wrl * reliability_loss + sosr_loss + KD_loss
        loss_group = {
            'reprojection_loss': reprojection_loss, 
            'dispersity_peak_loss': dispersity_peak_loss,
            'descriptor_loss': descriptor_loss,
            'reliability_loss': reliability_loss,
            'sosr_loss': sosr_loss,
            # 'std_loss': std_loss,
            # 'FA_des_loss': FA_des_loss,
            'KD_loss': KD_loss,
            }
        return loss_total, loss_group


    # patch/dense AT角度 黑白相似度加量化 NFA negtives NRL
    def detector_selfsupervised_loss_dkd_patch_ext_restrict_modify_oriR_ratio_NFA_qtbw_ns_wg_nori_AT_NE_NRL(self, kpA, kpB, pmaskA, pmaskB, descA, descB, desc_mapA, desc_mapB, scoreddisA, scoreddisB, scoresA, scoresB, scores_mapA, scores_mapB, Homo, inv_Homo, inv_Homo_en, ori_all_patchA, ori_all_patchB, ori_kp_patchA, ori_kp_patchB, bin_allA, bin_allB, bin_kpA, bin_kpB, kp_ne, pmask_ne, desc_ne, bin_kp_ne, trans_angle, FA_flag, H, W, wrp=1, wpl=1, wdl=1, wrl=1, t_des=0.02, t_rel=1):
        # pmaskA: (BxMax_num) 32x350=11200
        batch_size = len(kpA)
        max_num = pmaskA.shape[-1] // batch_size    # 350
        dis_mean_total = 0
        dis_neighbor_mean_total = 0
        dis_peak_scored = 0
        dis_desc = 0
        dis_rel = 0
        desc_std = 0
        eps = 1e-12
        valid_batch_size = batch_size
        # valid_batch_size_FA = 0
        countA, countB, count_ne = 0, 0, 0
        # dis_desc_fa = 0
        # countA_T, countB_T = 0, 0
        for idx in range(batch_size):
            pntA, pntB, pnt_ne = kpA[idx], kpB[idx], kp_ne[idx]     # M X 2 (x,y)
            # kmask_TA, kmask_TB = kmask_T_allA[idx], kmask_T_allB[idx]
            pntA = pntA.float()
            pntB = pntB.float()
            pnt_ne = pnt_ne.float()

            # 剔除部分按压区域的点,且保留在重叠区域的点
            numA, numB, num_ne = pntA.shape[0], pntB.shape[0], pnt_ne.shape[0]
            # numA_T, numB_T = pntA[kmask_TA].shape[0], pntB[kmask_TB].shape[0]
            pmA, pmB, pm_ne = pmaskA[max_num * idx:max_num * idx + numA].bool(), pmaskB[max_num * idx:max_num * idx + numB].bool(), pmask_ne[max_num * idx:max_num * idx + num_ne].bool()
            pntA, pntB, pnt_ne = pntA[pmA, :], pntB[pmB, :], pnt_ne[pm_ne, :]
            new_numA, new_numB, new_num_ne = pntA.shape[0], pntB.shape[0], pnt_ne.shape[0]       
            
            pntA = (pntA + 1) / 2 * pntA.new_tensor([[W + 3, H - 1]]).to(pntA.device)
            pntB = (pntB + 1) / 2 * pntB.new_tensor([[W + 3, H - 1]]).to(pntB.device)

            # [120, 40] -> [120, 36],实际只取中心118x32区域的点对
            pntA[:, 0] -= 2
            pntB[:, 0] -= 2
            
            pntA_normalized = pntA / pntA.new_tensor([W - 1, H - 1]).to(pntA.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)
            pntB_normalized = pntB / pntB.new_tensor([W - 1, H - 1]).to(pntB.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)

            pntA_H = warp_points(pntA[:, :2], Homo[idx].squeeze(), device=self.device)  # 利用变换矩阵变换坐标点
            pntA_H, mask_pointA = filter_points(pntA_H, torch.tensor([W, H], device=self.device), return_mask=True)
            pntB_invH = warp_points(pntB[:, :2], inv_Homo[idx].squeeze(), device=self.device)
            pntB_invH, mask_pointB = filter_points(pntB_invH, torch.tensor([W, H], device=self.device), return_mask=True)
            
            current_descA, current_descB = descA[countA:countA+new_numA], descB[countB:countB+new_numB]
            current_desc_ne = desc_ne[count_ne:count_ne+new_num_ne]
            cross_sim_AB_sp = current_descA @ current_descB.transpose(0, 1)     # NTA X NTB
            
            cross_sim_AN_sp = current_descA @ current_desc_ne.transpose(0, 1)
            cross_sim_BN_sp = current_descB @ current_desc_ne.transpose(0, 1)
            
            # 黑白相似度
            current_binA, current_binB = (bin_kpA[countA:countA+new_numA] >= 0.5).float(), (bin_kpB[countB:countB+new_numB] >= 0.5).float()   # [NA, 256] [NB_256]
            current_bin_ne = (bin_kp_ne[count_ne:count_ne+new_num_ne] >= 0.5).float()
            bin_distAB = current_binA.shape[-1] - (current_binA @ current_binB.transpose(0, 1)) - ((1 - current_binA) @ (1 - current_binB.transpose(0, 1))) # [NA, NB]
            
            bin_distAN = current_binA.shape[-1] - (current_binA @ current_bin_ne.transpose(0, 1)) - ((1 - current_binA) @ (1 - current_bin_ne.transpose(0, 1))) # [NA, NE]
            bin_distBN = current_binB.shape[-1] - (current_binB @ current_bin_ne.transpose(0, 1)) - ((1 - current_binB) @ (1 - current_bin_ne.transpose(0, 1))) # [NA, NE]
            
            # 真匹配的trans
            try:
                FAN_bin_mask = bin_distAN >= (1 - self.FA_bin_thr) * current_binA.shape[-1] 
                FBN_bin_mask = bin_distBN >= (1 - self.FA_bin_thr) * current_binB.shape[-1] 
                # topk ?
                crossAN_mean = torch.mean(cross_sim_AN_sp[FAN_bin_mask])
                crossBN_mean = torch.mean(cross_sim_BN_sp[FBN_bin_mask])

                assert pntA_H.shape[0] > 0 and pntB_invH.shape[0] > 0 
                
                # 点对欧氏距离
                key_disAB = self.get_dis(pntA_H[:, :2], pntB[:, :2])            # repeatNA x NB
                key_disBA = self.get_dis(pntB_invH[:, :2], pntA[:, :2])
                pairAB_A, pairAB_B, dis_pairAB, _ = self.get_point_pair(key_disAB, dis_thre=self.correspond)  # p -> k # NTA(<1.5), NTA(<1.5), NTA(<1.5), NTA        
                pairBA_B, pairBA_A, dis_pairBA, _  = self.get_point_pair(key_disBA, dis_thre=self.correspond)  # p -> k # NTB(<1.5), NTB(<1.5), NTB(<1.5), NTB 
                
                # 点距离mask
                nn_maskAB = torch.zeros((pntA_H.shape[0], pntB.shape[0]), device=self.device) 
                nn_maskAB[pairAB_A, pairAB_B] = 1

                nn_maskBA = torch.zeros((pntB_invH.shape[0], pntA.shape[0]), device=self.device) 
                nn_maskBA[pairBA_B, pairBA_A] = 1

                # 点对曼哈顿距离
                key_manhattandisAB = self.get_manhattan_dis(pntA_H[:, :2], pntB[:, :2])
                key_manhattandisBA = self.get_manhattan_dis(pntB_invH[:, :2], pntA[:, :2])
                # print('pdis:', dis_pairAB.shape[0], dis_pairBA.shape[0])
                assert dis_pairAB.shape[0] > 0 and dis_pairBA.shape[0] > 0     

                pntA_H_normalized = pntA_H / pntA_H.new_tensor([W - 1, H - 1]).to(pntA_H.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)
                pntB_invH_normalized = pntB_invH / pntB_invH.new_tensor([W - 1, H - 1]).to(pntB_invH.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)

                # 用于score_map
                pntA_H_new = copy.deepcopy(pntA_H.detach())
                pntB_invH_new = copy.deepcopy(pntB_invH.detach())
                pntA_H_new[:, 0] += 10                   # 120 x 36 -> 128 x 56
                pntA_H_new[:, 1] += 4 
                pntB_invH_new[:, 0] += 10
                pntB_invH_new[:, 1] += 4
                
                pntA_H_normalized_new = pntA_H_new / pntA_H_new.new_tensor([W + 19, H + 7]).to(pntA_H.device) * 2 - 1

                # pntB_invH_new = warp_points(pntB_invH_new[:, :2], inv_Homo_en[idx].squeeze(), device=self.device)       # 转到A上，而不是AT上
                
                pntB_invH_normalized_new = pntB_invH_new / pntB_invH_new.new_tensor([W + 19, H + 7]).to(pntB_invH.device) * 2 - 1 
                
                # print('1_2:', main_ori_maskATB.shape[0])
                # exit()
                ori_kpAT_patch_ext = F.grid_sample(ori_kp_patchA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntA_H_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0).transpose(0, 1)          # repeatNA x 1
                ori_kpB_patch_ext = F.grid_sample(ori_all_patchB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntB_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0).transpose(0, 1)          # NTB x 1
                ori_kpA_patch_ext = F.grid_sample(ori_all_patchA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntA_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0).transpose(0, 1)          # NTA x 1
                ori_kpBT_patch_ext = F.grid_sample(ori_kp_patchB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntB_invH_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0).transpose(0, 1)          # repeatNB x 1
                # print('1_2_1:', pntB_invH_normalized_new.shape[0])
                ori_maskATB, dis_oriATB = self.get_main_ori_consistence_AT(ori_kpAT_patch_ext, ori_kpB_patch_ext)  # repeatNA x NTB
                # print('1_2_2:', ori_maskATB.shape)
                ori_maskBTA, dis_oriBTA = self.get_main_ori_consistence_AT(ori_kpBT_patch_ext, ori_kpA_patch_ext)  # repeatNB x NTA

                match_maskAB_nb = (nn_maskAB == 1) * ori_maskATB           # repeatNA X NTB
                match_maskBA_nb = (nn_maskBA == 1) * ori_maskBTA          # repeatNB X NTA
                pairAB_A_nb_new, pairAB_B_nb_new = torch.where(match_maskAB_nb == 1)
                pairBA_B_nb_new, pairBA_A_nb_new = torch.where(match_maskBA_nb == 1)
                # assert pairAB_A_new.shape[0] > 0 and pairBA_B_new.shape[0] > 0 

                # 4x4邻域方向一致性
                ori_kpAB_patch_ext = F.grid_sample(ori_all_patchB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntA_H_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0).transpose(0, 1)  
                ori_kpBA_patch_ext = F.grid_sample(ori_all_patchA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntB_invH_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0).transpose(0, 1)  
                # print('1_2_4:', ori_kpAB_patch_ext.shape)
                ori_maskATAB, dis_oriATAB = self.get_main_ori_consistence_AT(ori_kpAT_patch_ext, ori_kpAB_patch_ext)  # repeatNA x repeatNA
                ori_maskBTBA, dis_oriBTBA = self.get_main_ori_consistence_AT(ori_kpBT_patch_ext, ori_kpBA_patch_ext)  # repeatNB x repeatNB
                
                # 黑白相似度
                bin_maskATB = bin_distAB <= (1 - self.FR_bin_thr) * current_binA.shape[-1]  
                bin_maskBTA = bin_maskATB.transpose(0, 1)  

                match_maskAB = match_maskAB_nb * bin_maskATB[mask_pointA, :]               # repeatNA X NB
                match_maskBA = match_maskBA_nb * bin_maskBTA[mask_pointB, :]               # repeatNB X NA

                pairAB_A_new, pairAB_B_new = torch.where(match_maskAB == 1)
                pairBA_B_new, pairBA_A_new = torch.where(match_maskBA == 1)
                # print('bin_mask:', pairAB_A_new.shape[0], pairBA_B_new.shape[0])
                assert pairAB_A_new.shape[0] > 0 and pairBA_B_new.shape[0] > 0 

                bin_kpAB_T = (F.grid_sample(bin_allB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntA_H_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0) >= 0.5).float()  # [256, repeatNA]
                bin_kpBA_T = (F.grid_sample(bin_allA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntB_invH_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0) >= 0.5).float()  # [256, repeatNB]
                bin_distATAB = bin_kpAB_T.shape[0] - (current_binA @ bin_kpAB_T) - ((1 - current_binA) @ (1 - bin_kpAB_T)) # [NTA, repeatNA]
                bin_distBTBA = bin_kpBA_T.shape[0] - (current_binB @ bin_kpBA_T) - ((1 - current_binB) @ (1 - bin_kpBA_T)) # [NTB, repeatNB]

                bin_maskATAB = bin_distATAB <= (1 - self.FR_bin_thr) * bin_kpAB_T.shape[0] 
                bin_maskBTBA = bin_distBTBA <= (1 - self.FR_bin_thr) * bin_kpBA_T.shape[0] 
                bin_maskATAB = bin_maskATAB[mask_pointA, :]
                bin_maskBTBA = bin_maskBTBA[mask_pointB, :]

                vmaskAH_nb = torch.diag(ori_maskATAB)
                vmaskBH_nb = torch.diag(ori_maskBTBA)
                vmaskAH = torch.diag(ori_maskATAB * bin_maskATAB) == 1      # [repeatNA, 1]
                vmaskBH = torch.diag(ori_maskBTBA * bin_maskBTBA) == 1      # [repeatNB, 1]

                # print('main_ori:', torch.sum(vmaskAH), torch.sum(vmaskBH))
                assert torch.sum(vmaskAH) > 0 and torch.sum(vmaskBH) > 0

                # SOSR: 简化的self-attention
                k_neighbor = 3
                cross_sim_AA_sp = current_descA @ current_descA.transpose(0, 1)
                cross_sim_BB_sp = current_descB @ current_descB.transpose(0, 1)
                # print('SOSR:', pairAB_A_new.shape[0], pairBA_B_new.shape[0])
                assert pairAB_A_new.shape[0] >= k_neighbor and pairBA_B_new.shape[0] >= k_neighbor 

                match_sim_AB_AA = cross_sim_AA_sp[mask_pointA, :][:, mask_pointA][pairAB_A_new, :][:, pairAB_A_new]
                match_sim_BA_BB = cross_sim_BB_sp[mask_pointB, :][:, mask_pointB][pairBA_B_new, :][:, pairBA_B_new]
                match_sim_AB_BB = cross_sim_BB_sp[pairAB_B_new, :][:, pairAB_B_new]
                match_sim_BA_AA = cross_sim_AA_sp[pairBA_A_new, :][:, pairBA_A_new]
                match_values_AB_AA, match_indices_AB_AA = torch.topk(match_sim_AB_AA, dim=1, k=k_neighbor, largest=False)
                match_values_BA_BB, match_indices_BA_BB = torch.topk(match_sim_BA_BB, dim=1, k=k_neighbor, largest=False)
                match_values_AB_BB_all = match_sim_AB_BB[:, match_indices_AB_AA]
                match_values_BA_AA_all = match_sim_BA_AA[:, match_indices_BA_BB]
                match_values_AB_BB = torch.diagonal(match_values_AB_BB_all, 0, dim1=0, dim2=1).transpose(0, 1)
                match_values_BA_AA = torch.diagonal(match_values_BA_AA_all, 0, dim1=0, dim2=1).transpose(0, 1)
                neighbor_dis_AB = (match_values_AB_AA - match_values_AB_BB) * (match_values_AB_AA - match_values_AB_BB)
                neighbor_dis_BA = (match_values_BA_BB - match_values_BA_AA) * (match_values_BA_BB - match_values_BA_AA)

                # PA VS PB
                # 计算bin值
                valid_cross_sim_AB_sp_mean = torch.mean(cross_sim_AB_sp[mask_pointA, :][match_maskAB == 1], dim=-1)
                valid_cross_sim_AB_sp_nb_mean = torch.mean(cross_sim_AB_sp[mask_pointA, :][match_maskAB_nb == 1], dim=-1)
                novalid_cross_sim_AB_sp_mean = (torch.sum(torch.sum(cross_sim_AB_sp.detach(), 1), 0) - valid_cross_sim_AB_sp_nb_mean * pairAB_A_nb_new.shape[0]) / (new_numA * new_numB - pairAB_A_nb_new.shape[0] + eps)
                valid_cross_sim_BA_sp_mean = torch.mean(cross_sim_AB_sp[:, mask_pointB][match_maskBA.transpose(0, 1) == 1], dim=-1)
                valid_cross_sim_BA_sp_nb_mean = torch.mean(cross_sim_AB_sp[:, mask_pointB][match_maskBA_nb.transpose(0, 1) == 1], dim=-1)
                novalid_cross_sim_BA_sp_mean = (torch.sum(torch.sum(cross_sim_AB_sp.detach(), 1), 0) - valid_cross_sim_BA_sp_nb_mean * pairBA_B_nb_new.shape[0]) / (new_numA * new_numB - pairBA_B_nb_new.shape[0] + eps)

                valid_indexesA = torch.tensor(list(range(cross_sim_AB_sp.shape[0])), device=self.device)[mask_pointA][pairAB_A_new]
                valid_indexesA_nb = torch.tensor(list(range(cross_sim_AB_sp.shape[0])), device=self.device)[mask_pointA][pairAB_A_nb_new]
                # cross_sim_BA_sp = current_descB @ current_descA.transpose(0, 1)
                cross_sim_AB_out_sp = torch.cat((cross_sim_AB_sp, torch.ones((cross_sim_AB_sp.shape[0], 2), device=cross_sim_AB_sp.device) * 2), dim=-1)      # NA X (NB + 2)
                cross_sim_AB_out_nb_sp = torch.cat((cross_sim_AB_sp, torch.ones((cross_sim_AB_sp.shape[0], 2), device=cross_sim_AB_sp.device) * 2), dim=-1)      # NA X (NB + 2)
                # cross_sim_BA_out_sp = torch.cat((cross_sim_BA_sp, torch.ones((numB, 1), device=cross_sim_BA_sp.device)), dim=-1)      # NB X (NA + 1)
                # valid_indexesB = torch.tensor(list(range(numB)), device=self.device)[mask_pointB][pairBA_B]
                # print('1_2')
                cross_sim_AB_out_sp[valid_indexesA, -1] = novalid_cross_sim_AB_sp_mean
                cross_sim_AB_out_sp[valid_indexesA, -2] = crossAN_mean
                cross_sim_AB_out_nb_sp[valid_indexesA_nb, -1] = novalid_cross_sim_AB_sp_mean
                novalid_indexesA = torch.tensor(list(range(cross_sim_AB_sp.shape[0])), device=self.device)[cross_sim_AB_out_nb_sp[:, -1]==2]
                cross_sim_AB_out_sp[novalid_indexesA, -1] = valid_cross_sim_AB_sp_mean
                # nomatch对不增加negtives的均值bin
                cross_sim_AB_out_sp[novalid_indexesA, -2] = -1 # crossAN_mean # -1

                soft_cross_sim_AtoB_sp = F.softmax((cross_sim_AB_out_sp - 1) / t_des, dim=-1)
                # soft_cross_sim_BtoA = F.softmax((cross_sim_BA_out - 1) / t_des, dim=-1)
                # print('1_3')
                soft_valid_cross_sim_AB_sp = soft_cross_sim_AtoB_sp[mask_pointA, :-2][match_maskAB==1]
                # soft_valid_cross_sim_BA = soft_cross_sim_BtoA[mask_pointB, :-1][pairBA_B, pairBA_A]
                soft_novalid_cross_sim_AB_sp = soft_cross_sim_AtoB_sp[novalid_indexesA, -1]
                # soft_novalid_cross_sim_BA = soft_cross_sim_BtoA[cross_sim_BA_out[:, -1]==1, -1]
                log_soft_valid_cross_sim_AB_sp = -torch.log(soft_valid_cross_sim_AB_sp + eps) * (1 - dis_oriATB[match_maskAB==1] / self.ori_diff) * (1 - bin_distAB[mask_pointA, :][match_maskAB==1] / current_binA.shape[-1]) * (1 - key_disAB[match_maskAB==1].detach() / self.correspond)
                # log_soft_valid_cross_sim_BA = -torch.log(soft_valid_cross_sim_BA + eps)
                log_soft_novalid_cross_sim_AB_sp = -torch.log(soft_novalid_cross_sim_AB_sp + eps)
                # log_soft_novalid_cross_sim_BA = -torch.log(soft_novalid_cross_sim_BA + eps)
                dis_cross_sim_mean_sp = torch.sum(torch.cat((4*log_soft_valid_cross_sim_AB_sp, log_soft_novalid_cross_sim_AB_sp), dim=-1), dim=-1) / new_numA
                
                # PA VS PAB
                # match_mask_A = copy.deepcopy(mask_pointA)
                # match_mask_B = copy.deepcopy(mask_pointB)
                match_mask_A = torch.zeros(cross_sim_AB_sp.shape[0], device=self.device)
                match_mask_nb_A = torch.zeros(cross_sim_AB_sp.shape[0], device=self.device)
                valid_match_indexesA = torch.tensor(list(range(cross_sim_AB_sp.shape[0])), device=self.device)[mask_pointA][vmaskAH]
                valid_match_indexesA_nb = torch.tensor(list(range(cross_sim_AB_sp.shape[0])), device=self.device)[mask_pointA][vmaskAH_nb]
                match_mask_A[valid_match_indexesA] = 1
                match_mask_nb_A[valid_match_indexesA_nb] = 1

                match_mask_B = torch.zeros(cross_sim_AB_sp.shape[1], device=self.device)
                match_mask_nb_B = torch.zeros(cross_sim_AB_sp.shape[1], device=self.device)
                valid_match_indexesB = torch.tensor(list(range(cross_sim_AB_sp.shape[1])), device=self.device)[mask_pointB][vmaskBH]
                valid_match_indexesB_nb = torch.tensor(list(range(cross_sim_AB_sp.shape[1])), device=self.device)[mask_pointB][vmaskBH_nb]
                match_mask_B[valid_match_indexesB] = 1
                match_mask_nb_B[valid_match_indexesB_nb] = 1

                cross_sim_AB = current_descA @ desc_mapB[idx, :, :, :].view(-1, H * W)
                # cross_sim_AB = cross_sim_AB[mask_pointA, :]
                cross_sim_AB_all = F.grid_sample(cross_sim_AB.view(-1, H, W).unsqueeze(0),
                                                pntA_H_normalized[vmaskAH, :].detach().view(1, 1, -1, 2),
                                                mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NA x repeatNA
                valid_cross_sim_AB_mean = torch.trace(cross_sim_AB_all[match_mask_A==1, :]) / cross_sim_AB_all[match_mask_A==1, :].shape[0]
                # novalid_cross_sim_AB_mean = (torch.sum(torch.sum(cross_sim_AB.detach(), 1), 1) - valid_cross_sim_AB_mean * pairAB_A.shape[0]) / (new_numA * H * W - pairAB_A.shape[0])

                cross_sim_BA = current_descB @ desc_mapA[idx, :, :, :].view(-1, H * W)   # M x H x W
                # cross_sim_BA = cross_sim_BA[mask_pointB, :]
                cross_sim_BA_all = F.grid_sample(cross_sim_BA.view(-1, H, W).unsqueeze(0),
                                                pntB_invH_normalized[vmaskBH, :].detach().view(1, 1, -1, 2),
                                                mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NB x match_nB
                valid_cross_sim_BA_mean = torch.trace(cross_sim_BA_all[match_mask_B==1, :]) / cross_sim_BA_all[match_mask_B==1, :].shape[0]
                # novalid_cross_sim_BA_mean = (torch.sum(torch.sum(cross_sim_BA.detach(), 1), 1) - valid_cross_sim_BA_mean * pairBA_B.shape[0]) / (new_numB * H * W - pairBA_B.shape[0])

                cross_sim_AB_out = torch.cat((cross_sim_AB, torch.ones((cross_sim_AB.shape[0], 2), device=cross_sim_AB.device)), dim=-1)      # NA X (H X W + 2)
                cross_sim_BA_out = torch.cat((cross_sim_BA, torch.ones((cross_sim_BA.shape[0], 2), device=cross_sim_BA.device)), dim=-1)      # NB X (H X W + 2)
                # print(3)
                # cross_sim_AB_out[mask_pointA, -1] -= 1
                # cross_sim_BA_out[mask_pointB, -1] -= 1
                # cross_sim_AB_out[match_mask_A, -1] -= 1
                cross_sim_AB_out[match_mask_A==1, -1] = novalid_cross_sim_AB_sp_mean
                cross_sim_AB_out[match_mask_A==1, -2] = crossAN_mean
                cross_sim_AB_out[match_mask_nb_A==0, -1] = valid_cross_sim_AB_mean
                cross_sim_AB_out[match_mask_nb_A==0, -2] = -1 # crossAN_mean # -1

                cross_sim_BA_out[match_mask_B==1, -1] = novalid_cross_sim_BA_sp_mean
                cross_sim_BA_out[match_mask_B==1, -2] = crossBN_mean
                cross_sim_BA_out[match_mask_nb_B==0, -1] = valid_cross_sim_BA_mean
                cross_sim_BA_out[match_mask_nb_B==0, -2] = -1 # crossBN_mean # -1

                soft_cross_sim_AtoB = F.softmax((cross_sim_AB_out - 1) / t_des, dim=-1)         # NA X (H X W + 1)
                soft_cross_sim_BtoA = F.softmax((cross_sim_BA_out - 1) / t_des, dim=-1)         # NB X (H X W + 1)
                soft_cross_sim_AB_all = F.grid_sample(soft_cross_sim_AtoB[:, :-2].view(-1, H, W).unsqueeze(0),
                                                    pntA_H_normalized[vmaskAH, :].detach().view(1, 1, -1, 2),
                                                    mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NA x match_nA
                
                soft_cross_sim_BA_all = F.grid_sample(soft_cross_sim_BtoA[:, :-2].view(-1, H, W).unsqueeze(0),
                                                    pntB_invH_normalized[vmaskBH, :].detach().view(1, 1, -1, 2),
                                                    mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NB x match_nB
                # soft_valid_cross_sim_AB_all = soft_cross_sim_AB_all[mask_pointA, :]             # repeat_nA x repeat_nA
                # soft_valid_cross_sim_BA_all = soft_cross_sim_BA_all[mask_pointB, :]             # repeat_nB x repeat_nB

                soft_valid_cross_sim_AB_all = soft_cross_sim_AB_all[match_mask_A==1, :]             # match_nA x match_nA
                soft_valid_cross_sim_BA_all = soft_cross_sim_BA_all[match_mask_B==1, :]             # match_nB x match_nB

                valid_mask_AB = torch.eye(soft_valid_cross_sim_AB_all.shape[0]) == 1
                valid_mask_BA = torch.eye(soft_valid_cross_sim_BA_all.shape[0]) == 1
                # print(4)
                # 取对角线
                soft_valid_cross_sim_AB = soft_valid_cross_sim_AB_all[valid_mask_AB]
                soft_valid_cross_sim_BA = soft_valid_cross_sim_BA_all[valid_mask_BA]

                # soft_novalid_cross_sim_AB = soft_cross_sim_AtoB[mask_pointA==False, -1]              # (NA-repeat_nA) x 1
                # soft_novalid_cross_sim_BA = soft_cross_sim_BtoA[mask_pointB==False, -1]
                soft_novalid_cross_sim_AB = soft_cross_sim_AtoB[match_mask_nb_A==0, -1]               # (NA-match_nA) x 1
                soft_novalid_cross_sim_BA = soft_cross_sim_BtoA[match_mask_nb_B==0, -1]
                # print(soft_novalid_cross_sim_AB, soft_novalid_cross_sim_BA)

                log_soft_valid_cross_sim_AB = -torch.log(soft_valid_cross_sim_AB + eps) * (1 - torch.diag(dis_oriATAB)[vmaskAH] / self.ori_diff) * (1 - torch.diag(bin_distATAB[mask_pointA, :])[vmaskAH] / bin_kpAB_T.shape[0])
                log_soft_valid_cross_sim_BA = -torch.log(soft_valid_cross_sim_BA + eps) * (1 - torch.diag(dis_oriBTBA)[vmaskBH] / self.ori_diff) * (1 - torch.diag(bin_distBTBA[mask_pointB, :])[vmaskBH] / bin_kpBA_T.shape[0])
                log_soft_novalid_cross_sim_AB = -torch.log(soft_novalid_cross_sim_AB + eps)
                log_soft_novalid_cross_sim_BA = -torch.log(soft_novalid_cross_sim_BA + eps)

                dis_cross_sim_mean = torch.sum(torch.cat((4*log_soft_valid_cross_sim_AB, 4*log_soft_valid_cross_sim_BA, log_soft_novalid_cross_sim_AB, log_soft_novalid_cross_sim_BA), dim=-1), dim=-1) / (new_numA + new_numB)
                
                # print(5)
                valid_cross_sim_AB = cross_sim_AB[mask_pointA, :]   # repeat_nA x (H X W)
                valid_cross_sim_BA = cross_sim_BA[mask_pointB, :]   # repeat_nB x (H X W)
                exp_valid_cross_sim_AtoB = torch.exp((valid_cross_sim_AB - 1) / t_rel).view(-1, H, W)
                exp_valid_cross_sim_BtoA = torch.exp((valid_cross_sim_BA - 1) / t_rel).view(-1, H, W)
                exp_valid_cross_sim_AB_all = F.grid_sample(exp_valid_cross_sim_AtoB.unsqueeze(0),
                                                        pntA_H_normalized.detach().view(1, 1, -1, 2),
                                                        mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # repeat_nA x repeat_nA
                
                exp_valid_cross_sim_BA_all = F.grid_sample(exp_valid_cross_sim_BtoA.unsqueeze(0),
                                                        pntB_invH_normalized.detach().view(1, 1, -1, 2),
                                                        mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # repeat_nB x repeat_nB

                repeat_mask_AB = torch.eye(exp_valid_cross_sim_AB_all.shape[0]) == 1
                repeat_mask_BA = torch.eye(exp_valid_cross_sim_BA_all.shape[0]) == 1
                rel_valid_cross_sim_AB = exp_valid_cross_sim_AB_all[repeat_mask_AB]
                rel_valid_cross_sim_BA = exp_valid_cross_sim_BA_all[repeat_mask_BA]

                # pntA_H_normalized_new = copy.deepcopy(pntA_H_normalized.detach())
                # pntB_invH_normalized_new = copy.deepcopy(pntB_invH_normalized.detach())

                # pntA_H_normalized_new[:, 0] += 2
                # pntB_invH_normalized_new[:, 0] += 2

                scoresAB_all = F.grid_sample(scores_mapB[idx, :, :, :].unsqueeze(0),
                                            pntA_H_normalized_new.view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)      # 1 x repeat_nA

                scoresBA_all = F.grid_sample(scores_mapA[idx, :, :, :].unsqueeze(0),
                                            pntB_invH_normalized_new.view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)      # 1 x repeat_nB
                # print(6)
                scores_AAB = scoresA[idx][pmA][mask_pointA] * scoresAB_all
                scores_BBA = scoresB[idx][pmB][mask_pointB] * scoresBA_all
                scores_sum_AAB = torch.sum(scores_AAB, dim=-1)
                scores_sum_BBA = torch.sum(scores_BBA, dim=-1)
                scores_normalize_AAB = scores_AAB / (scores_sum_AAB + eps)
                scores_normalize_BBA = scores_BBA / (scores_sum_BBA + eps)
                rel_meanA = torch.sum(scores_normalize_AAB * (1 - rel_valid_cross_sim_AB), dim=-1) / pntA_H_normalized_new.shape[0]
                rel_meanB = torch.sum(scores_normalize_BBA * (1 - rel_valid_cross_sim_BA), dim=-1) / pntB_invH_normalized_new.shape[0]

                # # 熵loss
                # current_descA_std, current_descB_std = descA_std[countA:countA+new_numA], descB_std[countB:countB+new_numB]
                # desc_std += torch.mean(current_descA_std) + torch.mean(current_descB_std)
                # countA_T += numA_T
                # countB_T += numB_T

                dis_neighbor_mean_total += torch.mean(torch.sum(neighbor_dis_AB, dim=1)) + torch.mean(torch.sum(neighbor_dis_BA, dim=1))
                dis_desc += dis_cross_sim_mean_sp
                dis_desc += dis_cross_sim_mean

                dis_pair_meanAB = torch.mean(key_manhattandisAB[pairAB_A, pairAB_B])
                dis_pair_meanBA = torch.mean(key_manhattandisBA[pairBA_B, pairBA_A])

                dis_peak_mean = torch.mean(torch.cat((scoreddisA[idx][pmA], scoreddisB[idx][pmB]), dim=0))
                # dis_peak_meanB = torch.mean(scoreddisB[idx])
                
                dis_mean_total += dis_pair_meanAB + dis_pair_meanBA
                dis_peak_scored += dis_peak_mean

                dis_rel += rel_meanA + rel_meanB
                
                countA += new_numA
                countB += new_numB
                count_ne += new_num_ne
                # # Penalty
                # scores_mean += (-torch.log(torch.mean(scoresA[idx], dim=-1) + eps) - torch.log(torch.mean(scoresB[idx], dim=-1) + eps)) 
                # print(scores_mean)
            except:
                # dis_mean_total += 0
                # dis_peak_scored += 0
                # dis_desc += 0
                # dis_rel += 0
                # print('Overlapping too small or Repeatable point pairs distance is greater than correspond(1.5):', pntA.shape[0], pntA_H.shape[0], pntB.shape[0], pntB_invH.shape[0], dis_pairAB.shape[0], dis_pairBA.shape[0])
                valid_batch_size -= 1
                countA += new_numA
                countB += new_numB
                count_ne += new_num_ne
                # countA_T += numA_T
                # countB_T += numB_T

        valid_batch_size = valid_batch_size if valid_batch_size > 0 else eps
        # Reprojection Loss 
        reprojection_loss = dis_mean_total / (valid_batch_size * 2)
        # Dispersity Peak Loss
        dispersity_peak_loss = dis_peak_scored / valid_batch_size
        # NRE Loss
        descriptor_loss = dis_desc / (2 * valid_batch_size)
        # Reliability Loss
        reliability_loss = dis_rel / (valid_batch_size * 2)
        # SOSR Loss
        sosr_loss = dis_neighbor_mean_total / ((valid_batch_size * 2))
        # # Entropy loss
        # std_loss = (valid_batch_size * 2) / desc_std  
        # # Score Penalty
        # score_penalty = scores_mean / (valid_batch_size * 2)
        # # FA Desc loss
        # FA_des_loss = dis_desc_fa / valid_batch_size_FA if valid_batch_size_FA > 0 else 0

        loss_total = wrp * reprojection_loss + wpl * dispersity_peak_loss + wdl * descriptor_loss + sosr_loss
        loss_group = {
            'reprojection_loss': reprojection_loss, 
            'dispersity_peak_loss': dispersity_peak_loss,
            'descriptor_loss': descriptor_loss,
            # 'reliability_loss': reliability_loss,
            'sosr_loss': sosr_loss,
            # 'std_loss': std_loss,
            # 'FA_des_loss': FA_des_loss,
            }
        return loss_total, loss_group

    # patch/dense AT角度 黑白相似度加量化 NFA negtives NSR
    def detector_selfsupervised_loss_dkd_patch_ext_restrict_modify_oriR_ratio_NFA_qtbw_ns_wg_nori_AT_NE_NSR(self, kpA, kpB, pmaskA, pmaskB, descA, descB, desc_mapA, desc_mapB, scoreddisA, scoreddisB, scoresA, scoresB, scores_mapA, scores_mapB, Homo, inv_Homo, inv_Homo_en, ori_all_patchA, ori_all_patchB, ori_kp_patchA, ori_kp_patchB, bin_allA, bin_allB, bin_kpA, bin_kpB, kp_ne, pmask_ne, desc_ne, bin_kp_ne, trans_angle, FA_flag, H, W, wrp=1, wpl=1, wdl=1, wrl=1, t_des=0.02, t_rel=1):
        # pmaskA: (BxMax_num) 32x350=11200
        batch_size = len(kpA)
        max_num = pmaskA.shape[-1] // batch_size    # 350
        dis_mean_total = 0
        dis_neighbor_mean_total = 0
        dis_peak_scored = 0
        dis_desc = 0
        dis_rel = 0
        desc_std = 0
        eps = 1e-12
        valid_batch_size = batch_size
        # valid_batch_size_FA = 0
        countA, countB, count_ne = 0, 0, 0
        # dis_desc_fa = 0
        # countA_T, countB_T = 0, 0
        for idx in range(batch_size):
            pntA, pntB, pnt_ne = kpA[idx], kpB[idx], kp_ne[idx]     # M X 2 (x,y)
            # kmask_TA, kmask_TB = kmask_T_allA[idx], kmask_T_allB[idx]
            pntA = pntA.float()
            pntB = pntB.float()
            pnt_ne = pnt_ne.float()

            # 剔除部分按压区域的点,且保留在重叠区域的点
            numA, numB, num_ne = pntA.shape[0], pntB.shape[0], pnt_ne.shape[0]
            # numA_T, numB_T = pntA[kmask_TA].shape[0], pntB[kmask_TB].shape[0]
            pmA, pmB, pm_ne = pmaskA[max_num * idx:max_num * idx + numA].bool(), pmaskB[max_num * idx:max_num * idx + numB].bool(), pmask_ne[max_num * idx:max_num * idx + num_ne].bool()
            pntA, pntB, pnt_ne = pntA[pmA, :], pntB[pmB, :], pnt_ne[pm_ne, :]
            new_numA, new_numB, new_num_ne = pntA.shape[0], pntB.shape[0], pnt_ne.shape[0]       
            
            pntA = (pntA + 1) / 2 * pntA.new_tensor([[W + 3, H - 1]]).to(pntA.device)
            pntB = (pntB + 1) / 2 * pntB.new_tensor([[W + 3, H - 1]]).to(pntB.device)

            # [120, 40] -> [120, 36],实际只取中心118x32区域的点对
            pntA[:, 0] -= 2
            pntB[:, 0] -= 2
            
            pntA_normalized = pntA / pntA.new_tensor([W - 1, H - 1]).to(pntA.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)
            pntB_normalized = pntB / pntB.new_tensor([W - 1, H - 1]).to(pntB.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)

            pntA_H = warp_points(pntA[:, :2], Homo[idx].squeeze(), device=self.device)  # 利用变换矩阵变换坐标点
            pntA_H, mask_pointA = filter_points(pntA_H, torch.tensor([W, H], device=self.device), return_mask=True)
            pntB_invH = warp_points(pntB[:, :2], inv_Homo[idx].squeeze(), device=self.device)
            pntB_invH, mask_pointB = filter_points(pntB_invH, torch.tensor([W, H], device=self.device), return_mask=True)
            
            current_descA, current_descB = descA[countA:countA+new_numA], descB[countB:countB+new_numB]
            current_desc_ne = desc_ne[count_ne:count_ne+new_num_ne]
            cross_sim_AB_sp = current_descA @ current_descB.transpose(0, 1)     # NTA X NTB
            
            cross_sim_AN_sp = current_descA @ current_desc_ne.transpose(0, 1)
            cross_sim_BN_sp = current_descB @ current_desc_ne.transpose(0, 1)
            
            # 黑白相似度
            current_binA, current_binB = (bin_kpA[countA:countA+new_numA] >= 0.5).float(), (bin_kpB[countB:countB+new_numB] >= 0.5).float()   # [NA, 256] [NB_256]
            current_bin_ne = (bin_kp_ne[count_ne:count_ne+new_num_ne] >= 0.5).float()
            bin_distAB = current_binA.shape[-1] - (current_binA @ current_binB.transpose(0, 1)) - ((1 - current_binA) @ (1 - current_binB.transpose(0, 1))) # [NA, NB]
            
            bin_distAN = current_binA.shape[-1] - (current_binA @ current_bin_ne.transpose(0, 1)) - ((1 - current_binA) @ (1 - current_bin_ne.transpose(0, 1))) # [NA, NE]
            bin_distBN = current_binB.shape[-1] - (current_binB @ current_bin_ne.transpose(0, 1)) - ((1 - current_binB) @ (1 - current_bin_ne.transpose(0, 1))) # [NA, NE]
            
            # 真匹配的trans
            try:
                FAN_bin_mask = bin_distAN >= (1 - self.FA_bin_thr) * current_binA.shape[-1] 
                FBN_bin_mask = bin_distBN >= (1 - self.FA_bin_thr) * current_binB.shape[-1] 
                # topk ?
                crossAN_mean = torch.mean(cross_sim_AN_sp[FAN_bin_mask])
                crossBN_mean = torch.mean(cross_sim_BN_sp[FBN_bin_mask])

                assert pntA_H.shape[0] > 0 and pntB_invH.shape[0] > 0 
                
                # 点对欧氏距离
                key_disAB = self.get_dis(pntA_H[:, :2], pntB[:, :2])            # repeatNA x NB
                key_disBA = self.get_dis(pntB_invH[:, :2], pntA[:, :2])
                pairAB_A, pairAB_B, dis_pairAB, _ = self.get_point_pair(key_disAB, dis_thre=self.correspond)  # p -> k # NTA(<1.5), NTA(<1.5), NTA(<1.5), NTA        
                pairBA_B, pairBA_A, dis_pairBA, _  = self.get_point_pair(key_disBA, dis_thre=self.correspond)  # p -> k # NTB(<1.5), NTB(<1.5), NTB(<1.5), NTB 
                
                # 点距离mask
                nn_maskAB = torch.zeros((pntA_H.shape[0], pntB.shape[0]), device=self.device) 
                nn_maskAB[pairAB_A, pairAB_B] = 1

                nn_maskBA = torch.zeros((pntB_invH.shape[0], pntA.shape[0]), device=self.device) 
                nn_maskBA[pairBA_B, pairBA_A] = 1

                # 点对曼哈顿距离
                key_manhattandisAB = self.get_manhattan_dis(pntA_H[:, :2], pntB[:, :2])
                key_manhattandisBA = self.get_manhattan_dis(pntB_invH[:, :2], pntA[:, :2])
                # print('pdis:', dis_pairAB.shape[0], dis_pairBA.shape[0])
                assert dis_pairAB.shape[0] > 0 and dis_pairBA.shape[0] > 0     

                pntA_H_normalized = pntA_H / pntA_H.new_tensor([W - 1, H - 1]).to(pntA_H.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)
                pntB_invH_normalized = pntB_invH / pntB_invH.new_tensor([W - 1, H - 1]).to(pntB_invH.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)

                # 用于score_map
                pntA_H_new = copy.deepcopy(pntA_H.detach())
                pntB_invH_new = copy.deepcopy(pntB_invH.detach())
                pntA_H_new[:, 0] += 10                   # 120 x 36 -> 128 x 56
                pntA_H_new[:, 1] += 4 
                pntB_invH_new[:, 0] += 10
                pntB_invH_new[:, 1] += 4
                
                pntA_H_normalized_new = pntA_H_new / pntA_H_new.new_tensor([W + 19, H + 7]).to(pntA_H.device) * 2 - 1

                # pntB_invH_new = warp_points(pntB_invH_new[:, :2], inv_Homo_en[idx].squeeze(), device=self.device)       # 转到A上，而不是AT上
                
                pntB_invH_normalized_new = pntB_invH_new / pntB_invH_new.new_tensor([W + 19, H + 7]).to(pntB_invH.device) * 2 - 1 
                
                # print('1_2:', main_ori_maskATB.shape[0])
                # exit()
                ori_kpAT_patch_ext = F.grid_sample(ori_kp_patchA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntA_H_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0).transpose(0, 1)          # repeatNA x 1
                ori_kpB_patch_ext = F.grid_sample(ori_all_patchB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntB_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0).transpose(0, 1)          # NTB x 1
                ori_kpA_patch_ext = F.grid_sample(ori_all_patchA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntA_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0).transpose(0, 1)          # NTA x 1
                ori_kpBT_patch_ext = F.grid_sample(ori_kp_patchB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntB_invH_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0).transpose(0, 1)          # repeatNB x 1
                # print('1_2_1:', pntB_invH_normalized_new.shape[0])
                ori_maskATB, dis_oriATB = self.get_main_ori_consistence_AT(ori_kpAT_patch_ext, ori_kpB_patch_ext)  # repeatNA x NTB
                # print('1_2_2:', ori_maskATB.shape)
                ori_maskBTA, dis_oriBTA = self.get_main_ori_consistence_AT(ori_kpBT_patch_ext, ori_kpA_patch_ext)  # repeatNB x NTA

                match_maskAB_nb = (nn_maskAB == 1) * ori_maskATB           # repeatNA X NTB
                match_maskBA_nb = (nn_maskBA == 1) * ori_maskBTA          # repeatNB X NTA
                pairAB_A_nb_new, pairAB_B_nb_new = torch.where(match_maskAB_nb == 1)
                pairBA_B_nb_new, pairBA_A_nb_new = torch.where(match_maskBA_nb == 1)
                # assert pairAB_A_new.shape[0] > 0 and pairBA_B_new.shape[0] > 0 

                # 4x4邻域方向一致性
                ori_kpAB_patch_ext = F.grid_sample(ori_all_patchB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntA_H_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0).transpose(0, 1)  
                ori_kpBA_patch_ext = F.grid_sample(ori_all_patchA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntB_invH_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0).transpose(0, 1)  
                # print('1_2_4:', ori_kpAB_patch_ext.shape)
                ori_maskATAB, dis_oriATAB = self.get_main_ori_consistence_AT(ori_kpAT_patch_ext, ori_kpAB_patch_ext)  # repeatNA x repeatNA
                ori_maskBTBA, dis_oriBTBA = self.get_main_ori_consistence_AT(ori_kpBT_patch_ext, ori_kpBA_patch_ext)  # repeatNB x repeatNB
                
                # 黑白相似度
                bin_maskATB = bin_distAB <= (1 - self.FR_bin_thr) * current_binA.shape[-1]  
                bin_maskBTA = bin_maskATB.transpose(0, 1)  

                match_maskAB = match_maskAB_nb * bin_maskATB[mask_pointA, :]               # repeatNA X NB
                match_maskBA = match_maskBA_nb * bin_maskBTA[mask_pointB, :]               # repeatNB X NA

                pairAB_A_new, pairAB_B_new = torch.where(match_maskAB == 1)
                pairBA_B_new, pairBA_A_new = torch.where(match_maskBA == 1)
                # print('bin_mask:', pairAB_A_new.shape[0], pairBA_B_new.shape[0])
                assert pairAB_A_new.shape[0] > 0 and pairBA_B_new.shape[0] > 0 

                bin_kpAB_T = (F.grid_sample(bin_allB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntA_H_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0) >= 0.5).float()  # [256, repeatNA]
                bin_kpBA_T = (F.grid_sample(bin_allA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntB_invH_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0) >= 0.5).float()  # [256, repeatNB]
                bin_distATAB = bin_kpAB_T.shape[0] - (current_binA @ bin_kpAB_T) - ((1 - current_binA) @ (1 - bin_kpAB_T)) # [NTA, repeatNA]
                bin_distBTBA = bin_kpBA_T.shape[0] - (current_binB @ bin_kpBA_T) - ((1 - current_binB) @ (1 - bin_kpBA_T)) # [NTB, repeatNB]

                bin_maskATAB = bin_distATAB <= (1 - self.FR_bin_thr) * bin_kpAB_T.shape[0] 
                bin_maskBTBA = bin_distBTBA <= (1 - self.FR_bin_thr) * bin_kpBA_T.shape[0] 
                bin_maskATAB = bin_maskATAB[mask_pointA, :]
                bin_maskBTBA = bin_maskBTBA[mask_pointB, :]

                vmaskAH_nb = torch.diag(ori_maskATAB)
                vmaskBH_nb = torch.diag(ori_maskBTBA)
                vmaskAH = torch.diag(ori_maskATAB * bin_maskATAB) == 1      # [repeatNA, 1]
                vmaskBH = torch.diag(ori_maskBTBA * bin_maskBTBA) == 1      # [repeatNB, 1]

                # print('main_ori:', torch.sum(vmaskAH), torch.sum(vmaskBH))
                assert torch.sum(vmaskAH) > 0 and torch.sum(vmaskBH) > 0

                # SOSR: 简化的self-attention
                k_neighbor = 3
                cross_sim_AA_sp = current_descA @ current_descA.transpose(0, 1)
                cross_sim_BB_sp = current_descB @ current_descB.transpose(0, 1)
                # print('SOSR:', pairAB_A_new.shape[0], pairBA_B_new.shape[0])
                assert pairAB_A_new.shape[0] >= k_neighbor and pairBA_B_new.shape[0] >= k_neighbor 

                match_sim_AB_AA = cross_sim_AA_sp[mask_pointA, :][:, mask_pointA][pairAB_A_new, :][:, pairAB_A_new]
                match_sim_BA_BB = cross_sim_BB_sp[mask_pointB, :][:, mask_pointB][pairBA_B_new, :][:, pairBA_B_new]
                match_sim_AB_BB = cross_sim_BB_sp[pairAB_B_new, :][:, pairAB_B_new]
                match_sim_BA_AA = cross_sim_AA_sp[pairBA_A_new, :][:, pairBA_A_new]
                match_values_AB_AA, match_indices_AB_AA = torch.topk(match_sim_AB_AA, dim=1, k=k_neighbor, largest=False)
                match_values_BA_BB, match_indices_BA_BB = torch.topk(match_sim_BA_BB, dim=1, k=k_neighbor, largest=False)
                match_values_AB_BB_all = match_sim_AB_BB[:, match_indices_AB_AA]
                match_values_BA_AA_all = match_sim_BA_AA[:, match_indices_BA_BB]
                match_values_AB_BB = torch.diagonal(match_values_AB_BB_all, 0, dim1=0, dim2=1).transpose(0, 1)
                match_values_BA_AA = torch.diagonal(match_values_BA_AA_all, 0, dim1=0, dim2=1).transpose(0, 1)
                neighbor_dis_AB = (match_values_AB_AA - match_values_AB_BB) * (match_values_AB_AA - match_values_AB_BB)
                neighbor_dis_BA = (match_values_BA_BB - match_values_BA_AA) * (match_values_BA_BB - match_values_BA_AA)

                # PA VS PB
                # 计算bin值
                valid_cross_sim_AB_sp_mean = torch.mean(cross_sim_AB_sp[mask_pointA, :][match_maskAB == 1], dim=-1)
                valid_cross_sim_AB_sp_nb_mean = torch.mean(cross_sim_AB_sp[mask_pointA, :][match_maskAB_nb == 1], dim=-1)
                novalid_cross_sim_AB_sp_mean = (torch.sum(torch.sum(cross_sim_AB_sp.detach(), 1), 0) - valid_cross_sim_AB_sp_nb_mean * pairAB_A_nb_new.shape[0]) / (new_numA * new_numB - pairAB_A_nb_new.shape[0] + eps)
                valid_cross_sim_BA_sp_mean = torch.mean(cross_sim_AB_sp[:, mask_pointB][match_maskBA.transpose(0, 1) == 1], dim=-1)
                valid_cross_sim_BA_sp_nb_mean = torch.mean(cross_sim_AB_sp[:, mask_pointB][match_maskBA_nb.transpose(0, 1) == 1], dim=-1)
                novalid_cross_sim_BA_sp_mean = (torch.sum(torch.sum(cross_sim_AB_sp.detach(), 1), 0) - valid_cross_sim_BA_sp_nb_mean * pairBA_B_nb_new.shape[0]) / (new_numA * new_numB - pairBA_B_nb_new.shape[0] + eps)

                valid_indexesA = torch.tensor(list(range(cross_sim_AB_sp.shape[0])), device=self.device)[mask_pointA][pairAB_A_new]
                valid_indexesA_nb = torch.tensor(list(range(cross_sim_AB_sp.shape[0])), device=self.device)[mask_pointA][pairAB_A_nb_new]
                # cross_sim_BA_sp = current_descB @ current_descA.transpose(0, 1)
                cross_sim_AB_out_sp = torch.cat((cross_sim_AB_sp, torch.ones((cross_sim_AB_sp.shape[0], 2), device=cross_sim_AB_sp.device) * 2), dim=-1)      # NA X (NB + 2)
                cross_sim_AB_out_nb_sp = torch.cat((cross_sim_AB_sp, torch.ones((cross_sim_AB_sp.shape[0], 2), device=cross_sim_AB_sp.device) * 2), dim=-1)      # NA X (NB + 2)
                # cross_sim_BA_out_sp = torch.cat((cross_sim_BA_sp, torch.ones((numB, 1), device=cross_sim_BA_sp.device)), dim=-1)      # NB X (NA + 1)
                # valid_indexesB = torch.tensor(list(range(numB)), device=self.device)[mask_pointB][pairBA_B]
                # print('1_2')
                cross_sim_AB_out_sp[valid_indexesA, -1] = novalid_cross_sim_AB_sp_mean
                cross_sim_AB_out_sp[valid_indexesA, -2] = crossAN_mean
                cross_sim_AB_out_nb_sp[valid_indexesA_nb, -1] = novalid_cross_sim_AB_sp_mean
                novalid_indexesA = torch.tensor(list(range(cross_sim_AB_sp.shape[0])), device=self.device)[cross_sim_AB_out_nb_sp[:, -1]==2]
                cross_sim_AB_out_sp[novalid_indexesA, -1] = valid_cross_sim_AB_sp_mean
                # nomatch对不增加negtives的均值bin
                cross_sim_AB_out_sp[novalid_indexesA, -2] = -1 # crossAN_mean # -1

                soft_cross_sim_AtoB_sp = F.softmax((cross_sim_AB_out_sp - 1) / t_des, dim=-1)
                # soft_cross_sim_BtoA = F.softmax((cross_sim_BA_out - 1) / t_des, dim=-1)
                # print('1_3')
                soft_valid_cross_sim_AB_sp = soft_cross_sim_AtoB_sp[mask_pointA, :-2][match_maskAB==1]
                # soft_valid_cross_sim_BA = soft_cross_sim_BtoA[mask_pointB, :-1][pairBA_B, pairBA_A]
                soft_novalid_cross_sim_AB_sp = soft_cross_sim_AtoB_sp[novalid_indexesA, -1]
                # soft_novalid_cross_sim_BA = soft_cross_sim_BtoA[cross_sim_BA_out[:, -1]==1, -1]
                log_soft_valid_cross_sim_AB_sp = -torch.log(soft_valid_cross_sim_AB_sp + eps) * (1 - dis_oriATB[match_maskAB==1] / self.ori_diff) * (1 - bin_distAB[mask_pointA, :][match_maskAB==1] / current_binA.shape[-1]) * (1 - key_disAB[match_maskAB==1].detach() / self.correspond)
                # log_soft_valid_cross_sim_BA = -torch.log(soft_valid_cross_sim_BA + eps)
                log_soft_novalid_cross_sim_AB_sp = -torch.log(soft_novalid_cross_sim_AB_sp + eps)
                # log_soft_novalid_cross_sim_BA = -torch.log(soft_novalid_cross_sim_BA + eps)
                dis_cross_sim_mean_sp = torch.sum(torch.cat((4*log_soft_valid_cross_sim_AB_sp, log_soft_novalid_cross_sim_AB_sp), dim=-1), dim=-1) / new_numA
                
                # PA VS PAB
                # match_mask_A = copy.deepcopy(mask_pointA)
                # match_mask_B = copy.deepcopy(mask_pointB)
                match_mask_A = torch.zeros(cross_sim_AB_sp.shape[0], device=self.device)
                match_mask_nb_A = torch.zeros(cross_sim_AB_sp.shape[0], device=self.device)
                valid_match_indexesA = torch.tensor(list(range(cross_sim_AB_sp.shape[0])), device=self.device)[mask_pointA][vmaskAH]
                valid_match_indexesA_nb = torch.tensor(list(range(cross_sim_AB_sp.shape[0])), device=self.device)[mask_pointA][vmaskAH_nb]
                match_mask_A[valid_match_indexesA] = 1
                match_mask_nb_A[valid_match_indexesA_nb] = 1

                match_mask_B = torch.zeros(cross_sim_AB_sp.shape[1], device=self.device)
                match_mask_nb_B = torch.zeros(cross_sim_AB_sp.shape[1], device=self.device)
                valid_match_indexesB = torch.tensor(list(range(cross_sim_AB_sp.shape[1])), device=self.device)[mask_pointB][vmaskBH]
                valid_match_indexesB_nb = torch.tensor(list(range(cross_sim_AB_sp.shape[1])), device=self.device)[mask_pointB][vmaskBH_nb]
                match_mask_B[valid_match_indexesB] = 1
                match_mask_nb_B[valid_match_indexesB_nb] = 1

                cross_sim_AB = current_descA @ desc_mapB[idx, :, :, :].view(-1, H * W)
                # cross_sim_AB = cross_sim_AB[mask_pointA, :]
                cross_sim_AB_all = F.grid_sample(cross_sim_AB.view(-1, H, W).unsqueeze(0),
                                                pntA_H_normalized[vmaskAH, :].detach().view(1, 1, -1, 2),
                                                mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NA x repeatNA
                valid_cross_sim_AB_mean = torch.trace(cross_sim_AB_all[match_mask_A==1, :]) / cross_sim_AB_all[match_mask_A==1, :].shape[0]
                # novalid_cross_sim_AB_mean = (torch.sum(torch.sum(cross_sim_AB.detach(), 1), 1) - valid_cross_sim_AB_mean * pairAB_A.shape[0]) / (new_numA * H * W - pairAB_A.shape[0])

                cross_sim_BA = current_descB @ desc_mapA[idx, :, :, :].view(-1, H * W)   # M x H x W
                # cross_sim_BA = cross_sim_BA[mask_pointB, :]
                cross_sim_BA_all = F.grid_sample(cross_sim_BA.view(-1, H, W).unsqueeze(0),
                                                pntB_invH_normalized[vmaskBH, :].detach().view(1, 1, -1, 2),
                                                mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NB x match_nB
                valid_cross_sim_BA_mean = torch.trace(cross_sim_BA_all[match_mask_B==1, :]) / cross_sim_BA_all[match_mask_B==1, :].shape[0]
                # novalid_cross_sim_BA_mean = (torch.sum(torch.sum(cross_sim_BA.detach(), 1), 1) - valid_cross_sim_BA_mean * pairBA_B.shape[0]) / (new_numB * H * W - pairBA_B.shape[0])

                cross_sim_AB_out = torch.cat((cross_sim_AB, torch.ones((cross_sim_AB.shape[0], 2), device=cross_sim_AB.device)), dim=-1)      # NA X (H X W + 2)
                cross_sim_BA_out = torch.cat((cross_sim_BA, torch.ones((cross_sim_BA.shape[0], 2), device=cross_sim_BA.device)), dim=-1)      # NB X (H X W + 2)
                # print(3)
                # cross_sim_AB_out[mask_pointA, -1] -= 1
                # cross_sim_BA_out[mask_pointB, -1] -= 1
                # cross_sim_AB_out[match_mask_A, -1] -= 1
                cross_sim_AB_out[match_mask_A==1, -1] = novalid_cross_sim_AB_sp_mean
                cross_sim_AB_out[match_mask_A==1, -2] = crossAN_mean
                cross_sim_AB_out[match_mask_nb_A==0, -1] = valid_cross_sim_AB_mean
                cross_sim_AB_out[match_mask_nb_A==0, -2] = -1 # crossAN_mean # -1

                cross_sim_BA_out[match_mask_B==1, -1] = novalid_cross_sim_BA_sp_mean
                cross_sim_BA_out[match_mask_B==1, -2] = crossBN_mean
                cross_sim_BA_out[match_mask_nb_B==0, -1] = valid_cross_sim_BA_mean
                cross_sim_BA_out[match_mask_nb_B==0, -2] = -1 # crossBN_mean # -1

                soft_cross_sim_AtoB = F.softmax((cross_sim_AB_out - 1) / t_des, dim=-1)         # NA X (H X W + 1)
                soft_cross_sim_BtoA = F.softmax((cross_sim_BA_out - 1) / t_des, dim=-1)         # NB X (H X W + 1)
                soft_cross_sim_AB_all = F.grid_sample(soft_cross_sim_AtoB[:, :-2].view(-1, H, W).unsqueeze(0),
                                                    pntA_H_normalized[vmaskAH, :].detach().view(1, 1, -1, 2),
                                                    mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NA x match_nA
                
                soft_cross_sim_BA_all = F.grid_sample(soft_cross_sim_BtoA[:, :-2].view(-1, H, W).unsqueeze(0),
                                                    pntB_invH_normalized[vmaskBH, :].detach().view(1, 1, -1, 2),
                                                    mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NB x match_nB
                # soft_valid_cross_sim_AB_all = soft_cross_sim_AB_all[mask_pointA, :]             # repeat_nA x repeat_nA
                # soft_valid_cross_sim_BA_all = soft_cross_sim_BA_all[mask_pointB, :]             # repeat_nB x repeat_nB

                soft_valid_cross_sim_AB_all = soft_cross_sim_AB_all[match_mask_A==1, :]             # match_nA x match_nA
                soft_valid_cross_sim_BA_all = soft_cross_sim_BA_all[match_mask_B==1, :]             # match_nB x match_nB

                valid_mask_AB = torch.eye(soft_valid_cross_sim_AB_all.shape[0]) == 1
                valid_mask_BA = torch.eye(soft_valid_cross_sim_BA_all.shape[0]) == 1
                # print(4)
                # 取对角线
                soft_valid_cross_sim_AB = soft_valid_cross_sim_AB_all[valid_mask_AB]
                soft_valid_cross_sim_BA = soft_valid_cross_sim_BA_all[valid_mask_BA]

                # soft_novalid_cross_sim_AB = soft_cross_sim_AtoB[mask_pointA==False, -1]              # (NA-repeat_nA) x 1
                # soft_novalid_cross_sim_BA = soft_cross_sim_BtoA[mask_pointB==False, -1]
                soft_novalid_cross_sim_AB = soft_cross_sim_AtoB[match_mask_nb_A==0, -1]               # (NA-match_nA) x 1
                soft_novalid_cross_sim_BA = soft_cross_sim_BtoA[match_mask_nb_B==0, -1]
                # print(soft_novalid_cross_sim_AB, soft_novalid_cross_sim_BA)

                log_soft_valid_cross_sim_AB = -torch.log(soft_valid_cross_sim_AB + eps) * (1 - torch.diag(dis_oriATAB)[vmaskAH] / self.ori_diff) * (1 - torch.diag(bin_distATAB[mask_pointA, :])[vmaskAH] / bin_kpAB_T.shape[0])
                log_soft_valid_cross_sim_BA = -torch.log(soft_valid_cross_sim_BA + eps) * (1 - torch.diag(dis_oriBTBA)[vmaskBH] / self.ori_diff) * (1 - torch.diag(bin_distBTBA[mask_pointB, :])[vmaskBH] / bin_kpBA_T.shape[0])
                log_soft_novalid_cross_sim_AB = -torch.log(soft_novalid_cross_sim_AB + eps)
                log_soft_novalid_cross_sim_BA = -torch.log(soft_novalid_cross_sim_BA + eps)

                dis_cross_sim_mean = torch.sum(torch.cat((4*log_soft_valid_cross_sim_AB, 4*log_soft_valid_cross_sim_BA, log_soft_novalid_cross_sim_AB, log_soft_novalid_cross_sim_BA), dim=-1), dim=-1) / (new_numA + new_numB)
                
                # print(5)
                valid_cross_sim_AB = cross_sim_AB[mask_pointA, :]   # repeat_nA x (H X W)
                valid_cross_sim_BA = cross_sim_BA[mask_pointB, :]   # repeat_nB x (H X W)
                exp_valid_cross_sim_AtoB = torch.exp((valid_cross_sim_AB - 1) / t_rel).view(-1, H, W)
                exp_valid_cross_sim_BtoA = torch.exp((valid_cross_sim_BA - 1) / t_rel).view(-1, H, W)
                exp_valid_cross_sim_AB_all = F.grid_sample(exp_valid_cross_sim_AtoB.unsqueeze(0),
                                                        pntA_H_normalized.detach().view(1, 1, -1, 2),
                                                        mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # repeat_nA x repeat_nA
                
                exp_valid_cross_sim_BA_all = F.grid_sample(exp_valid_cross_sim_BtoA.unsqueeze(0),
                                                        pntB_invH_normalized.detach().view(1, 1, -1, 2),
                                                        mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # repeat_nB x repeat_nB

                repeat_mask_AB = torch.eye(exp_valid_cross_sim_AB_all.shape[0]) == 1
                repeat_mask_BA = torch.eye(exp_valid_cross_sim_BA_all.shape[0]) == 1
                rel_valid_cross_sim_AB = exp_valid_cross_sim_AB_all[repeat_mask_AB]
                rel_valid_cross_sim_BA = exp_valid_cross_sim_BA_all[repeat_mask_BA]

                # pntA_H_normalized_new = copy.deepcopy(pntA_H_normalized.detach())
                # pntB_invH_normalized_new = copy.deepcopy(pntB_invH_normalized.detach())

                # pntA_H_normalized_new[:, 0] += 2
                # pntB_invH_normalized_new[:, 0] += 2

                scoresAB_all = F.grid_sample(scores_mapB[idx, :, :, :].unsqueeze(0),
                                            pntA_H_normalized_new.view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)      # 1 x repeat_nA

                scoresBA_all = F.grid_sample(scores_mapA[idx, :, :, :].unsqueeze(0),
                                            pntB_invH_normalized_new.view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)      # 1 x repeat_nB
                # print(6)
                scores_AAB = scoresA[idx][pmA][mask_pointA] * scoresAB_all
                scores_BBA = scoresB[idx][pmB][mask_pointB] * scoresBA_all
                scores_sum_AAB = torch.sum(scores_AAB, dim=-1)
                scores_sum_BBA = torch.sum(scores_BBA, dim=-1)
                scores_normalize_AAB = scores_AAB / (scores_sum_AAB + eps)
                scores_normalize_BBA = scores_BBA / (scores_sum_BBA + eps)
                rel_meanA = torch.sum(scores_normalize_AAB * (1 - rel_valid_cross_sim_AB), dim=-1) / pntA_H_normalized_new.shape[0]
                rel_meanB = torch.sum(scores_normalize_BBA * (1 - rel_valid_cross_sim_BA), dim=-1) / pntB_invH_normalized_new.shape[0]

                # # 熵loss
                # current_descA_std, current_descB_std = descA_std[countA:countA+new_numA], descB_std[countB:countB+new_numB]
                # desc_std += torch.mean(current_descA_std) + torch.mean(current_descB_std)
                # countA_T += numA_T
                # countB_T += numB_T

                dis_neighbor_mean_total += torch.mean(torch.sum(neighbor_dis_AB, dim=1)) + torch.mean(torch.sum(neighbor_dis_BA, dim=1))
                dis_desc += dis_cross_sim_mean_sp
                dis_desc += dis_cross_sim_mean

                dis_pair_meanAB = torch.mean(key_manhattandisAB[pairAB_A, pairAB_B])
                dis_pair_meanBA = torch.mean(key_manhattandisBA[pairBA_B, pairBA_A])

                dis_peak_mean = torch.mean(torch.cat((scoreddisA[idx][pmA], scoreddisB[idx][pmB]), dim=0))
                # dis_peak_meanB = torch.mean(scoreddisB[idx])
                
                dis_mean_total += dis_pair_meanAB + dis_pair_meanBA
                dis_peak_scored += dis_peak_mean

                dis_rel += rel_meanA + rel_meanB
                
                countA += new_numA
                countB += new_numB
                count_ne += new_num_ne
                # # Penalty
                # scores_mean += (-torch.log(torch.mean(scoresA[idx], dim=-1) + eps) - torch.log(torch.mean(scoresB[idx], dim=-1) + eps)) 
                # print(scores_mean)
            except:
                # dis_mean_total += 0
                # dis_peak_scored += 0
                # dis_desc += 0
                # dis_rel += 0
                # print('Overlapping too small or Repeatable point pairs distance is greater than correspond(1.5):', pntA.shape[0], pntA_H.shape[0], pntB.shape[0], pntB_invH.shape[0], dis_pairAB.shape[0], dis_pairBA.shape[0])
                valid_batch_size -= 1
                countA += new_numA
                countB += new_numB
                count_ne += new_num_ne
                # countA_T += numA_T
                # countB_T += numB_T

        valid_batch_size = valid_batch_size if valid_batch_size > 0 else eps
        # Reprojection Loss 
        reprojection_loss = dis_mean_total / (valid_batch_size * 2)
        # Dispersity Peak Loss
        dispersity_peak_loss = dis_peak_scored / valid_batch_size
        # NRE Loss
        descriptor_loss = dis_desc / (2 * valid_batch_size)
        # Reliability Loss
        reliability_loss = dis_rel / (valid_batch_size * 2)
        # SOSR Loss
        sosr_loss = dis_neighbor_mean_total / ((valid_batch_size * 2))
        # # Entropy loss
        # std_loss = (valid_batch_size * 2) / desc_std  
        # # Score Penalty
        # score_penalty = scores_mean / (valid_batch_size * 2)
        # # FA Desc loss
        # FA_des_loss = dis_desc_fa / valid_batch_size_FA if valid_batch_size_FA > 0 else 0

        loss_total = wrp * reprojection_loss + wpl * dispersity_peak_loss + wdl * descriptor_loss + wrl * reliability_loss
        loss_group = {
            'reprojection_loss': reprojection_loss, 
            'dispersity_peak_loss': dispersity_peak_loss,
            'descriptor_loss': descriptor_loss,
            'reliability_loss': reliability_loss,
            # 'sosr_loss': sosr_loss,
            # 'std_loss': std_loss,
            # 'FA_des_loss': FA_des_loss,
            }
        return loss_total, loss_group


    # patch/dense AT角度 黑白相似度加量化 NFA negtives 分别L2Norm2
    def detector_selfsupervised_loss_dkd_patch_ext_restrict_modify_oriR_ratio_NFA_qtbw_ns_wg_nori_AT_NE_norm2(self, kpA, kpB, pmaskA, pmaskB, descA, descB, desc_mapA, desc_mapB, scoreddisA, scoreddisB, scoresA, scoresB, scores_mapA, scores_mapB, Homo, inv_Homo, inv_Homo_en, ori_all_patchA, ori_all_patchB, ori_kp_patchA, ori_kp_patchB, bin_allA, bin_allB, bin_kpA, bin_kpB, kp_ne, pmask_ne, desc_ne, bin_kp_ne, trans_angle, FA_flag, H, W, wrp=1, wpl=1, wdl=1, wrl=1, t_des=0.02, t_rel=1):
        # pmaskA: (BxMax_num) 32x350=11200
        batch_size = len(kpA)
        max_num = pmaskA.shape[-1] // batch_size    # 350
        dis_mean_total = 0
        dis_neighbor_mean_total = 0
        dis_peak_scored = 0
        dis_desc = 0
        dis_rel = 0
        desc_std = 0
        eps = 1e-12
        valid_batch_size = batch_size
        # valid_batch_size_FA = 0
        countA, countB, count_ne = 0, 0, 0
        # dis_desc_fa = 0
        # countA_T, countB_T = 0, 0
        for idx in range(batch_size):
            pntA, pntB, pnt_ne = kpA[idx], kpB[idx], kp_ne[idx]     # M X 2 (x,y)
            # kmask_TA, kmask_TB = kmask_T_allA[idx], kmask_T_allB[idx]
            pntA = pntA.float()
            pntB = pntB.float()
            pnt_ne = pnt_ne.float()

            # 剔除部分按压区域的点,且保留在重叠区域的点
            numA, numB, num_ne = pntA.shape[0], pntB.shape[0], pnt_ne.shape[0]
            # numA_T, numB_T = pntA[kmask_TA].shape[0], pntB[kmask_TB].shape[0]
            pmA, pmB, pm_ne = pmaskA[max_num * idx:max_num * idx + numA].bool(), pmaskB[max_num * idx:max_num * idx + numB].bool(), pmask_ne[max_num * idx:max_num * idx + num_ne].bool()
            pntA, pntB, pnt_ne = pntA[pmA, :], pntB[pmB, :], pnt_ne[pm_ne, :]
            new_numA, new_numB, new_num_ne = pntA.shape[0], pntB.shape[0], pnt_ne.shape[0]       
            
            pntA = (pntA + 1) / 2 * pntA.new_tensor([[W + 3, H - 1]]).to(pntA.device)
            pntB = (pntB + 1) / 2 * pntB.new_tensor([[W + 3, H - 1]]).to(pntB.device)

            # [120, 40] -> [120, 36],实际只取中心118x32区域的点对
            pntA[:, 0] -= 2
            pntB[:, 0] -= 2
            
            pntA_normalized = pntA / pntA.new_tensor([W - 1, H - 1]).to(pntA.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)
            pntB_normalized = pntB / pntB.new_tensor([W - 1, H - 1]).to(pntB.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)

            pntA_H = warp_points(pntA[:, :2], Homo[idx].squeeze(), device=self.device)  # 利用变换矩阵变换坐标点
            pntA_H, mask_pointA = filter_points(pntA_H, torch.tensor([W, H], device=self.device), return_mask=True)
            pntB_invH = warp_points(pntB[:, :2], inv_Homo[idx].squeeze(), device=self.device)
            pntB_invH, mask_pointB = filter_points(pntB_invH, torch.tensor([W, H], device=self.device), return_mask=True)
            
            current_descA, current_descB = descA[countA:countA+new_numA], descB[countB:countB+new_numB]
            current_desc_ne = desc_ne[count_ne:count_ne+new_num_ne]

            # 分别归一化后的平方和为2
            cross_sim_AB_sp = current_descA @ current_descB.transpose(0, 1) / 2    # NTA X NTB 
            
            cross_sim_AN_sp = current_descA @ current_desc_ne.transpose(0, 1) / 2
            cross_sim_BN_sp = current_descB @ current_desc_ne.transpose(0, 1) / 2
            
            # 黑白相似度
            current_binA, current_binB = (bin_kpA[countA:countA+new_numA] >= 0.5).float(), (bin_kpB[countB:countB+new_numB] >= 0.5).float()   # [NA, 256] [NB_256]
            current_bin_ne = (bin_kp_ne[count_ne:count_ne+new_num_ne] >= 0.5).float()
            bin_distAB = current_binA.shape[-1] - (current_binA @ current_binB.transpose(0, 1)) - ((1 - current_binA) @ (1 - current_binB.transpose(0, 1))) # [NA, NB]
            
            bin_distAN = current_binA.shape[-1] - (current_binA @ current_bin_ne.transpose(0, 1)) - ((1 - current_binA) @ (1 - current_bin_ne.transpose(0, 1))) # [NA, NE]
            bin_distBN = current_binB.shape[-1] - (current_binB @ current_bin_ne.transpose(0, 1)) - ((1 - current_binB) @ (1 - current_bin_ne.transpose(0, 1))) # [NA, NE]
            
            # 真匹配的trans
            try:
                FAN_bin_mask = bin_distAN >= (1 - self.FA_bin_thr) * current_binA.shape[-1] 
                FBN_bin_mask = bin_distBN >= (1 - self.FA_bin_thr) * current_binB.shape[-1] 
                # topk ?
                crossAN_mean = torch.mean(cross_sim_AN_sp[FAN_bin_mask])
                crossBN_mean = torch.mean(cross_sim_BN_sp[FBN_bin_mask])

                assert pntA_H.shape[0] > 0 and pntB_invH.shape[0] > 0 
                
                # 点对欧氏距离
                key_disAB = self.get_dis(pntA_H[:, :2], pntB[:, :2])            # repeatNA x NB
                key_disBA = self.get_dis(pntB_invH[:, :2], pntA[:, :2])
                pairAB_A, pairAB_B, dis_pairAB, _ = self.get_point_pair(key_disAB, dis_thre=self.correspond)  # p -> k # NTA(<1.5), NTA(<1.5), NTA(<1.5), NTA        
                pairBA_B, pairBA_A, dis_pairBA, _  = self.get_point_pair(key_disBA, dis_thre=self.correspond)  # p -> k # NTB(<1.5), NTB(<1.5), NTB(<1.5), NTB 
                
                # 点距离mask
                nn_maskAB = torch.zeros((pntA_H.shape[0], pntB.shape[0]), device=self.device) 
                nn_maskAB[pairAB_A, pairAB_B] = 1

                nn_maskBA = torch.zeros((pntB_invH.shape[0], pntA.shape[0]), device=self.device) 
                nn_maskBA[pairBA_B, pairBA_A] = 1

                # 点对曼哈顿距离
                key_manhattandisAB = self.get_manhattan_dis(pntA_H[:, :2], pntB[:, :2])
                key_manhattandisBA = self.get_manhattan_dis(pntB_invH[:, :2], pntA[:, :2])
                # print('pdis:', dis_pairAB.shape[0], dis_pairBA.shape[0])
                assert dis_pairAB.shape[0] > 0 and dis_pairBA.shape[0] > 0     

                pntA_H_normalized = pntA_H / pntA_H.new_tensor([W - 1, H - 1]).to(pntA_H.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)
                pntB_invH_normalized = pntB_invH / pntB_invH.new_tensor([W - 1, H - 1]).to(pntB_invH.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)

                # 用于score_map
                pntA_H_new = copy.deepcopy(pntA_H.detach())
                pntB_invH_new = copy.deepcopy(pntB_invH.detach())
                pntA_H_new[:, 0] += 10                   # 120 x 36 -> 128 x 56
                pntA_H_new[:, 1] += 4 
                pntB_invH_new[:, 0] += 10
                pntB_invH_new[:, 1] += 4
                
                pntA_H_normalized_new = pntA_H_new / pntA_H_new.new_tensor([W + 19, H + 7]).to(pntA_H.device) * 2 - 1

                # pntB_invH_new = warp_points(pntB_invH_new[:, :2], inv_Homo_en[idx].squeeze(), device=self.device)       # 转到A上，而不是AT上
                
                pntB_invH_normalized_new = pntB_invH_new / pntB_invH_new.new_tensor([W + 19, H + 7]).to(pntB_invH.device) * 2 - 1 
                
                # print('1_2:', main_ori_maskATB.shape[0])
                # exit()
                ori_kpAT_patch_ext = F.grid_sample(ori_kp_patchA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntA_H_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0).transpose(0, 1)          # repeatNA x 1
                ori_kpB_patch_ext = F.grid_sample(ori_all_patchB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntB_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0).transpose(0, 1)          # NTB x 1
                ori_kpA_patch_ext = F.grid_sample(ori_all_patchA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntA_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0).transpose(0, 1)          # NTA x 1
                ori_kpBT_patch_ext = F.grid_sample(ori_kp_patchB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntB_invH_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0).transpose(0, 1)          # repeatNB x 1
                # print('1_2_1:', pntB_invH_normalized_new.shape[0])
                ori_maskATB, dis_oriATB = self.get_main_ori_consistence_AT(ori_kpAT_patch_ext, ori_kpB_patch_ext)  # repeatNA x NTB
                # print('1_2_2:', ori_maskATB.shape)
                ori_maskBTA, dis_oriBTA = self.get_main_ori_consistence_AT(ori_kpBT_patch_ext, ori_kpA_patch_ext)  # repeatNB x NTA

                match_maskAB_nb = (nn_maskAB == 1) * ori_maskATB           # repeatNA X NTB
                match_maskBA_nb = (nn_maskBA == 1) * ori_maskBTA          # repeatNB X NTA
                pairAB_A_nb_new, pairAB_B_nb_new = torch.where(match_maskAB_nb == 1)
                pairBA_B_nb_new, pairBA_A_nb_new = torch.where(match_maskBA_nb == 1)
                # assert pairAB_A_new.shape[0] > 0 and pairBA_B_new.shape[0] > 0 

                # 4x4邻域方向一致性
                ori_kpAB_patch_ext = F.grid_sample(ori_all_patchB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntA_H_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0).transpose(0, 1)  
                ori_kpBA_patch_ext = F.grid_sample(ori_all_patchA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntB_invH_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0).transpose(0, 1)  
                # print('1_2_4:', ori_kpAB_patch_ext.shape)
                ori_maskATAB, dis_oriATAB = self.get_main_ori_consistence_AT(ori_kpAT_patch_ext, ori_kpAB_patch_ext)  # repeatNA x repeatNA
                ori_maskBTBA, dis_oriBTBA = self.get_main_ori_consistence_AT(ori_kpBT_patch_ext, ori_kpBA_patch_ext)  # repeatNB x repeatNB
                
                # 黑白相似度
                bin_maskATB = bin_distAB <= (1 - self.FR_bin_thr) * current_binA.shape[-1]  
                bin_maskBTA = bin_maskATB.transpose(0, 1)  

                match_maskAB = match_maskAB_nb * bin_maskATB[mask_pointA, :]               # repeatNA X NB
                match_maskBA = match_maskBA_nb * bin_maskBTA[mask_pointB, :]               # repeatNB X NA

                pairAB_A_new, pairAB_B_new = torch.where(match_maskAB == 1)
                pairBA_B_new, pairBA_A_new = torch.where(match_maskBA == 1)
                # print('bin_mask:', pairAB_A_new.shape[0], pairBA_B_new.shape[0])
                assert pairAB_A_new.shape[0] > 0 and pairBA_B_new.shape[0] > 0 

                bin_kpAB_T = (F.grid_sample(bin_allB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntA_H_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0) >= 0.5).float()  # [256, repeatNA]
                bin_kpBA_T = (F.grid_sample(bin_allA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntB_invH_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0) >= 0.5).float()  # [256, repeatNB]
                bin_distATAB = bin_kpAB_T.shape[0] - (current_binA @ bin_kpAB_T) - ((1 - current_binA) @ (1 - bin_kpAB_T)) # [NTA, repeatNA]
                bin_distBTBA = bin_kpBA_T.shape[0] - (current_binB @ bin_kpBA_T) - ((1 - current_binB) @ (1 - bin_kpBA_T)) # [NTB, repeatNB]

                bin_maskATAB = bin_distATAB <= (1 - self.FR_bin_thr) * bin_kpAB_T.shape[0] 
                bin_maskBTBA = bin_distBTBA <= (1 - self.FR_bin_thr) * bin_kpBA_T.shape[0] 
                bin_maskATAB = bin_maskATAB[mask_pointA, :]
                bin_maskBTBA = bin_maskBTBA[mask_pointB, :]

                vmaskAH_nb = torch.diag(ori_maskATAB)
                vmaskBH_nb = torch.diag(ori_maskBTBA)
                vmaskAH = torch.diag(ori_maskATAB * bin_maskATAB) == 1      # [repeatNA, 1]
                vmaskBH = torch.diag(ori_maskBTBA * bin_maskBTBA) == 1      # [repeatNB, 1]

                # print('main_ori:', torch.sum(vmaskAH), torch.sum(vmaskBH))
                assert torch.sum(vmaskAH) > 0 and torch.sum(vmaskBH) > 0

                # SOSR: 简化的self-attention
                k_neighbor = 3
                cross_sim_AA_sp = current_descA @ current_descA.transpose(0, 1) / 2     # 保证范围在-1~1
                cross_sim_BB_sp = current_descB @ current_descB.transpose(0, 1) / 2
                # print('SOSR:', pairAB_A_new.shape[0], pairBA_B_new.shape[0])
                assert pairAB_A_new.shape[0] >= k_neighbor and pairBA_B_new.shape[0] >= k_neighbor 

                match_sim_AB_AA = cross_sim_AA_sp[mask_pointA, :][:, mask_pointA][pairAB_A_new, :][:, pairAB_A_new]
                match_sim_BA_BB = cross_sim_BB_sp[mask_pointB, :][:, mask_pointB][pairBA_B_new, :][:, pairBA_B_new]
                match_sim_AB_BB = cross_sim_BB_sp[pairAB_B_new, :][:, pairAB_B_new]
                match_sim_BA_AA = cross_sim_AA_sp[pairBA_A_new, :][:, pairBA_A_new]
                match_values_AB_AA, match_indices_AB_AA = torch.topk(match_sim_AB_AA, dim=1, k=k_neighbor, largest=False)
                match_values_BA_BB, match_indices_BA_BB = torch.topk(match_sim_BA_BB, dim=1, k=k_neighbor, largest=False)
                match_values_AB_BB_all = match_sim_AB_BB[:, match_indices_AB_AA]
                match_values_BA_AA_all = match_sim_BA_AA[:, match_indices_BA_BB]
                match_values_AB_BB = torch.diagonal(match_values_AB_BB_all, 0, dim1=0, dim2=1).transpose(0, 1)
                match_values_BA_AA = torch.diagonal(match_values_BA_AA_all, 0, dim1=0, dim2=1).transpose(0, 1)
                neighbor_dis_AB = (match_values_AB_AA - match_values_AB_BB) * (match_values_AB_AA - match_values_AB_BB)
                neighbor_dis_BA = (match_values_BA_BB - match_values_BA_AA) * (match_values_BA_BB - match_values_BA_AA)

                # PA VS PB
                # 计算bin值
                valid_cross_sim_AB_sp_mean = torch.mean(cross_sim_AB_sp[mask_pointA, :][match_maskAB == 1], dim=-1)
                valid_cross_sim_AB_sp_nb_mean = torch.mean(cross_sim_AB_sp[mask_pointA, :][match_maskAB_nb == 1], dim=-1)
                novalid_cross_sim_AB_sp_mean = (torch.sum(torch.sum(cross_sim_AB_sp.detach(), 1), 0) - valid_cross_sim_AB_sp_nb_mean * pairAB_A_nb_new.shape[0]) / (new_numA * new_numB - pairAB_A_nb_new.shape[0] + eps)
                valid_cross_sim_BA_sp_mean = torch.mean(cross_sim_AB_sp[:, mask_pointB][match_maskBA.transpose(0, 1) == 1], dim=-1)
                valid_cross_sim_BA_sp_nb_mean = torch.mean(cross_sim_AB_sp[:, mask_pointB][match_maskBA_nb.transpose(0, 1) == 1], dim=-1)
                novalid_cross_sim_BA_sp_mean = (torch.sum(torch.sum(cross_sim_AB_sp.detach(), 1), 0) - valid_cross_sim_BA_sp_nb_mean * pairBA_B_nb_new.shape[0]) / (new_numA * new_numB - pairBA_B_nb_new.shape[0] + eps)

                valid_indexesA = torch.tensor(list(range(cross_sim_AB_sp.shape[0])), device=self.device)[mask_pointA][pairAB_A_new]
                valid_indexesA_nb = torch.tensor(list(range(cross_sim_AB_sp.shape[0])), device=self.device)[mask_pointA][pairAB_A_nb_new]
                # cross_sim_BA_sp = current_descB @ current_descA.transpose(0, 1)
                cross_sim_AB_out_sp = torch.cat((cross_sim_AB_sp, torch.ones((cross_sim_AB_sp.shape[0], 2), device=cross_sim_AB_sp.device) * 2), dim=-1)      # NA X (NB + 2)
                cross_sim_AB_out_nb_sp = torch.cat((cross_sim_AB_sp, torch.ones((cross_sim_AB_sp.shape[0], 2), device=cross_sim_AB_sp.device) * 2), dim=-1)      # NA X (NB + 2)
                # cross_sim_BA_out_sp = torch.cat((cross_sim_BA_sp, torch.ones((numB, 1), device=cross_sim_BA_sp.device)), dim=-1)      # NB X (NA + 1)
                # valid_indexesB = torch.tensor(list(range(numB)), device=self.device)[mask_pointB][pairBA_B]
                # print('1_2')
                cross_sim_AB_out_sp[valid_indexesA, -1] = novalid_cross_sim_AB_sp_mean
                cross_sim_AB_out_sp[valid_indexesA, -2] = crossAN_mean
                cross_sim_AB_out_nb_sp[valid_indexesA_nb, -1] = novalid_cross_sim_AB_sp_mean
                novalid_indexesA = torch.tensor(list(range(cross_sim_AB_sp.shape[0])), device=self.device)[cross_sim_AB_out_nb_sp[:, -1]==2]
                cross_sim_AB_out_sp[novalid_indexesA, -1] = valid_cross_sim_AB_sp_mean
                # nomatch对不增加negtives的均值bin
                cross_sim_AB_out_sp[novalid_indexesA, -2] = -1 # crossAN_mean # -1

                soft_cross_sim_AtoB_sp = F.softmax((cross_sim_AB_out_sp - 1) / t_des, dim=-1)
                # soft_cross_sim_BtoA = F.softmax((cross_sim_BA_out - 1) / t_des, dim=-1)
                # print('1_3')
                soft_valid_cross_sim_AB_sp = soft_cross_sim_AtoB_sp[mask_pointA, :-2][match_maskAB==1]
                # soft_valid_cross_sim_BA = soft_cross_sim_BtoA[mask_pointB, :-1][pairBA_B, pairBA_A]
                soft_novalid_cross_sim_AB_sp = soft_cross_sim_AtoB_sp[novalid_indexesA, -1]
                # soft_novalid_cross_sim_BA = soft_cross_sim_BtoA[cross_sim_BA_out[:, -1]==1, -1]
                log_soft_valid_cross_sim_AB_sp = -torch.log(soft_valid_cross_sim_AB_sp + eps) * (1 - dis_oriATB[match_maskAB==1] / self.ori_diff) * (1 - bin_distAB[mask_pointA, :][match_maskAB==1] / current_binA.shape[-1]) * (1 - key_disAB[match_maskAB==1].detach() / self.correspond)
                # log_soft_valid_cross_sim_BA = -torch.log(soft_valid_cross_sim_BA + eps)
                log_soft_novalid_cross_sim_AB_sp = -torch.log(soft_novalid_cross_sim_AB_sp + eps)
                # log_soft_novalid_cross_sim_BA = -torch.log(soft_novalid_cross_sim_BA + eps)
                dis_cross_sim_mean_sp = torch.sum(torch.cat((4*log_soft_valid_cross_sim_AB_sp, log_soft_novalid_cross_sim_AB_sp), dim=-1), dim=-1) / new_numA
                
                # PA VS PAB
                # match_mask_A = copy.deepcopy(mask_pointA)
                # match_mask_B = copy.deepcopy(mask_pointB)
                match_mask_A = torch.zeros(cross_sim_AB_sp.shape[0], device=self.device)
                match_mask_nb_A = torch.zeros(cross_sim_AB_sp.shape[0], device=self.device)
                valid_match_indexesA = torch.tensor(list(range(cross_sim_AB_sp.shape[0])), device=self.device)[mask_pointA][vmaskAH]
                valid_match_indexesA_nb = torch.tensor(list(range(cross_sim_AB_sp.shape[0])), device=self.device)[mask_pointA][vmaskAH_nb]
                match_mask_A[valid_match_indexesA] = 1
                match_mask_nb_A[valid_match_indexesA_nb] = 1

                match_mask_B = torch.zeros(cross_sim_AB_sp.shape[1], device=self.device)
                match_mask_nb_B = torch.zeros(cross_sim_AB_sp.shape[1], device=self.device)
                valid_match_indexesB = torch.tensor(list(range(cross_sim_AB_sp.shape[1])), device=self.device)[mask_pointB][vmaskBH]
                valid_match_indexesB_nb = torch.tensor(list(range(cross_sim_AB_sp.shape[1])), device=self.device)[mask_pointB][vmaskBH_nb]
                match_mask_B[valid_match_indexesB] = 1
                match_mask_nb_B[valid_match_indexesB_nb] = 1

                cross_sim_AB = current_descA @ desc_mapB[idx, :, :, :].view(-1, H * W) / 2
                # cross_sim_AB = cross_sim_AB[mask_pointA, :]
                cross_sim_AB_all = F.grid_sample(cross_sim_AB.view(-1, H, W).unsqueeze(0),
                                                pntA_H_normalized[vmaskAH, :].detach().view(1, 1, -1, 2),
                                                mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NA x repeatNA
                valid_cross_sim_AB_mean = torch.trace(cross_sim_AB_all[match_mask_A==1, :]) / cross_sim_AB_all[match_mask_A==1, :].shape[0]
                # novalid_cross_sim_AB_mean = (torch.sum(torch.sum(cross_sim_AB.detach(), 1), 1) - valid_cross_sim_AB_mean * pairAB_A.shape[0]) / (new_numA * H * W - pairAB_A.shape[0])

                cross_sim_BA = current_descB @ desc_mapA[idx, :, :, :].view(-1, H * W) / 2  # M x H x W
                # cross_sim_BA = cross_sim_BA[mask_pointB, :]
                cross_sim_BA_all = F.grid_sample(cross_sim_BA.view(-1, H, W).unsqueeze(0),
                                                pntB_invH_normalized[vmaskBH, :].detach().view(1, 1, -1, 2),
                                                mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NB x match_nB
                valid_cross_sim_BA_mean = torch.trace(cross_sim_BA_all[match_mask_B==1, :]) / cross_sim_BA_all[match_mask_B==1, :].shape[0]
                # novalid_cross_sim_BA_mean = (torch.sum(torch.sum(cross_sim_BA.detach(), 1), 1) - valid_cross_sim_BA_mean * pairBA_B.shape[0]) / (new_numB * H * W - pairBA_B.shape[0])

                cross_sim_AB_out = torch.cat((cross_sim_AB, torch.ones((cross_sim_AB.shape[0], 2), device=cross_sim_AB.device)), dim=-1)      # NA X (H X W + 2)
                cross_sim_BA_out = torch.cat((cross_sim_BA, torch.ones((cross_sim_BA.shape[0], 2), device=cross_sim_BA.device)), dim=-1)      # NB X (H X W + 2)
                # print(3)
                # cross_sim_AB_out[mask_pointA, -1] -= 1
                # cross_sim_BA_out[mask_pointB, -1] -= 1
                # cross_sim_AB_out[match_mask_A, -1] -= 1
                cross_sim_AB_out[match_mask_A==1, -1] = novalid_cross_sim_AB_sp_mean
                cross_sim_AB_out[match_mask_A==1, -2] = crossAN_mean
                cross_sim_AB_out[match_mask_nb_A==0, -1] = valid_cross_sim_AB_mean
                cross_sim_AB_out[match_mask_nb_A==0, -2] = -1 # crossAN_mean # -1

                cross_sim_BA_out[match_mask_B==1, -1] = novalid_cross_sim_BA_sp_mean
                cross_sim_BA_out[match_mask_B==1, -2] = crossBN_mean
                cross_sim_BA_out[match_mask_nb_B==0, -1] = valid_cross_sim_BA_mean
                cross_sim_BA_out[match_mask_nb_B==0, -2] = -1 # crossBN_mean # -1

                soft_cross_sim_AtoB = F.softmax((cross_sim_AB_out - 1) / t_des, dim=-1)         # NA X (H X W + 1)
                soft_cross_sim_BtoA = F.softmax((cross_sim_BA_out - 1) / t_des, dim=-1)         # NB X (H X W + 1)
                soft_cross_sim_AB_all = F.grid_sample(soft_cross_sim_AtoB[:, :-2].view(-1, H, W).unsqueeze(0),
                                                    pntA_H_normalized[vmaskAH, :].detach().view(1, 1, -1, 2),
                                                    mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NA x match_nA
                
                soft_cross_sim_BA_all = F.grid_sample(soft_cross_sim_BtoA[:, :-2].view(-1, H, W).unsqueeze(0),
                                                    pntB_invH_normalized[vmaskBH, :].detach().view(1, 1, -1, 2),
                                                    mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NB x match_nB
                # soft_valid_cross_sim_AB_all = soft_cross_sim_AB_all[mask_pointA, :]             # repeat_nA x repeat_nA
                # soft_valid_cross_sim_BA_all = soft_cross_sim_BA_all[mask_pointB, :]             # repeat_nB x repeat_nB

                soft_valid_cross_sim_AB_all = soft_cross_sim_AB_all[match_mask_A==1, :]             # match_nA x match_nA
                soft_valid_cross_sim_BA_all = soft_cross_sim_BA_all[match_mask_B==1, :]             # match_nB x match_nB

                valid_mask_AB = torch.eye(soft_valid_cross_sim_AB_all.shape[0]) == 1
                valid_mask_BA = torch.eye(soft_valid_cross_sim_BA_all.shape[0]) == 1
                # print(4)
                # 取对角线
                soft_valid_cross_sim_AB = soft_valid_cross_sim_AB_all[valid_mask_AB]
                soft_valid_cross_sim_BA = soft_valid_cross_sim_BA_all[valid_mask_BA]

                # soft_novalid_cross_sim_AB = soft_cross_sim_AtoB[mask_pointA==False, -1]              # (NA-repeat_nA) x 1
                # soft_novalid_cross_sim_BA = soft_cross_sim_BtoA[mask_pointB==False, -1]
                soft_novalid_cross_sim_AB = soft_cross_sim_AtoB[match_mask_nb_A==0, -1]               # (NA-match_nA) x 1
                soft_novalid_cross_sim_BA = soft_cross_sim_BtoA[match_mask_nb_B==0, -1]
                # print(soft_novalid_cross_sim_AB, soft_novalid_cross_sim_BA)

                log_soft_valid_cross_sim_AB = -torch.log(soft_valid_cross_sim_AB + eps) * (1 - torch.diag(dis_oriATAB)[vmaskAH] / self.ori_diff) * (1 - torch.diag(bin_distATAB[mask_pointA, :])[vmaskAH] / bin_kpAB_T.shape[0])
                log_soft_valid_cross_sim_BA = -torch.log(soft_valid_cross_sim_BA + eps) * (1 - torch.diag(dis_oriBTBA)[vmaskBH] / self.ori_diff) * (1 - torch.diag(bin_distBTBA[mask_pointB, :])[vmaskBH] / bin_kpBA_T.shape[0])
                log_soft_novalid_cross_sim_AB = -torch.log(soft_novalid_cross_sim_AB + eps)
                log_soft_novalid_cross_sim_BA = -torch.log(soft_novalid_cross_sim_BA + eps)

                dis_cross_sim_mean = torch.sum(torch.cat((4*log_soft_valid_cross_sim_AB, 4*log_soft_valid_cross_sim_BA, log_soft_novalid_cross_sim_AB, log_soft_novalid_cross_sim_BA), dim=-1), dim=-1) / (new_numA + new_numB)
                
                # print(5)
                valid_cross_sim_AB = cross_sim_AB[mask_pointA, :]   # repeat_nA x (H X W)
                valid_cross_sim_BA = cross_sim_BA[mask_pointB, :]   # repeat_nB x (H X W)
                exp_valid_cross_sim_AtoB = torch.exp((valid_cross_sim_AB - 1) / t_rel).view(-1, H, W)
                exp_valid_cross_sim_BtoA = torch.exp((valid_cross_sim_BA - 1) / t_rel).view(-1, H, W)
                exp_valid_cross_sim_AB_all = F.grid_sample(exp_valid_cross_sim_AtoB.unsqueeze(0),
                                                        pntA_H_normalized.detach().view(1, 1, -1, 2),
                                                        mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # repeat_nA x repeat_nA
                
                exp_valid_cross_sim_BA_all = F.grid_sample(exp_valid_cross_sim_BtoA.unsqueeze(0),
                                                        pntB_invH_normalized.detach().view(1, 1, -1, 2),
                                                        mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # repeat_nB x repeat_nB

                repeat_mask_AB = torch.eye(exp_valid_cross_sim_AB_all.shape[0]) == 1
                repeat_mask_BA = torch.eye(exp_valid_cross_sim_BA_all.shape[0]) == 1
                rel_valid_cross_sim_AB = exp_valid_cross_sim_AB_all[repeat_mask_AB]
                rel_valid_cross_sim_BA = exp_valid_cross_sim_BA_all[repeat_mask_BA]

                # pntA_H_normalized_new = copy.deepcopy(pntA_H_normalized.detach())
                # pntB_invH_normalized_new = copy.deepcopy(pntB_invH_normalized.detach())

                # pntA_H_normalized_new[:, 0] += 2
                # pntB_invH_normalized_new[:, 0] += 2

                scoresAB_all = F.grid_sample(scores_mapB[idx, :, :, :].unsqueeze(0),
                                            pntA_H_normalized_new.view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)      # 1 x repeat_nA

                scoresBA_all = F.grid_sample(scores_mapA[idx, :, :, :].unsqueeze(0),
                                            pntB_invH_normalized_new.view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)      # 1 x repeat_nB
                # print(6)
                scores_AAB = scoresA[idx][pmA][mask_pointA] * scoresAB_all
                scores_BBA = scoresB[idx][pmB][mask_pointB] * scoresBA_all
                scores_sum_AAB = torch.sum(scores_AAB, dim=-1)
                scores_sum_BBA = torch.sum(scores_BBA, dim=-1)
                scores_normalize_AAB = scores_AAB / (scores_sum_AAB + eps)
                scores_normalize_BBA = scores_BBA / (scores_sum_BBA + eps)
                rel_meanA = torch.sum(scores_normalize_AAB * (1 - rel_valid_cross_sim_AB), dim=-1) / pntA_H_normalized_new.shape[0]
                rel_meanB = torch.sum(scores_normalize_BBA * (1 - rel_valid_cross_sim_BA), dim=-1) / pntB_invH_normalized_new.shape[0]

                # # 熵loss
                # current_descA_std, current_descB_std = descA_std[countA:countA+new_numA], descB_std[countB:countB+new_numB]
                # desc_std += torch.mean(current_descA_std) + torch.mean(current_descB_std)
                # countA_T += numA_T
                # countB_T += numB_T

                dis_neighbor_mean_total += torch.mean(torch.sum(neighbor_dis_AB, dim=1)) + torch.mean(torch.sum(neighbor_dis_BA, dim=1))
                dis_desc += dis_cross_sim_mean_sp
                dis_desc += dis_cross_sim_mean

                dis_pair_meanAB = torch.mean(key_manhattandisAB[pairAB_A, pairAB_B])
                dis_pair_meanBA = torch.mean(key_manhattandisBA[pairBA_B, pairBA_A])

                dis_peak_mean = torch.mean(torch.cat((scoreddisA[idx][pmA], scoreddisB[idx][pmB]), dim=0))
                # dis_peak_meanB = torch.mean(scoreddisB[idx])
                
                dis_mean_total += dis_pair_meanAB + dis_pair_meanBA
                dis_peak_scored += dis_peak_mean

                dis_rel += rel_meanA + rel_meanB
                
                countA += new_numA
                countB += new_numB
                count_ne += new_num_ne
                # # Penalty
                # scores_mean += (-torch.log(torch.mean(scoresA[idx], dim=-1) + eps) - torch.log(torch.mean(scoresB[idx], dim=-1) + eps)) 
                # print(scores_mean)
            except:
                # dis_mean_total += 0
                # dis_peak_scored += 0
                # dis_desc += 0
                # dis_rel += 0
                # print('Overlapping too small or Repeatable point pairs distance is greater than correspond(1.5):', pntA.shape[0], pntA_H.shape[0], pntB.shape[0], pntB_invH.shape[0], dis_pairAB.shape[0], dis_pairBA.shape[0])
                valid_batch_size -= 1
                countA += new_numA
                countB += new_numB
                count_ne += new_num_ne
                # countA_T += numA_T
                # countB_T += numB_T

        valid_batch_size = valid_batch_size if valid_batch_size > 0 else eps
        # Reprojection Loss 
        reprojection_loss = dis_mean_total / (valid_batch_size * 2)
        # Dispersity Peak Loss
        dispersity_peak_loss = dis_peak_scored / valid_batch_size
        # NRE Loss
        descriptor_loss = dis_desc / (2 * valid_batch_size)
        # Reliability Loss
        reliability_loss = dis_rel / (valid_batch_size * 2)
        # SOSR Loss
        sosr_loss = dis_neighbor_mean_total / ((valid_batch_size * 2))
        # # Entropy loss
        # std_loss = (valid_batch_size * 2) / desc_std  
        # # Score Penalty
        # score_penalty = scores_mean / (valid_batch_size * 2)
        # # FA Desc loss
        # FA_des_loss = dis_desc_fa / valid_batch_size_FA if valid_batch_size_FA > 0 else 0

        loss_total = wrp * reprojection_loss + wpl * dispersity_peak_loss + wdl * descriptor_loss + wrl * reliability_loss + sosr_loss
        loss_group = {
            'reprojection_loss': reprojection_loss, 
            'dispersity_peak_loss': dispersity_peak_loss,
            'descriptor_loss': descriptor_loss,
            'reliability_loss': reliability_loss,
            'sosr_loss': sosr_loss,
            # 'std_loss': std_loss,
            # 'FA_des_loss': FA_des_loss,
            }
        return loss_total, loss_group


    # patch/dense AT角度 黑白相似度加量化 NFA two negtives
    def detector_selfsupervised_loss_dkd_patch_ext_restrict_modify_oriR_ratio_NFA_qtbw_ns_wg_nori_AT_NE2(self, kpA, kpB, pmaskA, pmaskB, descA, descB, desc_mapA, desc_mapB, scoreddisA, scoreddisB, scoresA, scoresB, scores_mapA, scores_mapB, Homo, inv_Homo, inv_Homo_en, ori_all_patchA, ori_all_patchB, ori_kp_patchA, ori_kp_patchB, bin_allA, bin_allB, bin_kpA, bin_kpB, kp_ne, pmask_ne, desc_ne, bin_kp_ne, kp_ne2, pmask_ne2, desc_ne2, bin_kp_ne2, trans_angle, FA_flag, H, W, wrp=1, wpl=1, wdl=1, wrl=1, t_des=0.02, t_rel=1):
        # pmaskA: (BxMax_num) 32x350=11200
        batch_size = len(kpA)
        max_num = pmaskA.shape[-1] // batch_size    # 350
        dis_mean_total = 0
        dis_neighbor_mean_total = 0
        dis_peak_scored = 0
        dis_desc = 0
        dis_rel = 0
        desc_std = 0
        eps = 1e-12
        valid_batch_size = batch_size
        # valid_batch_size_FA = 0
        countA, countB, count_ne, count_ne2 = 0, 0, 0, 0
        # dis_desc_fa = 0
        # countA_T, countB_T = 0, 0
        for idx in range(batch_size):
            pntA, pntB, pnt_ne, pnt_ne2 = kpA[idx], kpB[idx], kp_ne[idx], kp_ne2[idx]     # M X 2 (x,y)
            # kmask_TA, kmask_TB = kmask_T_allA[idx], kmask_T_allB[idx]
            pntA = pntA.float()
            pntB = pntB.float()
            pnt_ne = pnt_ne.float()
            pnt_ne2 = pnt_ne2.float()

            # 剔除部分按压区域的点,且保留在重叠区域的点
            numA, numB, num_ne, num_ne2 = pntA.shape[0], pntB.shape[0], pnt_ne.shape[0], pnt_ne2.shape[0]
            # numA_T, numB_T = pntA[kmask_TA].shape[0], pntB[kmask_TB].shape[0]
            pmA, pmB, pm_ne, pm_ne2 = pmaskA[max_num * idx:max_num * idx + numA].bool(), pmaskB[max_num * idx:max_num * idx + numB].bool(), pmask_ne[max_num * idx:max_num * idx + num_ne].bool(), pmask_ne2[max_num * idx:max_num * idx + num_ne2].bool()
            pntA, pntB, pnt_ne, pnt_ne2 = pntA[pmA, :], pntB[pmB, :], pnt_ne[pm_ne, :], pnt_ne2[pm_ne2, :] 
            new_numA, new_numB, new_num_ne, new_num_ne2 = pntA.shape[0], pntB.shape[0], pnt_ne.shape[0], pnt_ne2.shape[0]      
            
            pntA = (pntA + 1) / 2 * pntA.new_tensor([[W + 3, H - 1]]).to(pntA.device)
            pntB = (pntB + 1) / 2 * pntB.new_tensor([[W + 3, H - 1]]).to(pntB.device)

            # [120, 40] -> [120, 36],实际只取中心118x32区域的点对
            pntA[:, 0] -= 2
            pntB[:, 0] -= 2
            
            pntA_normalized = pntA / pntA.new_tensor([W - 1, H - 1]).to(pntA.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)
            pntB_normalized = pntB / pntB.new_tensor([W - 1, H - 1]).to(pntB.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)

            pntA_H = warp_points(pntA[:, :2], Homo[idx].squeeze(), device=self.device)  # 利用变换矩阵变换坐标点
            pntA_H, mask_pointA = filter_points(pntA_H, torch.tensor([W, H], device=self.device), return_mask=True)
            pntB_invH = warp_points(pntB[:, :2], inv_Homo[idx].squeeze(), device=self.device)
            pntB_invH, mask_pointB = filter_points(pntB_invH, torch.tensor([W, H], device=self.device), return_mask=True)
            
            current_descA, current_descB = descA[countA:countA+new_numA], descB[countB:countB+new_numB]
            current_desc_ne = desc_ne[count_ne:count_ne+new_num_ne]
            current_desc_ne2 = desc_ne2[count_ne2:count_ne2+new_num_ne2]
            cross_sim_AB_sp = current_descA @ current_descB.transpose(0, 1)     # NTA X NTB
            
            cross_sim_AN_sp = current_descA @ current_desc_ne.transpose(0, 1)
            cross_sim_BN_sp = current_descB @ current_desc_ne.transpose(0, 1)
            cross_sim_AN2_sp = current_descA @ current_desc_ne2.transpose(0, 1)
            cross_sim_BN2_sp = current_descB @ current_desc_ne2.transpose(0, 1)
            
            # 黑白相似度
            current_binA, current_binB = (bin_kpA[countA:countA+new_numA] >= 0.5).float(), (bin_kpB[countB:countB+new_numB] >= 0.5).float()   # [NA, 256] [NB_256]
            current_bin_ne = (bin_kp_ne[count_ne:count_ne+new_num_ne] >= 0.5).float()
            current_bin_ne2 = (bin_kp_ne2[count_ne2:count_ne2+new_num_ne2] >= 0.5).float()
            bin_distAB = current_binA.shape[-1] - (current_binA @ current_binB.transpose(0, 1)) - ((1 - current_binA) @ (1 - current_binB.transpose(0, 1))) # [NA, NB]
            
            bin_distAN = current_binA.shape[-1] - (current_binA @ current_bin_ne.transpose(0, 1)) - ((1 - current_binA) @ (1 - current_bin_ne.transpose(0, 1))) # [NA, NE]
            bin_distBN = current_binB.shape[-1] - (current_binB @ current_bin_ne.transpose(0, 1)) - ((1 - current_binB) @ (1 - current_bin_ne.transpose(0, 1))) # [NA, NE]
            bin_distAN2 = current_binA.shape[-1] - (current_binA @ current_bin_ne2.transpose(0, 1)) - ((1 - current_binA) @ (1 - current_bin_ne2.transpose(0, 1))) # [NA, NE]
            bin_distBN2 = current_binB.shape[-1] - (current_binB @ current_bin_ne2.transpose(0, 1)) - ((1 - current_binB) @ (1 - current_bin_ne2.transpose(0, 1))) # [NA, NE]
            
            # 真匹配的trans
            try:
                FAN_bin_mask = bin_distAN >= (1 - self.FA_bin_thr) * current_binA.shape[-1] 
                FBN_bin_mask = bin_distBN >= (1 - self.FA_bin_thr) * current_binB.shape[-1] 
                FAN2_bin_mask = bin_distAN2 >= (1 - self.FA_bin_thr) * current_binA.shape[-1] 
                FBN2_bin_mask = bin_distBN2 >= (1 - self.FA_bin_thr) * current_binB.shape[-1] 
                # topk ?
                crossAN_mean = torch.mean(cross_sim_AN_sp[FAN_bin_mask])
                crossBN_mean = torch.mean(cross_sim_BN_sp[FBN_bin_mask])
                crossAN2_mean = torch.mean(cross_sim_AN2_sp[FAN2_bin_mask])
                crossBN2_mean = torch.mean(cross_sim_BN2_sp[FBN2_bin_mask])

                assert pntA_H.shape[0] > 0 and pntB_invH.shape[0] > 0 
                
                # 点对欧氏距离
                key_disAB = self.get_dis(pntA_H[:, :2], pntB[:, :2])            # repeatNA x NB
                key_disBA = self.get_dis(pntB_invH[:, :2], pntA[:, :2])
                pairAB_A, pairAB_B, dis_pairAB, _ = self.get_point_pair(key_disAB, dis_thre=self.correspond)  # p -> k # NTA(<1.5), NTA(<1.5), NTA(<1.5), NTA        
                pairBA_B, pairBA_A, dis_pairBA, _  = self.get_point_pair(key_disBA, dis_thre=self.correspond)  # p -> k # NTB(<1.5), NTB(<1.5), NTB(<1.5), NTB 
                
                # 点距离mask
                nn_maskAB = torch.zeros((pntA_H.shape[0], pntB.shape[0]), device=self.device) 
                nn_maskAB[pairAB_A, pairAB_B] = 1

                nn_maskBA = torch.zeros((pntB_invH.shape[0], pntA.shape[0]), device=self.device) 
                nn_maskBA[pairBA_B, pairBA_A] = 1

                # 点对曼哈顿距离
                key_manhattandisAB = self.get_manhattan_dis(pntA_H[:, :2], pntB[:, :2])
                key_manhattandisBA = self.get_manhattan_dis(pntB_invH[:, :2], pntA[:, :2])
                # print('pdis:', dis_pairAB.shape[0], dis_pairBA.shape[0])
                assert dis_pairAB.shape[0] > 0 and dis_pairBA.shape[0] > 0     

                pntA_H_normalized = pntA_H / pntA_H.new_tensor([W - 1, H - 1]).to(pntA_H.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)
                pntB_invH_normalized = pntB_invH / pntB_invH.new_tensor([W - 1, H - 1]).to(pntB_invH.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)

                # 用于score_map
                pntA_H_new = copy.deepcopy(pntA_H.detach())
                pntB_invH_new = copy.deepcopy(pntB_invH.detach())
                pntA_H_new[:, 0] += 10                   # 120 x 36 -> 128 x 56
                pntA_H_new[:, 1] += 4 
                pntB_invH_new[:, 0] += 10
                pntB_invH_new[:, 1] += 4
                
                pntA_H_normalized_new = pntA_H_new / pntA_H_new.new_tensor([W + 19, H + 7]).to(pntA_H.device) * 2 - 1

                # pntB_invH_new = warp_points(pntB_invH_new[:, :2], inv_Homo_en[idx].squeeze(), device=self.device)       # 转到A上，而不是AT上
                
                pntB_invH_normalized_new = pntB_invH_new / pntB_invH_new.new_tensor([W + 19, H + 7]).to(pntB_invH.device) * 2 - 1 
                
                # print('1_2:', main_ori_maskATB.shape[0])
                # exit()
                ori_kpAT_patch_ext = F.grid_sample(ori_kp_patchA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntA_H_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0).transpose(0, 1)          # repeatNA x 1
                ori_kpB_patch_ext = F.grid_sample(ori_all_patchB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntB_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0).transpose(0, 1)          # NTB x 1
                ori_kpA_patch_ext = F.grid_sample(ori_all_patchA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntA_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0).transpose(0, 1)          # NTA x 1
                ori_kpBT_patch_ext = F.grid_sample(ori_kp_patchB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntB_invH_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0).transpose(0, 1)          # repeatNB x 1
                # print('1_2_1:', pntB_invH_normalized_new.shape[0])
                ori_maskATB, dis_oriATB = self.get_main_ori_consistence_AT(ori_kpAT_patch_ext, ori_kpB_patch_ext)  # repeatNA x NTB
                # print('1_2_2:', ori_maskATB.shape)
                ori_maskBTA, dis_oriBTA = self.get_main_ori_consistence_AT(ori_kpBT_patch_ext, ori_kpA_patch_ext)  # repeatNB x NTA

                match_maskAB_nb = (nn_maskAB == 1) * ori_maskATB           # repeatNA X NTB
                match_maskBA_nb = (nn_maskBA == 1) * ori_maskBTA          # repeatNB X NTA
                pairAB_A_nb_new, pairAB_B_nb_new = torch.where(match_maskAB_nb == 1)
                pairBA_B_nb_new, pairBA_A_nb_new = torch.where(match_maskBA_nb == 1)
                # assert pairAB_A_new.shape[0] > 0 and pairBA_B_new.shape[0] > 0 

                # 4x4邻域方向一致性
                ori_kpAB_patch_ext = F.grid_sample(ori_all_patchB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntA_H_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0).transpose(0, 1)  
                ori_kpBA_patch_ext = F.grid_sample(ori_all_patchA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntB_invH_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0).transpose(0, 1)  
                # print('1_2_4:', ori_kpAB_patch_ext.shape)
                ori_maskATAB, dis_oriATAB = self.get_main_ori_consistence_AT(ori_kpAT_patch_ext, ori_kpAB_patch_ext)  # repeatNA x repeatNA
                ori_maskBTBA, dis_oriBTBA = self.get_main_ori_consistence_AT(ori_kpBT_patch_ext, ori_kpBA_patch_ext)  # repeatNB x repeatNB
                
                # 黑白相似度
                bin_maskATB = bin_distAB <= (1 - self.FR_bin_thr) * current_binA.shape[-1]  
                bin_maskBTA = bin_maskATB.transpose(0, 1)  

                match_maskAB = match_maskAB_nb * bin_maskATB[mask_pointA, :]               # repeatNA X NB
                match_maskBA = match_maskBA_nb * bin_maskBTA[mask_pointB, :]               # repeatNB X NA

                pairAB_A_new, pairAB_B_new = torch.where(match_maskAB == 1)
                pairBA_B_new, pairBA_A_new = torch.where(match_maskBA == 1)
                # print('bin_mask:', pairAB_A_new.shape[0], pairBA_B_new.shape[0])
                assert pairAB_A_new.shape[0] > 0 and pairBA_B_new.shape[0] > 0 

                bin_kpAB_T = (F.grid_sample(bin_allB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntA_H_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0) >= 0.5).float()  # [256, repeatNA]
                bin_kpBA_T = (F.grid_sample(bin_allA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntB_invH_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0) >= 0.5).float()  # [256, repeatNB]
                bin_distATAB = bin_kpAB_T.shape[0] - (current_binA @ bin_kpAB_T) - ((1 - current_binA) @ (1 - bin_kpAB_T)) # [NTA, repeatNA]
                bin_distBTBA = bin_kpBA_T.shape[0] - (current_binB @ bin_kpBA_T) - ((1 - current_binB) @ (1 - bin_kpBA_T)) # [NTB, repeatNB]

                bin_maskATAB = bin_distATAB <= (1 - self.FR_bin_thr) * bin_kpAB_T.shape[0] 
                bin_maskBTBA = bin_distBTBA <= (1 - self.FR_bin_thr) * bin_kpBA_T.shape[0] 
                bin_maskATAB = bin_maskATAB[mask_pointA, :]
                bin_maskBTBA = bin_maskBTBA[mask_pointB, :]

                vmaskAH_nb = torch.diag(ori_maskATAB)
                vmaskBH_nb = torch.diag(ori_maskBTBA)
                vmaskAH = torch.diag(ori_maskATAB * bin_maskATAB) == 1      # [repeatNA, 1]
                vmaskBH = torch.diag(ori_maskBTBA * bin_maskBTBA) == 1      # [repeatNB, 1]

                # print('main_ori:', torch.sum(vmaskAH), torch.sum(vmaskBH))
                assert torch.sum(vmaskAH) > 0 and torch.sum(vmaskBH) > 0

                # SOSR: 简化的self-attention
                k_neighbor = 3
                cross_sim_AA_sp = current_descA @ current_descA.transpose(0, 1)
                cross_sim_BB_sp = current_descB @ current_descB.transpose(0, 1)
                # print('SOSR:', pairAB_A_new.shape[0], pairBA_B_new.shape[0])
                assert pairAB_A_new.shape[0] >= k_neighbor and pairBA_B_new.shape[0] >= k_neighbor 

                match_sim_AB_AA = cross_sim_AA_sp[mask_pointA, :][:, mask_pointA][pairAB_A_new, :][:, pairAB_A_new]
                match_sim_BA_BB = cross_sim_BB_sp[mask_pointB, :][:, mask_pointB][pairBA_B_new, :][:, pairBA_B_new]
                match_sim_AB_BB = cross_sim_BB_sp[pairAB_B_new, :][:, pairAB_B_new]
                match_sim_BA_AA = cross_sim_AA_sp[pairBA_A_new, :][:, pairBA_A_new]
                match_values_AB_AA, match_indices_AB_AA = torch.topk(match_sim_AB_AA, dim=1, k=k_neighbor, largest=False)
                match_values_BA_BB, match_indices_BA_BB = torch.topk(match_sim_BA_BB, dim=1, k=k_neighbor, largest=False)
                match_values_AB_BB_all = match_sim_AB_BB[:, match_indices_AB_AA]
                match_values_BA_AA_all = match_sim_BA_AA[:, match_indices_BA_BB]
                match_values_AB_BB = torch.diagonal(match_values_AB_BB_all, 0, dim1=0, dim2=1).transpose(0, 1)
                match_values_BA_AA = torch.diagonal(match_values_BA_AA_all, 0, dim1=0, dim2=1).transpose(0, 1)
                neighbor_dis_AB = (match_values_AB_AA - match_values_AB_BB) * (match_values_AB_AA - match_values_AB_BB)
                neighbor_dis_BA = (match_values_BA_BB - match_values_BA_AA) * (match_values_BA_BB - match_values_BA_AA)

                # PA VS PB
                # 计算bin值
                valid_cross_sim_AB_sp_mean = torch.mean(cross_sim_AB_sp[mask_pointA, :][match_maskAB == 1], dim=-1)
                valid_cross_sim_AB_sp_nb_mean = torch.mean(cross_sim_AB_sp[mask_pointA, :][match_maskAB_nb == 1], dim=-1)
                novalid_cross_sim_AB_sp_mean = (torch.sum(torch.sum(cross_sim_AB_sp.detach(), 1), 0) - valid_cross_sim_AB_sp_nb_mean * pairAB_A_nb_new.shape[0]) / (new_numA * new_numB - pairAB_A_nb_new.shape[0] + eps)
                valid_cross_sim_BA_sp_mean = torch.mean(cross_sim_AB_sp[:, mask_pointB][match_maskBA.transpose(0, 1) == 1], dim=-1)
                valid_cross_sim_BA_sp_nb_mean = torch.mean(cross_sim_AB_sp[:, mask_pointB][match_maskBA_nb.transpose(0, 1) == 1], dim=-1)
                novalid_cross_sim_BA_sp_mean = (torch.sum(torch.sum(cross_sim_AB_sp.detach(), 1), 0) - valid_cross_sim_BA_sp_nb_mean * pairBA_B_nb_new.shape[0]) / (new_numA * new_numB - pairBA_B_nb_new.shape[0] + eps)

                valid_indexesA = torch.tensor(list(range(cross_sim_AB_sp.shape[0])), device=self.device)[mask_pointA][pairAB_A_new]
                valid_indexesA_nb = torch.tensor(list(range(cross_sim_AB_sp.shape[0])), device=self.device)[mask_pointA][pairAB_A_nb_new]
                # cross_sim_BA_sp = current_descB @ current_descA.transpose(0, 1)
                cross_sim_AB_out_sp = torch.cat((cross_sim_AB_sp, torch.ones((cross_sim_AB_sp.shape[0], 3), device=cross_sim_AB_sp.device) * 2), dim=-1)      # NA X (NB + 2)
                cross_sim_AB_out_nb_sp = torch.cat((cross_sim_AB_sp, torch.ones((cross_sim_AB_sp.shape[0], 3), device=cross_sim_AB_sp.device) * 2), dim=-1)      # NA X (NB + 2)
                # cross_sim_BA_out_sp = torch.cat((cross_sim_BA_sp, torch.ones((numB, 1), device=cross_sim_BA_sp.device)), dim=-1)      # NB X (NA + 1)
                # valid_indexesB = torch.tensor(list(range(numB)), device=self.device)[mask_pointB][pairBA_B]
                # print('1_2')
                cross_sim_AB_out_sp[valid_indexesA, -1] = novalid_cross_sim_AB_sp_mean
                cross_sim_AB_out_sp[valid_indexesA, -2] = crossAN_mean
                cross_sim_AB_out_sp[valid_indexesA, -3] = crossAN2_mean
                cross_sim_AB_out_nb_sp[valid_indexesA_nb, -1] = novalid_cross_sim_AB_sp_mean
                novalid_indexesA = torch.tensor(list(range(cross_sim_AB_sp.shape[0])), device=self.device)[cross_sim_AB_out_nb_sp[:, -1]==2]
                cross_sim_AB_out_sp[novalid_indexesA, -1] = valid_cross_sim_AB_sp_mean
                # nomatch对不增加negtives的均值bin
                cross_sim_AB_out_sp[novalid_indexesA, -2] = -1 # crossAN_mean # -1
                cross_sim_AB_out_sp[novalid_indexesA, -3] = -1 # crossAN_mean # -1

                soft_cross_sim_AtoB_sp = F.softmax((cross_sim_AB_out_sp - 1) / t_des, dim=-1)
                # soft_cross_sim_BtoA = F.softmax((cross_sim_BA_out - 1) / t_des, dim=-1)
                # print('1_3')
                soft_valid_cross_sim_AB_sp = soft_cross_sim_AtoB_sp[mask_pointA, :-3][match_maskAB==1]
                # soft_valid_cross_sim_BA = soft_cross_sim_BtoA[mask_pointB, :-1][pairBA_B, pairBA_A]
                soft_novalid_cross_sim_AB_sp = soft_cross_sim_AtoB_sp[novalid_indexesA, -1]
                # soft_novalid_cross_sim_BA = soft_cross_sim_BtoA[cross_sim_BA_out[:, -1]==1, -1]
                log_soft_valid_cross_sim_AB_sp = -torch.log(soft_valid_cross_sim_AB_sp + eps) * (1 - dis_oriATB[match_maskAB==1] / self.ori_diff) * (1 - bin_distAB[mask_pointA, :][match_maskAB==1] / current_binA.shape[-1]) * (1 - key_disAB[match_maskAB==1].detach() / self.correspond)
                # log_soft_valid_cross_sim_BA = -torch.log(soft_valid_cross_sim_BA + eps)
                log_soft_novalid_cross_sim_AB_sp = -torch.log(soft_novalid_cross_sim_AB_sp + eps)
                # log_soft_novalid_cross_sim_BA = -torch.log(soft_novalid_cross_sim_BA + eps)
                dis_cross_sim_mean_sp = torch.sum(torch.cat((4*log_soft_valid_cross_sim_AB_sp, log_soft_novalid_cross_sim_AB_sp), dim=-1), dim=-1) / new_numA
                
                # PA VS PAB
                # match_mask_A = copy.deepcopy(mask_pointA)
                # match_mask_B = copy.deepcopy(mask_pointB)
                match_mask_A = torch.zeros(cross_sim_AB_sp.shape[0], device=self.device)
                match_mask_nb_A = torch.zeros(cross_sim_AB_sp.shape[0], device=self.device)
                valid_match_indexesA = torch.tensor(list(range(cross_sim_AB_sp.shape[0])), device=self.device)[mask_pointA][vmaskAH]
                valid_match_indexesA_nb = torch.tensor(list(range(cross_sim_AB_sp.shape[0])), device=self.device)[mask_pointA][vmaskAH_nb]
                match_mask_A[valid_match_indexesA] = 1
                match_mask_nb_A[valid_match_indexesA_nb] = 1

                match_mask_B = torch.zeros(cross_sim_AB_sp.shape[1], device=self.device)
                match_mask_nb_B = torch.zeros(cross_sim_AB_sp.shape[1], device=self.device)
                valid_match_indexesB = torch.tensor(list(range(cross_sim_AB_sp.shape[1])), device=self.device)[mask_pointB][vmaskBH]
                valid_match_indexesB_nb = torch.tensor(list(range(cross_sim_AB_sp.shape[1])), device=self.device)[mask_pointB][vmaskBH_nb]
                match_mask_B[valid_match_indexesB] = 1
                match_mask_nb_B[valid_match_indexesB_nb] = 1

                cross_sim_AB = current_descA @ desc_mapB[idx, :, :, :].view(-1, H * W)
                # cross_sim_AB = cross_sim_AB[mask_pointA, :]
                cross_sim_AB_all = F.grid_sample(cross_sim_AB.view(-1, H, W).unsqueeze(0),
                                                pntA_H_normalized[vmaskAH, :].detach().view(1, 1, -1, 2),
                                                mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NA x repeatNA
                valid_cross_sim_AB_mean = torch.trace(cross_sim_AB_all[match_mask_A==1, :]) / cross_sim_AB_all[match_mask_A==1, :].shape[0]
                # novalid_cross_sim_AB_mean = (torch.sum(torch.sum(cross_sim_AB.detach(), 1), 1) - valid_cross_sim_AB_mean * pairAB_A.shape[0]) / (new_numA * H * W - pairAB_A.shape[0])

                cross_sim_BA = current_descB @ desc_mapA[idx, :, :, :].view(-1, H * W)   # M x H x W
                # cross_sim_BA = cross_sim_BA[mask_pointB, :]
                cross_sim_BA_all = F.grid_sample(cross_sim_BA.view(-1, H, W).unsqueeze(0),
                                                pntB_invH_normalized[vmaskBH, :].detach().view(1, 1, -1, 2),
                                                mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NB x match_nB
                valid_cross_sim_BA_mean = torch.trace(cross_sim_BA_all[match_mask_B==1, :]) / cross_sim_BA_all[match_mask_B==1, :].shape[0]
                # novalid_cross_sim_BA_mean = (torch.sum(torch.sum(cross_sim_BA.detach(), 1), 1) - valid_cross_sim_BA_mean * pairBA_B.shape[0]) / (new_numB * H * W - pairBA_B.shape[0])

                cross_sim_AB_out = torch.cat((cross_sim_AB, torch.ones((cross_sim_AB.shape[0], 3), device=cross_sim_AB.device)), dim=-1)      # NA X (H X W + 2)
                cross_sim_BA_out = torch.cat((cross_sim_BA, torch.ones((cross_sim_BA.shape[0], 3), device=cross_sim_BA.device)), dim=-1)      # NB X (H X W + 2)
                # print(3)
                # cross_sim_AB_out[mask_pointA, -1] -= 1
                # cross_sim_BA_out[mask_pointB, -1] -= 1
                # cross_sim_AB_out[match_mask_A, -1] -= 1
                cross_sim_AB_out[match_mask_A==1, -1] = novalid_cross_sim_AB_sp_mean
                cross_sim_AB_out[match_mask_A==1, -2] = crossAN_mean
                cross_sim_AB_out[match_mask_A==1, -3] = crossAN2_mean
                cross_sim_AB_out[match_mask_nb_A==0, -1] = valid_cross_sim_AB_mean
                cross_sim_AB_out[match_mask_nb_A==0, -2] = -1 # crossAN_mean # -1
                cross_sim_AB_out[match_mask_nb_A==0, -3] = -1 # crossAN_mean # -1

                cross_sim_BA_out[match_mask_B==1, -1] = novalid_cross_sim_BA_sp_mean
                cross_sim_BA_out[match_mask_B==1, -2] = crossBN_mean
                cross_sim_BA_out[match_mask_B==1, -3] = crossBN2_mean
                cross_sim_BA_out[match_mask_nb_B==0, -1] = valid_cross_sim_BA_mean
                cross_sim_BA_out[match_mask_nb_B==0, -2] = -1 # crossBN_mean # -1
                cross_sim_BA_out[match_mask_nb_B==0, -3] = -1 # crossBN_mean # -1

                soft_cross_sim_AtoB = F.softmax((cross_sim_AB_out - 1) / t_des, dim=-1)         # NA X (H X W + 1)
                soft_cross_sim_BtoA = F.softmax((cross_sim_BA_out - 1) / t_des, dim=-1)         # NB X (H X W + 1)
                soft_cross_sim_AB_all = F.grid_sample(soft_cross_sim_AtoB[:, :-3].view(-1, H, W).unsqueeze(0),
                                                    pntA_H_normalized[vmaskAH, :].detach().view(1, 1, -1, 2),
                                                    mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NA x match_nA
                
                soft_cross_sim_BA_all = F.grid_sample(soft_cross_sim_BtoA[:, :-3].view(-1, H, W).unsqueeze(0),
                                                    pntB_invH_normalized[vmaskBH, :].detach().view(1, 1, -1, 2),
                                                    mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NB x match_nB
                # soft_valid_cross_sim_AB_all = soft_cross_sim_AB_all[mask_pointA, :]             # repeat_nA x repeat_nA
                # soft_valid_cross_sim_BA_all = soft_cross_sim_BA_all[mask_pointB, :]             # repeat_nB x repeat_nB

                soft_valid_cross_sim_AB_all = soft_cross_sim_AB_all[match_mask_A==1, :]             # match_nA x match_nA
                soft_valid_cross_sim_BA_all = soft_cross_sim_BA_all[match_mask_B==1, :]             # match_nB x match_nB

                valid_mask_AB = torch.eye(soft_valid_cross_sim_AB_all.shape[0]) == 1
                valid_mask_BA = torch.eye(soft_valid_cross_sim_BA_all.shape[0]) == 1
                # print(4)
                # 取对角线
                soft_valid_cross_sim_AB = soft_valid_cross_sim_AB_all[valid_mask_AB]
                soft_valid_cross_sim_BA = soft_valid_cross_sim_BA_all[valid_mask_BA]

                # soft_novalid_cross_sim_AB = soft_cross_sim_AtoB[mask_pointA==False, -1]              # (NA-repeat_nA) x 1
                # soft_novalid_cross_sim_BA = soft_cross_sim_BtoA[mask_pointB==False, -1]
                soft_novalid_cross_sim_AB = soft_cross_sim_AtoB[match_mask_nb_A==0, -1]               # (NA-match_nA) x 1
                soft_novalid_cross_sim_BA = soft_cross_sim_BtoA[match_mask_nb_B==0, -1]
                # print(soft_novalid_cross_sim_AB, soft_novalid_cross_sim_BA)

                log_soft_valid_cross_sim_AB = -torch.log(soft_valid_cross_sim_AB + eps) * (1 - torch.diag(dis_oriATAB)[vmaskAH] / self.ori_diff) * (1 - torch.diag(bin_distATAB[mask_pointA, :])[vmaskAH] / bin_kpAB_T.shape[0])
                log_soft_valid_cross_sim_BA = -torch.log(soft_valid_cross_sim_BA + eps) * (1 - torch.diag(dis_oriBTBA)[vmaskBH] / self.ori_diff) * (1 - torch.diag(bin_distBTBA[mask_pointB, :])[vmaskBH] / bin_kpBA_T.shape[0])
                log_soft_novalid_cross_sim_AB = -torch.log(soft_novalid_cross_sim_AB + eps)
                log_soft_novalid_cross_sim_BA = -torch.log(soft_novalid_cross_sim_BA + eps)

                dis_cross_sim_mean = torch.sum(torch.cat((4*log_soft_valid_cross_sim_AB, 4*log_soft_valid_cross_sim_BA, log_soft_novalid_cross_sim_AB, log_soft_novalid_cross_sim_BA), dim=-1), dim=-1) / (new_numA + new_numB)
                
                # print(5)
                valid_cross_sim_AB = cross_sim_AB[mask_pointA, :]   # repeat_nA x (H X W)
                valid_cross_sim_BA = cross_sim_BA[mask_pointB, :]   # repeat_nB x (H X W)
                exp_valid_cross_sim_AtoB = torch.exp((valid_cross_sim_AB - 1) / t_rel).view(-1, H, W)
                exp_valid_cross_sim_BtoA = torch.exp((valid_cross_sim_BA - 1) / t_rel).view(-1, H, W)
                exp_valid_cross_sim_AB_all = F.grid_sample(exp_valid_cross_sim_AtoB.unsqueeze(0),
                                                        pntA_H_normalized.detach().view(1, 1, -1, 2),
                                                        mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # repeat_nA x repeat_nA
                
                exp_valid_cross_sim_BA_all = F.grid_sample(exp_valid_cross_sim_BtoA.unsqueeze(0),
                                                        pntB_invH_normalized.detach().view(1, 1, -1, 2),
                                                        mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # repeat_nB x repeat_nB

                repeat_mask_AB = torch.eye(exp_valid_cross_sim_AB_all.shape[0]) == 1
                repeat_mask_BA = torch.eye(exp_valid_cross_sim_BA_all.shape[0]) == 1
                rel_valid_cross_sim_AB = exp_valid_cross_sim_AB_all[repeat_mask_AB]
                rel_valid_cross_sim_BA = exp_valid_cross_sim_BA_all[repeat_mask_BA]

                # pntA_H_normalized_new = copy.deepcopy(pntA_H_normalized.detach())
                # pntB_invH_normalized_new = copy.deepcopy(pntB_invH_normalized.detach())

                # pntA_H_normalized_new[:, 0] += 2
                # pntB_invH_normalized_new[:, 0] += 2

                scoresAB_all = F.grid_sample(scores_mapB[idx, :, :, :].unsqueeze(0),
                                            pntA_H_normalized_new.view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)      # 1 x repeat_nA

                scoresBA_all = F.grid_sample(scores_mapA[idx, :, :, :].unsqueeze(0),
                                            pntB_invH_normalized_new.view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)      # 1 x repeat_nB
                # print(6)
                scores_AAB = scoresA[idx][pmA][mask_pointA] * scoresAB_all
                scores_BBA = scoresB[idx][pmB][mask_pointB] * scoresBA_all
                scores_sum_AAB = torch.sum(scores_AAB, dim=-1)
                scores_sum_BBA = torch.sum(scores_BBA, dim=-1)
                scores_normalize_AAB = scores_AAB / (scores_sum_AAB + eps)
                scores_normalize_BBA = scores_BBA / (scores_sum_BBA + eps)
                rel_meanA = torch.sum(scores_normalize_AAB * (1 - rel_valid_cross_sim_AB), dim=-1) / pntA_H_normalized_new.shape[0]
                rel_meanB = torch.sum(scores_normalize_BBA * (1 - rel_valid_cross_sim_BA), dim=-1) / pntB_invH_normalized_new.shape[0]

                # # 熵loss
                # current_descA_std, current_descB_std = descA_std[countA:countA+new_numA], descB_std[countB:countB+new_numB]
                # desc_std += torch.mean(current_descA_std) + torch.mean(current_descB_std)
                # countA_T += numA_T
                # countB_T += numB_T

                dis_neighbor_mean_total += torch.mean(torch.sum(neighbor_dis_AB, dim=1)) + torch.mean(torch.sum(neighbor_dis_BA, dim=1))
                dis_desc += dis_cross_sim_mean_sp
                dis_desc += dis_cross_sim_mean

                dis_pair_meanAB = torch.mean(key_manhattandisAB[pairAB_A, pairAB_B])
                dis_pair_meanBA = torch.mean(key_manhattandisBA[pairBA_B, pairBA_A])

                dis_peak_mean = torch.mean(torch.cat((scoreddisA[idx][pmA], scoreddisB[idx][pmB]), dim=0))
                # dis_peak_meanB = torch.mean(scoreddisB[idx])
                
                dis_mean_total += dis_pair_meanAB + dis_pair_meanBA
                dis_peak_scored += dis_peak_mean

                dis_rel += rel_meanA + rel_meanB
                
                countA += new_numA
                countB += new_numB
                count_ne += new_num_ne
                # # Penalty
                # scores_mean += (-torch.log(torch.mean(scoresA[idx], dim=-1) + eps) - torch.log(torch.mean(scoresB[idx], dim=-1) + eps)) 
                # print(scores_mean)
            except:
                # dis_mean_total += 0
                # dis_peak_scored += 0
                # dis_desc += 0
                # dis_rel += 0
                # print('Overlapping too small or Repeatable point pairs distance is greater than correspond(1.5):', pntA.shape[0], pntA_H.shape[0], pntB.shape[0], pntB_invH.shape[0], dis_pairAB.shape[0], dis_pairBA.shape[0])
                valid_batch_size -= 1
                countA += new_numA
                countB += new_numB
                count_ne += new_num_ne
                # countA_T += numA_T
                # countB_T += numB_T

        valid_batch_size = valid_batch_size if valid_batch_size > 0 else eps
        # Reprojection Loss 
        reprojection_loss = dis_mean_total / (valid_batch_size * 2)
        # Dispersity Peak Loss
        dispersity_peak_loss = dis_peak_scored / valid_batch_size
        # NRE Loss
        descriptor_loss = dis_desc / (2 * valid_batch_size)
        # Reliability Loss
        reliability_loss = dis_rel / (valid_batch_size * 2)
        # SOSR Loss
        sosr_loss = dis_neighbor_mean_total / ((valid_batch_size * 2))
        # # Entropy loss
        # std_loss = (valid_batch_size * 2) / desc_std  
        # # Score Penalty
        # score_penalty = scores_mean / (valid_batch_size * 2)
        # # FA Desc loss
        # FA_des_loss = dis_desc_fa / valid_batch_size_FA if valid_batch_size_FA > 0 else 0

        loss_total = wrp * reprojection_loss + wpl * dispersity_peak_loss + wdl * descriptor_loss + wrl * reliability_loss + sosr_loss
        loss_group = {
            'reprojection_loss': reprojection_loss, 
            'dispersity_peak_loss': dispersity_peak_loss,
            'descriptor_loss': descriptor_loss,
            'reliability_loss': reliability_loss,
            'sosr_loss': sosr_loss,
            # 'std_loss': std_loss,
            # 'FA_des_loss': FA_des_loss,
            }
        return loss_total, loss_group

    # patch/dense AT角度 黑白相似度加量化 NFA (two negtives) + (TopK hard negtives)
    def detector_selfsupervised_loss_dkd_patch_ext_restrict_modify_oriR_ratio_NFA_qtbw_ns_wg_nori_AT_HN_NE2(self, kpA, kpB, pmaskA, pmaskB, descA, descB, desc_mapA, desc_mapB, scoreddisA, scoreddisB, scoresA, scoresB, scores_mapA, scores_mapB, Homo, inv_Homo, inv_Homo_en, ori_all_patchA, ori_all_patchB, ori_kp_patchA, ori_kp_patchB, bin_allA, bin_allB, bin_kpA, bin_kpB, kp_ne, pmask_ne, desc_ne, bin_kp_ne, kp_ne2, pmask_ne2, desc_ne2, bin_kp_ne2, trans_angle, FA_flag, H, W, wrp=1, wpl=1, wdl=1, wrl=1, t_des=0.02, t_rel=1):
        # pmaskA: (BxMax_num) 32x350=11200
        batch_size = len(kpA)
        max_num = pmaskA.shape[-1] // batch_size    # 350
        dis_mean_total = 0
        dis_neighbor_mean_total = 0
        dis_peak_scored = 0
        dis_desc = 0
        dis_rel = 0
        desc_std = 0
        eps = 1e-12
        valid_batch_size = batch_size
        # valid_batch_size_FA = 0
        countA, countB, count_ne, count_ne2 = 0, 0, 0, 0
        # dis_desc_fa = 0
        # countA_T, countB_T = 0, 0
        for idx in range(batch_size):
            pntA, pntB, pnt_ne, pnt_ne2 = kpA[idx], kpB[idx], kp_ne[idx], kp_ne2[idx]     # M X 2 (x,y)
            # kmask_TA, kmask_TB = kmask_T_allA[idx], kmask_T_allB[idx]
            pntA = pntA.float()
            pntB = pntB.float()
            pnt_ne = pnt_ne.float()
            pnt_ne2 = pnt_ne2.float()

            # 剔除部分按压区域的点,且保留在重叠区域的点
            numA, numB, num_ne, num_ne2 = pntA.shape[0], pntB.shape[0], pnt_ne.shape[0], pnt_ne2.shape[0]
            # numA_T, numB_T = pntA[kmask_TA].shape[0], pntB[kmask_TB].shape[0]
            pmA, pmB, pm_ne, pm_ne2 = pmaskA[max_num * idx:max_num * idx + numA].bool(), pmaskB[max_num * idx:max_num * idx + numB].bool(), pmask_ne[max_num * idx:max_num * idx + num_ne].bool(), pmask_ne2[max_num * idx:max_num * idx + num_ne2].bool()
            pntA, pntB, pnt_ne, pnt_ne2 = pntA[pmA, :], pntB[pmB, :], pnt_ne[pm_ne, :], pnt_ne2[pm_ne2, :] 
            new_numA, new_numB, new_num_ne, new_num_ne2 = pntA.shape[0], pntB.shape[0], pnt_ne.shape[0], pnt_ne2.shape[0]      
            
            pntA = (pntA + 1) / 2 * pntA.new_tensor([[W + 3, H - 1]]).to(pntA.device)
            pntB = (pntB + 1) / 2 * pntB.new_tensor([[W + 3, H - 1]]).to(pntB.device)

            # [120, 40] -> [120, 36],实际只取中心118x32区域的点对
            pntA[:, 0] -= 2
            pntB[:, 0] -= 2
            
            pntA_normalized = pntA / pntA.new_tensor([W - 1, H - 1]).to(pntA.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)
            pntB_normalized = pntB / pntB.new_tensor([W - 1, H - 1]).to(pntB.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)

            pntA_H = warp_points(pntA[:, :2], Homo[idx].squeeze(), device=self.device)  # 利用变换矩阵变换坐标点
            pntA_H, mask_pointA = filter_points(pntA_H, torch.tensor([W, H], device=self.device), return_mask=True)
            pntB_invH = warp_points(pntB[:, :2], inv_Homo[idx].squeeze(), device=self.device)
            pntB_invH, mask_pointB = filter_points(pntB_invH, torch.tensor([W, H], device=self.device), return_mask=True)
            
            current_descA, current_descB = descA[countA:countA+new_numA], descB[countB:countB+new_numB]
            current_desc_ne = desc_ne[count_ne:count_ne+new_num_ne]
            current_desc_ne2 = desc_ne2[count_ne2:count_ne2+new_num_ne2]
            cross_sim_AB_sp = current_descA @ current_descB.transpose(0, 1)     # NTA X NTB
            
            cross_sim_AN_sp = current_descA @ current_desc_ne.transpose(0, 1)
            cross_sim_BN_sp = current_descB @ current_desc_ne.transpose(0, 1)
            cross_sim_AN2_sp = current_descA @ current_desc_ne2.transpose(0, 1)
            cross_sim_BN2_sp = current_descB @ current_desc_ne2.transpose(0, 1)
            
            # 黑白相似度
            current_binA, current_binB = (bin_kpA[countA:countA+new_numA] >= 0.5).float(), (bin_kpB[countB:countB+new_numB] >= 0.5).float()   # [NA, 256] [NB_256]
            current_bin_ne = (bin_kp_ne[count_ne:count_ne+new_num_ne] >= 0.5).float()
            current_bin_ne2 = (bin_kp_ne2[count_ne2:count_ne2+new_num_ne2] >= 0.5).float()
            bin_distAB = current_binA.shape[-1] - (current_binA @ current_binB.transpose(0, 1)) - ((1 - current_binA) @ (1 - current_binB.transpose(0, 1))) # [NA, NB]
            
            bin_distAN = current_binA.shape[-1] - (current_binA @ current_bin_ne.transpose(0, 1)) - ((1 - current_binA) @ (1 - current_bin_ne.transpose(0, 1))) # [NA, NE]
            bin_distBN = current_binB.shape[-1] - (current_binB @ current_bin_ne.transpose(0, 1)) - ((1 - current_binB) @ (1 - current_bin_ne.transpose(0, 1))) # [NA, NE]
            bin_distAN2 = current_binA.shape[-1] - (current_binA @ current_bin_ne2.transpose(0, 1)) - ((1 - current_binA) @ (1 - current_bin_ne2.transpose(0, 1))) # [NA, NE]
            bin_distBN2 = current_binB.shape[-1] - (current_binB @ current_bin_ne2.transpose(0, 1)) - ((1 - current_binB) @ (1 - current_bin_ne2.transpose(0, 1))) # [NA, NE]
            
            # 真匹配的trans
            try:
                FAN_bin_mask = bin_distAN >= (1 - self.FA_bin_thr) * current_binA.shape[-1] 
                FBN_bin_mask = bin_distBN >= (1 - self.FA_bin_thr) * current_binB.shape[-1] 
                FAN2_bin_mask = bin_distAN2 >= (1 - self.FA_bin_thr) * current_binA.shape[-1] 
                FBN2_bin_mask = bin_distBN2 >= (1 - self.FA_bin_thr) * current_binB.shape[-1] 
                # topk ?
                crossAN_mean = torch.mean(cross_sim_AN_sp[FAN_bin_mask])
                crossBN_mean = torch.mean(cross_sim_BN_sp[FBN_bin_mask])
                crossAN2_mean = torch.mean(cross_sim_AN2_sp[FAN2_bin_mask])
                crossBN2_mean = torch.mean(cross_sim_BN2_sp[FBN2_bin_mask])

                assert pntA_H.shape[0] > 0 and pntB_invH.shape[0] > 0 
                
                # 点对欧氏距离
                key_disAB = self.get_dis(pntA_H[:, :2], pntB[:, :2])            # repeatNA x NB
                key_disBA = self.get_dis(pntB_invH[:, :2], pntA[:, :2])
                pairAB_A, pairAB_B, dis_pairAB, _ = self.get_point_pair(key_disAB, dis_thre=self.correspond)  # p -> k # NTA(<1.5), NTA(<1.5), NTA(<1.5), NTA        
                pairBA_B, pairBA_A, dis_pairBA, _  = self.get_point_pair(key_disBA, dis_thre=self.correspond)  # p -> k # NTB(<1.5), NTB(<1.5), NTB(<1.5), NTB 
                
                # 点距离mask
                nn_maskAB = torch.zeros((pntA_H.shape[0], pntB.shape[0]), device=self.device) 
                nn_maskAB[pairAB_A, pairAB_B] = 1

                nn_maskBA = torch.zeros((pntB_invH.shape[0], pntA.shape[0]), device=self.device) 
                nn_maskBA[pairBA_B, pairBA_A] = 1

                # 点对曼哈顿距离
                key_manhattandisAB = self.get_manhattan_dis(pntA_H[:, :2], pntB[:, :2])
                key_manhattandisBA = self.get_manhattan_dis(pntB_invH[:, :2], pntA[:, :2])
                # print('pdis:', dis_pairAB.shape[0], dis_pairBA.shape[0])
                assert dis_pairAB.shape[0] > 0 and dis_pairBA.shape[0] > 0     

                pntA_H_normalized = pntA_H / pntA_H.new_tensor([W - 1, H - 1]).to(pntA_H.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)
                pntB_invH_normalized = pntB_invH / pntB_invH.new_tensor([W - 1, H - 1]).to(pntB_invH.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)

                # 用于score_map
                pntA_H_new = copy.deepcopy(pntA_H.detach())
                pntB_invH_new = copy.deepcopy(pntB_invH.detach())
                pntA_H_new[:, 0] += 10                   # 120 x 36 -> 128 x 56
                pntA_H_new[:, 1] += 4 
                pntB_invH_new[:, 0] += 10
                pntB_invH_new[:, 1] += 4
                
                pntA_H_normalized_new = pntA_H_new / pntA_H_new.new_tensor([W + 19, H + 7]).to(pntA_H.device) * 2 - 1

                # pntB_invH_new = warp_points(pntB_invH_new[:, :2], inv_Homo_en[idx].squeeze(), device=self.device)       # 转到A上，而不是AT上
                
                pntB_invH_normalized_new = pntB_invH_new / pntB_invH_new.new_tensor([W + 19, H + 7]).to(pntB_invH.device) * 2 - 1 
                
                # print('1_2:', main_ori_maskATB.shape[0])
                # exit()
                ori_kpAT_patch_ext = F.grid_sample(ori_kp_patchA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntA_H_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0).transpose(0, 1)          # repeatNA x 1
                ori_kpB_patch_ext = F.grid_sample(ori_all_patchB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntB_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0).transpose(0, 1)          # NTB x 1
                ori_kpA_patch_ext = F.grid_sample(ori_all_patchA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntA_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0).transpose(0, 1)          # NTA x 1
                ori_kpBT_patch_ext = F.grid_sample(ori_kp_patchB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntB_invH_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0).transpose(0, 1)          # repeatNB x 1
                # print('1_2_1:', pntB_invH_normalized_new.shape[0])
                ori_maskATB, dis_oriATB = self.get_main_ori_consistence_AT(ori_kpAT_patch_ext, ori_kpB_patch_ext)  # repeatNA x NTB
                # print('1_2_2:', ori_maskATB.shape)
                ori_maskBTA, dis_oriBTA = self.get_main_ori_consistence_AT(ori_kpBT_patch_ext, ori_kpA_patch_ext)  # repeatNB x NTA

                match_maskAB_nb = (nn_maskAB == 1) * ori_maskATB           # repeatNA X NTB
                match_maskBA_nb = (nn_maskBA == 1) * ori_maskBTA          # repeatNB X NTA
                pairAB_A_nb_new, pairAB_B_nb_new = torch.where(match_maskAB_nb == 1)
                pairBA_B_nb_new, pairBA_A_nb_new = torch.where(match_maskBA_nb == 1)
                # assert pairAB_A_new.shape[0] > 0 and pairBA_B_new.shape[0] > 0 

                # 4x4邻域方向一致性
                ori_kpAB_patch_ext = F.grid_sample(ori_all_patchB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntA_H_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0).transpose(0, 1)  
                ori_kpBA_patch_ext = F.grid_sample(ori_all_patchA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntB_invH_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0).transpose(0, 1)  
                # print('1_2_4:', ori_kpAB_patch_ext.shape)
                ori_maskATAB, dis_oriATAB = self.get_main_ori_consistence_AT(ori_kpAT_patch_ext, ori_kpAB_patch_ext)  # repeatNA x repeatNA
                ori_maskBTBA, dis_oriBTBA = self.get_main_ori_consistence_AT(ori_kpBT_patch_ext, ori_kpBA_patch_ext)  # repeatNB x repeatNB
                
                # 黑白相似度
                bin_maskATB = bin_distAB <= (1 - self.FR_bin_thr) * current_binA.shape[-1]  
                bin_maskBTA = bin_maskATB.transpose(0, 1)  

                match_maskAB = match_maskAB_nb * bin_maskATB[mask_pointA, :]               # repeatNA X NB
                match_maskBA = match_maskBA_nb * bin_maskBTA[mask_pointB, :]               # repeatNB X NA

                pairAB_A_new, pairAB_B_new = torch.where(match_maskAB == 1)
                pairBA_B_new, pairBA_A_new = torch.where(match_maskBA == 1)
                # print('bin_mask:', pairAB_A_new.shape[0], pairBA_B_new.shape[0])
                assert pairAB_A_new.shape[0] > 0 and pairBA_B_new.shape[0] > 0 

                bin_kpAB_T = (F.grid_sample(bin_allB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntA_H_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0) >= 0.5).float()  # [256, repeatNA]
                bin_kpBA_T = (F.grid_sample(bin_allA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntB_invH_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0) >= 0.5).float()  # [256, repeatNB]
                bin_distATAB = bin_kpAB_T.shape[0] - (current_binA @ bin_kpAB_T) - ((1 - current_binA) @ (1 - bin_kpAB_T)) # [NTA, repeatNA]
                bin_distBTBA = bin_kpBA_T.shape[0] - (current_binB @ bin_kpBA_T) - ((1 - current_binB) @ (1 - bin_kpBA_T)) # [NTB, repeatNB]

                bin_maskATAB = bin_distATAB <= (1 - self.FR_bin_thr) * bin_kpAB_T.shape[0] 
                bin_maskBTBA = bin_distBTBA <= (1 - self.FR_bin_thr) * bin_kpBA_T.shape[0] 
                bin_maskATAB = bin_maskATAB[mask_pointA, :]
                bin_maskBTBA = bin_maskBTBA[mask_pointB, :]

                vmaskAH_nb = torch.diag(ori_maskATAB)
                vmaskBH_nb = torch.diag(ori_maskBTBA)
                vmaskAH = torch.diag(ori_maskATAB * bin_maskATAB) == 1      # [repeatNA, 1]
                vmaskBH = torch.diag(ori_maskBTBA * bin_maskBTBA) == 1      # [repeatNB, 1]

                # print('main_ori:', torch.sum(vmaskAH), torch.sum(vmaskBH))
                assert torch.sum(vmaskAH) > 0 and torch.sum(vmaskBH) > 0

                # SOSR: 简化的self-attention
                k_neighbor = 3
                cross_sim_AA_sp = current_descA @ current_descA.transpose(0, 1)
                cross_sim_BB_sp = current_descB @ current_descB.transpose(0, 1)
                # print('SOSR:', pairAB_A_new.shape[0], pairBA_B_new.shape[0])
                assert pairAB_A_new.shape[0] >= k_neighbor and pairBA_B_new.shape[0] >= k_neighbor 

                match_sim_AB_AA = cross_sim_AA_sp[mask_pointA, :][:, mask_pointA][pairAB_A_new, :][:, pairAB_A_new]
                match_sim_BA_BB = cross_sim_BB_sp[mask_pointB, :][:, mask_pointB][pairBA_B_new, :][:, pairBA_B_new]
                match_sim_AB_BB = cross_sim_BB_sp[pairAB_B_new, :][:, pairAB_B_new]
                match_sim_BA_AA = cross_sim_AA_sp[pairBA_A_new, :][:, pairBA_A_new]
                match_values_AB_AA, match_indices_AB_AA = torch.topk(match_sim_AB_AA, dim=1, k=k_neighbor, largest=False)
                match_values_BA_BB, match_indices_BA_BB = torch.topk(match_sim_BA_BB, dim=1, k=k_neighbor, largest=False)
                match_values_AB_BB_all = match_sim_AB_BB[:, match_indices_AB_AA]
                match_values_BA_AA_all = match_sim_BA_AA[:, match_indices_BA_BB]
                match_values_AB_BB = torch.diagonal(match_values_AB_BB_all, 0, dim1=0, dim2=1).transpose(0, 1)
                match_values_BA_AA = torch.diagonal(match_values_BA_AA_all, 0, dim1=0, dim2=1).transpose(0, 1)
                neighbor_dis_AB = (match_values_AB_AA - match_values_AB_BB) * (match_values_AB_AA - match_values_AB_BB)
                neighbor_dis_BA = (match_values_BA_BB - match_values_BA_AA) * (match_values_BA_BB - match_values_BA_AA)

                # PA VS PB
                # 计算bin值
                valid_cross_sim_AB_sp_mean = torch.mean(cross_sim_AB_sp[mask_pointA, :][match_maskAB == 1], dim=-1)
                valid_cross_sim_AB_sp_nb_mean = torch.mean(cross_sim_AB_sp[mask_pointA, :][match_maskAB_nb == 1], dim=-1)

                # novalid_cross_sim_AB_sp_mean = (torch.sum(torch.sum(cross_sim_AB_sp.detach(), 1), 0) - valid_cross_sim_AB_sp_nb_mean * pairAB_A_nb_new.shape[0]) / (new_numA * new_numB - pairAB_A_nb_new.shape[0] + eps)
                # 取负样本对中的困难topk
                hn_k_neighborA = int(cross_sim_AB_sp[mask_pointA, :][match_maskAB_nb == 0].view(-1).detach().shape[0] * self.hn_k_neighbor_ratio) 
                hn_k_neighborB = int(cross_sim_AB_sp[:, mask_pointB][match_maskBA_nb.transpose(0, 1) == 0].view(-1).detach().shape[0] * self.hn_k_neighbor_ratio) 
                novalid_cross_sim_AB_sp_mean = torch.mean(torch.topk(cross_sim_AB_sp[mask_pointA, :][match_maskAB_nb == 0].view(-1).detach(), dim=-1, k=hn_k_neighborA, largest=True)[0], dim=-1)
                valid_cross_sim_BA_sp_mean = torch.mean(cross_sim_AB_sp[:, mask_pointB][match_maskBA.transpose(0, 1) == 1], dim=-1)
                valid_cross_sim_BA_sp_nb_mean = torch.mean(cross_sim_AB_sp[:, mask_pointB][match_maskBA_nb.transpose(0, 1) == 1], dim=-1)

                # novalid_cross_sim_BA_sp_mean = (torch.sum(torch.sum(cross_sim_AB_sp.detach(), 1), 0) - valid_cross_sim_BA_sp_nb_mean * pairBA_B_nb_new.shape[0]) / (new_numA * new_numB - pairBA_B_nb_new.shape[0] + eps)
                novalid_cross_sim_BA_sp_mean = torch.mean(torch.topk(cross_sim_AB_sp[:, mask_pointB][match_maskBA_nb.transpose(0, 1) == 0].view(-1).detach(), dim=-1, k=hn_k_neighborB, largest=True)[0], dim=-1)

                valid_indexesA = torch.tensor(list(range(cross_sim_AB_sp.shape[0])), device=self.device)[mask_pointA][pairAB_A_new]
                valid_indexesA_nb = torch.tensor(list(range(cross_sim_AB_sp.shape[0])), device=self.device)[mask_pointA][pairAB_A_nb_new]
                # cross_sim_BA_sp = current_descB @ current_descA.transpose(0, 1)
                cross_sim_AB_out_sp = torch.cat((cross_sim_AB_sp, torch.ones((cross_sim_AB_sp.shape[0], 3), device=cross_sim_AB_sp.device) * 2), dim=-1)      # NA X (NB + 2)
                cross_sim_AB_out_nb_sp = torch.cat((cross_sim_AB_sp, torch.ones((cross_sim_AB_sp.shape[0], 3), device=cross_sim_AB_sp.device) * 2), dim=-1)      # NA X (NB + 2)
                # cross_sim_BA_out_sp = torch.cat((cross_sim_BA_sp, torch.ones((numB, 1), device=cross_sim_BA_sp.device)), dim=-1)      # NB X (NA + 1)
                # valid_indexesB = torch.tensor(list(range(numB)), device=self.device)[mask_pointB][pairBA_B]
                # print('1_2')
                cross_sim_AB_out_sp[valid_indexesA, -1] = novalid_cross_sim_AB_sp_mean
                cross_sim_AB_out_sp[valid_indexesA, -2] = crossAN_mean
                cross_sim_AB_out_sp[valid_indexesA, -3] = crossAN2_mean
                cross_sim_AB_out_nb_sp[valid_indexesA_nb, -1] = novalid_cross_sim_AB_sp_mean
                novalid_indexesA = torch.tensor(list(range(cross_sim_AB_sp.shape[0])), device=self.device)[cross_sim_AB_out_nb_sp[:, -1]==2]
                cross_sim_AB_out_sp[novalid_indexesA, -1] = valid_cross_sim_AB_sp_mean
                # nomatch对不增加negtives的均值bin
                cross_sim_AB_out_sp[novalid_indexesA, -2] = -1 # crossAN_mean # -1
                cross_sim_AB_out_sp[novalid_indexesA, -3] = -1 # crossAN_mean # -1

                soft_cross_sim_AtoB_sp = F.softmax((cross_sim_AB_out_sp - 1) / t_des, dim=-1)
                # soft_cross_sim_BtoA = F.softmax((cross_sim_BA_out - 1) / t_des, dim=-1)
                # print('1_3')
                soft_valid_cross_sim_AB_sp = soft_cross_sim_AtoB_sp[mask_pointA, :-3][match_maskAB==1]
                # soft_valid_cross_sim_BA = soft_cross_sim_BtoA[mask_pointB, :-1][pairBA_B, pairBA_A]
                soft_novalid_cross_sim_AB_sp = soft_cross_sim_AtoB_sp[novalid_indexesA, -1]
                # soft_novalid_cross_sim_BA = soft_cross_sim_BtoA[cross_sim_BA_out[:, -1]==1, -1]
                log_soft_valid_cross_sim_AB_sp = -torch.log(soft_valid_cross_sim_AB_sp + eps) * (1 - dis_oriATB[match_maskAB==1] / self.ori_diff) * (1 - bin_distAB[mask_pointA, :][match_maskAB==1] / current_binA.shape[-1]) * (1 - key_disAB[match_maskAB==1].detach() / self.correspond)
                # log_soft_valid_cross_sim_BA = -torch.log(soft_valid_cross_sim_BA + eps)
                log_soft_novalid_cross_sim_AB_sp = -torch.log(soft_novalid_cross_sim_AB_sp + eps)
                # log_soft_novalid_cross_sim_BA = -torch.log(soft_novalid_cross_sim_BA + eps)
                dis_cross_sim_mean_sp = torch.sum(torch.cat((4*log_soft_valid_cross_sim_AB_sp, log_soft_novalid_cross_sim_AB_sp), dim=-1), dim=-1) / new_numA
                
                # PA VS PAB
                # match_mask_A = copy.deepcopy(mask_pointA)
                # match_mask_B = copy.deepcopy(mask_pointB)
                match_mask_A = torch.zeros(cross_sim_AB_sp.shape[0], device=self.device)
                match_mask_nb_A = torch.zeros(cross_sim_AB_sp.shape[0], device=self.device)
                valid_match_indexesA = torch.tensor(list(range(cross_sim_AB_sp.shape[0])), device=self.device)[mask_pointA][vmaskAH]
                valid_match_indexesA_nb = torch.tensor(list(range(cross_sim_AB_sp.shape[0])), device=self.device)[mask_pointA][vmaskAH_nb]
                match_mask_A[valid_match_indexesA] = 1
                match_mask_nb_A[valid_match_indexesA_nb] = 1

                match_mask_B = torch.zeros(cross_sim_AB_sp.shape[1], device=self.device)
                match_mask_nb_B = torch.zeros(cross_sim_AB_sp.shape[1], device=self.device)
                valid_match_indexesB = torch.tensor(list(range(cross_sim_AB_sp.shape[1])), device=self.device)[mask_pointB][vmaskBH]
                valid_match_indexesB_nb = torch.tensor(list(range(cross_sim_AB_sp.shape[1])), device=self.device)[mask_pointB][vmaskBH_nb]
                match_mask_B[valid_match_indexesB] = 1
                match_mask_nb_B[valid_match_indexesB_nb] = 1

                cross_sim_AB = current_descA @ desc_mapB[idx, :, :, :].view(-1, H * W)
                # cross_sim_AB = cross_sim_AB[mask_pointA, :]
                cross_sim_AB_all = F.grid_sample(cross_sim_AB.view(-1, H, W).unsqueeze(0),
                                                pntA_H_normalized[vmaskAH, :].detach().view(1, 1, -1, 2),
                                                mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NA x repeatNA
                valid_cross_sim_AB_mean = torch.trace(cross_sim_AB_all[match_mask_A==1, :]) / cross_sim_AB_all[match_mask_A==1, :].shape[0]
                # novalid_cross_sim_AB_mean = (torch.sum(torch.sum(cross_sim_AB.detach(), 1), 1) - valid_cross_sim_AB_mean * pairAB_A.shape[0]) / (new_numA * H * W - pairAB_A.shape[0])

                cross_sim_BA = current_descB @ desc_mapA[idx, :, :, :].view(-1, H * W)   # M x H x W
                # cross_sim_BA = cross_sim_BA[mask_pointB, :]
                cross_sim_BA_all = F.grid_sample(cross_sim_BA.view(-1, H, W).unsqueeze(0),
                                                pntB_invH_normalized[vmaskBH, :].detach().view(1, 1, -1, 2),
                                                mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NB x match_nB
                valid_cross_sim_BA_mean = torch.trace(cross_sim_BA_all[match_mask_B==1, :]) / cross_sim_BA_all[match_mask_B==1, :].shape[0]
                # novalid_cross_sim_BA_mean = (torch.sum(torch.sum(cross_sim_BA.detach(), 1), 1) - valid_cross_sim_BA_mean * pairBA_B.shape[0]) / (new_numB * H * W - pairBA_B.shape[0])

                cross_sim_AB_out = torch.cat((cross_sim_AB, torch.ones((cross_sim_AB.shape[0], 3), device=cross_sim_AB.device)), dim=-1)      # NA X (H X W + 2)
                cross_sim_BA_out = torch.cat((cross_sim_BA, torch.ones((cross_sim_BA.shape[0], 3), device=cross_sim_BA.device)), dim=-1)      # NB X (H X W + 2)
                # print(3)
                # cross_sim_AB_out[mask_pointA, -1] -= 1
                # cross_sim_BA_out[mask_pointB, -1] -= 1
                # cross_sim_AB_out[match_mask_A, -1] -= 1
                cross_sim_AB_out[match_mask_A==1, -1] = novalid_cross_sim_AB_sp_mean
                cross_sim_AB_out[match_mask_A==1, -2] = crossAN_mean
                cross_sim_AB_out[match_mask_A==1, -3] = crossAN2_mean
                cross_sim_AB_out[match_mask_nb_A==0, -1] = valid_cross_sim_AB_mean
                cross_sim_AB_out[match_mask_nb_A==0, -2] = -1 # crossAN_mean # -1
                cross_sim_AB_out[match_mask_nb_A==0, -3] = -1 # crossAN_mean # -1

                cross_sim_BA_out[match_mask_B==1, -1] = novalid_cross_sim_BA_sp_mean
                cross_sim_BA_out[match_mask_B==1, -2] = crossBN_mean
                cross_sim_BA_out[match_mask_B==1, -3] = crossBN2_mean
                cross_sim_BA_out[match_mask_nb_B==0, -1] = valid_cross_sim_BA_mean
                cross_sim_BA_out[match_mask_nb_B==0, -2] = -1 # crossBN_mean # -1
                cross_sim_BA_out[match_mask_nb_B==0, -3] = -1 # crossBN_mean # -1

                soft_cross_sim_AtoB = F.softmax((cross_sim_AB_out - 1) / t_des, dim=-1)         # NA X (H X W + 1)
                soft_cross_sim_BtoA = F.softmax((cross_sim_BA_out - 1) / t_des, dim=-1)         # NB X (H X W + 1)
                soft_cross_sim_AB_all = F.grid_sample(soft_cross_sim_AtoB[:, :-3].view(-1, H, W).unsqueeze(0),
                                                    pntA_H_normalized[vmaskAH, :].detach().view(1, 1, -1, 2),
                                                    mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NA x match_nA
                
                soft_cross_sim_BA_all = F.grid_sample(soft_cross_sim_BtoA[:, :-3].view(-1, H, W).unsqueeze(0),
                                                    pntB_invH_normalized[vmaskBH, :].detach().view(1, 1, -1, 2),
                                                    mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NB x match_nB
                # soft_valid_cross_sim_AB_all = soft_cross_sim_AB_all[mask_pointA, :]             # repeat_nA x repeat_nA
                # soft_valid_cross_sim_BA_all = soft_cross_sim_BA_all[mask_pointB, :]             # repeat_nB x repeat_nB

                soft_valid_cross_sim_AB_all = soft_cross_sim_AB_all[match_mask_A==1, :]             # match_nA x match_nA
                soft_valid_cross_sim_BA_all = soft_cross_sim_BA_all[match_mask_B==1, :]             # match_nB x match_nB

                valid_mask_AB = torch.eye(soft_valid_cross_sim_AB_all.shape[0]) == 1
                valid_mask_BA = torch.eye(soft_valid_cross_sim_BA_all.shape[0]) == 1
                # print(4)
                # 取对角线
                soft_valid_cross_sim_AB = soft_valid_cross_sim_AB_all[valid_mask_AB]
                soft_valid_cross_sim_BA = soft_valid_cross_sim_BA_all[valid_mask_BA]

                # soft_novalid_cross_sim_AB = soft_cross_sim_AtoB[mask_pointA==False, -1]              # (NA-repeat_nA) x 1
                # soft_novalid_cross_sim_BA = soft_cross_sim_BtoA[mask_pointB==False, -1]
                soft_novalid_cross_sim_AB = soft_cross_sim_AtoB[match_mask_nb_A==0, -1]               # (NA-match_nA) x 1
                soft_novalid_cross_sim_BA = soft_cross_sim_BtoA[match_mask_nb_B==0, -1]
                # print(soft_novalid_cross_sim_AB, soft_novalid_cross_sim_BA)

                log_soft_valid_cross_sim_AB = -torch.log(soft_valid_cross_sim_AB + eps) * (1 - torch.diag(dis_oriATAB)[vmaskAH] / self.ori_diff) * (1 - torch.diag(bin_distATAB[mask_pointA, :])[vmaskAH] / bin_kpAB_T.shape[0])
                log_soft_valid_cross_sim_BA = -torch.log(soft_valid_cross_sim_BA + eps) * (1 - torch.diag(dis_oriBTBA)[vmaskBH] / self.ori_diff) * (1 - torch.diag(bin_distBTBA[mask_pointB, :])[vmaskBH] / bin_kpBA_T.shape[0])
                log_soft_novalid_cross_sim_AB = -torch.log(soft_novalid_cross_sim_AB + eps)
                log_soft_novalid_cross_sim_BA = -torch.log(soft_novalid_cross_sim_BA + eps)

                dis_cross_sim_mean = torch.sum(torch.cat((4*log_soft_valid_cross_sim_AB, 4*log_soft_valid_cross_sim_BA, log_soft_novalid_cross_sim_AB, log_soft_novalid_cross_sim_BA), dim=-1), dim=-1) / (new_numA + new_numB)
                
                # print(5)
                valid_cross_sim_AB = cross_sim_AB[mask_pointA, :]   # repeat_nA x (H X W)
                valid_cross_sim_BA = cross_sim_BA[mask_pointB, :]   # repeat_nB x (H X W)
                exp_valid_cross_sim_AtoB = torch.exp((valid_cross_sim_AB - 1) / t_rel).view(-1, H, W)
                exp_valid_cross_sim_BtoA = torch.exp((valid_cross_sim_BA - 1) / t_rel).view(-1, H, W)
                exp_valid_cross_sim_AB_all = F.grid_sample(exp_valid_cross_sim_AtoB.unsqueeze(0),
                                                        pntA_H_normalized.detach().view(1, 1, -1, 2),
                                                        mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # repeat_nA x repeat_nA
                
                exp_valid_cross_sim_BA_all = F.grid_sample(exp_valid_cross_sim_BtoA.unsqueeze(0),
                                                        pntB_invH_normalized.detach().view(1, 1, -1, 2),
                                                        mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # repeat_nB x repeat_nB

                repeat_mask_AB = torch.eye(exp_valid_cross_sim_AB_all.shape[0]) == 1
                repeat_mask_BA = torch.eye(exp_valid_cross_sim_BA_all.shape[0]) == 1
                rel_valid_cross_sim_AB = exp_valid_cross_sim_AB_all[repeat_mask_AB]
                rel_valid_cross_sim_BA = exp_valid_cross_sim_BA_all[repeat_mask_BA]

                # pntA_H_normalized_new = copy.deepcopy(pntA_H_normalized.detach())
                # pntB_invH_normalized_new = copy.deepcopy(pntB_invH_normalized.detach())

                # pntA_H_normalized_new[:, 0] += 2
                # pntB_invH_normalized_new[:, 0] += 2

                scoresAB_all = F.grid_sample(scores_mapB[idx, :, :, :].unsqueeze(0),
                                            pntA_H_normalized_new.view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)      # 1 x repeat_nA

                scoresBA_all = F.grid_sample(scores_mapA[idx, :, :, :].unsqueeze(0),
                                            pntB_invH_normalized_new.view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)      # 1 x repeat_nB
                # print(6)
                scores_AAB = scoresA[idx][pmA][mask_pointA] * scoresAB_all
                scores_BBA = scoresB[idx][pmB][mask_pointB] * scoresBA_all
                scores_sum_AAB = torch.sum(scores_AAB, dim=-1)
                scores_sum_BBA = torch.sum(scores_BBA, dim=-1)
                scores_normalize_AAB = scores_AAB / (scores_sum_AAB + eps)
                scores_normalize_BBA = scores_BBA / (scores_sum_BBA + eps)
                rel_meanA = torch.sum(scores_normalize_AAB * (1 - rel_valid_cross_sim_AB), dim=-1) / pntA_H_normalized_new.shape[0]
                rel_meanB = torch.sum(scores_normalize_BBA * (1 - rel_valid_cross_sim_BA), dim=-1) / pntB_invH_normalized_new.shape[0]

                # # 熵loss
                # current_descA_std, current_descB_std = descA_std[countA:countA+new_numA], descB_std[countB:countB+new_numB]
                # desc_std += torch.mean(current_descA_std) + torch.mean(current_descB_std)
                # countA_T += numA_T
                # countB_T += numB_T

                dis_neighbor_mean_total += torch.mean(torch.sum(neighbor_dis_AB, dim=1)) + torch.mean(torch.sum(neighbor_dis_BA, dim=1))
                dis_desc += dis_cross_sim_mean_sp
                dis_desc += dis_cross_sim_mean

                dis_pair_meanAB = torch.mean(key_manhattandisAB[pairAB_A, pairAB_B])
                dis_pair_meanBA = torch.mean(key_manhattandisBA[pairBA_B, pairBA_A])

                dis_peak_mean = torch.mean(torch.cat((scoreddisA[idx][pmA], scoreddisB[idx][pmB]), dim=0))
                # dis_peak_meanB = torch.mean(scoreddisB[idx])
                
                dis_mean_total += dis_pair_meanAB + dis_pair_meanBA
                dis_peak_scored += dis_peak_mean

                dis_rel += rel_meanA + rel_meanB
                
                countA += new_numA
                countB += new_numB
                count_ne += new_num_ne
                # # Penalty
                # scores_mean += (-torch.log(torch.mean(scoresA[idx], dim=-1) + eps) - torch.log(torch.mean(scoresB[idx], dim=-1) + eps)) 
                # print(scores_mean)
            except:
                # dis_mean_total += 0
                # dis_peak_scored += 0
                # dis_desc += 0
                # dis_rel += 0
                # print('Overlapping too small or Repeatable point pairs distance is greater than correspond(1.5):', pntA.shape[0], pntA_H.shape[0], pntB.shape[0], pntB_invH.shape[0], dis_pairAB.shape[0], dis_pairBA.shape[0])
                valid_batch_size -= 1
                countA += new_numA
                countB += new_numB
                count_ne += new_num_ne
                # countA_T += numA_T
                # countB_T += numB_T

        valid_batch_size = valid_batch_size if valid_batch_size > 0 else eps
        # Reprojection Loss 
        reprojection_loss = dis_mean_total / (valid_batch_size * 2)
        # Dispersity Peak Loss
        dispersity_peak_loss = dis_peak_scored / valid_batch_size
        # NRE Loss
        descriptor_loss = dis_desc / (2 * valid_batch_size)
        # Reliability Loss
        reliability_loss = dis_rel / (valid_batch_size * 2)
        # SOSR Loss
        sosr_loss = dis_neighbor_mean_total / ((valid_batch_size * 2))
        # # Entropy loss
        # std_loss = (valid_batch_size * 2) / desc_std  
        # # Score Penalty
        # score_penalty = scores_mean / (valid_batch_size * 2)
        # # FA Desc loss
        # FA_des_loss = dis_desc_fa / valid_batch_size_FA if valid_batch_size_FA > 0 else 0

        loss_total = wrp * reprojection_loss + wpl * dispersity_peak_loss + wdl * descriptor_loss + wrl * reliability_loss + sosr_loss
        loss_group = {
            'reprojection_loss': reprojection_loss, 
            'dispersity_peak_loss': dispersity_peak_loss,
            'descriptor_loss': descriptor_loss,
            'reliability_loss': reliability_loss,
            'sosr_loss': sosr_loss,
            # 'std_loss': std_loss,
            # 'FA_des_loss': FA_des_loss,
            }
        return loss_total, loss_group



    # patch/dense AT角度 黑白相似度加量化 NFA two negtives
    def detector_selfsupervised_loss_dkd_patch_ext_restrict_modify_oriR_ratio_NFA_qtbw_ns_wg_nori_AT_NE2_UWT(self, kpA, kpB, pmaskA, pmaskB, descA, descB, desc_mapA, desc_mapB, scoreddisA, scoreddisB, scoresA, scoresB, scores_mapA, scores_mapB, Homo, inv_Homo, inv_Homo_en, ori_all_patchA, ori_all_patchB, ori_kp_patchA, ori_kp_patchB, bin_allA, bin_allB, bin_kpA, bin_kpB, kp_ne, pmask_ne, desc_ne, bin_kp_ne, kp_ne2, pmask_ne2, desc_ne2, bin_kp_ne2, trans_angle, FA_flag, H, W, wrp=1, wpl=1, wdl=1, wrl=1, t_des=0.02, t_rel=1):
        # pmaskA: (BxMax_num) 32x350=11200
        batch_size = len(kpA)
        max_num = pmaskA.shape[-1] // batch_size    # 350
        dis_mean_total = 0
        dis_neighbor_mean_total = 0
        dis_peak_scored = 0
        dis_desc = 0
        dis_rel = 0
        desc_std = 0
        eps = 1e-12
        valid_batch_size = batch_size
        # valid_batch_size_FA = 0
        countA, countB, count_ne, count_ne2 = 0, 0, 0, 0
        add, divide_num, t = 1.1, 1., 8
        # dis_desc_fa = 0
        # countA_T, countB_T = 0, 0
        for idx in range(batch_size):
            pntA, pntB, pnt_ne, pnt_ne2 = kpA[idx], kpB[idx], kp_ne[idx], kp_ne2[idx]     # M X 2 (x,y)
            # kmask_TA, kmask_TB = kmask_T_allA[idx], kmask_T_allB[idx]
            pntA = pntA.float()
            pntB = pntB.float()
            pnt_ne = pnt_ne.float()
            pnt_ne2 = pnt_ne2.float()

            # 剔除部分按压区域的点,且保留在重叠区域的点
            numA, numB, num_ne, num_ne2 = pntA.shape[0], pntB.shape[0], pnt_ne.shape[0], pnt_ne2.shape[0]
            # numA_T, numB_T = pntA[kmask_TA].shape[0], pntB[kmask_TB].shape[0]
            pmA, pmB, pm_ne, pm_ne2 = pmaskA[max_num * idx:max_num * idx + numA].bool(), pmaskB[max_num * idx:max_num * idx + numB].bool(), pmask_ne[max_num * idx:max_num * idx + num_ne].bool(), pmask_ne2[max_num * idx:max_num * idx + num_ne2].bool()
            pntA, pntB, pnt_ne, pnt_ne2 = pntA[pmA, :], pntB[pmB, :], pnt_ne[pm_ne, :], pnt_ne2[pm_ne2, :] 
            new_numA, new_numB, new_num_ne, new_num_ne2 = pntA.shape[0], pntB.shape[0], pnt_ne.shape[0], pnt_ne2.shape[0]      
            
            pntA = (pntA + 1) / 2 * pntA.new_tensor([[W + 3, H - 1]]).to(pntA.device)
            pntB = (pntB + 1) / 2 * pntB.new_tensor([[W + 3, H - 1]]).to(pntB.device)

            # [120, 40] -> [120, 36],实际只取中心118x32区域的点对
            pntA[:, 0] -= 2
            pntB[:, 0] -= 2
            
            pntA_normalized = pntA / pntA.new_tensor([W - 1, H - 1]).to(pntA.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)
            pntB_normalized = pntB / pntB.new_tensor([W - 1, H - 1]).to(pntB.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)

            pntA_H = warp_points(pntA[:, :2], Homo[idx].squeeze(), device=self.device)  # 利用变换矩阵变换坐标点
            pntA_H, mask_pointA = filter_points(pntA_H, torch.tensor([W, H], device=self.device), return_mask=True)
            pntB_invH = warp_points(pntB[:, :2], inv_Homo[idx].squeeze(), device=self.device)
            pntB_invH, mask_pointB = filter_points(pntB_invH, torch.tensor([W, H], device=self.device), return_mask=True)
            
            current_descA, current_descB = descA[countA:countA+new_numA], descB[countB:countB+new_numB]
            current_desc_ne = desc_ne[count_ne:count_ne+new_num_ne]
            current_desc_ne2 = desc_ne2[count_ne2:count_ne2+new_num_ne2]
            cross_sim_AB_sp = current_descA @ current_descB.transpose(0, 1)     # NTA X NTB
            
            cross_sim_AN_sp = current_descA @ current_desc_ne.transpose(0, 1)
            cross_sim_BN_sp = current_descB @ current_desc_ne.transpose(0, 1)
            cross_sim_AN2_sp = current_descA @ current_desc_ne2.transpose(0, 1)
            cross_sim_BN2_sp = current_descB @ current_desc_ne2.transpose(0, 1)
            
            # 黑白相似度
            current_binA, current_binB = (bin_kpA[countA:countA+new_numA] >= 0.5).float(), (bin_kpB[countB:countB+new_numB] >= 0.5).float()   # [NA, 256] [NB_256]
            current_bin_ne = (bin_kp_ne[count_ne:count_ne+new_num_ne] >= 0.5).float()
            current_bin_ne2 = (bin_kp_ne2[count_ne2:count_ne2+new_num_ne2] >= 0.5).float()
            bin_distAB = current_binA.shape[-1] - (current_binA @ current_binB.transpose(0, 1)) - ((1 - current_binA) @ (1 - current_binB.transpose(0, 1))) # [NA, NB]
            
            bin_distAN = current_binA.shape[-1] - (current_binA @ current_bin_ne.transpose(0, 1)) - ((1 - current_binA) @ (1 - current_bin_ne.transpose(0, 1))) # [NA, NE]
            bin_distBN = current_binB.shape[-1] - (current_binB @ current_bin_ne.transpose(0, 1)) - ((1 - current_binB) @ (1 - current_bin_ne.transpose(0, 1))) # [NA, NE]
            bin_distAN2 = current_binA.shape[-1] - (current_binA @ current_bin_ne2.transpose(0, 1)) - ((1 - current_binA) @ (1 - current_bin_ne2.transpose(0, 1))) # [NA, NE]
            bin_distBN2 = current_binB.shape[-1] - (current_binB @ current_bin_ne2.transpose(0, 1)) - ((1 - current_binB) @ (1 - current_bin_ne2.transpose(0, 1))) # [NA, NE]
            
            # 真匹配的trans
            try:
                FAN_bin_mask = bin_distAN >= (1 - self.FA_bin_thr) * current_binA.shape[-1] 
                FBN_bin_mask = bin_distBN >= (1 - self.FA_bin_thr) * current_binB.shape[-1] 
                FAN2_bin_mask = bin_distAN2 >= (1 - self.FA_bin_thr) * current_binA.shape[-1] 
                FBN2_bin_mask = bin_distBN2 >= (1 - self.FA_bin_thr) * current_binB.shape[-1] 
                # topk ?
                crossAN_mean = torch.mean(cross_sim_AN_sp[FAN_bin_mask])
                crossBN_mean = torch.mean(cross_sim_BN_sp[FBN_bin_mask])
                crossAN2_mean = torch.mean(cross_sim_AN2_sp[FAN2_bin_mask])
                crossBN2_mean = torch.mean(cross_sim_BN2_sp[FBN2_bin_mask])

                assert pntA_H.shape[0] > 0 and pntB_invH.shape[0] > 0 
                
                # 点对欧氏距离
                key_disAB = self.get_dis(pntA_H[:, :2], pntB[:, :2])            # repeatNA x NB
                key_disBA = self.get_dis(pntB_invH[:, :2], pntA[:, :2])
                pairAB_A, pairAB_B, dis_pairAB, _ = self.get_point_pair(key_disAB, dis_thre=self.correspond)  # p -> k # NTA(<1.5), NTA(<1.5), NTA(<1.5), NTA        
                pairBA_B, pairBA_A, dis_pairBA, _  = self.get_point_pair(key_disBA, dis_thre=self.correspond)  # p -> k # NTB(<1.5), NTB(<1.5), NTB(<1.5), NTB 
                
                # 点距离mask
                nn_maskAB = torch.zeros((pntA_H.shape[0], pntB.shape[0]), device=self.device) 
                nn_maskAB[pairAB_A, pairAB_B] = 1

                nn_maskBA = torch.zeros((pntB_invH.shape[0], pntA.shape[0]), device=self.device) 
                nn_maskBA[pairBA_B, pairBA_A] = 1

                # 点对曼哈顿距离
                key_manhattandisAB = self.get_manhattan_dis(pntA_H[:, :2], pntB[:, :2])
                key_manhattandisBA = self.get_manhattan_dis(pntB_invH[:, :2], pntA[:, :2])
                # print('pdis:', dis_pairAB.shape[0], dis_pairBA.shape[0])
                assert dis_pairAB.shape[0] > 0 and dis_pairBA.shape[0] > 0     

                pntA_H_normalized = pntA_H / pntA_H.new_tensor([W - 1, H - 1]).to(pntA_H.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)
                pntB_invH_normalized = pntB_invH / pntB_invH.new_tensor([W - 1, H - 1]).to(pntB_invH.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)

                # 用于score_map
                pntA_H_new = copy.deepcopy(pntA_H.detach())
                pntB_invH_new = copy.deepcopy(pntB_invH.detach())
                pntA_H_new[:, 0] += 10                   # 120 x 36 -> 128 x 56
                pntA_H_new[:, 1] += 4 
                pntB_invH_new[:, 0] += 10
                pntB_invH_new[:, 1] += 4
                
                pntA_H_normalized_new = pntA_H_new / pntA_H_new.new_tensor([W + 19, H + 7]).to(pntA_H.device) * 2 - 1

                # pntB_invH_new = warp_points(pntB_invH_new[:, :2], inv_Homo_en[idx].squeeze(), device=self.device)       # 转到A上，而不是AT上
                
                pntB_invH_normalized_new = pntB_invH_new / pntB_invH_new.new_tensor([W + 19, H + 7]).to(pntB_invH.device) * 2 - 1 
                
                # print('1_2:', main_ori_maskATB.shape[0])
                # exit()
                ori_kpAT_patch_ext = F.grid_sample(ori_kp_patchA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntA_H_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0).transpose(0, 1)          # repeatNA x 1
                ori_kpB_patch_ext = F.grid_sample(ori_all_patchB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntB_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0).transpose(0, 1)          # NTB x 1
                ori_kpA_patch_ext = F.grid_sample(ori_all_patchA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntA_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0).transpose(0, 1)          # NTA x 1
                ori_kpBT_patch_ext = F.grid_sample(ori_kp_patchB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntB_invH_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0).transpose(0, 1)          # repeatNB x 1
                # print('1_2_1:', pntB_invH_normalized_new.shape[0])
                ori_maskATB, dis_oriATB = self.get_main_ori_consistence_AT(ori_kpAT_patch_ext, ori_kpB_patch_ext)  # repeatNA x NTB
                # print('1_2_2:', ori_maskATB.shape)
                ori_maskBTA, dis_oriBTA = self.get_main_ori_consistence_AT(ori_kpBT_patch_ext, ori_kpA_patch_ext)  # repeatNB x NTA

                match_maskAB_nb = (nn_maskAB == 1) * ori_maskATB           # repeatNA X NTB
                match_maskBA_nb = (nn_maskBA == 1) * ori_maskBTA          # repeatNB X NTA
                pairAB_A_nb_new, pairAB_B_nb_new = torch.where(match_maskAB_nb == 1)
                pairBA_B_nb_new, pairBA_A_nb_new = torch.where(match_maskBA_nb == 1)
                # assert pairAB_A_new.shape[0] > 0 and pairBA_B_new.shape[0] > 0 

                # 4x4邻域方向一致性
                ori_kpAB_patch_ext = F.grid_sample(ori_all_patchB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntA_H_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0).transpose(0, 1)  
                ori_kpBA_patch_ext = F.grid_sample(ori_all_patchA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntB_invH_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0).transpose(0, 1)  
                # print('1_2_4:', ori_kpAB_patch_ext.shape)
                ori_maskATAB, dis_oriATAB = self.get_main_ori_consistence_AT(ori_kpAT_patch_ext, ori_kpAB_patch_ext)  # repeatNA x repeatNA
                ori_maskBTBA, dis_oriBTBA = self.get_main_ori_consistence_AT(ori_kpBT_patch_ext, ori_kpBA_patch_ext)  # repeatNB x repeatNB
                
                # 黑白相似度
                bin_maskATB = bin_distAB <= (1 - self.FR_bin_thr) * current_binA.shape[-1]  
                bin_maskBTA = bin_maskATB.transpose(0, 1)  

                match_maskAB = match_maskAB_nb * bin_maskATB[mask_pointA, :]               # repeatNA X NB
                match_maskBA = match_maskBA_nb * bin_maskBTA[mask_pointB, :]               # repeatNB X NA

                pairAB_A_new, pairAB_B_new = torch.where(match_maskAB == 1)
                pairBA_B_new, pairBA_A_new = torch.where(match_maskBA == 1)
                # print('bin_mask:', pairAB_A_new.shape[0], pairBA_B_new.shape[0])
                assert pairAB_A_new.shape[0] > 0 and pairBA_B_new.shape[0] > 0 

                bin_kpAB_T = (F.grid_sample(bin_allB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntA_H_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0) >= 0.5).float()  # [256, repeatNA]
                bin_kpBA_T = (F.grid_sample(bin_allA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntB_invH_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0) >= 0.5).float()  # [256, repeatNB]
                bin_distATAB = bin_kpAB_T.shape[0] - (current_binA @ bin_kpAB_T) - ((1 - current_binA) @ (1 - bin_kpAB_T)) # [NTA, repeatNA]
                bin_distBTBA = bin_kpBA_T.shape[0] - (current_binB @ bin_kpBA_T) - ((1 - current_binB) @ (1 - bin_kpBA_T)) # [NTB, repeatNB]

                bin_maskATAB = bin_distATAB <= (1 - self.FR_bin_thr) * bin_kpAB_T.shape[0] 
                bin_maskBTBA = bin_distBTBA <= (1 - self.FR_bin_thr) * bin_kpBA_T.shape[0] 
                bin_maskATAB = bin_maskATAB[mask_pointA, :]
                bin_maskBTBA = bin_maskBTBA[mask_pointB, :]

                vmaskAH_nb = torch.diag(ori_maskATAB)
                vmaskBH_nb = torch.diag(ori_maskBTBA)
                vmaskAH = torch.diag(ori_maskATAB * bin_maskATAB) == 1      # [repeatNA, 1]
                vmaskBH = torch.diag(ori_maskBTBA * bin_maskBTBA) == 1      # [repeatNB, 1]

                # print('main_ori:', torch.sum(vmaskAH), torch.sum(vmaskBH))
                assert torch.sum(vmaskAH) > 0 and torch.sum(vmaskBH) > 0

                # SOSR: 简化的self-attention
                k_neighbor = 3
                cross_sim_AA_sp = current_descA @ current_descA.transpose(0, 1)
                cross_sim_BB_sp = current_descB @ current_descB.transpose(0, 1)
                # print('SOSR:', pairAB_A_new.shape[0], pairBA_B_new.shape[0])
                assert pairAB_A_new.shape[0] >= k_neighbor and pairBA_B_new.shape[0] >= k_neighbor 

                match_sim_AB_AA = cross_sim_AA_sp[mask_pointA, :][:, mask_pointA][pairAB_A_new, :][:, pairAB_A_new]
                match_sim_BA_BB = cross_sim_BB_sp[mask_pointB, :][:, mask_pointB][pairBA_B_new, :][:, pairBA_B_new]
                match_sim_AB_BB = cross_sim_BB_sp[pairAB_B_new, :][:, pairAB_B_new]
                match_sim_BA_AA = cross_sim_AA_sp[pairBA_A_new, :][:, pairBA_A_new]
                match_values_AB_AA, match_indices_AB_AA = torch.topk(match_sim_AB_AA, dim=1, k=k_neighbor, largest=False)
                match_values_BA_BB, match_indices_BA_BB = torch.topk(match_sim_BA_BB, dim=1, k=k_neighbor, largest=False)
                match_values_AB_BB_all = match_sim_AB_BB[:, match_indices_AB_AA]
                match_values_BA_AA_all = match_sim_BA_AA[:, match_indices_BA_BB]
                match_values_AB_BB = torch.diagonal(match_values_AB_BB_all, 0, dim1=0, dim2=1).transpose(0, 1)
                match_values_BA_AA = torch.diagonal(match_values_BA_AA_all, 0, dim1=0, dim2=1).transpose(0, 1)
                neighbor_dis_AB = (match_values_AB_AA - match_values_AB_BB) * (match_values_AB_AA - match_values_AB_BB)
                neighbor_dis_BA = (match_values_BA_BB - match_values_BA_AA) * (match_values_BA_BB - match_values_BA_AA)

                # PA VS PB
                # 计算bin值
                valid_cross_sim_AB_sp_mean = torch.mean(cross_sim_AB_sp[mask_pointA, :][match_maskAB == 1], dim=-1)
                valid_cross_sim_AB_sp_nb_mean = torch.mean(cross_sim_AB_sp[mask_pointA, :][match_maskAB_nb == 1], dim=-1)
                novalid_cross_sim_AB_sp_mean = (torch.sum(torch.sum(cross_sim_AB_sp.detach(), 1), 0) - valid_cross_sim_AB_sp_nb_mean * pairAB_A_nb_new.shape[0]) / (new_numA * new_numB - pairAB_A_nb_new.shape[0] + eps)
                valid_cross_sim_BA_sp_mean = torch.mean(cross_sim_AB_sp[:, mask_pointB][match_maskBA.transpose(0, 1) == 1], dim=-1)
                valid_cross_sim_BA_sp_nb_mean = torch.mean(cross_sim_AB_sp[:, mask_pointB][match_maskBA_nb.transpose(0, 1) == 1], dim=-1)
                novalid_cross_sim_BA_sp_mean = (torch.sum(torch.sum(cross_sim_AB_sp.detach(), 1), 0) - valid_cross_sim_BA_sp_nb_mean * pairBA_B_nb_new.shape[0]) / (new_numA * new_numB - pairBA_B_nb_new.shape[0] + eps)

                valid_indexesA = torch.tensor(list(range(cross_sim_AB_sp.shape[0])), device=self.device)[mask_pointA][pairAB_A_new]
                valid_indexesA_nb = torch.tensor(list(range(cross_sim_AB_sp.shape[0])), device=self.device)[mask_pointA][pairAB_A_nb_new]
                # cross_sim_BA_sp = current_descB @ current_descA.transpose(0, 1)
                cross_sim_AB_out_sp = torch.cat((cross_sim_AB_sp, torch.ones((cross_sim_AB_sp.shape[0], 3), device=cross_sim_AB_sp.device) * 2), dim=-1)      # NA X (NB + 2)
                cross_sim_AB_out_nb_sp = torch.cat((cross_sim_AB_sp, torch.ones((cross_sim_AB_sp.shape[0], 3), device=cross_sim_AB_sp.device) * 2), dim=-1)      # NA X (NB + 2)
                # cross_sim_BA_out_sp = torch.cat((cross_sim_BA_sp, torch.ones((numB, 1), device=cross_sim_BA_sp.device)), dim=-1)      # NB X (NA + 1)
                # valid_indexesB = torch.tensor(list(range(numB)), device=self.device)[mask_pointB][pairBA_B]
                # print('1_2')
                cross_sim_AB_out_sp[valid_indexesA, -1] = novalid_cross_sim_AB_sp_mean
                cross_sim_AB_out_sp[valid_indexesA, -2] = crossAN_mean
                cross_sim_AB_out_sp[valid_indexesA, -3] = crossAN2_mean
                cross_sim_AB_out_nb_sp[valid_indexesA_nb, -1] = novalid_cross_sim_AB_sp_mean
                novalid_indexesA = torch.tensor(list(range(cross_sim_AB_sp.shape[0])), device=self.device)[cross_sim_AB_out_nb_sp[:, -1]==2]
                cross_sim_AB_out_sp[novalid_indexesA, -1] = valid_cross_sim_AB_sp_mean
                # nomatch对不增加negtives的均值bin
                cross_sim_AB_out_sp[novalid_indexesA, -2] = -1 # crossAN_mean # -1
                cross_sim_AB_out_sp[novalid_indexesA, -3] = -1 # crossAN_mean # -1

                soft_cross_sim_AtoB_sp = self.UWTXent(cross_sim_AB_out_sp, add, divide_num, t) # F.softmax((cross_sim_AB_out_sp - 1) / t_des, dim=-1)
                # soft_cross_sim_BtoA = F.softmax((cross_sim_BA_out - 1) / t_des, dim=-1)
                # print('1_3')
                soft_valid_cross_sim_AB_sp = soft_cross_sim_AtoB_sp[mask_pointA, :-3][match_maskAB==1]
                # soft_valid_cross_sim_BA = soft_cross_sim_BtoA[mask_pointB, :-1][pairBA_B, pairBA_A]
                soft_novalid_cross_sim_AB_sp = soft_cross_sim_AtoB_sp[novalid_indexesA, -1]
                # soft_novalid_cross_sim_BA = soft_cross_sim_BtoA[cross_sim_BA_out[:, -1]==1, -1]
                log_soft_valid_cross_sim_AB_sp = -torch.log(soft_valid_cross_sim_AB_sp + eps) * (1 - dis_oriATB[match_maskAB==1] / self.ori_diff) * (1 - bin_distAB[mask_pointA, :][match_maskAB==1] / current_binA.shape[-1]) * (1 - key_disAB[match_maskAB==1].detach() / self.correspond)
                # log_soft_valid_cross_sim_BA = -torch.log(soft_valid_cross_sim_BA + eps)
                log_soft_novalid_cross_sim_AB_sp = -torch.log(soft_novalid_cross_sim_AB_sp + eps)
                # log_soft_novalid_cross_sim_BA = -torch.log(soft_novalid_cross_sim_BA + eps)
                dis_cross_sim_mean_sp = torch.sum(torch.cat((4*log_soft_valid_cross_sim_AB_sp, log_soft_novalid_cross_sim_AB_sp), dim=-1), dim=-1) / new_numA
                
                # PA VS PAB
                # match_mask_A = copy.deepcopy(mask_pointA)
                # match_mask_B = copy.deepcopy(mask_pointB)
                match_mask_A = torch.zeros(cross_sim_AB_sp.shape[0], device=self.device)
                match_mask_nb_A = torch.zeros(cross_sim_AB_sp.shape[0], device=self.device)
                valid_match_indexesA = torch.tensor(list(range(cross_sim_AB_sp.shape[0])), device=self.device)[mask_pointA][vmaskAH]
                valid_match_indexesA_nb = torch.tensor(list(range(cross_sim_AB_sp.shape[0])), device=self.device)[mask_pointA][vmaskAH_nb]
                match_mask_A[valid_match_indexesA] = 1
                match_mask_nb_A[valid_match_indexesA_nb] = 1

                match_mask_B = torch.zeros(cross_sim_AB_sp.shape[1], device=self.device)
                match_mask_nb_B = torch.zeros(cross_sim_AB_sp.shape[1], device=self.device)
                valid_match_indexesB = torch.tensor(list(range(cross_sim_AB_sp.shape[1])), device=self.device)[mask_pointB][vmaskBH]
                valid_match_indexesB_nb = torch.tensor(list(range(cross_sim_AB_sp.shape[1])), device=self.device)[mask_pointB][vmaskBH_nb]
                match_mask_B[valid_match_indexesB] = 1
                match_mask_nb_B[valid_match_indexesB_nb] = 1

                cross_sim_AB = current_descA @ desc_mapB[idx, :, :, :].view(-1, H * W)
                # cross_sim_AB = cross_sim_AB[mask_pointA, :]
                cross_sim_AB_all = F.grid_sample(cross_sim_AB.view(-1, H, W).unsqueeze(0),
                                                pntA_H_normalized[vmaskAH, :].detach().view(1, 1, -1, 2),
                                                mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NA x repeatNA
                valid_cross_sim_AB_mean = torch.trace(cross_sim_AB_all[match_mask_A==1, :]) / cross_sim_AB_all[match_mask_A==1, :].shape[0]
                # novalid_cross_sim_AB_mean = (torch.sum(torch.sum(cross_sim_AB.detach(), 1), 1) - valid_cross_sim_AB_mean * pairAB_A.shape[0]) / (new_numA * H * W - pairAB_A.shape[0])

                cross_sim_BA = current_descB @ desc_mapA[idx, :, :, :].view(-1, H * W)   # M x H x W
                # cross_sim_BA = cross_sim_BA[mask_pointB, :]
                cross_sim_BA_all = F.grid_sample(cross_sim_BA.view(-1, H, W).unsqueeze(0),
                                                pntB_invH_normalized[vmaskBH, :].detach().view(1, 1, -1, 2),
                                                mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NB x match_nB
                valid_cross_sim_BA_mean = torch.trace(cross_sim_BA_all[match_mask_B==1, :]) / cross_sim_BA_all[match_mask_B==1, :].shape[0]
                # novalid_cross_sim_BA_mean = (torch.sum(torch.sum(cross_sim_BA.detach(), 1), 1) - valid_cross_sim_BA_mean * pairBA_B.shape[0]) / (new_numB * H * W - pairBA_B.shape[0])

                cross_sim_AB_out = torch.cat((cross_sim_AB, torch.ones((cross_sim_AB.shape[0], 3), device=cross_sim_AB.device)), dim=-1)      # NA X (H X W + 2)
                cross_sim_BA_out = torch.cat((cross_sim_BA, torch.ones((cross_sim_BA.shape[0], 3), device=cross_sim_BA.device)), dim=-1)      # NB X (H X W + 2)
                # print(3)
                # cross_sim_AB_out[mask_pointA, -1] -= 1
                # cross_sim_BA_out[mask_pointB, -1] -= 1
                # cross_sim_AB_out[match_mask_A, -1] -= 1
                cross_sim_AB_out[match_mask_A==1, -1] = novalid_cross_sim_AB_sp_mean
                cross_sim_AB_out[match_mask_A==1, -2] = crossAN_mean
                cross_sim_AB_out[match_mask_A==1, -3] = crossAN2_mean
                cross_sim_AB_out[match_mask_nb_A==0, -1] = valid_cross_sim_AB_mean
                cross_sim_AB_out[match_mask_nb_A==0, -2] = -1 # crossAN_mean # -1
                cross_sim_AB_out[match_mask_nb_A==0, -3] = -1 # crossAN_mean # -1

                cross_sim_BA_out[match_mask_B==1, -1] = novalid_cross_sim_BA_sp_mean
                cross_sim_BA_out[match_mask_B==1, -2] = crossBN_mean
                cross_sim_BA_out[match_mask_B==1, -3] = crossBN2_mean
                cross_sim_BA_out[match_mask_nb_B==0, -1] = valid_cross_sim_BA_mean
                cross_sim_BA_out[match_mask_nb_B==0, -2] = -1 # crossBN_mean # -1
                cross_sim_BA_out[match_mask_nb_B==0, -3] = -1 # crossBN_mean # -1

                soft_cross_sim_AtoB = self.UWTXent(cross_sim_AB_out, add, divide_num, t) # F.softmax((cross_sim_AB_out - 1) / t_des, dim=-1)         # NA X (H X W + 1)
                soft_cross_sim_BtoA = self.UWTXent(cross_sim_BA_out, add, divide_num, t) # F.softmax((cross_sim_BA_out - 1) / t_des, dim=-1)         # NB X (H X W + 1)
                soft_cross_sim_AB_all = F.grid_sample(soft_cross_sim_AtoB[:, :-3].view(-1, H, W).unsqueeze(0),
                                                    pntA_H_normalized[vmaskAH, :].detach().view(1, 1, -1, 2),
                                                    mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NA x match_nA
                
                soft_cross_sim_BA_all = F.grid_sample(soft_cross_sim_BtoA[:, :-3].view(-1, H, W).unsqueeze(0),
                                                    pntB_invH_normalized[vmaskBH, :].detach().view(1, 1, -1, 2),
                                                    mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NB x match_nB
                # soft_valid_cross_sim_AB_all = soft_cross_sim_AB_all[mask_pointA, :]             # repeat_nA x repeat_nA
                # soft_valid_cross_sim_BA_all = soft_cross_sim_BA_all[mask_pointB, :]             # repeat_nB x repeat_nB

                soft_valid_cross_sim_AB_all = soft_cross_sim_AB_all[match_mask_A==1, :]             # match_nA x match_nA
                soft_valid_cross_sim_BA_all = soft_cross_sim_BA_all[match_mask_B==1, :]             # match_nB x match_nB

                valid_mask_AB = torch.eye(soft_valid_cross_sim_AB_all.shape[0]) == 1
                valid_mask_BA = torch.eye(soft_valid_cross_sim_BA_all.shape[0]) == 1
                # print(4)
                # 取对角线
                soft_valid_cross_sim_AB = soft_valid_cross_sim_AB_all[valid_mask_AB]
                soft_valid_cross_sim_BA = soft_valid_cross_sim_BA_all[valid_mask_BA]

                # soft_novalid_cross_sim_AB = soft_cross_sim_AtoB[mask_pointA==False, -1]              # (NA-repeat_nA) x 1
                # soft_novalid_cross_sim_BA = soft_cross_sim_BtoA[mask_pointB==False, -1]
                soft_novalid_cross_sim_AB = soft_cross_sim_AtoB[match_mask_nb_A==0, -1]               # (NA-match_nA) x 1
                soft_novalid_cross_sim_BA = soft_cross_sim_BtoA[match_mask_nb_B==0, -1]
                # print(soft_novalid_cross_sim_AB, soft_novalid_cross_sim_BA)

                log_soft_valid_cross_sim_AB = -torch.log(soft_valid_cross_sim_AB + eps) * (1 - torch.diag(dis_oriATAB)[vmaskAH] / self.ori_diff) * (1 - torch.diag(bin_distATAB[mask_pointA, :])[vmaskAH] / bin_kpAB_T.shape[0])
                log_soft_valid_cross_sim_BA = -torch.log(soft_valid_cross_sim_BA + eps) * (1 - torch.diag(dis_oriBTBA)[vmaskBH] / self.ori_diff) * (1 - torch.diag(bin_distBTBA[mask_pointB, :])[vmaskBH] / bin_kpBA_T.shape[0])
                log_soft_novalid_cross_sim_AB = -torch.log(soft_novalid_cross_sim_AB + eps)
                log_soft_novalid_cross_sim_BA = -torch.log(soft_novalid_cross_sim_BA + eps)

                dis_cross_sim_mean = torch.sum(torch.cat((4*log_soft_valid_cross_sim_AB, 4*log_soft_valid_cross_sim_BA, log_soft_novalid_cross_sim_AB, log_soft_novalid_cross_sim_BA), dim=-1), dim=-1) / (new_numA + new_numB)
                
                # print(5)
                valid_cross_sim_AB = cross_sim_AB[mask_pointA, :]   # repeat_nA x (H X W)
                valid_cross_sim_BA = cross_sim_BA[mask_pointB, :]   # repeat_nB x (H X W)
                exp_valid_cross_sim_AtoB = torch.pow((valid_cross_sim_AB / divide_num + add), t).view(-1, H, W) # torch.exp((valid_cross_sim_AB - 1) / t_rel).view(-1, H, W)
                exp_valid_cross_sim_BtoA = torch.pow((valid_cross_sim_BA / divide_num + add), t).view(-1, H, W) # torch.exp((valid_cross_sim_BA - 1) / t_rel).view(-1, H, W)
                exp_valid_cross_sim_AB_all = F.grid_sample(exp_valid_cross_sim_AtoB.unsqueeze(0),
                                                        pntA_H_normalized.detach().view(1, 1, -1, 2),
                                                        mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # repeat_nA x repeat_nA
                
                exp_valid_cross_sim_BA_all = F.grid_sample(exp_valid_cross_sim_BtoA.unsqueeze(0),
                                                        pntB_invH_normalized.detach().view(1, 1, -1, 2),
                                                        mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # repeat_nB x repeat_nB

                repeat_mask_AB = torch.eye(exp_valid_cross_sim_AB_all.shape[0]) == 1
                repeat_mask_BA = torch.eye(exp_valid_cross_sim_BA_all.shape[0]) == 1
                rel_valid_cross_sim_AB = exp_valid_cross_sim_AB_all[repeat_mask_AB]
                rel_valid_cross_sim_BA = exp_valid_cross_sim_BA_all[repeat_mask_BA]

                # pntA_H_normalized_new = copy.deepcopy(pntA_H_normalized.detach())
                # pntB_invH_normalized_new = copy.deepcopy(pntB_invH_normalized.detach())

                # pntA_H_normalized_new[:, 0] += 2
                # pntB_invH_normalized_new[:, 0] += 2

                scoresAB_all = F.grid_sample(scores_mapB[idx, :, :, :].unsqueeze(0),
                                            pntA_H_normalized_new.view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)      # 1 x repeat_nA

                scoresBA_all = F.grid_sample(scores_mapA[idx, :, :, :].unsqueeze(0),
                                            pntB_invH_normalized_new.view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)      # 1 x repeat_nB
                # print(6)
                scores_AAB = scoresA[idx][pmA][mask_pointA] * scoresAB_all
                scores_BBA = scoresB[idx][pmB][mask_pointB] * scoresBA_all
                scores_sum_AAB = torch.sum(scores_AAB, dim=-1)
                scores_sum_BBA = torch.sum(scores_BBA, dim=-1)
                scores_normalize_AAB = scores_AAB / (scores_sum_AAB + eps)
                scores_normalize_BBA = scores_BBA / (scores_sum_BBA + eps)
                rel_meanA = torch.sum(scores_normalize_AAB * (1 - rel_valid_cross_sim_AB / pow((1 + add), t)), dim=-1) / pntA_H_normalized_new.shape[0]
                rel_meanB = torch.sum(scores_normalize_BBA * (1 - rel_valid_cross_sim_BA / pow((1 + add), t)), dim=-1) / pntB_invH_normalized_new.shape[0]

                # # 熵loss
                # current_descA_std, current_descB_std = descA_std[countA:countA+new_numA], descB_std[countB:countB+new_numB]
                # desc_std += torch.mean(current_descA_std) + torch.mean(current_descB_std)
                # countA_T += numA_T
                # countB_T += numB_T

                dis_neighbor_mean_total += torch.mean(torch.sum(neighbor_dis_AB, dim=1)) + torch.mean(torch.sum(neighbor_dis_BA, dim=1))
                dis_desc += dis_cross_sim_mean_sp
                dis_desc += dis_cross_sim_mean

                dis_pair_meanAB = torch.mean(key_manhattandisAB[pairAB_A, pairAB_B])
                dis_pair_meanBA = torch.mean(key_manhattandisBA[pairBA_B, pairBA_A])

                dis_peak_mean = torch.mean(torch.cat((scoreddisA[idx][pmA], scoreddisB[idx][pmB]), dim=0))
                # dis_peak_meanB = torch.mean(scoreddisB[idx])
                
                dis_mean_total += dis_pair_meanAB + dis_pair_meanBA
                dis_peak_scored += dis_peak_mean

                dis_rel += rel_meanA + rel_meanB
                
                countA += new_numA
                countB += new_numB
                count_ne += new_num_ne
                # # Penalty
                # scores_mean += (-torch.log(torch.mean(scoresA[idx], dim=-1) + eps) - torch.log(torch.mean(scoresB[idx], dim=-1) + eps)) 
                # print(scores_mean)
            except:
                # dis_mean_total += 0
                # dis_peak_scored += 0
                # dis_desc += 0
                # dis_rel += 0
                # print('Overlapping too small or Repeatable point pairs distance is greater than correspond(1.5):', pntA.shape[0], pntA_H.shape[0], pntB.shape[0], pntB_invH.shape[0], dis_pairAB.shape[0], dis_pairBA.shape[0])
                valid_batch_size -= 1
                countA += new_numA
                countB += new_numB
                count_ne += new_num_ne
                # countA_T += numA_T
                # countB_T += numB_T

        valid_batch_size = valid_batch_size if valid_batch_size > 0 else eps
        # Reprojection Loss 
        reprojection_loss = dis_mean_total / (valid_batch_size * 2)
        # Dispersity Peak Loss
        dispersity_peak_loss = dis_peak_scored / valid_batch_size
        # NRE Loss
        descriptor_loss = dis_desc / (2 * valid_batch_size)
        # Reliability Loss
        reliability_loss = dis_rel / (valid_batch_size * 2)
        # SOSR Loss
        sosr_loss = dis_neighbor_mean_total / ((valid_batch_size * 2))
        # # Entropy loss
        # std_loss = (valid_batch_size * 2) / desc_std  
        # # Score Penalty
        # score_penalty = scores_mean / (valid_batch_size * 2)
        # # FA Desc loss
        # FA_des_loss = dis_desc_fa / valid_batch_size_FA if valid_batch_size_FA > 0 else 0

        loss_total = wrp * reprojection_loss + wpl * dispersity_peak_loss + wdl * descriptor_loss + wrl * reliability_loss + sosr_loss
        loss_group = {
            'reprojection_loss': reprojection_loss, 
            'dispersity_peak_loss': dispersity_peak_loss,
            'descriptor_loss': descriptor_loss,
            'reliability_loss': reliability_loss,
            'sosr_loss': sosr_loss,
            # 'std_loss': std_loss,
            # 'FA_des_loss': FA_des_loss,
            }
        return loss_total, loss_group



    # patch/dense AT角度 黑白相似度加量化 NFA two negtives KD(Softmax 知识蒸馏)
    def detector_selfsupervised_loss_dkd_patch_ext_restrict_modify_oriR_ratio_NFA_qtbw_ns_wg_nori_AT_NE2_KD(self, kpA, kpB, pmaskA, pmaskB, descA, descA_tea, descB, descB_tea, desc_mapA, desc_mapB, scoreddisA, scoreddisB, scoresA, scoresB, scores_mapA, scores_mapB, Homo, inv_Homo, inv_Homo_en, ori_all_patchA, ori_all_patchB, ori_kp_patchA, ori_kp_patchB, bin_allA, bin_allB, bin_kpA, bin_kpB, kp_ne, pmask_ne, desc_ne, bin_kp_ne, kp_ne2, pmask_ne2, desc_ne2, bin_kp_ne2, trans_angle, FA_flag, H, W, wrp=1, wpl=1, wdl=1, wrl=1, t_des=0.02, t_rel=1, t_kd=0.04):
        # pmaskA: (BxMax_num) 32x350=11200
        batch_size = len(kpA)
        max_num = pmaskA.shape[-1] // batch_size    # 350
        dis_mean_total = 0
        dis_neighbor_mean_total = 0
        dis_peak_scored = 0
        dis_desc = 0
        dis_rel = 0
        desc_std = 0
        dis_cross_sim_KD = 0
        eps = 1e-12
        valid_batch_size = batch_size
        # valid_batch_size_FA = 0
        countA, countB, count_ne, count_ne2 = 0, 0, 0, 0
        # dis_desc_fa = 0
        # countA_T, countB_T = 0, 0
        for idx in range(batch_size):
            pntA, pntB, pnt_ne, pnt_ne2 = kpA[idx], kpB[idx], kp_ne[idx], kp_ne2[idx]     # M X 2 (x,y)
            # kmask_TA, kmask_TB = kmask_T_allA[idx], kmask_T_allB[idx]
            pntA = pntA.float()
            pntB = pntB.float()
            pnt_ne = pnt_ne.float()
            pnt_ne2 = pnt_ne2.float()

            # 剔除部分按压区域的点,且保留在重叠区域的点
            numA, numB, num_ne, num_ne2 = pntA.shape[0], pntB.shape[0], pnt_ne.shape[0], pnt_ne2.shape[0]
            # numA_T, numB_T = pntA[kmask_TA].shape[0], pntB[kmask_TB].shape[0]
            pmA, pmB, pm_ne, pm_ne2 = pmaskA[max_num * idx:max_num * idx + numA].bool(), pmaskB[max_num * idx:max_num * idx + numB].bool(), pmask_ne[max_num * idx:max_num * idx + num_ne].bool(), pmask_ne2[max_num * idx:max_num * idx + num_ne2].bool()
            pntA, pntB, pnt_ne, pnt_ne2 = pntA[pmA, :], pntB[pmB, :], pnt_ne[pm_ne, :], pnt_ne2[pm_ne2, :] 
            new_numA, new_numB, new_num_ne, new_num_ne2 = pntA.shape[0], pntB.shape[0], pnt_ne.shape[0], pnt_ne2.shape[0]      
            
            pntA = (pntA + 1) / 2 * pntA.new_tensor([[W + 3, H - 1]]).to(pntA.device)
            pntB = (pntB + 1) / 2 * pntB.new_tensor([[W + 3, H - 1]]).to(pntB.device)

            # [120, 40] -> [120, 36],实际只取中心118x32区域的点对
            pntA[:, 0] -= 2
            pntB[:, 0] -= 2
            
            pntA_normalized = pntA / pntA.new_tensor([W - 1, H - 1]).to(pntA.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)
            pntB_normalized = pntB / pntB.new_tensor([W - 1, H - 1]).to(pntB.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)

            pntA_H = warp_points(pntA[:, :2], Homo[idx].squeeze(), device=self.device)  # 利用变换矩阵变换坐标点
            pntA_H, mask_pointA = filter_points(pntA_H, torch.tensor([W, H], device=self.device), return_mask=True)
            pntB_invH = warp_points(pntB[:, :2], inv_Homo[idx].squeeze(), device=self.device)
            pntB_invH, mask_pointB = filter_points(pntB_invH, torch.tensor([W, H], device=self.device), return_mask=True)
            
            current_descA, current_descB = descA[countA:countA+new_numA], descB[countB:countB+new_numB]
            current_descA_tea, current_descB_tea = descA_tea[countA:countA+new_numA], descB_tea[countB:countB+new_numB]
            current_desc_ne = desc_ne[count_ne:count_ne+new_num_ne]
            current_desc_ne2 = desc_ne2[count_ne2:count_ne2+new_num_ne2]
            cross_sim_AB_sp = current_descA @ current_descB.transpose(0, 1)     # NTA X NTB
            cross_sim_KDA_sp = current_descA @ current_descA_tea.transpose(0, 1)  # NTA x NTA
            cross_sim_KDB_sp = current_descB @ current_descB_tea.transpose(0, 1)  # NTB x NTB

            cross_sim_AN_sp = current_descA @ current_desc_ne.transpose(0, 1)
            cross_sim_BN_sp = current_descB @ current_desc_ne.transpose(0, 1)
            cross_sim_AN2_sp = current_descA @ current_desc_ne2.transpose(0, 1)
            cross_sim_BN2_sp = current_descB @ current_desc_ne2.transpose(0, 1)
            
            # 黑白相似度
            current_binA, current_binB = (bin_kpA[countA:countA+new_numA] >= 0.5).float(), (bin_kpB[countB:countB+new_numB] >= 0.5).float()   # [NA, 256] [NB_256]
            current_bin_ne = (bin_kp_ne[count_ne:count_ne+new_num_ne] >= 0.5).float()
            current_bin_ne2 = (bin_kp_ne2[count_ne2:count_ne2+new_num_ne2] >= 0.5).float()
            bin_distAB = current_binA.shape[-1] - (current_binA @ current_binB.transpose(0, 1)) - ((1 - current_binA) @ (1 - current_binB.transpose(0, 1))) # [NA, NB]
            
            bin_distAN = current_binA.shape[-1] - (current_binA @ current_bin_ne.transpose(0, 1)) - ((1 - current_binA) @ (1 - current_bin_ne.transpose(0, 1))) # [NA, NE]
            bin_distBN = current_binB.shape[-1] - (current_binB @ current_bin_ne.transpose(0, 1)) - ((1 - current_binB) @ (1 - current_bin_ne.transpose(0, 1))) # [NA, NE]
            bin_distAN2 = current_binA.shape[-1] - (current_binA @ current_bin_ne2.transpose(0, 1)) - ((1 - current_binA) @ (1 - current_bin_ne2.transpose(0, 1))) # [NA, NE]
            bin_distBN2 = current_binB.shape[-1] - (current_binB @ current_bin_ne2.transpose(0, 1)) - ((1 - current_binB) @ (1 - current_bin_ne2.transpose(0, 1))) # [NA, NE]
            
            # 真匹配的trans
            try:
                FAN_bin_mask = bin_distAN >= (1 - self.FA_bin_thr) * current_binA.shape[-1] 
                FBN_bin_mask = bin_distBN >= (1 - self.FA_bin_thr) * current_binB.shape[-1] 
                FAN2_bin_mask = bin_distAN2 >= (1 - self.FA_bin_thr) * current_binA.shape[-1] 
                FBN2_bin_mask = bin_distBN2 >= (1 - self.FA_bin_thr) * current_binB.shape[-1] 
                # topk ?
                crossAN_mean = torch.mean(cross_sim_AN_sp[FAN_bin_mask])
                crossBN_mean = torch.mean(cross_sim_BN_sp[FBN_bin_mask])
                crossAN2_mean = torch.mean(cross_sim_AN2_sp[FAN2_bin_mask])
                crossBN2_mean = torch.mean(cross_sim_BN2_sp[FBN2_bin_mask])

                assert pntA_H.shape[0] > 0 and pntB_invH.shape[0] > 0 
                
                # 点对欧氏距离
                key_disAB = self.get_dis(pntA_H[:, :2], pntB[:, :2])            # repeatNA x NB
                key_disBA = self.get_dis(pntB_invH[:, :2], pntA[:, :2])
                pairAB_A, pairAB_B, dis_pairAB, _ = self.get_point_pair(key_disAB, dis_thre=self.correspond)  # p -> k # NTA(<1.5), NTA(<1.5), NTA(<1.5), NTA        
                pairBA_B, pairBA_A, dis_pairBA, _  = self.get_point_pair(key_disBA, dis_thre=self.correspond)  # p -> k # NTB(<1.5), NTB(<1.5), NTB(<1.5), NTB 
                
                # 点距离mask
                nn_maskAB = torch.zeros((pntA_H.shape[0], pntB.shape[0]), device=self.device) 
                nn_maskAB[pairAB_A, pairAB_B] = 1

                nn_maskBA = torch.zeros((pntB_invH.shape[0], pntA.shape[0]), device=self.device) 
                nn_maskBA[pairBA_B, pairBA_A] = 1

                # 点对曼哈顿距离
                key_manhattandisAB = self.get_manhattan_dis(pntA_H[:, :2], pntB[:, :2])
                key_manhattandisBA = self.get_manhattan_dis(pntB_invH[:, :2], pntA[:, :2])
                # print('pdis:', dis_pairAB.shape[0], dis_pairBA.shape[0])
                assert dis_pairAB.shape[0] > 0 and dis_pairBA.shape[0] > 0     

                pntA_H_normalized = pntA_H / pntA_H.new_tensor([W - 1, H - 1]).to(pntA_H.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)
                pntB_invH_normalized = pntB_invH / pntB_invH.new_tensor([W - 1, H - 1]).to(pntB_invH.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)

                # 用于score_map
                pntA_H_new = copy.deepcopy(pntA_H.detach())
                pntB_invH_new = copy.deepcopy(pntB_invH.detach())
                pntA_H_new[:, 0] += 10                   # 120 x 36 -> 128 x 56
                pntA_H_new[:, 1] += 4 
                pntB_invH_new[:, 0] += 10
                pntB_invH_new[:, 1] += 4
                
                pntA_H_normalized_new = pntA_H_new / pntA_H_new.new_tensor([W + 19, H + 7]).to(pntA_H.device) * 2 - 1

                # pntB_invH_new = warp_points(pntB_invH_new[:, :2], inv_Homo_en[idx].squeeze(), device=self.device)       # 转到A上，而不是AT上
                
                pntB_invH_normalized_new = pntB_invH_new / pntB_invH_new.new_tensor([W + 19, H + 7]).to(pntB_invH.device) * 2 - 1 
                
                # print('1_2:', main_ori_maskATB.shape[0])
                # exit()
                ori_kpAT_patch_ext = F.grid_sample(ori_kp_patchA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntA_H_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0).transpose(0, 1)          # repeatNA x 1
                ori_kpB_patch_ext = F.grid_sample(ori_all_patchB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntB_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0).transpose(0, 1)          # NTB x 1
                ori_kpA_patch_ext = F.grid_sample(ori_all_patchA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntA_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0).transpose(0, 1)          # NTA x 1
                ori_kpBT_patch_ext = F.grid_sample(ori_kp_patchB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntB_invH_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0).transpose(0, 1)          # repeatNB x 1
                # print('1_2_1:', pntB_invH_normalized_new.shape[0])
                ori_maskATB, dis_oriATB = self.get_main_ori_consistence_AT(ori_kpAT_patch_ext, ori_kpB_patch_ext)  # repeatNA x NTB
                # print('1_2_2:', ori_maskATB.shape)
                ori_maskBTA, dis_oriBTA = self.get_main_ori_consistence_AT(ori_kpBT_patch_ext, ori_kpA_patch_ext)  # repeatNB x NTA

                match_maskAB_nb = (nn_maskAB == 1) * ori_maskATB           # repeatNA X NTB
                match_maskBA_nb = (nn_maskBA == 1) * ori_maskBTA          # repeatNB X NTA
                pairAB_A_nb_new, pairAB_B_nb_new = torch.where(match_maskAB_nb == 1)
                pairBA_B_nb_new, pairBA_A_nb_new = torch.where(match_maskBA_nb == 1)
                # assert pairAB_A_new.shape[0] > 0 and pairBA_B_new.shape[0] > 0 

                # 4x4邻域方向一致性
                ori_kpAB_patch_ext = F.grid_sample(ori_all_patchB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntA_H_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0).transpose(0, 1)  
                ori_kpBA_patch_ext = F.grid_sample(ori_all_patchA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntB_invH_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0).transpose(0, 1)  
                # print('1_2_4:', ori_kpAB_patch_ext.shape)
                ori_maskATAB, dis_oriATAB = self.get_main_ori_consistence_AT(ori_kpAT_patch_ext, ori_kpAB_patch_ext)  # repeatNA x repeatNA
                ori_maskBTBA, dis_oriBTBA = self.get_main_ori_consistence_AT(ori_kpBT_patch_ext, ori_kpBA_patch_ext)  # repeatNB x repeatNB
                
                # 黑白相似度
                bin_maskATB = bin_distAB <= (1 - self.FR_bin_thr) * current_binA.shape[-1]  
                bin_maskBTA = bin_maskATB.transpose(0, 1)  

                match_maskAB = match_maskAB_nb * bin_maskATB[mask_pointA, :]               # repeatNA X NB
                match_maskBA = match_maskBA_nb * bin_maskBTA[mask_pointB, :]               # repeatNB X NA

                pairAB_A_new, pairAB_B_new = torch.where(match_maskAB == 1)
                pairBA_B_new, pairBA_A_new = torch.where(match_maskBA == 1)
                # print('bin_mask:', pairAB_A_new.shape[0], pairBA_B_new.shape[0])
                assert pairAB_A_new.shape[0] > 0 and pairBA_B_new.shape[0] > 0 

                bin_kpAB_T = (F.grid_sample(bin_allB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntA_H_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0) >= 0.5).float()  # [256, repeatNA]
                bin_kpBA_T = (F.grid_sample(bin_allA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntB_invH_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0) >= 0.5).float()  # [256, repeatNB]
                bin_distATAB = bin_kpAB_T.shape[0] - (current_binA @ bin_kpAB_T) - ((1 - current_binA) @ (1 - bin_kpAB_T)) # [NTA, repeatNA]
                bin_distBTBA = bin_kpBA_T.shape[0] - (current_binB @ bin_kpBA_T) - ((1 - current_binB) @ (1 - bin_kpBA_T)) # [NTB, repeatNB]

                bin_maskATAB = bin_distATAB <= (1 - self.FR_bin_thr) * bin_kpAB_T.shape[0] 
                bin_maskBTBA = bin_distBTBA <= (1 - self.FR_bin_thr) * bin_kpBA_T.shape[0] 
                bin_maskATAB = bin_maskATAB[mask_pointA, :]
                bin_maskBTBA = bin_maskBTBA[mask_pointB, :]

                vmaskAH_nb = torch.diag(ori_maskATAB)
                vmaskBH_nb = torch.diag(ori_maskBTBA)
                vmaskAH = torch.diag(ori_maskATAB * bin_maskATAB) == 1      # [repeatNA, 1]
                vmaskBH = torch.diag(ori_maskBTBA * bin_maskBTBA) == 1      # [repeatNB, 1]

                # print('main_ori:', torch.sum(vmaskAH), torch.sum(vmaskBH))
                assert torch.sum(vmaskAH) > 0 and torch.sum(vmaskBH) > 0

                # SOSR: 简化的self-attention
                k_neighbor = 3
                cross_sim_AA_sp = current_descA @ current_descA.transpose(0, 1)
                cross_sim_BB_sp = current_descB @ current_descB.transpose(0, 1)
                # print('SOSR:', pairAB_A_new.shape[0], pairBA_B_new.shape[0])
                assert pairAB_A_new.shape[0] >= k_neighbor and pairBA_B_new.shape[0] >= k_neighbor 

                match_sim_AB_AA = cross_sim_AA_sp[mask_pointA, :][:, mask_pointA][pairAB_A_new, :][:, pairAB_A_new]
                match_sim_BA_BB = cross_sim_BB_sp[mask_pointB, :][:, mask_pointB][pairBA_B_new, :][:, pairBA_B_new]
                match_sim_AB_BB = cross_sim_BB_sp[pairAB_B_new, :][:, pairAB_B_new]
                match_sim_BA_AA = cross_sim_AA_sp[pairBA_A_new, :][:, pairBA_A_new]
                match_values_AB_AA, match_indices_AB_AA = torch.topk(match_sim_AB_AA, dim=1, k=k_neighbor, largest=False)
                match_values_BA_BB, match_indices_BA_BB = torch.topk(match_sim_BA_BB, dim=1, k=k_neighbor, largest=False)
                match_values_AB_BB_all = match_sim_AB_BB[:, match_indices_AB_AA]
                match_values_BA_AA_all = match_sim_BA_AA[:, match_indices_BA_BB]
                match_values_AB_BB = torch.diagonal(match_values_AB_BB_all, 0, dim1=0, dim2=1).transpose(0, 1)
                match_values_BA_AA = torch.diagonal(match_values_BA_AA_all, 0, dim1=0, dim2=1).transpose(0, 1)
                neighbor_dis_AB = (match_values_AB_AA - match_values_AB_BB) * (match_values_AB_AA - match_values_AB_BB)
                neighbor_dis_BA = (match_values_BA_BB - match_values_BA_AA) * (match_values_BA_BB - match_values_BA_AA)

                # PA VS PB
                # 计算bin值
                valid_cross_sim_AB_sp_mean = torch.mean(cross_sim_AB_sp[mask_pointA, :][match_maskAB == 1], dim=-1)
                valid_cross_sim_AB_sp_nb_mean = torch.mean(cross_sim_AB_sp[mask_pointA, :][match_maskAB_nb == 1], dim=-1)
                novalid_cross_sim_AB_sp_mean = (torch.sum(torch.sum(cross_sim_AB_sp.detach(), 1), 0) - valid_cross_sim_AB_sp_nb_mean * pairAB_A_nb_new.shape[0]) / (new_numA * new_numB - pairAB_A_nb_new.shape[0] + eps)
                valid_cross_sim_BA_sp_mean = torch.mean(cross_sim_AB_sp[:, mask_pointB][match_maskBA.transpose(0, 1) == 1], dim=-1)
                valid_cross_sim_BA_sp_nb_mean = torch.mean(cross_sim_AB_sp[:, mask_pointB][match_maskBA_nb.transpose(0, 1) == 1], dim=-1)
                novalid_cross_sim_BA_sp_mean = (torch.sum(torch.sum(cross_sim_AB_sp.detach(), 1), 0) - valid_cross_sim_BA_sp_nb_mean * pairBA_B_nb_new.shape[0]) / (new_numA * new_numB - pairBA_B_nb_new.shape[0] + eps)

                valid_indexesA = torch.tensor(list(range(cross_sim_AB_sp.shape[0])), device=self.device)[mask_pointA][pairAB_A_new]
                valid_indexesA_nb = torch.tensor(list(range(cross_sim_AB_sp.shape[0])), device=self.device)[mask_pointA][pairAB_A_nb_new]
                # cross_sim_BA_sp = current_descB @ current_descA.transpose(0, 1)
                cross_sim_AB_out_sp = torch.cat((cross_sim_AB_sp, torch.ones((cross_sim_AB_sp.shape[0], 3), device=cross_sim_AB_sp.device) * 2), dim=-1)      # NA X (NB + 2)
                cross_sim_AB_out_nb_sp = torch.cat((cross_sim_AB_sp, torch.ones((cross_sim_AB_sp.shape[0], 3), device=cross_sim_AB_sp.device) * 2), dim=-1)      # NA X (NB + 2)
                # cross_sim_BA_out_sp = torch.cat((cross_sim_BA_sp, torch.ones((numB, 1), device=cross_sim_BA_sp.device)), dim=-1)      # NB X (NA + 1)
                # valid_indexesB = torch.tensor(list(range(numB)), device=self.device)[mask_pointB][pairBA_B]
                # print('1_2')
                cross_sim_AB_out_sp[valid_indexesA, -1] = novalid_cross_sim_AB_sp_mean
                cross_sim_AB_out_sp[valid_indexesA, -2] = crossAN_mean
                cross_sim_AB_out_sp[valid_indexesA, -3] = crossAN2_mean
                cross_sim_AB_out_nb_sp[valid_indexesA_nb, -1] = novalid_cross_sim_AB_sp_mean
                novalid_indexesA = torch.tensor(list(range(cross_sim_AB_sp.shape[0])), device=self.device)[cross_sim_AB_out_nb_sp[:, -1]==2]
                cross_sim_AB_out_sp[novalid_indexesA, -1] = valid_cross_sim_AB_sp_mean
                # nomatch对不增加negtives的均值bin
                cross_sim_AB_out_sp[novalid_indexesA, -2] = -1 # crossAN_mean # -1
                cross_sim_AB_out_sp[novalid_indexesA, -3] = -1 # crossAN_mean # -1

                soft_cross_sim_AtoB_sp = F.softmax((cross_sim_AB_out_sp - 1) / t_des, dim=-1)
                # soft_cross_sim_BtoA = F.softmax((cross_sim_BA_out - 1) / t_des, dim=-1)
                # print('1_3')
                soft_valid_cross_sim_AB_sp = soft_cross_sim_AtoB_sp[mask_pointA, :-3][match_maskAB==1]
                # soft_valid_cross_sim_BA = soft_cross_sim_BtoA[mask_pointB, :-1][pairBA_B, pairBA_A]
                soft_novalid_cross_sim_AB_sp = soft_cross_sim_AtoB_sp[novalid_indexesA, -1]
                # soft_novalid_cross_sim_BA = soft_cross_sim_BtoA[cross_sim_BA_out[:, -1]==1, -1]
                log_soft_valid_cross_sim_AB_sp = -torch.log(soft_valid_cross_sim_AB_sp + eps) * (1 - dis_oriATB[match_maskAB==1] / self.ori_diff) * (1 - bin_distAB[mask_pointA, :][match_maskAB==1] / current_binA.shape[-1]) * (1 - key_disAB[match_maskAB==1].detach() / self.correspond)
                # log_soft_valid_cross_sim_BA = -torch.log(soft_valid_cross_sim_BA + eps)
                log_soft_novalid_cross_sim_AB_sp = -torch.log(soft_novalid_cross_sim_AB_sp + eps)
                # log_soft_novalid_cross_sim_BA = -torch.log(soft_novalid_cross_sim_BA + eps)
                dis_cross_sim_mean_sp = torch.sum(torch.cat((4*log_soft_valid_cross_sim_AB_sp, log_soft_novalid_cross_sim_AB_sp), dim=-1), dim=-1) / new_numA
                
                # PA VS PAB
                # match_mask_A = copy.deepcopy(mask_pointA)
                # match_mask_B = copy.deepcopy(mask_pointB)
                match_mask_A = torch.zeros(cross_sim_AB_sp.shape[0], device=self.device)
                match_mask_nb_A = torch.zeros(cross_sim_AB_sp.shape[0], device=self.device)
                valid_match_indexesA = torch.tensor(list(range(cross_sim_AB_sp.shape[0])), device=self.device)[mask_pointA][vmaskAH]
                valid_match_indexesA_nb = torch.tensor(list(range(cross_sim_AB_sp.shape[0])), device=self.device)[mask_pointA][vmaskAH_nb]
                match_mask_A[valid_match_indexesA] = 1
                match_mask_nb_A[valid_match_indexesA_nb] = 1

                match_mask_B = torch.zeros(cross_sim_AB_sp.shape[1], device=self.device)
                match_mask_nb_B = torch.zeros(cross_sim_AB_sp.shape[1], device=self.device)
                valid_match_indexesB = torch.tensor(list(range(cross_sim_AB_sp.shape[1])), device=self.device)[mask_pointB][vmaskBH]
                valid_match_indexesB_nb = torch.tensor(list(range(cross_sim_AB_sp.shape[1])), device=self.device)[mask_pointB][vmaskBH_nb]
                match_mask_B[valid_match_indexesB] = 1
                match_mask_nb_B[valid_match_indexesB_nb] = 1

                cross_sim_AB = current_descA @ desc_mapB[idx, :, :, :].view(-1, H * W)
                # cross_sim_AB = cross_sim_AB[mask_pointA, :]
                cross_sim_AB_all = F.grid_sample(cross_sim_AB.view(-1, H, W).unsqueeze(0),
                                                pntA_H_normalized[vmaskAH, :].detach().view(1, 1, -1, 2),
                                                mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NA x repeatNA
                valid_cross_sim_AB_mean = torch.trace(cross_sim_AB_all[match_mask_A==1, :]) / cross_sim_AB_all[match_mask_A==1, :].shape[0]
                # novalid_cross_sim_AB_mean = (torch.sum(torch.sum(cross_sim_AB.detach(), 1), 1) - valid_cross_sim_AB_mean * pairAB_A.shape[0]) / (new_numA * H * W - pairAB_A.shape[0])

                cross_sim_BA = current_descB @ desc_mapA[idx, :, :, :].view(-1, H * W)   # M x H x W
                # cross_sim_BA = cross_sim_BA[mask_pointB, :]
                cross_sim_BA_all = F.grid_sample(cross_sim_BA.view(-1, H, W).unsqueeze(0),
                                                pntB_invH_normalized[vmaskBH, :].detach().view(1, 1, -1, 2),
                                                mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NB x match_nB
                valid_cross_sim_BA_mean = torch.trace(cross_sim_BA_all[match_mask_B==1, :]) / cross_sim_BA_all[match_mask_B==1, :].shape[0]
                # novalid_cross_sim_BA_mean = (torch.sum(torch.sum(cross_sim_BA.detach(), 1), 1) - valid_cross_sim_BA_mean * pairBA_B.shape[0]) / (new_numB * H * W - pairBA_B.shape[0])

                cross_sim_AB_out = torch.cat((cross_sim_AB, torch.ones((cross_sim_AB.shape[0], 3), device=cross_sim_AB.device)), dim=-1)      # NA X (H X W + 2)
                cross_sim_BA_out = torch.cat((cross_sim_BA, torch.ones((cross_sim_BA.shape[0], 3), device=cross_sim_BA.device)), dim=-1)      # NB X (H X W + 2)
                # print(3)
                # cross_sim_AB_out[mask_pointA, -1] -= 1
                # cross_sim_BA_out[mask_pointB, -1] -= 1
                # cross_sim_AB_out[match_mask_A, -1] -= 1
                cross_sim_AB_out[match_mask_A==1, -1] = novalid_cross_sim_AB_sp_mean
                cross_sim_AB_out[match_mask_A==1, -2] = crossAN_mean
                cross_sim_AB_out[match_mask_A==1, -3] = crossAN2_mean
                cross_sim_AB_out[match_mask_nb_A==0, -1] = valid_cross_sim_AB_mean
                cross_sim_AB_out[match_mask_nb_A==0, -2] = -1 # crossAN_mean # -1
                cross_sim_AB_out[match_mask_nb_A==0, -3] = -1 # crossAN_mean # -1

                cross_sim_BA_out[match_mask_B==1, -1] = novalid_cross_sim_BA_sp_mean
                cross_sim_BA_out[match_mask_B==1, -2] = crossBN_mean
                cross_sim_BA_out[match_mask_B==1, -3] = crossBN2_mean
                cross_sim_BA_out[match_mask_nb_B==0, -1] = valid_cross_sim_BA_mean
                cross_sim_BA_out[match_mask_nb_B==0, -2] = -1 # crossBN_mean # -1
                cross_sim_BA_out[match_mask_nb_B==0, -3] = -1 # crossBN_mean # -1

                soft_cross_sim_AtoB = F.softmax((cross_sim_AB_out - 1) / t_des, dim=-1)         # NA X (H X W + 1)
                soft_cross_sim_BtoA = F.softmax((cross_sim_BA_out - 1) / t_des, dim=-1)         # NB X (H X W + 1)
                soft_cross_sim_AB_all = F.grid_sample(soft_cross_sim_AtoB[:, :-3].view(-1, H, W).unsqueeze(0),
                                                    pntA_H_normalized[vmaskAH, :].detach().view(1, 1, -1, 2),
                                                    mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NA x match_nA
                
                soft_cross_sim_BA_all = F.grid_sample(soft_cross_sim_BtoA[:, :-3].view(-1, H, W).unsqueeze(0),
                                                    pntB_invH_normalized[vmaskBH, :].detach().view(1, 1, -1, 2),
                                                    mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NB x match_nB
                # soft_valid_cross_sim_AB_all = soft_cross_sim_AB_all[mask_pointA, :]             # repeat_nA x repeat_nA
                # soft_valid_cross_sim_BA_all = soft_cross_sim_BA_all[mask_pointB, :]             # repeat_nB x repeat_nB

                soft_valid_cross_sim_AB_all = soft_cross_sim_AB_all[match_mask_A==1, :]             # match_nA x match_nA
                soft_valid_cross_sim_BA_all = soft_cross_sim_BA_all[match_mask_B==1, :]             # match_nB x match_nB

                valid_mask_AB = torch.eye(soft_valid_cross_sim_AB_all.shape[0]) == 1
                valid_mask_BA = torch.eye(soft_valid_cross_sim_BA_all.shape[0]) == 1
                # print(4)
                # 取对角线
                soft_valid_cross_sim_AB = soft_valid_cross_sim_AB_all[valid_mask_AB]
                soft_valid_cross_sim_BA = soft_valid_cross_sim_BA_all[valid_mask_BA]

                # soft_novalid_cross_sim_AB = soft_cross_sim_AtoB[mask_pointA==False, -1]              # (NA-repeat_nA) x 1
                # soft_novalid_cross_sim_BA = soft_cross_sim_BtoA[mask_pointB==False, -1]
                soft_novalid_cross_sim_AB = soft_cross_sim_AtoB[match_mask_nb_A==0, -1]               # (NA-match_nA) x 1
                soft_novalid_cross_sim_BA = soft_cross_sim_BtoA[match_mask_nb_B==0, -1]
                # print(soft_novalid_cross_sim_AB, soft_novalid_cross_sim_BA)

                log_soft_valid_cross_sim_AB = -torch.log(soft_valid_cross_sim_AB + eps) * (1 - torch.diag(dis_oriATAB)[vmaskAH] / self.ori_diff) * (1 - torch.diag(bin_distATAB[mask_pointA, :])[vmaskAH] / bin_kpAB_T.shape[0])
                log_soft_valid_cross_sim_BA = -torch.log(soft_valid_cross_sim_BA + eps) * (1 - torch.diag(dis_oriBTBA)[vmaskBH] / self.ori_diff) * (1 - torch.diag(bin_distBTBA[mask_pointB, :])[vmaskBH] / bin_kpBA_T.shape[0])
                log_soft_novalid_cross_sim_AB = -torch.log(soft_novalid_cross_sim_AB + eps)
                log_soft_novalid_cross_sim_BA = -torch.log(soft_novalid_cross_sim_BA + eps)

                dis_cross_sim_mean = torch.sum(torch.cat((4*log_soft_valid_cross_sim_AB, 4*log_soft_valid_cross_sim_BA, log_soft_novalid_cross_sim_AB, log_soft_novalid_cross_sim_BA), dim=-1), dim=-1) / (new_numA + new_numB)
                
                # print(5)
                valid_cross_sim_AB = cross_sim_AB[mask_pointA, :]   # repeat_nA x (H X W)
                valid_cross_sim_BA = cross_sim_BA[mask_pointB, :]   # repeat_nB x (H X W)
                exp_valid_cross_sim_AtoB = torch.exp((valid_cross_sim_AB - 1) / t_rel).view(-1, H, W)
                exp_valid_cross_sim_BtoA = torch.exp((valid_cross_sim_BA - 1) / t_rel).view(-1, H, W)
                exp_valid_cross_sim_AB_all = F.grid_sample(exp_valid_cross_sim_AtoB.unsqueeze(0),
                                                        pntA_H_normalized.detach().view(1, 1, -1, 2),
                                                        mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # repeat_nA x repeat_nA
                
                exp_valid_cross_sim_BA_all = F.grid_sample(exp_valid_cross_sim_BtoA.unsqueeze(0),
                                                        pntB_invH_normalized.detach().view(1, 1, -1, 2),
                                                        mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # repeat_nB x repeat_nB

                repeat_mask_AB = torch.eye(exp_valid_cross_sim_AB_all.shape[0]) == 1
                repeat_mask_BA = torch.eye(exp_valid_cross_sim_BA_all.shape[0]) == 1
                rel_valid_cross_sim_AB = exp_valid_cross_sim_AB_all[repeat_mask_AB]
                rel_valid_cross_sim_BA = exp_valid_cross_sim_BA_all[repeat_mask_BA]

                # pntA_H_normalized_new = copy.deepcopy(pntA_H_normalized.detach())
                # pntB_invH_normalized_new = copy.deepcopy(pntB_invH_normalized.detach())

                # pntA_H_normalized_new[:, 0] += 2
                # pntB_invH_normalized_new[:, 0] += 2

                scoresAB_all = F.grid_sample(scores_mapB[idx, :, :, :].unsqueeze(0),
                                            pntA_H_normalized_new.view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)      # 1 x repeat_nA

                scoresBA_all = F.grid_sample(scores_mapA[idx, :, :, :].unsqueeze(0),
                                            pntB_invH_normalized_new.view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)      # 1 x repeat_nB
                # print(6)
                scores_AAB = scoresA[idx][pmA][mask_pointA] * scoresAB_all
                scores_BBA = scoresB[idx][pmB][mask_pointB] * scoresBA_all
                scores_sum_AAB = torch.sum(scores_AAB, dim=-1)
                scores_sum_BBA = torch.sum(scores_BBA, dim=-1)
                scores_normalize_AAB = scores_AAB / (scores_sum_AAB + eps)
                scores_normalize_BBA = scores_BBA / (scores_sum_BBA + eps)
                rel_meanA = torch.sum(scores_normalize_AAB * (1 - rel_valid_cross_sim_AB), dim=-1) / pntA_H_normalized_new.shape[0]
                rel_meanB = torch.sum(scores_normalize_BBA * (1 - rel_valid_cross_sim_BA), dim=-1) / pntB_invH_normalized_new.shape[0]

                # # 熵loss
                # current_descA_std, current_descB_std = descA_std[countA:countA+new_numA], descB_std[countB:countB+new_numB]
                # desc_std += torch.mean(current_descA_std) + torch.mean(current_descB_std)
                # countA_T += numA_T
                # countB_T += numB_T

                # KD loss
                soft_cross_sim_KDA_sp = F.softmax((cross_sim_KDA_sp - 1) / t_kd, dim=-1)   # NTA X NTA
                soft_cross_sim_KDB_sp = F.softmax((cross_sim_KDB_sp - 1) / t_kd, dim=-1)   # NTB X NTB
                log_soft_valid_cross_sim_KDA = -torch.log(soft_cross_sim_KDA_sp + eps)
                log_soft_valid_cross_sim_KDB = -torch.log(soft_cross_sim_KDB_sp + eps)
                dis_cross_sim_KD += (torch.trace(log_soft_valid_cross_sim_KDA) + torch.trace(log_soft_valid_cross_sim_KDB)) / (new_numA + new_numB)

                # dis_cross_sim_KD += (1 - (torch.trace(SK_scores_KDA) + torch.trace(SK_scores_KDB)) / (new_numA + new_numB))

                dis_neighbor_mean_total += torch.mean(torch.sum(neighbor_dis_AB, dim=1)) + torch.mean(torch.sum(neighbor_dis_BA, dim=1))
                dis_desc += dis_cross_sim_mean_sp
                dis_desc += dis_cross_sim_mean

                dis_pair_meanAB = torch.mean(key_manhattandisAB[pairAB_A, pairAB_B])
                dis_pair_meanBA = torch.mean(key_manhattandisBA[pairBA_B, pairBA_A])

                dis_peak_mean = torch.mean(torch.cat((scoreddisA[idx][pmA], scoreddisB[idx][pmB]), dim=0))
                # dis_peak_meanB = torch.mean(scoreddisB[idx])
                
                dis_mean_total += dis_pair_meanAB + dis_pair_meanBA
                dis_peak_scored += dis_peak_mean

                dis_rel += rel_meanA + rel_meanB
                
                countA += new_numA
                countB += new_numB
                count_ne += new_num_ne
                # # Penalty
                # scores_mean += (-torch.log(torch.mean(scoresA[idx], dim=-1) + eps) - torch.log(torch.mean(scoresB[idx], dim=-1) + eps)) 
                # print(scores_mean)
            except:
                # dis_mean_total += 0
                # dis_peak_scored += 0
                # dis_desc += 0
                # dis_rel += 0
                # print('Overlapping too small or Repeatable point pairs distance is greater than correspond(1.5):', pntA.shape[0], pntA_H.shape[0], pntB.shape[0], pntB_invH.shape[0], dis_pairAB.shape[0], dis_pairBA.shape[0])
                valid_batch_size -= 1
                countA += new_numA
                countB += new_numB
                count_ne += new_num_ne
                # countA_T += numA_T
                # countB_T += numB_T

        valid_batch_size = valid_batch_size if valid_batch_size > 0 else eps
        # Reprojection Loss 
        reprojection_loss = dis_mean_total / (valid_batch_size * 2)
        # Dispersity Peak Loss
        dispersity_peak_loss = dis_peak_scored / valid_batch_size
        # NRE Loss
        descriptor_loss = dis_desc / (2 * valid_batch_size)
        # Reliability Loss
        reliability_loss = dis_rel / (valid_batch_size * 2)
        # SOSR Loss
        sosr_loss = dis_neighbor_mean_total / ((valid_batch_size * 2))
        # # Entropy loss
        # std_loss = (valid_batch_size * 2) / desc_std  
        # # Score Penalty
        # score_penalty = scores_mean / (valid_batch_size * 2)
        # # FA Desc loss
        # FA_des_loss = dis_desc_fa / valid_batch_size_FA if valid_batch_size_FA > 0 else 0
        # KD_loss
        KD_loss = dis_cross_sim_KD / valid_batch_size

        loss_total = wrp * reprojection_loss + wpl * dispersity_peak_loss + wdl * descriptor_loss + wrl * reliability_loss + sosr_loss + KD_loss
        loss_group = {
            'reprojection_loss': reprojection_loss, 
            'dispersity_peak_loss': dispersity_peak_loss,
            'descriptor_loss': descriptor_loss,
            'reliability_loss': reliability_loss,
            'sosr_loss': sosr_loss,
            # 'std_loss': std_loss,
            # 'FA_des_loss': FA_des_loss,
            'KD_loss': KD_loss
            }
        return loss_total, loss_group

    # patch/dense AT角度 黑白相似度加量化 NFA two negtives SKKD(Sinkhorn 知识蒸馏)
    def detector_selfsupervised_loss_dkd_patch_ext_restrict_modify_oriR_ratio_NFA_qtbw_ns_wg_nori_AT_NE2_SKKD(self, kpA, kpB, pmaskA, pmaskB, descA, descA_tea, descB, descB_tea, desc_mapA, desc_mapB, scoreddisA, scoreddisB, scoresA, scoresB, scores_mapA, scores_mapB, Homo, inv_Homo, inv_Homo_en, ori_all_patchA, ori_all_patchB, ori_kp_patchA, ori_kp_patchB, bin_allA, bin_allB, bin_kpA, bin_kpB, kp_ne, pmask_ne, desc_ne, bin_kp_ne, kp_ne2, pmask_ne2, desc_ne2, bin_kp_ne2, trans_angle, FA_flag, H, W, wrp=1, wpl=1, wdl=1, wrl=1, t_des=0.02, t_rel=1, t_kd=0.04):
        # pmaskA: (BxMax_num) 32x350=11200
        batch_size = len(kpA)
        max_num = pmaskA.shape[-1] // batch_size    # 350
        dis_mean_total = 0
        dis_neighbor_mean_total = 0
        dis_peak_scored = 0
        dis_desc = 0
        dis_rel = 0
        desc_std = 0
        dis_cross_sim_KD = 0
        eps = 1e-12
        valid_batch_size = batch_size
        # valid_batch_size_FA = 0
        countA, countB, count_ne, count_ne2 = 0, 0, 0, 0
        # dis_desc_fa = 0
        # countA_T, countB_T = 0, 0
        for idx in range(batch_size):
            pntA, pntB, pnt_ne, pnt_ne2 = kpA[idx], kpB[idx], kp_ne[idx], kp_ne2[idx]     # M X 2 (x,y)
            # kmask_TA, kmask_TB = kmask_T_allA[idx], kmask_T_allB[idx]
            pntA = pntA.float()
            pntB = pntB.float()
            pnt_ne = pnt_ne.float()
            pnt_ne2 = pnt_ne2.float()

            # 剔除部分按压区域的点,且保留在重叠区域的点
            numA, numB, num_ne, num_ne2 = pntA.shape[0], pntB.shape[0], pnt_ne.shape[0], pnt_ne2.shape[0]
            # numA_T, numB_T = pntA[kmask_TA].shape[0], pntB[kmask_TB].shape[0]
            pmA, pmB, pm_ne, pm_ne2 = pmaskA[max_num * idx:max_num * idx + numA].bool(), pmaskB[max_num * idx:max_num * idx + numB].bool(), pmask_ne[max_num * idx:max_num * idx + num_ne].bool(), pmask_ne2[max_num * idx:max_num * idx + num_ne2].bool()
            pntA, pntB, pnt_ne, pnt_ne2 = pntA[pmA, :], pntB[pmB, :], pnt_ne[pm_ne, :], pnt_ne2[pm_ne2, :] 
            new_numA, new_numB, new_num_ne, new_num_ne2 = pntA.shape[0], pntB.shape[0], pnt_ne.shape[0], pnt_ne2.shape[0]      
            
            pntA = (pntA + 1) / 2 * pntA.new_tensor([[W + 3, H - 1]]).to(pntA.device)
            pntB = (pntB + 1) / 2 * pntB.new_tensor([[W + 3, H - 1]]).to(pntB.device)

            # [120, 40] -> [120, 36],实际只取中心118x32区域的点对
            pntA[:, 0] -= 2
            pntB[:, 0] -= 2
            
            pntA_normalized = pntA / pntA.new_tensor([W - 1, H - 1]).to(pntA.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)
            pntB_normalized = pntB / pntB.new_tensor([W - 1, H - 1]).to(pntB.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)

            pntA_H = warp_points(pntA[:, :2], Homo[idx].squeeze(), device=self.device)  # 利用变换矩阵变换坐标点
            pntA_H, mask_pointA = filter_points(pntA_H, torch.tensor([W, H], device=self.device), return_mask=True)
            pntB_invH = warp_points(pntB[:, :2], inv_Homo[idx].squeeze(), device=self.device)
            pntB_invH, mask_pointB = filter_points(pntB_invH, torch.tensor([W, H], device=self.device), return_mask=True)
            
            current_descA, current_descB = descA[countA:countA+new_numA], descB[countB:countB+new_numB]
            current_descA_tea, current_descB_tea = descA_tea[countA:countA+new_numA], descB_tea[countB:countB+new_numB]
            current_desc_ne = desc_ne[count_ne:count_ne+new_num_ne]
            current_desc_ne2 = desc_ne2[count_ne2:count_ne2+new_num_ne2]
            cross_sim_AB_sp = current_descA @ current_descB.transpose(0, 1)     # NTA X NTB
            cross_sim_KDA_sp = current_descA @ current_descA_tea.transpose(0, 1)  # NTA x NTA
            cross_sim_KDB_sp = current_descB @ current_descB_tea.transpose(0, 1)  # NTB x NTB

            cross_sim_AN_sp = current_descA @ current_desc_ne.transpose(0, 1)
            cross_sim_BN_sp = current_descB @ current_desc_ne.transpose(0, 1)
            cross_sim_AN2_sp = current_descA @ current_desc_ne2.transpose(0, 1)
            cross_sim_BN2_sp = current_descB @ current_desc_ne2.transpose(0, 1)
            
            # 黑白相似度
            current_binA, current_binB = (bin_kpA[countA:countA+new_numA] >= 0.5).float(), (bin_kpB[countB:countB+new_numB] >= 0.5).float()   # [NA, 256] [NB_256]
            current_bin_ne = (bin_kp_ne[count_ne:count_ne+new_num_ne] >= 0.5).float()
            current_bin_ne2 = (bin_kp_ne2[count_ne2:count_ne2+new_num_ne2] >= 0.5).float()
            bin_distAB = current_binA.shape[-1] - (current_binA @ current_binB.transpose(0, 1)) - ((1 - current_binA) @ (1 - current_binB.transpose(0, 1))) # [NA, NB]
            
            bin_distAN = current_binA.shape[-1] - (current_binA @ current_bin_ne.transpose(0, 1)) - ((1 - current_binA) @ (1 - current_bin_ne.transpose(0, 1))) # [NA, NE]
            bin_distBN = current_binB.shape[-1] - (current_binB @ current_bin_ne.transpose(0, 1)) - ((1 - current_binB) @ (1 - current_bin_ne.transpose(0, 1))) # [NA, NE]
            bin_distAN2 = current_binA.shape[-1] - (current_binA @ current_bin_ne2.transpose(0, 1)) - ((1 - current_binA) @ (1 - current_bin_ne2.transpose(0, 1))) # [NA, NE]
            bin_distBN2 = current_binB.shape[-1] - (current_binB @ current_bin_ne2.transpose(0, 1)) - ((1 - current_binB) @ (1 - current_bin_ne2.transpose(0, 1))) # [NA, NE]
            
            # 真匹配的trans
            try:
                FAN_bin_mask = bin_distAN >= (1 - self.FA_bin_thr) * current_binA.shape[-1] 
                FBN_bin_mask = bin_distBN >= (1 - self.FA_bin_thr) * current_binB.shape[-1] 
                FAN2_bin_mask = bin_distAN2 >= (1 - self.FA_bin_thr) * current_binA.shape[-1] 
                FBN2_bin_mask = bin_distBN2 >= (1 - self.FA_bin_thr) * current_binB.shape[-1] 
                # topk ?
                crossAN_mean = torch.mean(cross_sim_AN_sp[FAN_bin_mask])
                crossBN_mean = torch.mean(cross_sim_BN_sp[FBN_bin_mask])
                crossAN2_mean = torch.mean(cross_sim_AN2_sp[FAN2_bin_mask])
                crossBN2_mean = torch.mean(cross_sim_BN2_sp[FBN2_bin_mask])

                assert pntA_H.shape[0] > 0 and pntB_invH.shape[0] > 0 
                
                # 点对欧氏距离
                key_disAB = self.get_dis(pntA_H[:, :2], pntB[:, :2])            # repeatNA x NB
                key_disBA = self.get_dis(pntB_invH[:, :2], pntA[:, :2])
                pairAB_A, pairAB_B, dis_pairAB, _ = self.get_point_pair(key_disAB, dis_thre=self.correspond)  # p -> k # NTA(<1.5), NTA(<1.5), NTA(<1.5), NTA        
                pairBA_B, pairBA_A, dis_pairBA, _  = self.get_point_pair(key_disBA, dis_thre=self.correspond)  # p -> k # NTB(<1.5), NTB(<1.5), NTB(<1.5), NTB 
                
                # 点距离mask
                nn_maskAB = torch.zeros((pntA_H.shape[0], pntB.shape[0]), device=self.device) 
                nn_maskAB[pairAB_A, pairAB_B] = 1

                nn_maskBA = torch.zeros((pntB_invH.shape[0], pntA.shape[0]), device=self.device) 
                nn_maskBA[pairBA_B, pairBA_A] = 1

                # 点对曼哈顿距离
                key_manhattandisAB = self.get_manhattan_dis(pntA_H[:, :2], pntB[:, :2])
                key_manhattandisBA = self.get_manhattan_dis(pntB_invH[:, :2], pntA[:, :2])
                # print('pdis:', dis_pairAB.shape[0], dis_pairBA.shape[0])
                assert dis_pairAB.shape[0] > 0 and dis_pairBA.shape[0] > 0     

                pntA_H_normalized = pntA_H / pntA_H.new_tensor([W - 1, H - 1]).to(pntA_H.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)
                pntB_invH_normalized = pntB_invH / pntB_invH.new_tensor([W - 1, H - 1]).to(pntB_invH.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)

                # 用于score_map
                pntA_H_new = copy.deepcopy(pntA_H.detach())
                pntB_invH_new = copy.deepcopy(pntB_invH.detach())
                pntA_H_new[:, 0] += 10                   # 120 x 36 -> 128 x 56
                pntA_H_new[:, 1] += 4 
                pntB_invH_new[:, 0] += 10
                pntB_invH_new[:, 1] += 4
                
                pntA_H_normalized_new = pntA_H_new / pntA_H_new.new_tensor([W + 19, H + 7]).to(pntA_H.device) * 2 - 1

                # pntB_invH_new = warp_points(pntB_invH_new[:, :2], inv_Homo_en[idx].squeeze(), device=self.device)       # 转到A上，而不是AT上
                
                pntB_invH_normalized_new = pntB_invH_new / pntB_invH_new.new_tensor([W + 19, H + 7]).to(pntB_invH.device) * 2 - 1 
                
                # print('1_2:', main_ori_maskATB.shape[0])
                # exit()
                ori_kpAT_patch_ext = F.grid_sample(ori_kp_patchA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntA_H_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0).transpose(0, 1)          # repeatNA x 1
                ori_kpB_patch_ext = F.grid_sample(ori_all_patchB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntB_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0).transpose(0, 1)          # NTB x 1
                ori_kpA_patch_ext = F.grid_sample(ori_all_patchA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntA_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0).transpose(0, 1)          # NTA x 1
                ori_kpBT_patch_ext = F.grid_sample(ori_kp_patchB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntB_invH_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0).transpose(0, 1)          # repeatNB x 1
                # print('1_2_1:', pntB_invH_normalized_new.shape[0])
                ori_maskATB, dis_oriATB = self.get_main_ori_consistence_AT(ori_kpAT_patch_ext, ori_kpB_patch_ext)  # repeatNA x NTB
                # print('1_2_2:', ori_maskATB.shape)
                ori_maskBTA, dis_oriBTA = self.get_main_ori_consistence_AT(ori_kpBT_patch_ext, ori_kpA_patch_ext)  # repeatNB x NTA

                match_maskAB_nb = (nn_maskAB == 1) * ori_maskATB           # repeatNA X NTB
                match_maskBA_nb = (nn_maskBA == 1) * ori_maskBTA          # repeatNB X NTA
                pairAB_A_nb_new, pairAB_B_nb_new = torch.where(match_maskAB_nb == 1)
                pairBA_B_nb_new, pairBA_A_nb_new = torch.where(match_maskBA_nb == 1)
                # assert pairAB_A_new.shape[0] > 0 and pairBA_B_new.shape[0] > 0 

                # 4x4邻域方向一致性
                ori_kpAB_patch_ext = F.grid_sample(ori_all_patchB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntA_H_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0).transpose(0, 1)  
                ori_kpBA_patch_ext = F.grid_sample(ori_all_patchA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntB_invH_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0).transpose(0, 1)  
                # print('1_2_4:', ori_kpAB_patch_ext.shape)
                ori_maskATAB, dis_oriATAB = self.get_main_ori_consistence_AT(ori_kpAT_patch_ext, ori_kpAB_patch_ext)  # repeatNA x repeatNA
                ori_maskBTBA, dis_oriBTBA = self.get_main_ori_consistence_AT(ori_kpBT_patch_ext, ori_kpBA_patch_ext)  # repeatNB x repeatNB
                
                # 黑白相似度
                bin_maskATB = bin_distAB <= (1 - self.FR_bin_thr) * current_binA.shape[-1]  
                bin_maskBTA = bin_maskATB.transpose(0, 1)  

                match_maskAB = match_maskAB_nb * bin_maskATB[mask_pointA, :]               # repeatNA X NB
                match_maskBA = match_maskBA_nb * bin_maskBTA[mask_pointB, :]               # repeatNB X NA

                pairAB_A_new, pairAB_B_new = torch.where(match_maskAB == 1)
                pairBA_B_new, pairBA_A_new = torch.where(match_maskBA == 1)
                # print('bin_mask:', pairAB_A_new.shape[0], pairBA_B_new.shape[0])
                assert pairAB_A_new.shape[0] > 0 and pairBA_B_new.shape[0] > 0 

                bin_kpAB_T = (F.grid_sample(bin_allB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntA_H_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0) >= 0.5).float()  # [256, repeatNA]
                bin_kpBA_T = (F.grid_sample(bin_allA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntB_invH_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0) >= 0.5).float()  # [256, repeatNB]
                bin_distATAB = bin_kpAB_T.shape[0] - (current_binA @ bin_kpAB_T) - ((1 - current_binA) @ (1 - bin_kpAB_T)) # [NTA, repeatNA]
                bin_distBTBA = bin_kpBA_T.shape[0] - (current_binB @ bin_kpBA_T) - ((1 - current_binB) @ (1 - bin_kpBA_T)) # [NTB, repeatNB]

                bin_maskATAB = bin_distATAB <= (1 - self.FR_bin_thr) * bin_kpAB_T.shape[0] 
                bin_maskBTBA = bin_distBTBA <= (1 - self.FR_bin_thr) * bin_kpBA_T.shape[0] 
                bin_maskATAB = bin_maskATAB[mask_pointA, :]
                bin_maskBTBA = bin_maskBTBA[mask_pointB, :]

                vmaskAH_nb = torch.diag(ori_maskATAB)
                vmaskBH_nb = torch.diag(ori_maskBTBA)
                vmaskAH = torch.diag(ori_maskATAB * bin_maskATAB) == 1      # [repeatNA, 1]
                vmaskBH = torch.diag(ori_maskBTBA * bin_maskBTBA) == 1      # [repeatNB, 1]

                # print('main_ori:', torch.sum(vmaskAH), torch.sum(vmaskBH))
                assert torch.sum(vmaskAH) > 0 and torch.sum(vmaskBH) > 0

                # SOSR: 简化的self-attention
                k_neighbor = 3
                cross_sim_AA_sp = current_descA @ current_descA.transpose(0, 1)
                cross_sim_BB_sp = current_descB @ current_descB.transpose(0, 1)
                # print('SOSR:', pairAB_A_new.shape[0], pairBA_B_new.shape[0])
                assert pairAB_A_new.shape[0] >= k_neighbor and pairBA_B_new.shape[0] >= k_neighbor 

                match_sim_AB_AA = cross_sim_AA_sp[mask_pointA, :][:, mask_pointA][pairAB_A_new, :][:, pairAB_A_new]
                match_sim_BA_BB = cross_sim_BB_sp[mask_pointB, :][:, mask_pointB][pairBA_B_new, :][:, pairBA_B_new]
                match_sim_AB_BB = cross_sim_BB_sp[pairAB_B_new, :][:, pairAB_B_new]
                match_sim_BA_AA = cross_sim_AA_sp[pairBA_A_new, :][:, pairBA_A_new]
                match_values_AB_AA, match_indices_AB_AA = torch.topk(match_sim_AB_AA, dim=1, k=k_neighbor, largest=False)
                match_values_BA_BB, match_indices_BA_BB = torch.topk(match_sim_BA_BB, dim=1, k=k_neighbor, largest=False)
                match_values_AB_BB_all = match_sim_AB_BB[:, match_indices_AB_AA]
                match_values_BA_AA_all = match_sim_BA_AA[:, match_indices_BA_BB]
                match_values_AB_BB = torch.diagonal(match_values_AB_BB_all, 0, dim1=0, dim2=1).transpose(0, 1)
                match_values_BA_AA = torch.diagonal(match_values_BA_AA_all, 0, dim1=0, dim2=1).transpose(0, 1)
                neighbor_dis_AB = (match_values_AB_AA - match_values_AB_BB) * (match_values_AB_AA - match_values_AB_BB)
                neighbor_dis_BA = (match_values_BA_BB - match_values_BA_AA) * (match_values_BA_BB - match_values_BA_AA)

                # PA VS PB
                # 计算bin值
                valid_cross_sim_AB_sp_mean = torch.mean(cross_sim_AB_sp[mask_pointA, :][match_maskAB == 1], dim=-1)
                valid_cross_sim_AB_sp_nb_mean = torch.mean(cross_sim_AB_sp[mask_pointA, :][match_maskAB_nb == 1], dim=-1)
                novalid_cross_sim_AB_sp_mean = (torch.sum(torch.sum(cross_sim_AB_sp.detach(), 1), 0) - valid_cross_sim_AB_sp_nb_mean * pairAB_A_nb_new.shape[0]) / (new_numA * new_numB - pairAB_A_nb_new.shape[0] + eps)
                valid_cross_sim_BA_sp_mean = torch.mean(cross_sim_AB_sp[:, mask_pointB][match_maskBA.transpose(0, 1) == 1], dim=-1)
                valid_cross_sim_BA_sp_nb_mean = torch.mean(cross_sim_AB_sp[:, mask_pointB][match_maskBA_nb.transpose(0, 1) == 1], dim=-1)
                novalid_cross_sim_BA_sp_mean = (torch.sum(torch.sum(cross_sim_AB_sp.detach(), 1), 0) - valid_cross_sim_BA_sp_nb_mean * pairBA_B_nb_new.shape[0]) / (new_numA * new_numB - pairBA_B_nb_new.shape[0] + eps)

                valid_indexesA = torch.tensor(list(range(cross_sim_AB_sp.shape[0])), device=self.device)[mask_pointA][pairAB_A_new]
                valid_indexesA_nb = torch.tensor(list(range(cross_sim_AB_sp.shape[0])), device=self.device)[mask_pointA][pairAB_A_nb_new]
                # cross_sim_BA_sp = current_descB @ current_descA.transpose(0, 1)
                cross_sim_AB_out_sp = torch.cat((cross_sim_AB_sp, torch.ones((cross_sim_AB_sp.shape[0], 3), device=cross_sim_AB_sp.device) * 2), dim=-1)      # NA X (NB + 2)
                cross_sim_AB_out_nb_sp = torch.cat((cross_sim_AB_sp, torch.ones((cross_sim_AB_sp.shape[0], 3), device=cross_sim_AB_sp.device) * 2), dim=-1)      # NA X (NB + 2)
                # cross_sim_BA_out_sp = torch.cat((cross_sim_BA_sp, torch.ones((numB, 1), device=cross_sim_BA_sp.device)), dim=-1)      # NB X (NA + 1)
                # valid_indexesB = torch.tensor(list(range(numB)), device=self.device)[mask_pointB][pairBA_B]
                # print('1_2')
                cross_sim_AB_out_sp[valid_indexesA, -1] = novalid_cross_sim_AB_sp_mean
                cross_sim_AB_out_sp[valid_indexesA, -2] = crossAN_mean
                cross_sim_AB_out_sp[valid_indexesA, -3] = crossAN2_mean
                cross_sim_AB_out_nb_sp[valid_indexesA_nb, -1] = novalid_cross_sim_AB_sp_mean
                novalid_indexesA = torch.tensor(list(range(cross_sim_AB_sp.shape[0])), device=self.device)[cross_sim_AB_out_nb_sp[:, -1]==2]
                cross_sim_AB_out_sp[novalid_indexesA, -1] = valid_cross_sim_AB_sp_mean
                # nomatch对不增加negtives的均值bin
                cross_sim_AB_out_sp[novalid_indexesA, -2] = -1 # crossAN_mean # -1
                cross_sim_AB_out_sp[novalid_indexesA, -3] = -1 # crossAN_mean # -1

                soft_cross_sim_AtoB_sp = F.softmax((cross_sim_AB_out_sp - 1) / t_des, dim=-1)
                # soft_cross_sim_BtoA = F.softmax((cross_sim_BA_out - 1) / t_des, dim=-1)
                # print('1_3')
                soft_valid_cross_sim_AB_sp = soft_cross_sim_AtoB_sp[mask_pointA, :-3][match_maskAB==1]
                # soft_valid_cross_sim_BA = soft_cross_sim_BtoA[mask_pointB, :-1][pairBA_B, pairBA_A]
                soft_novalid_cross_sim_AB_sp = soft_cross_sim_AtoB_sp[novalid_indexesA, -1]
                # soft_novalid_cross_sim_BA = soft_cross_sim_BtoA[cross_sim_BA_out[:, -1]==1, -1]
                log_soft_valid_cross_sim_AB_sp = -torch.log(soft_valid_cross_sim_AB_sp + eps) * (1 - dis_oriATB[match_maskAB==1] / self.ori_diff) * (1 - bin_distAB[mask_pointA, :][match_maskAB==1] / current_binA.shape[-1]) * (1 - key_disAB[match_maskAB==1].detach() / self.correspond)
                # log_soft_valid_cross_sim_BA = -torch.log(soft_valid_cross_sim_BA + eps)
                log_soft_novalid_cross_sim_AB_sp = -torch.log(soft_novalid_cross_sim_AB_sp + eps)
                # log_soft_novalid_cross_sim_BA = -torch.log(soft_novalid_cross_sim_BA + eps)
                dis_cross_sim_mean_sp = torch.sum(torch.cat((4*log_soft_valid_cross_sim_AB_sp, log_soft_novalid_cross_sim_AB_sp), dim=-1), dim=-1) / new_numA
                
                # PA VS PAB
                # match_mask_A = copy.deepcopy(mask_pointA)
                # match_mask_B = copy.deepcopy(mask_pointB)
                match_mask_A = torch.zeros(cross_sim_AB_sp.shape[0], device=self.device)
                match_mask_nb_A = torch.zeros(cross_sim_AB_sp.shape[0], device=self.device)
                valid_match_indexesA = torch.tensor(list(range(cross_sim_AB_sp.shape[0])), device=self.device)[mask_pointA][vmaskAH]
                valid_match_indexesA_nb = torch.tensor(list(range(cross_sim_AB_sp.shape[0])), device=self.device)[mask_pointA][vmaskAH_nb]
                match_mask_A[valid_match_indexesA] = 1
                match_mask_nb_A[valid_match_indexesA_nb] = 1

                match_mask_B = torch.zeros(cross_sim_AB_sp.shape[1], device=self.device)
                match_mask_nb_B = torch.zeros(cross_sim_AB_sp.shape[1], device=self.device)
                valid_match_indexesB = torch.tensor(list(range(cross_sim_AB_sp.shape[1])), device=self.device)[mask_pointB][vmaskBH]
                valid_match_indexesB_nb = torch.tensor(list(range(cross_sim_AB_sp.shape[1])), device=self.device)[mask_pointB][vmaskBH_nb]
                match_mask_B[valid_match_indexesB] = 1
                match_mask_nb_B[valid_match_indexesB_nb] = 1

                cross_sim_AB = current_descA @ desc_mapB[idx, :, :, :].view(-1, H * W)
                # cross_sim_AB = cross_sim_AB[mask_pointA, :]
                cross_sim_AB_all = F.grid_sample(cross_sim_AB.view(-1, H, W).unsqueeze(0),
                                                pntA_H_normalized[vmaskAH, :].detach().view(1, 1, -1, 2),
                                                mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NA x repeatNA
                valid_cross_sim_AB_mean = torch.trace(cross_sim_AB_all[match_mask_A==1, :]) / cross_sim_AB_all[match_mask_A==1, :].shape[0]
                # novalid_cross_sim_AB_mean = (torch.sum(torch.sum(cross_sim_AB.detach(), 1), 1) - valid_cross_sim_AB_mean * pairAB_A.shape[0]) / (new_numA * H * W - pairAB_A.shape[0])

                cross_sim_BA = current_descB @ desc_mapA[idx, :, :, :].view(-1, H * W)   # M x H x W
                # cross_sim_BA = cross_sim_BA[mask_pointB, :]
                cross_sim_BA_all = F.grid_sample(cross_sim_BA.view(-1, H, W).unsqueeze(0),
                                                pntB_invH_normalized[vmaskBH, :].detach().view(1, 1, -1, 2),
                                                mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NB x match_nB
                valid_cross_sim_BA_mean = torch.trace(cross_sim_BA_all[match_mask_B==1, :]) / cross_sim_BA_all[match_mask_B==1, :].shape[0]
                # novalid_cross_sim_BA_mean = (torch.sum(torch.sum(cross_sim_BA.detach(), 1), 1) - valid_cross_sim_BA_mean * pairBA_B.shape[0]) / (new_numB * H * W - pairBA_B.shape[0])

                cross_sim_AB_out = torch.cat((cross_sim_AB, torch.ones((cross_sim_AB.shape[0], 3), device=cross_sim_AB.device)), dim=-1)      # NA X (H X W + 2)
                cross_sim_BA_out = torch.cat((cross_sim_BA, torch.ones((cross_sim_BA.shape[0], 3), device=cross_sim_BA.device)), dim=-1)      # NB X (H X W + 2)
                # print(3)
                # cross_sim_AB_out[mask_pointA, -1] -= 1
                # cross_sim_BA_out[mask_pointB, -1] -= 1
                # cross_sim_AB_out[match_mask_A, -1] -= 1
                cross_sim_AB_out[match_mask_A==1, -1] = novalid_cross_sim_AB_sp_mean
                cross_sim_AB_out[match_mask_A==1, -2] = crossAN_mean
                cross_sim_AB_out[match_mask_A==1, -3] = crossAN2_mean
                cross_sim_AB_out[match_mask_nb_A==0, -1] = valid_cross_sim_AB_mean
                cross_sim_AB_out[match_mask_nb_A==0, -2] = -1 # crossAN_mean # -1
                cross_sim_AB_out[match_mask_nb_A==0, -3] = -1 # crossAN_mean # -1

                cross_sim_BA_out[match_mask_B==1, -1] = novalid_cross_sim_BA_sp_mean
                cross_sim_BA_out[match_mask_B==1, -2] = crossBN_mean
                cross_sim_BA_out[match_mask_B==1, -3] = crossBN2_mean
                cross_sim_BA_out[match_mask_nb_B==0, -1] = valid_cross_sim_BA_mean
                cross_sim_BA_out[match_mask_nb_B==0, -2] = -1 # crossBN_mean # -1
                cross_sim_BA_out[match_mask_nb_B==0, -3] = -1 # crossBN_mean # -1

                soft_cross_sim_AtoB = F.softmax((cross_sim_AB_out - 1) / t_des, dim=-1)         # NA X (H X W + 1)
                soft_cross_sim_BtoA = F.softmax((cross_sim_BA_out - 1) / t_des, dim=-1)         # NB X (H X W + 1)
                soft_cross_sim_AB_all = F.grid_sample(soft_cross_sim_AtoB[:, :-3].view(-1, H, W).unsqueeze(0),
                                                    pntA_H_normalized[vmaskAH, :].detach().view(1, 1, -1, 2),
                                                    mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NA x match_nA
                
                soft_cross_sim_BA_all = F.grid_sample(soft_cross_sim_BtoA[:, :-3].view(-1, H, W).unsqueeze(0),
                                                    pntB_invH_normalized[vmaskBH, :].detach().view(1, 1, -1, 2),
                                                    mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NB x match_nB
                # soft_valid_cross_sim_AB_all = soft_cross_sim_AB_all[mask_pointA, :]             # repeat_nA x repeat_nA
                # soft_valid_cross_sim_BA_all = soft_cross_sim_BA_all[mask_pointB, :]             # repeat_nB x repeat_nB

                soft_valid_cross_sim_AB_all = soft_cross_sim_AB_all[match_mask_A==1, :]             # match_nA x match_nA
                soft_valid_cross_sim_BA_all = soft_cross_sim_BA_all[match_mask_B==1, :]             # match_nB x match_nB

                valid_mask_AB = torch.eye(soft_valid_cross_sim_AB_all.shape[0]) == 1
                valid_mask_BA = torch.eye(soft_valid_cross_sim_BA_all.shape[0]) == 1
                # print(4)
                # 取对角线
                soft_valid_cross_sim_AB = soft_valid_cross_sim_AB_all[valid_mask_AB]
                soft_valid_cross_sim_BA = soft_valid_cross_sim_BA_all[valid_mask_BA]

                # soft_novalid_cross_sim_AB = soft_cross_sim_AtoB[mask_pointA==False, -1]              # (NA-repeat_nA) x 1
                # soft_novalid_cross_sim_BA = soft_cross_sim_BtoA[mask_pointB==False, -1]
                soft_novalid_cross_sim_AB = soft_cross_sim_AtoB[match_mask_nb_A==0, -1]               # (NA-match_nA) x 1
                soft_novalid_cross_sim_BA = soft_cross_sim_BtoA[match_mask_nb_B==0, -1]
                # print(soft_novalid_cross_sim_AB, soft_novalid_cross_sim_BA)

                log_soft_valid_cross_sim_AB = -torch.log(soft_valid_cross_sim_AB + eps) * (1 - torch.diag(dis_oriATAB)[vmaskAH] / self.ori_diff) * (1 - torch.diag(bin_distATAB[mask_pointA, :])[vmaskAH] / bin_kpAB_T.shape[0])
                log_soft_valid_cross_sim_BA = -torch.log(soft_valid_cross_sim_BA + eps) * (1 - torch.diag(dis_oriBTBA)[vmaskBH] / self.ori_diff) * (1 - torch.diag(bin_distBTBA[mask_pointB, :])[vmaskBH] / bin_kpBA_T.shape[0])
                log_soft_novalid_cross_sim_AB = -torch.log(soft_novalid_cross_sim_AB + eps)
                log_soft_novalid_cross_sim_BA = -torch.log(soft_novalid_cross_sim_BA + eps)

                dis_cross_sim_mean = torch.sum(torch.cat((4*log_soft_valid_cross_sim_AB, 4*log_soft_valid_cross_sim_BA, log_soft_novalid_cross_sim_AB, log_soft_novalid_cross_sim_BA), dim=-1), dim=-1) / (new_numA + new_numB)
                
                # print(5)
                valid_cross_sim_AB = cross_sim_AB[mask_pointA, :]   # repeat_nA x (H X W)
                valid_cross_sim_BA = cross_sim_BA[mask_pointB, :]   # repeat_nB x (H X W)
                exp_valid_cross_sim_AtoB = torch.exp((valid_cross_sim_AB - 1) / t_rel).view(-1, H, W)
                exp_valid_cross_sim_BtoA = torch.exp((valid_cross_sim_BA - 1) / t_rel).view(-1, H, W)
                exp_valid_cross_sim_AB_all = F.grid_sample(exp_valid_cross_sim_AtoB.unsqueeze(0),
                                                        pntA_H_normalized.detach().view(1, 1, -1, 2),
                                                        mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # repeat_nA x repeat_nA
                
                exp_valid_cross_sim_BA_all = F.grid_sample(exp_valid_cross_sim_BtoA.unsqueeze(0),
                                                        pntB_invH_normalized.detach().view(1, 1, -1, 2),
                                                        mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # repeat_nB x repeat_nB

                repeat_mask_AB = torch.eye(exp_valid_cross_sim_AB_all.shape[0]) == 1
                repeat_mask_BA = torch.eye(exp_valid_cross_sim_BA_all.shape[0]) == 1
                rel_valid_cross_sim_AB = exp_valid_cross_sim_AB_all[repeat_mask_AB]
                rel_valid_cross_sim_BA = exp_valid_cross_sim_BA_all[repeat_mask_BA]

                # pntA_H_normalized_new = copy.deepcopy(pntA_H_normalized.detach())
                # pntB_invH_normalized_new = copy.deepcopy(pntB_invH_normalized.detach())

                # pntA_H_normalized_new[:, 0] += 2
                # pntB_invH_normalized_new[:, 0] += 2

                scoresAB_all = F.grid_sample(scores_mapB[idx, :, :, :].unsqueeze(0),
                                            pntA_H_normalized_new.view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)      # 1 x repeat_nA

                scoresBA_all = F.grid_sample(scores_mapA[idx, :, :, :].unsqueeze(0),
                                            pntB_invH_normalized_new.view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)      # 1 x repeat_nB
                # print(6)
                scores_AAB = scoresA[idx][pmA][mask_pointA] * scoresAB_all
                scores_BBA = scoresB[idx][pmB][mask_pointB] * scoresBA_all
                scores_sum_AAB = torch.sum(scores_AAB, dim=-1)
                scores_sum_BBA = torch.sum(scores_BBA, dim=-1)
                scores_normalize_AAB = scores_AAB / (scores_sum_AAB + eps)
                scores_normalize_BBA = scores_BBA / (scores_sum_BBA + eps)
                rel_meanA = torch.sum(scores_normalize_AAB * (1 - rel_valid_cross_sim_AB), dim=-1) / pntA_H_normalized_new.shape[0]
                rel_meanB = torch.sum(scores_normalize_BBA * (1 - rel_valid_cross_sim_BA), dim=-1) / pntB_invH_normalized_new.shape[0]

                # # 熵loss
                # current_descA_std, current_descB_std = descA_std[countA:countA+new_numA], descB_std[countB:countB+new_numB]
                # desc_std += torch.mean(current_descA_std) + torch.mean(current_descB_std)
                # countA_T += numA_T
                # countB_T += numB_T

                # Sinkhorn KD loss
                SK_scores_KDA = log_optimal_transport(cross_sim_KDA_sp.unsqueeze(0), 3).squeeze(0)  
                SK_scores_KDB = log_optimal_transport(cross_sim_KDB_sp.unsqueeze(0), 3).squeeze(0)  

                dis_cross_sim_KD += (-(torch.trace(SK_scores_KDA) + torch.trace(SK_scores_KDB)) / (new_numA + new_numB))

                dis_neighbor_mean_total += torch.mean(torch.sum(neighbor_dis_AB, dim=1)) + torch.mean(torch.sum(neighbor_dis_BA, dim=1))
                dis_desc += dis_cross_sim_mean_sp
                dis_desc += dis_cross_sim_mean

                dis_pair_meanAB = torch.mean(key_manhattandisAB[pairAB_A, pairAB_B])
                dis_pair_meanBA = torch.mean(key_manhattandisBA[pairBA_B, pairBA_A])

                dis_peak_mean = torch.mean(torch.cat((scoreddisA[idx][pmA], scoreddisB[idx][pmB]), dim=0))
                # dis_peak_meanB = torch.mean(scoreddisB[idx])
                
                dis_mean_total += dis_pair_meanAB + dis_pair_meanBA
                dis_peak_scored += dis_peak_mean

                dis_rel += rel_meanA + rel_meanB
                
                countA += new_numA
                countB += new_numB
                count_ne += new_num_ne
                # # Penalty
                # scores_mean += (-torch.log(torch.mean(scoresA[idx], dim=-1) + eps) - torch.log(torch.mean(scoresB[idx], dim=-1) + eps)) 
                # print(scores_mean)
            except:
                # dis_mean_total += 0
                # dis_peak_scored += 0
                # dis_desc += 0
                # dis_rel += 0
                # print('Overlapping too small or Repeatable point pairs distance is greater than correspond(1.5):', pntA.shape[0], pntA_H.shape[0], pntB.shape[0], pntB_invH.shape[0], dis_pairAB.shape[0], dis_pairBA.shape[0])
                valid_batch_size -= 1
                countA += new_numA
                countB += new_numB
                count_ne += new_num_ne
                # countA_T += numA_T
                # countB_T += numB_T

        valid_batch_size = valid_batch_size if valid_batch_size > 0 else eps
        # Reprojection Loss 
        reprojection_loss = dis_mean_total / (valid_batch_size * 2)
        # Dispersity Peak Loss
        dispersity_peak_loss = dis_peak_scored / valid_batch_size
        # NRE Loss
        descriptor_loss = dis_desc / (2 * valid_batch_size)
        # Reliability Loss
        reliability_loss = dis_rel / (valid_batch_size * 2)
        # SOSR Loss
        sosr_loss = dis_neighbor_mean_total / ((valid_batch_size * 2))
        # # Entropy loss
        # std_loss = (valid_batch_size * 2) / desc_std  
        # # Score Penalty
        # score_penalty = scores_mean / (valid_batch_size * 2)
        # # FA Desc loss
        # FA_des_loss = dis_desc_fa / valid_batch_size_FA if valid_batch_size_FA > 0 else 0
        # KD_loss
        KD_loss = dis_cross_sim_KD / valid_batch_size

        loss_total = wrp * reprojection_loss + wpl * dispersity_peak_loss + wdl * descriptor_loss + wrl * reliability_loss + sosr_loss + KD_loss
        loss_group = {
            'reprojection_loss': reprojection_loss, 
            'dispersity_peak_loss': dispersity_peak_loss,
            'descriptor_loss': descriptor_loss,
            'reliability_loss': reliability_loss,
            'sosr_loss': sosr_loss,
            # 'std_loss': std_loss,
            # 'FA_des_loss': FA_des_loss,
            'KD_loss': KD_loss
            }
        return loss_total, loss_group

    # patch/dense AT角度 黑白相似度加量化 NFA two negtives DSKD(Dual-Softmax 知识蒸馏)
    def detector_selfsupervised_loss_dkd_patch_ext_restrict_modify_oriR_ratio_NFA_qtbw_ns_wg_nori_AT_NE2_DSKD(self, kpA, kpB, pmaskA, pmaskB, descA, descA_tea, descB, descB_tea, desc_mapA, desc_mapB, scoreddisA, scoreddisB, scoresA, scoresB, scores_mapA, scores_mapB, Homo, inv_Homo, inv_Homo_en, ori_all_patchA, ori_all_patchB, ori_kp_patchA, ori_kp_patchB, bin_allA, bin_allB, bin_kpA, bin_kpB, kp_ne, pmask_ne, desc_ne, bin_kp_ne, kp_ne2, pmask_ne2, desc_ne2, bin_kp_ne2, trans_angle, FA_flag, H, W, wrp=1, wpl=1, wdl=1, wrl=1, t_des=0.02, t_rel=1, t_kd=0.04):
        # pmaskA: (BxMax_num) 32x350=11200
        batch_size = len(kpA)
        max_num = pmaskA.shape[-1] // batch_size    # 350
        dis_mean_total = 0
        dis_neighbor_mean_total = 0
        dis_peak_scored = 0
        dis_desc = 0
        dis_rel = 0
        desc_std = 0
        dis_cross_sim_KD = 0
        eps = 1e-12
        valid_batch_size = batch_size
        # valid_batch_size_FA = 0
        countA, countB, count_ne, count_ne2 = 0, 0, 0, 0
        # dis_desc_fa = 0
        # countA_T, countB_T = 0, 0
        for idx in range(batch_size):
            pntA, pntB, pnt_ne, pnt_ne2 = kpA[idx], kpB[idx], kp_ne[idx], kp_ne2[idx]     # M X 2 (x,y)
            # kmask_TA, kmask_TB = kmask_T_allA[idx], kmask_T_allB[idx]
            pntA = pntA.float()
            pntB = pntB.float()
            pnt_ne = pnt_ne.float()
            pnt_ne2 = pnt_ne2.float()

            # 剔除部分按压区域的点,且保留在重叠区域的点
            numA, numB, num_ne, num_ne2 = pntA.shape[0], pntB.shape[0], pnt_ne.shape[0], pnt_ne2.shape[0]
            # numA_T, numB_T = pntA[kmask_TA].shape[0], pntB[kmask_TB].shape[0]
            pmA, pmB, pm_ne, pm_ne2 = pmaskA[max_num * idx:max_num * idx + numA].bool(), pmaskB[max_num * idx:max_num * idx + numB].bool(), pmask_ne[max_num * idx:max_num * idx + num_ne].bool(), pmask_ne2[max_num * idx:max_num * idx + num_ne2].bool()
            pntA, pntB, pnt_ne, pnt_ne2 = pntA[pmA, :], pntB[pmB, :], pnt_ne[pm_ne, :], pnt_ne2[pm_ne2, :] 
            new_numA, new_numB, new_num_ne, new_num_ne2 = pntA.shape[0], pntB.shape[0], pnt_ne.shape[0], pnt_ne2.shape[0]      
            
            pntA = (pntA + 1) / 2 * pntA.new_tensor([[W + 3, H - 1]]).to(pntA.device)
            pntB = (pntB + 1) / 2 * pntB.new_tensor([[W + 3, H - 1]]).to(pntB.device)

            # [120, 40] -> [120, 36],实际只取中心118x32区域的点对
            pntA[:, 0] -= 2
            pntB[:, 0] -= 2
            
            pntA_normalized = pntA / pntA.new_tensor([W - 1, H - 1]).to(pntA.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)
            pntB_normalized = pntB / pntB.new_tensor([W - 1, H - 1]).to(pntB.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)

            pntA_H = warp_points(pntA[:, :2], Homo[idx].squeeze(), device=self.device)  # 利用变换矩阵变换坐标点
            pntA_H, mask_pointA = filter_points(pntA_H, torch.tensor([W, H], device=self.device), return_mask=True)
            pntB_invH = warp_points(pntB[:, :2], inv_Homo[idx].squeeze(), device=self.device)
            pntB_invH, mask_pointB = filter_points(pntB_invH, torch.tensor([W, H], device=self.device), return_mask=True)
            
            current_descA, current_descB = descA[countA:countA+new_numA], descB[countB:countB+new_numB]
            current_descA_tea, current_descB_tea = descA_tea[countA:countA+new_numA], descB_tea[countB:countB+new_numB]
            current_desc_ne = desc_ne[count_ne:count_ne+new_num_ne]
            current_desc_ne2 = desc_ne2[count_ne2:count_ne2+new_num_ne2]
            cross_sim_AB_sp = current_descA @ current_descB.transpose(0, 1)     # NTA X NTB
            cross_sim_KDA_sp = current_descA @ current_descA_tea.transpose(0, 1)  # NTA x NTA
            cross_sim_KDB_sp = current_descB @ current_descB_tea.transpose(0, 1)  # NTB x NTB

            cross_sim_AN_sp = current_descA @ current_desc_ne.transpose(0, 1)
            cross_sim_BN_sp = current_descB @ current_desc_ne.transpose(0, 1)
            cross_sim_AN2_sp = current_descA @ current_desc_ne2.transpose(0, 1)
            cross_sim_BN2_sp = current_descB @ current_desc_ne2.transpose(0, 1)
            
            # 黑白相似度
            current_binA, current_binB = (bin_kpA[countA:countA+new_numA] >= 0.5).float(), (bin_kpB[countB:countB+new_numB] >= 0.5).float()   # [NA, 256] [NB_256]
            current_bin_ne = (bin_kp_ne[count_ne:count_ne+new_num_ne] >= 0.5).float()
            current_bin_ne2 = (bin_kp_ne2[count_ne2:count_ne2+new_num_ne2] >= 0.5).float()
            bin_distAB = current_binA.shape[-1] - (current_binA @ current_binB.transpose(0, 1)) - ((1 - current_binA) @ (1 - current_binB.transpose(0, 1))) # [NA, NB]
            
            bin_distAN = current_binA.shape[-1] - (current_binA @ current_bin_ne.transpose(0, 1)) - ((1 - current_binA) @ (1 - current_bin_ne.transpose(0, 1))) # [NA, NE]
            bin_distBN = current_binB.shape[-1] - (current_binB @ current_bin_ne.transpose(0, 1)) - ((1 - current_binB) @ (1 - current_bin_ne.transpose(0, 1))) # [NA, NE]
            bin_distAN2 = current_binA.shape[-1] - (current_binA @ current_bin_ne2.transpose(0, 1)) - ((1 - current_binA) @ (1 - current_bin_ne2.transpose(0, 1))) # [NA, NE]
            bin_distBN2 = current_binB.shape[-1] - (current_binB @ current_bin_ne2.transpose(0, 1)) - ((1 - current_binB) @ (1 - current_bin_ne2.transpose(0, 1))) # [NA, NE]
            
            # 真匹配的trans
            try:
                FAN_bin_mask = bin_distAN >= (1 - self.FA_bin_thr) * current_binA.shape[-1] 
                FBN_bin_mask = bin_distBN >= (1 - self.FA_bin_thr) * current_binB.shape[-1] 
                FAN2_bin_mask = bin_distAN2 >= (1 - self.FA_bin_thr) * current_binA.shape[-1] 
                FBN2_bin_mask = bin_distBN2 >= (1 - self.FA_bin_thr) * current_binB.shape[-1] 
                # topk ?
                crossAN_mean = torch.mean(cross_sim_AN_sp[FAN_bin_mask])
                crossBN_mean = torch.mean(cross_sim_BN_sp[FBN_bin_mask])
                crossAN2_mean = torch.mean(cross_sim_AN2_sp[FAN2_bin_mask])
                crossBN2_mean = torch.mean(cross_sim_BN2_sp[FBN2_bin_mask])

                assert pntA_H.shape[0] > 0 and pntB_invH.shape[0] > 0 
                
                # 点对欧氏距离
                key_disAB = self.get_dis(pntA_H[:, :2], pntB[:, :2])            # repeatNA x NB
                key_disBA = self.get_dis(pntB_invH[:, :2], pntA[:, :2])
                pairAB_A, pairAB_B, dis_pairAB, _ = self.get_point_pair(key_disAB, dis_thre=self.correspond)  # p -> k # NTA(<1.5), NTA(<1.5), NTA(<1.5), NTA        
                pairBA_B, pairBA_A, dis_pairBA, _  = self.get_point_pair(key_disBA, dis_thre=self.correspond)  # p -> k # NTB(<1.5), NTB(<1.5), NTB(<1.5), NTB 
                
                # 点距离mask
                nn_maskAB = torch.zeros((pntA_H.shape[0], pntB.shape[0]), device=self.device) 
                nn_maskAB[pairAB_A, pairAB_B] = 1

                nn_maskBA = torch.zeros((pntB_invH.shape[0], pntA.shape[0]), device=self.device) 
                nn_maskBA[pairBA_B, pairBA_A] = 1

                # 点对曼哈顿距离
                key_manhattandisAB = self.get_manhattan_dis(pntA_H[:, :2], pntB[:, :2])
                key_manhattandisBA = self.get_manhattan_dis(pntB_invH[:, :2], pntA[:, :2])
                # print('pdis:', dis_pairAB.shape[0], dis_pairBA.shape[0])
                assert dis_pairAB.shape[0] > 0 and dis_pairBA.shape[0] > 0     

                pntA_H_normalized = pntA_H / pntA_H.new_tensor([W - 1, H - 1]).to(pntA_H.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)
                pntB_invH_normalized = pntB_invH / pntB_invH.new_tensor([W - 1, H - 1]).to(pntB_invH.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)

                # 用于score_map
                pntA_H_new = copy.deepcopy(pntA_H.detach())
                pntB_invH_new = copy.deepcopy(pntB_invH.detach())
                pntA_H_new[:, 0] += 10                   # 120 x 36 -> 128 x 56
                pntA_H_new[:, 1] += 4 
                pntB_invH_new[:, 0] += 10
                pntB_invH_new[:, 1] += 4
                
                pntA_H_normalized_new = pntA_H_new / pntA_H_new.new_tensor([W + 19, H + 7]).to(pntA_H.device) * 2 - 1

                # pntB_invH_new = warp_points(pntB_invH_new[:, :2], inv_Homo_en[idx].squeeze(), device=self.device)       # 转到A上，而不是AT上
                
                pntB_invH_normalized_new = pntB_invH_new / pntB_invH_new.new_tensor([W + 19, H + 7]).to(pntB_invH.device) * 2 - 1 
                
                # print('1_2:', main_ori_maskATB.shape[0])
                # exit()
                ori_kpAT_patch_ext = F.grid_sample(ori_kp_patchA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntA_H_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0).transpose(0, 1)          # repeatNA x 1
                ori_kpB_patch_ext = F.grid_sample(ori_all_patchB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntB_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0).transpose(0, 1)          # NTB x 1
                ori_kpA_patch_ext = F.grid_sample(ori_all_patchA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntA_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0).transpose(0, 1)          # NTA x 1
                ori_kpBT_patch_ext = F.grid_sample(ori_kp_patchB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntB_invH_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0).transpose(0, 1)          # repeatNB x 1
                # print('1_2_1:', pntB_invH_normalized_new.shape[0])
                ori_maskATB, dis_oriATB = self.get_main_ori_consistence_AT(ori_kpAT_patch_ext, ori_kpB_patch_ext)  # repeatNA x NTB
                # print('1_2_2:', ori_maskATB.shape)
                ori_maskBTA, dis_oriBTA = self.get_main_ori_consistence_AT(ori_kpBT_patch_ext, ori_kpA_patch_ext)  # repeatNB x NTA

                match_maskAB_nb = (nn_maskAB == 1) * ori_maskATB           # repeatNA X NTB
                match_maskBA_nb = (nn_maskBA == 1) * ori_maskBTA          # repeatNB X NTA
                pairAB_A_nb_new, pairAB_B_nb_new = torch.where(match_maskAB_nb == 1)
                pairBA_B_nb_new, pairBA_A_nb_new = torch.where(match_maskBA_nb == 1)
                # assert pairAB_A_new.shape[0] > 0 and pairBA_B_new.shape[0] > 0 

                # 4x4邻域方向一致性
                ori_kpAB_patch_ext = F.grid_sample(ori_all_patchB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntA_H_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0).transpose(0, 1)  
                ori_kpBA_patch_ext = F.grid_sample(ori_all_patchA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntB_invH_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0).transpose(0, 1)  
                # print('1_2_4:', ori_kpAB_patch_ext.shape)
                ori_maskATAB, dis_oriATAB = self.get_main_ori_consistence_AT(ori_kpAT_patch_ext, ori_kpAB_patch_ext)  # repeatNA x repeatNA
                ori_maskBTBA, dis_oriBTBA = self.get_main_ori_consistence_AT(ori_kpBT_patch_ext, ori_kpBA_patch_ext)  # repeatNB x repeatNB
                
                # 黑白相似度
                bin_maskATB = bin_distAB <= (1 - self.FR_bin_thr) * current_binA.shape[-1]  
                bin_maskBTA = bin_maskATB.transpose(0, 1)  

                match_maskAB = match_maskAB_nb * bin_maskATB[mask_pointA, :]               # repeatNA X NB
                match_maskBA = match_maskBA_nb * bin_maskBTA[mask_pointB, :]               # repeatNB X NA

                pairAB_A_new, pairAB_B_new = torch.where(match_maskAB == 1)
                pairBA_B_new, pairBA_A_new = torch.where(match_maskBA == 1)
                # print('bin_mask:', pairAB_A_new.shape[0], pairBA_B_new.shape[0])
                assert pairAB_A_new.shape[0] > 0 and pairBA_B_new.shape[0] > 0 

                bin_kpAB_T = (F.grid_sample(bin_allB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntA_H_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0) >= 0.5).float()  # [256, repeatNA]
                bin_kpBA_T = (F.grid_sample(bin_allA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntB_invH_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0) >= 0.5).float()  # [256, repeatNB]
                bin_distATAB = bin_kpAB_T.shape[0] - (current_binA @ bin_kpAB_T) - ((1 - current_binA) @ (1 - bin_kpAB_T)) # [NTA, repeatNA]
                bin_distBTBA = bin_kpBA_T.shape[0] - (current_binB @ bin_kpBA_T) - ((1 - current_binB) @ (1 - bin_kpBA_T)) # [NTB, repeatNB]

                bin_maskATAB = bin_distATAB <= (1 - self.FR_bin_thr) * bin_kpAB_T.shape[0] 
                bin_maskBTBA = bin_distBTBA <= (1 - self.FR_bin_thr) * bin_kpBA_T.shape[0] 
                bin_maskATAB = bin_maskATAB[mask_pointA, :]
                bin_maskBTBA = bin_maskBTBA[mask_pointB, :]

                vmaskAH_nb = torch.diag(ori_maskATAB)
                vmaskBH_nb = torch.diag(ori_maskBTBA)
                vmaskAH = torch.diag(ori_maskATAB * bin_maskATAB) == 1      # [repeatNA, 1]
                vmaskBH = torch.diag(ori_maskBTBA * bin_maskBTBA) == 1      # [repeatNB, 1]

                # print('main_ori:', torch.sum(vmaskAH), torch.sum(vmaskBH))
                assert torch.sum(vmaskAH) > 0 and torch.sum(vmaskBH) > 0

                # SOSR: 简化的self-attention
                k_neighbor = 3
                cross_sim_AA_sp = current_descA @ current_descA.transpose(0, 1)
                cross_sim_BB_sp = current_descB @ current_descB.transpose(0, 1)
                # print('SOSR:', pairAB_A_new.shape[0], pairBA_B_new.shape[0])
                assert pairAB_A_new.shape[0] >= k_neighbor and pairBA_B_new.shape[0] >= k_neighbor 

                match_sim_AB_AA = cross_sim_AA_sp[mask_pointA, :][:, mask_pointA][pairAB_A_new, :][:, pairAB_A_new]
                match_sim_BA_BB = cross_sim_BB_sp[mask_pointB, :][:, mask_pointB][pairBA_B_new, :][:, pairBA_B_new]
                match_sim_AB_BB = cross_sim_BB_sp[pairAB_B_new, :][:, pairAB_B_new]
                match_sim_BA_AA = cross_sim_AA_sp[pairBA_A_new, :][:, pairBA_A_new]
                match_values_AB_AA, match_indices_AB_AA = torch.topk(match_sim_AB_AA, dim=1, k=k_neighbor, largest=False)
                match_values_BA_BB, match_indices_BA_BB = torch.topk(match_sim_BA_BB, dim=1, k=k_neighbor, largest=False)
                match_values_AB_BB_all = match_sim_AB_BB[:, match_indices_AB_AA]
                match_values_BA_AA_all = match_sim_BA_AA[:, match_indices_BA_BB]
                match_values_AB_BB = torch.diagonal(match_values_AB_BB_all, 0, dim1=0, dim2=1).transpose(0, 1)
                match_values_BA_AA = torch.diagonal(match_values_BA_AA_all, 0, dim1=0, dim2=1).transpose(0, 1)
                neighbor_dis_AB = (match_values_AB_AA - match_values_AB_BB) * (match_values_AB_AA - match_values_AB_BB)
                neighbor_dis_BA = (match_values_BA_BB - match_values_BA_AA) * (match_values_BA_BB - match_values_BA_AA)

                # PA VS PB
                # 计算bin值
                valid_cross_sim_AB_sp_mean = torch.mean(cross_sim_AB_sp[mask_pointA, :][match_maskAB == 1], dim=-1)
                valid_cross_sim_AB_sp_nb_mean = torch.mean(cross_sim_AB_sp[mask_pointA, :][match_maskAB_nb == 1], dim=-1)
                novalid_cross_sim_AB_sp_mean = (torch.sum(torch.sum(cross_sim_AB_sp.detach(), 1), 0) - valid_cross_sim_AB_sp_nb_mean * pairAB_A_nb_new.shape[0]) / (new_numA * new_numB - pairAB_A_nb_new.shape[0] + eps)
                valid_cross_sim_BA_sp_mean = torch.mean(cross_sim_AB_sp[:, mask_pointB][match_maskBA.transpose(0, 1) == 1], dim=-1)
                valid_cross_sim_BA_sp_nb_mean = torch.mean(cross_sim_AB_sp[:, mask_pointB][match_maskBA_nb.transpose(0, 1) == 1], dim=-1)
                novalid_cross_sim_BA_sp_mean = (torch.sum(torch.sum(cross_sim_AB_sp.detach(), 1), 0) - valid_cross_sim_BA_sp_nb_mean * pairBA_B_nb_new.shape[0]) / (new_numA * new_numB - pairBA_B_nb_new.shape[0] + eps)

                valid_indexesA = torch.tensor(list(range(cross_sim_AB_sp.shape[0])), device=self.device)[mask_pointA][pairAB_A_new]
                valid_indexesA_nb = torch.tensor(list(range(cross_sim_AB_sp.shape[0])), device=self.device)[mask_pointA][pairAB_A_nb_new]
                # cross_sim_BA_sp = current_descB @ current_descA.transpose(0, 1)
                cross_sim_AB_out_sp = torch.cat((cross_sim_AB_sp, torch.ones((cross_sim_AB_sp.shape[0], 3), device=cross_sim_AB_sp.device) * 2), dim=-1)      # NA X (NB + 2)
                cross_sim_AB_out_nb_sp = torch.cat((cross_sim_AB_sp, torch.ones((cross_sim_AB_sp.shape[0], 3), device=cross_sim_AB_sp.device) * 2), dim=-1)      # NA X (NB + 2)
                # cross_sim_BA_out_sp = torch.cat((cross_sim_BA_sp, torch.ones((numB, 1), device=cross_sim_BA_sp.device)), dim=-1)      # NB X (NA + 1)
                # valid_indexesB = torch.tensor(list(range(numB)), device=self.device)[mask_pointB][pairBA_B]
                # print('1_2')
                cross_sim_AB_out_sp[valid_indexesA, -1] = novalid_cross_sim_AB_sp_mean
                cross_sim_AB_out_sp[valid_indexesA, -2] = crossAN_mean
                cross_sim_AB_out_sp[valid_indexesA, -3] = crossAN2_mean
                cross_sim_AB_out_nb_sp[valid_indexesA_nb, -1] = novalid_cross_sim_AB_sp_mean
                novalid_indexesA = torch.tensor(list(range(cross_sim_AB_sp.shape[0])), device=self.device)[cross_sim_AB_out_nb_sp[:, -1]==2]
                cross_sim_AB_out_sp[novalid_indexesA, -1] = valid_cross_sim_AB_sp_mean
                # nomatch对不增加negtives的均值bin
                cross_sim_AB_out_sp[novalid_indexesA, -2] = -1 # crossAN_mean # -1
                cross_sim_AB_out_sp[novalid_indexesA, -3] = -1 # crossAN_mean # -1

                soft_cross_sim_AtoB_sp = F.softmax((cross_sim_AB_out_sp - 1) / t_des, dim=-1)
                # soft_cross_sim_BtoA = F.softmax((cross_sim_BA_out - 1) / t_des, dim=-1)
                # print('1_3')
                soft_valid_cross_sim_AB_sp = soft_cross_sim_AtoB_sp[mask_pointA, :-3][match_maskAB==1]
                # soft_valid_cross_sim_BA = soft_cross_sim_BtoA[mask_pointB, :-1][pairBA_B, pairBA_A]
                soft_novalid_cross_sim_AB_sp = soft_cross_sim_AtoB_sp[novalid_indexesA, -1]
                # soft_novalid_cross_sim_BA = soft_cross_sim_BtoA[cross_sim_BA_out[:, -1]==1, -1]
                log_soft_valid_cross_sim_AB_sp = -torch.log(soft_valid_cross_sim_AB_sp + eps) * (1 - dis_oriATB[match_maskAB==1] / self.ori_diff) * (1 - bin_distAB[mask_pointA, :][match_maskAB==1] / current_binA.shape[-1]) * (1 - key_disAB[match_maskAB==1].detach() / self.correspond)
                # log_soft_valid_cross_sim_BA = -torch.log(soft_valid_cross_sim_BA + eps)
                log_soft_novalid_cross_sim_AB_sp = -torch.log(soft_novalid_cross_sim_AB_sp + eps)
                # log_soft_novalid_cross_sim_BA = -torch.log(soft_novalid_cross_sim_BA + eps)
                dis_cross_sim_mean_sp = torch.sum(torch.cat((4*log_soft_valid_cross_sim_AB_sp, log_soft_novalid_cross_sim_AB_sp), dim=-1), dim=-1) / new_numA
                
                # PA VS PAB
                # match_mask_A = copy.deepcopy(mask_pointA)
                # match_mask_B = copy.deepcopy(mask_pointB)
                match_mask_A = torch.zeros(cross_sim_AB_sp.shape[0], device=self.device)
                match_mask_nb_A = torch.zeros(cross_sim_AB_sp.shape[0], device=self.device)
                valid_match_indexesA = torch.tensor(list(range(cross_sim_AB_sp.shape[0])), device=self.device)[mask_pointA][vmaskAH]
                valid_match_indexesA_nb = torch.tensor(list(range(cross_sim_AB_sp.shape[0])), device=self.device)[mask_pointA][vmaskAH_nb]
                match_mask_A[valid_match_indexesA] = 1
                match_mask_nb_A[valid_match_indexesA_nb] = 1

                match_mask_B = torch.zeros(cross_sim_AB_sp.shape[1], device=self.device)
                match_mask_nb_B = torch.zeros(cross_sim_AB_sp.shape[1], device=self.device)
                valid_match_indexesB = torch.tensor(list(range(cross_sim_AB_sp.shape[1])), device=self.device)[mask_pointB][vmaskBH]
                valid_match_indexesB_nb = torch.tensor(list(range(cross_sim_AB_sp.shape[1])), device=self.device)[mask_pointB][vmaskBH_nb]
                match_mask_B[valid_match_indexesB] = 1
                match_mask_nb_B[valid_match_indexesB_nb] = 1

                cross_sim_AB = current_descA @ desc_mapB[idx, :, :, :].view(-1, H * W)
                # cross_sim_AB = cross_sim_AB[mask_pointA, :]
                cross_sim_AB_all = F.grid_sample(cross_sim_AB.view(-1, H, W).unsqueeze(0),
                                                pntA_H_normalized[vmaskAH, :].detach().view(1, 1, -1, 2),
                                                mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NA x repeatNA
                valid_cross_sim_AB_mean = torch.trace(cross_sim_AB_all[match_mask_A==1, :]) / cross_sim_AB_all[match_mask_A==1, :].shape[0]
                # novalid_cross_sim_AB_mean = (torch.sum(torch.sum(cross_sim_AB.detach(), 1), 1) - valid_cross_sim_AB_mean * pairAB_A.shape[0]) / (new_numA * H * W - pairAB_A.shape[0])

                cross_sim_BA = current_descB @ desc_mapA[idx, :, :, :].view(-1, H * W)   # M x H x W
                # cross_sim_BA = cross_sim_BA[mask_pointB, :]
                cross_sim_BA_all = F.grid_sample(cross_sim_BA.view(-1, H, W).unsqueeze(0),
                                                pntB_invH_normalized[vmaskBH, :].detach().view(1, 1, -1, 2),
                                                mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NB x match_nB
                valid_cross_sim_BA_mean = torch.trace(cross_sim_BA_all[match_mask_B==1, :]) / cross_sim_BA_all[match_mask_B==1, :].shape[0]
                # novalid_cross_sim_BA_mean = (torch.sum(torch.sum(cross_sim_BA.detach(), 1), 1) - valid_cross_sim_BA_mean * pairBA_B.shape[0]) / (new_numB * H * W - pairBA_B.shape[0])

                cross_sim_AB_out = torch.cat((cross_sim_AB, torch.ones((cross_sim_AB.shape[0], 3), device=cross_sim_AB.device)), dim=-1)      # NA X (H X W + 2)
                cross_sim_BA_out = torch.cat((cross_sim_BA, torch.ones((cross_sim_BA.shape[0], 3), device=cross_sim_BA.device)), dim=-1)      # NB X (H X W + 2)
                # print(3)
                # cross_sim_AB_out[mask_pointA, -1] -= 1
                # cross_sim_BA_out[mask_pointB, -1] -= 1
                # cross_sim_AB_out[match_mask_A, -1] -= 1
                cross_sim_AB_out[match_mask_A==1, -1] = novalid_cross_sim_AB_sp_mean
                cross_sim_AB_out[match_mask_A==1, -2] = crossAN_mean
                cross_sim_AB_out[match_mask_A==1, -3] = crossAN2_mean
                cross_sim_AB_out[match_mask_nb_A==0, -1] = valid_cross_sim_AB_mean
                cross_sim_AB_out[match_mask_nb_A==0, -2] = -1 # crossAN_mean # -1
                cross_sim_AB_out[match_mask_nb_A==0, -3] = -1 # crossAN_mean # -1

                cross_sim_BA_out[match_mask_B==1, -1] = novalid_cross_sim_BA_sp_mean
                cross_sim_BA_out[match_mask_B==1, -2] = crossBN_mean
                cross_sim_BA_out[match_mask_B==1, -3] = crossBN2_mean
                cross_sim_BA_out[match_mask_nb_B==0, -1] = valid_cross_sim_BA_mean
                cross_sim_BA_out[match_mask_nb_B==0, -2] = -1 # crossBN_mean # -1
                cross_sim_BA_out[match_mask_nb_B==0, -3] = -1 # crossBN_mean # -1

                soft_cross_sim_AtoB = F.softmax((cross_sim_AB_out - 1) / t_des, dim=-1)         # NA X (H X W + 1)
                soft_cross_sim_BtoA = F.softmax((cross_sim_BA_out - 1) / t_des, dim=-1)         # NB X (H X W + 1)
                soft_cross_sim_AB_all = F.grid_sample(soft_cross_sim_AtoB[:, :-3].view(-1, H, W).unsqueeze(0),
                                                    pntA_H_normalized[vmaskAH, :].detach().view(1, 1, -1, 2),
                                                    mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NA x match_nA
                
                soft_cross_sim_BA_all = F.grid_sample(soft_cross_sim_BtoA[:, :-3].view(-1, H, W).unsqueeze(0),
                                                    pntB_invH_normalized[vmaskBH, :].detach().view(1, 1, -1, 2),
                                                    mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NB x match_nB
                # soft_valid_cross_sim_AB_all = soft_cross_sim_AB_all[mask_pointA, :]             # repeat_nA x repeat_nA
                # soft_valid_cross_sim_BA_all = soft_cross_sim_BA_all[mask_pointB, :]             # repeat_nB x repeat_nB

                soft_valid_cross_sim_AB_all = soft_cross_sim_AB_all[match_mask_A==1, :]             # match_nA x match_nA
                soft_valid_cross_sim_BA_all = soft_cross_sim_BA_all[match_mask_B==1, :]             # match_nB x match_nB

                valid_mask_AB = torch.eye(soft_valid_cross_sim_AB_all.shape[0]) == 1
                valid_mask_BA = torch.eye(soft_valid_cross_sim_BA_all.shape[0]) == 1
                # print(4)
                # 取对角线
                soft_valid_cross_sim_AB = soft_valid_cross_sim_AB_all[valid_mask_AB]
                soft_valid_cross_sim_BA = soft_valid_cross_sim_BA_all[valid_mask_BA]

                # soft_novalid_cross_sim_AB = soft_cross_sim_AtoB[mask_pointA==False, -1]              # (NA-repeat_nA) x 1
                # soft_novalid_cross_sim_BA = soft_cross_sim_BtoA[mask_pointB==False, -1]
                soft_novalid_cross_sim_AB = soft_cross_sim_AtoB[match_mask_nb_A==0, -1]               # (NA-match_nA) x 1
                soft_novalid_cross_sim_BA = soft_cross_sim_BtoA[match_mask_nb_B==0, -1]
                # print(soft_novalid_cross_sim_AB, soft_novalid_cross_sim_BA)

                log_soft_valid_cross_sim_AB = -torch.log(soft_valid_cross_sim_AB + eps) * (1 - torch.diag(dis_oriATAB)[vmaskAH] / self.ori_diff) * (1 - torch.diag(bin_distATAB[mask_pointA, :])[vmaskAH] / bin_kpAB_T.shape[0])
                log_soft_valid_cross_sim_BA = -torch.log(soft_valid_cross_sim_BA + eps) * (1 - torch.diag(dis_oriBTBA)[vmaskBH] / self.ori_diff) * (1 - torch.diag(bin_distBTBA[mask_pointB, :])[vmaskBH] / bin_kpBA_T.shape[0])
                log_soft_novalid_cross_sim_AB = -torch.log(soft_novalid_cross_sim_AB + eps)
                log_soft_novalid_cross_sim_BA = -torch.log(soft_novalid_cross_sim_BA + eps)

                dis_cross_sim_mean = torch.sum(torch.cat((4*log_soft_valid_cross_sim_AB, 4*log_soft_valid_cross_sim_BA, log_soft_novalid_cross_sim_AB, log_soft_novalid_cross_sim_BA), dim=-1), dim=-1) / (new_numA + new_numB)
                
                # print(5)
                valid_cross_sim_AB = cross_sim_AB[mask_pointA, :]   # repeat_nA x (H X W)
                valid_cross_sim_BA = cross_sim_BA[mask_pointB, :]   # repeat_nB x (H X W)
                exp_valid_cross_sim_AtoB = torch.exp((valid_cross_sim_AB - 1) / t_rel).view(-1, H, W)
                exp_valid_cross_sim_BtoA = torch.exp((valid_cross_sim_BA - 1) / t_rel).view(-1, H, W)
                exp_valid_cross_sim_AB_all = F.grid_sample(exp_valid_cross_sim_AtoB.unsqueeze(0),
                                                        pntA_H_normalized.detach().view(1, 1, -1, 2),
                                                        mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # repeat_nA x repeat_nA
                
                exp_valid_cross_sim_BA_all = F.grid_sample(exp_valid_cross_sim_BtoA.unsqueeze(0),
                                                        pntB_invH_normalized.detach().view(1, 1, -1, 2),
                                                        mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # repeat_nB x repeat_nB

                repeat_mask_AB = torch.eye(exp_valid_cross_sim_AB_all.shape[0]) == 1
                repeat_mask_BA = torch.eye(exp_valid_cross_sim_BA_all.shape[0]) == 1
                rel_valid_cross_sim_AB = exp_valid_cross_sim_AB_all[repeat_mask_AB]
                rel_valid_cross_sim_BA = exp_valid_cross_sim_BA_all[repeat_mask_BA]

                # pntA_H_normalized_new = copy.deepcopy(pntA_H_normalized.detach())
                # pntB_invH_normalized_new = copy.deepcopy(pntB_invH_normalized.detach())

                # pntA_H_normalized_new[:, 0] += 2
                # pntB_invH_normalized_new[:, 0] += 2

                scoresAB_all = F.grid_sample(scores_mapB[idx, :, :, :].unsqueeze(0),
                                            pntA_H_normalized_new.view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)      # 1 x repeat_nA

                scoresBA_all = F.grid_sample(scores_mapA[idx, :, :, :].unsqueeze(0),
                                            pntB_invH_normalized_new.view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)      # 1 x repeat_nB
                # print(6)
                scores_AAB = scoresA[idx][pmA][mask_pointA] * scoresAB_all
                scores_BBA = scoresB[idx][pmB][mask_pointB] * scoresBA_all
                scores_sum_AAB = torch.sum(scores_AAB, dim=-1)
                scores_sum_BBA = torch.sum(scores_BBA, dim=-1)
                scores_normalize_AAB = scores_AAB / (scores_sum_AAB + eps)
                scores_normalize_BBA = scores_BBA / (scores_sum_BBA + eps)
                rel_meanA = torch.sum(scores_normalize_AAB * (1 - rel_valid_cross_sim_AB), dim=-1) / pntA_H_normalized_new.shape[0]
                rel_meanB = torch.sum(scores_normalize_BBA * (1 - rel_valid_cross_sim_BA), dim=-1) / pntB_invH_normalized_new.shape[0]

                # # 熵loss
                # current_descA_std, current_descB_std = descA_std[countA:countA+new_numA], descB_std[countB:countB+new_numB]
                # desc_std += torch.mean(current_descA_std) + torch.mean(current_descB_std)
                # countA_T += numA_T
                # countB_T += numB_T

                # Dual-Softmax
                DS_scores_KDA = dual_softmax(cross_sim_KDA_sp.unsqueeze(0)).squeeze(0)
                DS_scores_KDB = dual_softmax(cross_sim_KDB_sp.unsqueeze(0)).squeeze(0)
                dis_cross_sim_KD += -(torch.trace(DS_scores_KDA) + torch.trace(DS_scores_KDB)) / (new_numA + new_numB)

                dis_neighbor_mean_total += torch.mean(torch.sum(neighbor_dis_AB, dim=1)) + torch.mean(torch.sum(neighbor_dis_BA, dim=1))
                dis_desc += dis_cross_sim_mean_sp
                dis_desc += dis_cross_sim_mean

                dis_pair_meanAB = torch.mean(key_manhattandisAB[pairAB_A, pairAB_B])
                dis_pair_meanBA = torch.mean(key_manhattandisBA[pairBA_B, pairBA_A])

                dis_peak_mean = torch.mean(torch.cat((scoreddisA[idx][pmA], scoreddisB[idx][pmB]), dim=0))
                # dis_peak_meanB = torch.mean(scoreddisB[idx])
                
                dis_mean_total += dis_pair_meanAB + dis_pair_meanBA
                dis_peak_scored += dis_peak_mean

                dis_rel += rel_meanA + rel_meanB
                
                countA += new_numA
                countB += new_numB
                count_ne += new_num_ne
                # # Penalty
                # scores_mean += (-torch.log(torch.mean(scoresA[idx], dim=-1) + eps) - torch.log(torch.mean(scoresB[idx], dim=-1) + eps)) 
                # print(scores_mean)
            except:
                # dis_mean_total += 0
                # dis_peak_scored += 0
                # dis_desc += 0
                # dis_rel += 0
                # print('Overlapping too small or Repeatable point pairs distance is greater than correspond(1.5):', pntA.shape[0], pntA_H.shape[0], pntB.shape[0], pntB_invH.shape[0], dis_pairAB.shape[0], dis_pairBA.shape[0])
                valid_batch_size -= 1
                countA += new_numA
                countB += new_numB
                count_ne += new_num_ne
                # countA_T += numA_T
                # countB_T += numB_T

        valid_batch_size = valid_batch_size if valid_batch_size > 0 else eps
        # Reprojection Loss 
        reprojection_loss = dis_mean_total / (valid_batch_size * 2)
        # Dispersity Peak Loss
        dispersity_peak_loss = dis_peak_scored / valid_batch_size
        # NRE Loss
        descriptor_loss = dis_desc / (2 * valid_batch_size)
        # Reliability Loss
        reliability_loss = dis_rel / (valid_batch_size * 2)
        # SOSR Loss
        sosr_loss = dis_neighbor_mean_total / ((valid_batch_size * 2))
        # # Entropy loss
        # std_loss = (valid_batch_size * 2) / desc_std  
        # # Score Penalty
        # score_penalty = scores_mean / (valid_batch_size * 2)
        # # FA Desc loss
        # FA_des_loss = dis_desc_fa / valid_batch_size_FA if valid_batch_size_FA > 0 else 0
        # KD_loss
        KD_loss = dis_cross_sim_KD / valid_batch_size

        loss_total = wrp * reprojection_loss + wpl * dispersity_peak_loss + wdl * descriptor_loss + wrl * reliability_loss + sosr_loss + KD_loss
        loss_group = {
            'reprojection_loss': reprojection_loss, 
            'dispersity_peak_loss': dispersity_peak_loss,
            'descriptor_loss': descriptor_loss,
            'reliability_loss': reliability_loss,
            'sosr_loss': sosr_loss,
            # 'std_loss': std_loss,
            # 'FA_des_loss': FA_des_loss,
            'KD_loss': KD_loss
            }
        return loss_total, loss_group

    # patch/dense AT角度 黑白相似度加量化 NFA two negtives SKKD(Sinkhorn 知识蒸馏) FGD(Focal & Global KD loss)
    def detector_selfsupervised_loss_dkd_patch_ext_restrict_modify_oriR_ratio_NFA_qtbw_ns_wg_nori_AT_NE2_SKKD_FGD(self, kpA, kpB, pmaskA, pmaskB, descA, descA_tea, fea_lossA, descB, descB_tea, fea_lossB, desc_mapA, desc_mapB, scoreddisA, scoreddisB, scoresA, scoresB, scores_mapA, scores_mapB, Homo, inv_Homo, inv_Homo_en, ori_all_patchA, ori_all_patchB, ori_kp_patchA, ori_kp_patchB, bin_allA, bin_allB, bin_kpA, bin_kpB, kp_ne, pmask_ne, desc_ne, bin_kp_ne, kp_ne2, pmask_ne2, desc_ne2, bin_kp_ne2, trans_angle, FA_flag, H, W, wrp=1, wpl=1, wdl=1, wrl=1, t_des=0.02, t_rel=1, t_kd=0.04):
        # pmaskA: (BxMax_num) 32x350=11200
        batch_size = len(kpA)
        max_num = pmaskA.shape[-1] // batch_size    # 350
        dis_mean_total = 0
        dis_neighbor_mean_total = 0
        dis_peak_scored = 0
        dis_desc = 0
        dis_rel = 0
        desc_std = 0
        dis_cross_sim_KD = 0
        eps = 1e-12
        valid_batch_size = batch_size
        # valid_batch_size_FA = 0
        countA, countB, count_ne, count_ne2 = 0, 0, 0, 0
        # dis_desc_fa = 0
        # countA_T, countB_T = 0, 0
        for idx in range(batch_size):
            pntA, pntB, pnt_ne, pnt_ne2 = kpA[idx], kpB[idx], kp_ne[idx], kp_ne2[idx]     # M X 2 (x,y)
            # kmask_TA, kmask_TB = kmask_T_allA[idx], kmask_T_allB[idx]
            pntA = pntA.float()
            pntB = pntB.float()
            pnt_ne = pnt_ne.float()
            pnt_ne2 = pnt_ne2.float()

            # 剔除部分按压区域的点,且保留在重叠区域的点
            numA, numB, num_ne, num_ne2 = pntA.shape[0], pntB.shape[0], pnt_ne.shape[0], pnt_ne2.shape[0]
            # numA_T, numB_T = pntA[kmask_TA].shape[0], pntB[kmask_TB].shape[0]
            pmA, pmB, pm_ne, pm_ne2 = pmaskA[max_num * idx:max_num * idx + numA].bool(), pmaskB[max_num * idx:max_num * idx + numB].bool(), pmask_ne[max_num * idx:max_num * idx + num_ne].bool(), pmask_ne2[max_num * idx:max_num * idx + num_ne2].bool()
            pntA, pntB, pnt_ne, pnt_ne2 = pntA[pmA, :], pntB[pmB, :], pnt_ne[pm_ne, :], pnt_ne2[pm_ne2, :] 
            new_numA, new_numB, new_num_ne, new_num_ne2 = pntA.shape[0], pntB.shape[0], pnt_ne.shape[0], pnt_ne2.shape[0]      
            
            pntA = (pntA + 1) / 2 * pntA.new_tensor([[W + 3, H - 1]]).to(pntA.device)
            pntB = (pntB + 1) / 2 * pntB.new_tensor([[W + 3, H - 1]]).to(pntB.device)

            # [120, 40] -> [120, 36],实际只取中心118x32区域的点对
            pntA[:, 0] -= 2
            pntB[:, 0] -= 2
            
            pntA_normalized = pntA / pntA.new_tensor([W - 1, H - 1]).to(pntA.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)
            pntB_normalized = pntB / pntB.new_tensor([W - 1, H - 1]).to(pntB.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)

            pntA_H = warp_points(pntA[:, :2], Homo[idx].squeeze(), device=self.device)  # 利用变换矩阵变换坐标点
            pntA_H, mask_pointA = filter_points(pntA_H, torch.tensor([W, H], device=self.device), return_mask=True)
            pntB_invH = warp_points(pntB[:, :2], inv_Homo[idx].squeeze(), device=self.device)
            pntB_invH, mask_pointB = filter_points(pntB_invH, torch.tensor([W, H], device=self.device), return_mask=True)
            
            current_descA, current_descB = descA[countA:countA+new_numA], descB[countB:countB+new_numB]
            current_descA_tea, current_descB_tea = descA_tea[countA:countA+new_numA], descB_tea[countB:countB+new_numB]
            current_desc_ne = desc_ne[count_ne:count_ne+new_num_ne]
            current_desc_ne2 = desc_ne2[count_ne2:count_ne2+new_num_ne2]
            cross_sim_AB_sp = current_descA @ current_descB.transpose(0, 1)     # NTA X NTB
            cross_sim_KDA_sp = current_descA @ current_descA_tea.transpose(0, 1)  # NTA x NTA
            cross_sim_KDB_sp = current_descB @ current_descB_tea.transpose(0, 1)  # NTB x NTB

            cross_sim_AN_sp = current_descA @ current_desc_ne.transpose(0, 1)
            cross_sim_BN_sp = current_descB @ current_desc_ne.transpose(0, 1)
            cross_sim_AN2_sp = current_descA @ current_desc_ne2.transpose(0, 1)
            cross_sim_BN2_sp = current_descB @ current_desc_ne2.transpose(0, 1)
            
            # 黑白相似度
            current_binA, current_binB = (bin_kpA[countA:countA+new_numA] >= 0.5).float(), (bin_kpB[countB:countB+new_numB] >= 0.5).float()   # [NA, 256] [NB_256]
            current_bin_ne = (bin_kp_ne[count_ne:count_ne+new_num_ne] >= 0.5).float()
            current_bin_ne2 = (bin_kp_ne2[count_ne2:count_ne2+new_num_ne2] >= 0.5).float()
            bin_distAB = current_binA.shape[-1] - (current_binA @ current_binB.transpose(0, 1)) - ((1 - current_binA) @ (1 - current_binB.transpose(0, 1))) # [NA, NB]
            
            bin_distAN = current_binA.shape[-1] - (current_binA @ current_bin_ne.transpose(0, 1)) - ((1 - current_binA) @ (1 - current_bin_ne.transpose(0, 1))) # [NA, NE]
            bin_distBN = current_binB.shape[-1] - (current_binB @ current_bin_ne.transpose(0, 1)) - ((1 - current_binB) @ (1 - current_bin_ne.transpose(0, 1))) # [NA, NE]
            bin_distAN2 = current_binA.shape[-1] - (current_binA @ current_bin_ne2.transpose(0, 1)) - ((1 - current_binA) @ (1 - current_bin_ne2.transpose(0, 1))) # [NA, NE]
            bin_distBN2 = current_binB.shape[-1] - (current_binB @ current_bin_ne2.transpose(0, 1)) - ((1 - current_binB) @ (1 - current_bin_ne2.transpose(0, 1))) # [NA, NE]
            
            # 真匹配的trans
            try:
                FAN_bin_mask = bin_distAN >= (1 - self.FA_bin_thr) * current_binA.shape[-1] 
                FBN_bin_mask = bin_distBN >= (1 - self.FA_bin_thr) * current_binB.shape[-1] 
                FAN2_bin_mask = bin_distAN2 >= (1 - self.FA_bin_thr) * current_binA.shape[-1] 
                FBN2_bin_mask = bin_distBN2 >= (1 - self.FA_bin_thr) * current_binB.shape[-1] 
                # topk ?
                crossAN_mean = torch.mean(cross_sim_AN_sp[FAN_bin_mask])
                crossBN_mean = torch.mean(cross_sim_BN_sp[FBN_bin_mask])
                crossAN2_mean = torch.mean(cross_sim_AN2_sp[FAN2_bin_mask])
                crossBN2_mean = torch.mean(cross_sim_BN2_sp[FBN2_bin_mask])

                assert pntA_H.shape[0] > 0 and pntB_invH.shape[0] > 0 
                
                # 点对欧氏距离
                key_disAB = self.get_dis(pntA_H[:, :2], pntB[:, :2])            # repeatNA x NB
                key_disBA = self.get_dis(pntB_invH[:, :2], pntA[:, :2])
                pairAB_A, pairAB_B, dis_pairAB, _ = self.get_point_pair(key_disAB, dis_thre=self.correspond)  # p -> k # NTA(<1.5), NTA(<1.5), NTA(<1.5), NTA        
                pairBA_B, pairBA_A, dis_pairBA, _  = self.get_point_pair(key_disBA, dis_thre=self.correspond)  # p -> k # NTB(<1.5), NTB(<1.5), NTB(<1.5), NTB 
                
                # 点距离mask
                nn_maskAB = torch.zeros((pntA_H.shape[0], pntB.shape[0]), device=self.device) 
                nn_maskAB[pairAB_A, pairAB_B] = 1

                nn_maskBA = torch.zeros((pntB_invH.shape[0], pntA.shape[0]), device=self.device) 
                nn_maskBA[pairBA_B, pairBA_A] = 1

                # 点对曼哈顿距离
                key_manhattandisAB = self.get_manhattan_dis(pntA_H[:, :2], pntB[:, :2])
                key_manhattandisBA = self.get_manhattan_dis(pntB_invH[:, :2], pntA[:, :2])
                # print('pdis:', dis_pairAB.shape[0], dis_pairBA.shape[0])
                assert dis_pairAB.shape[0] > 0 and dis_pairBA.shape[0] > 0     

                pntA_H_normalized = pntA_H / pntA_H.new_tensor([W - 1, H - 1]).to(pntA_H.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)
                pntB_invH_normalized = pntB_invH / pntB_invH.new_tensor([W - 1, H - 1]).to(pntB_invH.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)

                # 用于score_map
                pntA_H_new = copy.deepcopy(pntA_H.detach())
                pntB_invH_new = copy.deepcopy(pntB_invH.detach())
                pntA_H_new[:, 0] += 10                   # 120 x 36 -> 128 x 56
                pntA_H_new[:, 1] += 4 
                pntB_invH_new[:, 0] += 10
                pntB_invH_new[:, 1] += 4
                
                pntA_H_normalized_new = pntA_H_new / pntA_H_new.new_tensor([W + 19, H + 7]).to(pntA_H.device) * 2 - 1

                # pntB_invH_new = warp_points(pntB_invH_new[:, :2], inv_Homo_en[idx].squeeze(), device=self.device)       # 转到A上，而不是AT上
                
                pntB_invH_normalized_new = pntB_invH_new / pntB_invH_new.new_tensor([W + 19, H + 7]).to(pntB_invH.device) * 2 - 1 
                
                # print('1_2:', main_ori_maskATB.shape[0])
                # exit()
                ori_kpAT_patch_ext = F.grid_sample(ori_kp_patchA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntA_H_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0).transpose(0, 1)          # repeatNA x 1
                ori_kpB_patch_ext = F.grid_sample(ori_all_patchB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntB_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0).transpose(0, 1)          # NTB x 1
                ori_kpA_patch_ext = F.grid_sample(ori_all_patchA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntA_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0).transpose(0, 1)          # NTA x 1
                ori_kpBT_patch_ext = F.grid_sample(ori_kp_patchB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntB_invH_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0).transpose(0, 1)          # repeatNB x 1
                # print('1_2_1:', pntB_invH_normalized_new.shape[0])
                ori_maskATB, dis_oriATB = self.get_main_ori_consistence_AT(ori_kpAT_patch_ext, ori_kpB_patch_ext)  # repeatNA x NTB
                # print('1_2_2:', ori_maskATB.shape)
                ori_maskBTA, dis_oriBTA = self.get_main_ori_consistence_AT(ori_kpBT_patch_ext, ori_kpA_patch_ext)  # repeatNB x NTA

                match_maskAB_nb = (nn_maskAB == 1) * ori_maskATB           # repeatNA X NTB
                match_maskBA_nb = (nn_maskBA == 1) * ori_maskBTA          # repeatNB X NTA
                pairAB_A_nb_new, pairAB_B_nb_new = torch.where(match_maskAB_nb == 1)
                pairBA_B_nb_new, pairBA_A_nb_new = torch.where(match_maskBA_nb == 1)
                # assert pairAB_A_new.shape[0] > 0 and pairBA_B_new.shape[0] > 0 

                # 4x4邻域方向一致性
                ori_kpAB_patch_ext = F.grid_sample(ori_all_patchB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntA_H_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0).transpose(0, 1)  
                ori_kpBA_patch_ext = F.grid_sample(ori_all_patchA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntB_invH_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0).transpose(0, 1)  
                # print('1_2_4:', ori_kpAB_patch_ext.shape)
                ori_maskATAB, dis_oriATAB = self.get_main_ori_consistence_AT(ori_kpAT_patch_ext, ori_kpAB_patch_ext)  # repeatNA x repeatNA
                ori_maskBTBA, dis_oriBTBA = self.get_main_ori_consistence_AT(ori_kpBT_patch_ext, ori_kpBA_patch_ext)  # repeatNB x repeatNB
                
                # 黑白相似度
                bin_maskATB = bin_distAB <= (1 - self.FR_bin_thr) * current_binA.shape[-1]  
                bin_maskBTA = bin_maskATB.transpose(0, 1)  

                match_maskAB = match_maskAB_nb * bin_maskATB[mask_pointA, :]               # repeatNA X NB
                match_maskBA = match_maskBA_nb * bin_maskBTA[mask_pointB, :]               # repeatNB X NA

                pairAB_A_new, pairAB_B_new = torch.where(match_maskAB == 1)
                pairBA_B_new, pairBA_A_new = torch.where(match_maskBA == 1)
                # print('bin_mask:', pairAB_A_new.shape[0], pairBA_B_new.shape[0])
                assert pairAB_A_new.shape[0] > 0 and pairBA_B_new.shape[0] > 0 

                bin_kpAB_T = (F.grid_sample(bin_allB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntA_H_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0) >= 0.5).float()  # [256, repeatNA]
                bin_kpBA_T = (F.grid_sample(bin_allA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntB_invH_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0) >= 0.5).float()  # [256, repeatNB]
                bin_distATAB = bin_kpAB_T.shape[0] - (current_binA @ bin_kpAB_T) - ((1 - current_binA) @ (1 - bin_kpAB_T)) # [NTA, repeatNA]
                bin_distBTBA = bin_kpBA_T.shape[0] - (current_binB @ bin_kpBA_T) - ((1 - current_binB) @ (1 - bin_kpBA_T)) # [NTB, repeatNB]

                bin_maskATAB = bin_distATAB <= (1 - self.FR_bin_thr) * bin_kpAB_T.shape[0] 
                bin_maskBTBA = bin_distBTBA <= (1 - self.FR_bin_thr) * bin_kpBA_T.shape[0] 
                bin_maskATAB = bin_maskATAB[mask_pointA, :]
                bin_maskBTBA = bin_maskBTBA[mask_pointB, :]

                vmaskAH_nb = torch.diag(ori_maskATAB)
                vmaskBH_nb = torch.diag(ori_maskBTBA)
                vmaskAH = torch.diag(ori_maskATAB * bin_maskATAB) == 1      # [repeatNA, 1]
                vmaskBH = torch.diag(ori_maskBTBA * bin_maskBTBA) == 1      # [repeatNB, 1]

                # print('main_ori:', torch.sum(vmaskAH), torch.sum(vmaskBH))
                assert torch.sum(vmaskAH) > 0 and torch.sum(vmaskBH) > 0

                # SOSR: 简化的self-attention
                k_neighbor = 3
                cross_sim_AA_sp = current_descA @ current_descA.transpose(0, 1)
                cross_sim_BB_sp = current_descB @ current_descB.transpose(0, 1)
                # print('SOSR:', pairAB_A_new.shape[0], pairBA_B_new.shape[0])
                assert pairAB_A_new.shape[0] >= k_neighbor and pairBA_B_new.shape[0] >= k_neighbor 

                match_sim_AB_AA = cross_sim_AA_sp[mask_pointA, :][:, mask_pointA][pairAB_A_new, :][:, pairAB_A_new]
                match_sim_BA_BB = cross_sim_BB_sp[mask_pointB, :][:, mask_pointB][pairBA_B_new, :][:, pairBA_B_new]
                match_sim_AB_BB = cross_sim_BB_sp[pairAB_B_new, :][:, pairAB_B_new]
                match_sim_BA_AA = cross_sim_AA_sp[pairBA_A_new, :][:, pairBA_A_new]
                match_values_AB_AA, match_indices_AB_AA = torch.topk(match_sim_AB_AA, dim=1, k=k_neighbor, largest=False)
                match_values_BA_BB, match_indices_BA_BB = torch.topk(match_sim_BA_BB, dim=1, k=k_neighbor, largest=False)
                match_values_AB_BB_all = match_sim_AB_BB[:, match_indices_AB_AA]
                match_values_BA_AA_all = match_sim_BA_AA[:, match_indices_BA_BB]
                match_values_AB_BB = torch.diagonal(match_values_AB_BB_all, 0, dim1=0, dim2=1).transpose(0, 1)
                match_values_BA_AA = torch.diagonal(match_values_BA_AA_all, 0, dim1=0, dim2=1).transpose(0, 1)
                neighbor_dis_AB = (match_values_AB_AA - match_values_AB_BB) * (match_values_AB_AA - match_values_AB_BB)
                neighbor_dis_BA = (match_values_BA_BB - match_values_BA_AA) * (match_values_BA_BB - match_values_BA_AA)

                # PA VS PB
                # 计算bin值
                valid_cross_sim_AB_sp_mean = torch.mean(cross_sim_AB_sp[mask_pointA, :][match_maskAB == 1], dim=-1)
                valid_cross_sim_AB_sp_nb_mean = torch.mean(cross_sim_AB_sp[mask_pointA, :][match_maskAB_nb == 1], dim=-1)
                novalid_cross_sim_AB_sp_mean = (torch.sum(torch.sum(cross_sim_AB_sp.detach(), 1), 0) - valid_cross_sim_AB_sp_nb_mean * pairAB_A_nb_new.shape[0]) / (new_numA * new_numB - pairAB_A_nb_new.shape[0] + eps)
                valid_cross_sim_BA_sp_mean = torch.mean(cross_sim_AB_sp[:, mask_pointB][match_maskBA.transpose(0, 1) == 1], dim=-1)
                valid_cross_sim_BA_sp_nb_mean = torch.mean(cross_sim_AB_sp[:, mask_pointB][match_maskBA_nb.transpose(0, 1) == 1], dim=-1)
                novalid_cross_sim_BA_sp_mean = (torch.sum(torch.sum(cross_sim_AB_sp.detach(), 1), 0) - valid_cross_sim_BA_sp_nb_mean * pairBA_B_nb_new.shape[0]) / (new_numA * new_numB - pairBA_B_nb_new.shape[0] + eps)

                valid_indexesA = torch.tensor(list(range(cross_sim_AB_sp.shape[0])), device=self.device)[mask_pointA][pairAB_A_new]
                valid_indexesA_nb = torch.tensor(list(range(cross_sim_AB_sp.shape[0])), device=self.device)[mask_pointA][pairAB_A_nb_new]
                # cross_sim_BA_sp = current_descB @ current_descA.transpose(0, 1)
                cross_sim_AB_out_sp = torch.cat((cross_sim_AB_sp, torch.ones((cross_sim_AB_sp.shape[0], 3), device=cross_sim_AB_sp.device) * 2), dim=-1)      # NA X (NB + 2)
                cross_sim_AB_out_nb_sp = torch.cat((cross_sim_AB_sp, torch.ones((cross_sim_AB_sp.shape[0], 3), device=cross_sim_AB_sp.device) * 2), dim=-1)      # NA X (NB + 2)
                # cross_sim_BA_out_sp = torch.cat((cross_sim_BA_sp, torch.ones((numB, 1), device=cross_sim_BA_sp.device)), dim=-1)      # NB X (NA + 1)
                # valid_indexesB = torch.tensor(list(range(numB)), device=self.device)[mask_pointB][pairBA_B]
                # print('1_2')
                cross_sim_AB_out_sp[valid_indexesA, -1] = novalid_cross_sim_AB_sp_mean
                cross_sim_AB_out_sp[valid_indexesA, -2] = crossAN_mean
                cross_sim_AB_out_sp[valid_indexesA, -3] = crossAN2_mean
                cross_sim_AB_out_nb_sp[valid_indexesA_nb, -1] = novalid_cross_sim_AB_sp_mean
                novalid_indexesA = torch.tensor(list(range(cross_sim_AB_sp.shape[0])), device=self.device)[cross_sim_AB_out_nb_sp[:, -1]==2]
                cross_sim_AB_out_sp[novalid_indexesA, -1] = valid_cross_sim_AB_sp_mean
                # nomatch对不增加negtives的均值bin
                cross_sim_AB_out_sp[novalid_indexesA, -2] = -1 # crossAN_mean # -1
                cross_sim_AB_out_sp[novalid_indexesA, -3] = -1 # crossAN_mean # -1

                soft_cross_sim_AtoB_sp = F.softmax((cross_sim_AB_out_sp - 1) / t_des, dim=-1)
                # soft_cross_sim_BtoA = F.softmax((cross_sim_BA_out - 1) / t_des, dim=-1)
                # print('1_3')
                soft_valid_cross_sim_AB_sp = soft_cross_sim_AtoB_sp[mask_pointA, :-3][match_maskAB==1]
                # soft_valid_cross_sim_BA = soft_cross_sim_BtoA[mask_pointB, :-1][pairBA_B, pairBA_A]
                soft_novalid_cross_sim_AB_sp = soft_cross_sim_AtoB_sp[novalid_indexesA, -1]
                # soft_novalid_cross_sim_BA = soft_cross_sim_BtoA[cross_sim_BA_out[:, -1]==1, -1]
                log_soft_valid_cross_sim_AB_sp = -torch.log(soft_valid_cross_sim_AB_sp + eps) * (1 - dis_oriATB[match_maskAB==1] / self.ori_diff) * (1 - bin_distAB[mask_pointA, :][match_maskAB==1] / current_binA.shape[-1]) * (1 - key_disAB[match_maskAB==1].detach() / self.correspond)
                # log_soft_valid_cross_sim_BA = -torch.log(soft_valid_cross_sim_BA + eps)
                log_soft_novalid_cross_sim_AB_sp = -torch.log(soft_novalid_cross_sim_AB_sp + eps)
                # log_soft_novalid_cross_sim_BA = -torch.log(soft_novalid_cross_sim_BA + eps)
                dis_cross_sim_mean_sp = torch.sum(torch.cat((4*log_soft_valid_cross_sim_AB_sp, log_soft_novalid_cross_sim_AB_sp), dim=-1), dim=-1) / new_numA
                
                # PA VS PAB
                # match_mask_A = copy.deepcopy(mask_pointA)
                # match_mask_B = copy.deepcopy(mask_pointB)
                match_mask_A = torch.zeros(cross_sim_AB_sp.shape[0], device=self.device)
                match_mask_nb_A = torch.zeros(cross_sim_AB_sp.shape[0], device=self.device)
                valid_match_indexesA = torch.tensor(list(range(cross_sim_AB_sp.shape[0])), device=self.device)[mask_pointA][vmaskAH]
                valid_match_indexesA_nb = torch.tensor(list(range(cross_sim_AB_sp.shape[0])), device=self.device)[mask_pointA][vmaskAH_nb]
                match_mask_A[valid_match_indexesA] = 1
                match_mask_nb_A[valid_match_indexesA_nb] = 1

                match_mask_B = torch.zeros(cross_sim_AB_sp.shape[1], device=self.device)
                match_mask_nb_B = torch.zeros(cross_sim_AB_sp.shape[1], device=self.device)
                valid_match_indexesB = torch.tensor(list(range(cross_sim_AB_sp.shape[1])), device=self.device)[mask_pointB][vmaskBH]
                valid_match_indexesB_nb = torch.tensor(list(range(cross_sim_AB_sp.shape[1])), device=self.device)[mask_pointB][vmaskBH_nb]
                match_mask_B[valid_match_indexesB] = 1
                match_mask_nb_B[valid_match_indexesB_nb] = 1

                cross_sim_AB = current_descA @ desc_mapB[idx, :, :, :].view(-1, H * W)
                # cross_sim_AB = cross_sim_AB[mask_pointA, :]
                cross_sim_AB_all = F.grid_sample(cross_sim_AB.view(-1, H, W).unsqueeze(0),
                                                pntA_H_normalized[vmaskAH, :].detach().view(1, 1, -1, 2),
                                                mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NA x repeatNA
                valid_cross_sim_AB_mean = torch.trace(cross_sim_AB_all[match_mask_A==1, :]) / cross_sim_AB_all[match_mask_A==1, :].shape[0]
                # novalid_cross_sim_AB_mean = (torch.sum(torch.sum(cross_sim_AB.detach(), 1), 1) - valid_cross_sim_AB_mean * pairAB_A.shape[0]) / (new_numA * H * W - pairAB_A.shape[0])

                cross_sim_BA = current_descB @ desc_mapA[idx, :, :, :].view(-1, H * W)   # M x H x W
                # cross_sim_BA = cross_sim_BA[mask_pointB, :]
                cross_sim_BA_all = F.grid_sample(cross_sim_BA.view(-1, H, W).unsqueeze(0),
                                                pntB_invH_normalized[vmaskBH, :].detach().view(1, 1, -1, 2),
                                                mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NB x match_nB
                valid_cross_sim_BA_mean = torch.trace(cross_sim_BA_all[match_mask_B==1, :]) / cross_sim_BA_all[match_mask_B==1, :].shape[0]
                # novalid_cross_sim_BA_mean = (torch.sum(torch.sum(cross_sim_BA.detach(), 1), 1) - valid_cross_sim_BA_mean * pairBA_B.shape[0]) / (new_numB * H * W - pairBA_B.shape[0])

                cross_sim_AB_out = torch.cat((cross_sim_AB, torch.ones((cross_sim_AB.shape[0], 3), device=cross_sim_AB.device)), dim=-1)      # NA X (H X W + 2)
                cross_sim_BA_out = torch.cat((cross_sim_BA, torch.ones((cross_sim_BA.shape[0], 3), device=cross_sim_BA.device)), dim=-1)      # NB X (H X W + 2)
                # print(3)
                # cross_sim_AB_out[mask_pointA, -1] -= 1
                # cross_sim_BA_out[mask_pointB, -1] -= 1
                # cross_sim_AB_out[match_mask_A, -1] -= 1
                cross_sim_AB_out[match_mask_A==1, -1] = novalid_cross_sim_AB_sp_mean
                cross_sim_AB_out[match_mask_A==1, -2] = crossAN_mean
                cross_sim_AB_out[match_mask_A==1, -3] = crossAN2_mean
                cross_sim_AB_out[match_mask_nb_A==0, -1] = valid_cross_sim_AB_mean
                cross_sim_AB_out[match_mask_nb_A==0, -2] = -1 # crossAN_mean # -1
                cross_sim_AB_out[match_mask_nb_A==0, -3] = -1 # crossAN_mean # -1

                cross_sim_BA_out[match_mask_B==1, -1] = novalid_cross_sim_BA_sp_mean
                cross_sim_BA_out[match_mask_B==1, -2] = crossBN_mean
                cross_sim_BA_out[match_mask_B==1, -3] = crossBN2_mean
                cross_sim_BA_out[match_mask_nb_B==0, -1] = valid_cross_sim_BA_mean
                cross_sim_BA_out[match_mask_nb_B==0, -2] = -1 # crossBN_mean # -1
                cross_sim_BA_out[match_mask_nb_B==0, -3] = -1 # crossBN_mean # -1

                soft_cross_sim_AtoB = F.softmax((cross_sim_AB_out - 1) / t_des, dim=-1)         # NA X (H X W + 1)
                soft_cross_sim_BtoA = F.softmax((cross_sim_BA_out - 1) / t_des, dim=-1)         # NB X (H X W + 1)
                soft_cross_sim_AB_all = F.grid_sample(soft_cross_sim_AtoB[:, :-3].view(-1, H, W).unsqueeze(0),
                                                    pntA_H_normalized[vmaskAH, :].detach().view(1, 1, -1, 2),
                                                    mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NA x match_nA
                
                soft_cross_sim_BA_all = F.grid_sample(soft_cross_sim_BtoA[:, :-3].view(-1, H, W).unsqueeze(0),
                                                    pntB_invH_normalized[vmaskBH, :].detach().view(1, 1, -1, 2),
                                                    mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NB x match_nB
                # soft_valid_cross_sim_AB_all = soft_cross_sim_AB_all[mask_pointA, :]             # repeat_nA x repeat_nA
                # soft_valid_cross_sim_BA_all = soft_cross_sim_BA_all[mask_pointB, :]             # repeat_nB x repeat_nB

                soft_valid_cross_sim_AB_all = soft_cross_sim_AB_all[match_mask_A==1, :]             # match_nA x match_nA
                soft_valid_cross_sim_BA_all = soft_cross_sim_BA_all[match_mask_B==1, :]             # match_nB x match_nB

                valid_mask_AB = torch.eye(soft_valid_cross_sim_AB_all.shape[0]) == 1
                valid_mask_BA = torch.eye(soft_valid_cross_sim_BA_all.shape[0]) == 1
                # print(4)
                # 取对角线
                soft_valid_cross_sim_AB = soft_valid_cross_sim_AB_all[valid_mask_AB]
                soft_valid_cross_sim_BA = soft_valid_cross_sim_BA_all[valid_mask_BA]

                # soft_novalid_cross_sim_AB = soft_cross_sim_AtoB[mask_pointA==False, -1]              # (NA-repeat_nA) x 1
                # soft_novalid_cross_sim_BA = soft_cross_sim_BtoA[mask_pointB==False, -1]
                soft_novalid_cross_sim_AB = soft_cross_sim_AtoB[match_mask_nb_A==0, -1]               # (NA-match_nA) x 1
                soft_novalid_cross_sim_BA = soft_cross_sim_BtoA[match_mask_nb_B==0, -1]
                # print(soft_novalid_cross_sim_AB, soft_novalid_cross_sim_BA)

                log_soft_valid_cross_sim_AB = -torch.log(soft_valid_cross_sim_AB + eps) * (1 - torch.diag(dis_oriATAB)[vmaskAH] / self.ori_diff) * (1 - torch.diag(bin_distATAB[mask_pointA, :])[vmaskAH] / bin_kpAB_T.shape[0])
                log_soft_valid_cross_sim_BA = -torch.log(soft_valid_cross_sim_BA + eps) * (1 - torch.diag(dis_oriBTBA)[vmaskBH] / self.ori_diff) * (1 - torch.diag(bin_distBTBA[mask_pointB, :])[vmaskBH] / bin_kpBA_T.shape[0])
                log_soft_novalid_cross_sim_AB = -torch.log(soft_novalid_cross_sim_AB + eps)
                log_soft_novalid_cross_sim_BA = -torch.log(soft_novalid_cross_sim_BA + eps)

                dis_cross_sim_mean = torch.sum(torch.cat((4*log_soft_valid_cross_sim_AB, 4*log_soft_valid_cross_sim_BA, log_soft_novalid_cross_sim_AB, log_soft_novalid_cross_sim_BA), dim=-1), dim=-1) / (new_numA + new_numB)
                
                # print(5)
                valid_cross_sim_AB = cross_sim_AB[mask_pointA, :]   # repeat_nA x (H X W)
                valid_cross_sim_BA = cross_sim_BA[mask_pointB, :]   # repeat_nB x (H X W)
                exp_valid_cross_sim_AtoB = torch.exp((valid_cross_sim_AB - 1) / t_rel).view(-1, H, W)
                exp_valid_cross_sim_BtoA = torch.exp((valid_cross_sim_BA - 1) / t_rel).view(-1, H, W)
                exp_valid_cross_sim_AB_all = F.grid_sample(exp_valid_cross_sim_AtoB.unsqueeze(0),
                                                        pntA_H_normalized.detach().view(1, 1, -1, 2),
                                                        mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # repeat_nA x repeat_nA
                
                exp_valid_cross_sim_BA_all = F.grid_sample(exp_valid_cross_sim_BtoA.unsqueeze(0),
                                                        pntB_invH_normalized.detach().view(1, 1, -1, 2),
                                                        mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # repeat_nB x repeat_nB

                repeat_mask_AB = torch.eye(exp_valid_cross_sim_AB_all.shape[0]) == 1
                repeat_mask_BA = torch.eye(exp_valid_cross_sim_BA_all.shape[0]) == 1
                rel_valid_cross_sim_AB = exp_valid_cross_sim_AB_all[repeat_mask_AB]
                rel_valid_cross_sim_BA = exp_valid_cross_sim_BA_all[repeat_mask_BA]

                # pntA_H_normalized_new = copy.deepcopy(pntA_H_normalized.detach())
                # pntB_invH_normalized_new = copy.deepcopy(pntB_invH_normalized.detach())

                # pntA_H_normalized_new[:, 0] += 2
                # pntB_invH_normalized_new[:, 0] += 2

                scoresAB_all = F.grid_sample(scores_mapB[idx, :, :, :].unsqueeze(0),
                                            pntA_H_normalized_new.view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)      # 1 x repeat_nA

                scoresBA_all = F.grid_sample(scores_mapA[idx, :, :, :].unsqueeze(0),
                                            pntB_invH_normalized_new.view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)      # 1 x repeat_nB
                # print(6)
                scores_AAB = scoresA[idx][pmA][mask_pointA] * scoresAB_all
                scores_BBA = scoresB[idx][pmB][mask_pointB] * scoresBA_all
                scores_sum_AAB = torch.sum(scores_AAB, dim=-1)
                scores_sum_BBA = torch.sum(scores_BBA, dim=-1)
                scores_normalize_AAB = scores_AAB / (scores_sum_AAB + eps)
                scores_normalize_BBA = scores_BBA / (scores_sum_BBA + eps)
                rel_meanA = torch.sum(scores_normalize_AAB * (1 - rel_valid_cross_sim_AB), dim=-1) / pntA_H_normalized_new.shape[0]
                rel_meanB = torch.sum(scores_normalize_BBA * (1 - rel_valid_cross_sim_BA), dim=-1) / pntB_invH_normalized_new.shape[0]

                # # 熵loss
                # current_descA_std, current_descB_std = descA_std[countA:countA+new_numA], descB_std[countB:countB+new_numB]
                # desc_std += torch.mean(current_descA_std) + torch.mean(current_descB_std)
                # countA_T += numA_T
                # countB_T += numB_T

                # Sinkhorn KD loss
                SK_scores_KDA = log_optimal_transport(cross_sim_KDA_sp.unsqueeze(0), 3).squeeze(0)  
                SK_scores_KDB = log_optimal_transport(cross_sim_KDB_sp.unsqueeze(0), 3).squeeze(0)  

                dis_cross_sim_KD += (-(torch.trace(SK_scores_KDA) + torch.trace(SK_scores_KDB)) / (new_numA + new_numB))

                dis_neighbor_mean_total += torch.mean(torch.sum(neighbor_dis_AB, dim=1)) + torch.mean(torch.sum(neighbor_dis_BA, dim=1))
                dis_desc += dis_cross_sim_mean_sp
                dis_desc += dis_cross_sim_mean

                dis_pair_meanAB = torch.mean(key_manhattandisAB[pairAB_A, pairAB_B])
                dis_pair_meanBA = torch.mean(key_manhattandisBA[pairBA_B, pairBA_A])

                dis_peak_mean = torch.mean(torch.cat((scoreddisA[idx][pmA], scoreddisB[idx][pmB]), dim=0))
                # dis_peak_meanB = torch.mean(scoreddisB[idx])
                
                dis_mean_total += dis_pair_meanAB + dis_pair_meanBA
                dis_peak_scored += dis_peak_mean

                dis_rel += rel_meanA + rel_meanB
                
                countA += new_numA
                countB += new_numB
                count_ne += new_num_ne
                # # Penalty
                # scores_mean += (-torch.log(torch.mean(scoresA[idx], dim=-1) + eps) - torch.log(torch.mean(scoresB[idx], dim=-1) + eps)) 
                # print(scores_mean)
            except:
                # dis_mean_total += 0
                # dis_peak_scored += 0
                # dis_desc += 0
                # dis_rel += 0
                # print('Overlapping too small or Repeatable point pairs distance is greater than correspond(1.5):', pntA.shape[0], pntA_H.shape[0], pntB.shape[0], pntB_invH.shape[0], dis_pairAB.shape[0], dis_pairBA.shape[0])
                valid_batch_size -= 1
                countA += new_numA
                countB += new_numB
                count_ne += new_num_ne
                # countA_T += numA_T
                # countB_T += numB_T

        valid_batch_size = valid_batch_size if valid_batch_size > 0 else eps
        # Reprojection Loss 
        reprojection_loss = dis_mean_total / (valid_batch_size * 2)
        # Dispersity Peak Loss
        dispersity_peak_loss = dis_peak_scored / valid_batch_size
        # NRE Loss
        descriptor_loss = dis_desc / (2 * valid_batch_size)
        # Reliability Loss
        reliability_loss = dis_rel / (valid_batch_size * 2)
        # SOSR Loss
        sosr_loss = dis_neighbor_mean_total / ((valid_batch_size * 2))
        # # Entropy loss
        # std_loss = (valid_batch_size * 2) / desc_std  
        # # Score Penalty
        # score_penalty = scores_mean / (valid_batch_size * 2)
        # # FA Desc loss
        # FA_des_loss = dis_desc_fa / valid_batch_size_FA if valid_batch_size_FA > 0 else 0
        # KD_loss
        KD_loss = dis_cross_sim_KD / valid_batch_size
        # FGD_KD_loss
        fgd_loss = (fea_lossA + fea_lossB) / 2

        loss_total = wrp * reprojection_loss + wpl * dispersity_peak_loss + wdl * descriptor_loss + wrl * reliability_loss + sosr_loss + KD_loss + fgd_loss
        loss_group = {
            'reprojection_loss': reprojection_loss, 
            'dispersity_peak_loss': dispersity_peak_loss,
            'descriptor_loss': descriptor_loss,
            'reliability_loss': reliability_loss,
            'sosr_loss': sosr_loss,
            # 'std_loss': std_loss,
            # 'FA_des_loss': FA_des_loss,
            'KD_loss': KD_loss,
            'fgd_loss': fgd_loss,
            }
        return loss_total, loss_group



    # patch/dense AT角度 黑白相似度加量化 FA negtives
    def detector_selfsupervised_loss_dkd_patch_ext_restrict_modify_oriR_ratio_FA_qtbw_ns_wg_nori_AT_NE(self, kpA, kpB, pmaskA, pmaskB, descA, descB, desc_mapA, desc_mapB, scoreddisA, scoreddisB, scoresA, scoresB, scores_mapA, scores_mapB, Homo, inv_Homo, inv_Homo_en, ori_all_patchA, ori_all_patchB, ori_kp_patchA, ori_kp_patchB, bin_allA, bin_allB, bin_kpA, bin_kpB, kp_ne, pmask_ne, desc_ne, bin_kp_ne, trans_angle, FA_flag, H, W, wrp=1, wpl=1, wdl=1, wrl=1, t_des=0.02, t_rel=1):
        # pmaskA: (BxMax_num) 32x350=11200
        batch_size = len(kpA)
        max_num = pmaskA.shape[-1] // batch_size    # 350
        dis_mean_total = 0
        dis_neighbor_mean_total = 0
        dis_peak_scored = 0
        dis_desc = 0
        dis_rel = 0
        desc_std = 0
        eps = 1e-12
        valid_batch_size = batch_size
        countA, countB, count_ne = 0, 0, 0
        valid_batch_size_FA = 0
        dis_desc_fa = 0
        # countA_T, countB_T = 0, 0
        for idx in range(batch_size):
            pntA, pntB, pnt_ne = kpA[idx], kpB[idx], kp_ne[idx]     # M X 2 (x,y)
            # kmask_TA, kmask_TB = kmask_T_allA[idx], kmask_T_allB[idx]
            pntA = pntA.float()
            pntB = pntB.float()
            pnt_ne = pnt_ne.float()

            # 剔除部分按压区域的点,且保留在重叠区域的点
            numA, numB, num_ne = pntA.shape[0], pntB.shape[0], pnt_ne.shape[0]
            # numA_T, numB_T = pntA[kmask_TA].shape[0], pntB[kmask_TB].shape[0]
            pmA, pmB, pm_ne = pmaskA[max_num * idx:max_num * idx + numA].bool(), pmaskB[max_num * idx:max_num * idx + numB].bool(), pmask_ne[max_num * idx:max_num * idx + num_ne].bool()
            pntA, pntB, pnt_ne = pntA[pmA, :], pntB[pmB, :], pnt_ne[pm_ne, :]
            new_numA, new_numB, new_num_ne = pntA.shape[0], pntB.shape[0], pnt_ne.shape[0]       
            
            pntA = (pntA + 1) / 2 * pntA.new_tensor([[W + 3, H - 1]]).to(pntA.device)
            pntB = (pntB + 1) / 2 * pntB.new_tensor([[W + 3, H - 1]]).to(pntB.device)

            # [120, 40] -> [120, 36],实际只取中心118x32区域的点对
            pntA[:, 0] -= 2
            pntB[:, 0] -= 2
            
            pntA_normalized = pntA / pntA.new_tensor([W - 1, H - 1]).to(pntA.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)
            pntB_normalized = pntB / pntB.new_tensor([W - 1, H - 1]).to(pntB.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)

            pntA_H = warp_points(pntA[:, :2], Homo[idx].squeeze(), device=self.device)  # 利用变换矩阵变换坐标点
            pntA_H, mask_pointA = filter_points(pntA_H, torch.tensor([W, H], device=self.device), return_mask=True)
            pntB_invH = warp_points(pntB[:, :2], inv_Homo[idx].squeeze(), device=self.device)
            pntB_invH, mask_pointB = filter_points(pntB_invH, torch.tensor([W, H], device=self.device), return_mask=True)
            
            current_descA, current_descB = descA[countA:countA+new_numA], descB[countB:countB+new_numB]
            current_desc_ne = desc_ne[count_ne:count_ne+new_num_ne]
            cross_sim_AB_sp = current_descA @ current_descB.transpose(0, 1)     # NTA X NTB
            
            cross_sim_AN_sp = current_descA @ current_desc_ne.transpose(0, 1)
            cross_sim_BN_sp = current_descB @ current_desc_ne.transpose(0, 1)
            
            # 黑白相似度
            current_binA, current_binB = (bin_kpA[countA:countA+new_numA] >= 0.5).float(), (bin_kpB[countB:countB+new_numB] >= 0.5).float()   # [NA, 256] [NB_256]
            current_bin_ne = (bin_kp_ne[count_ne:count_ne+new_num_ne] >= 0.5).float()
            bin_distAB = current_binA.shape[-1] - (current_binA @ current_binB.transpose(0, 1)) - ((1 - current_binA) @ (1 - current_binB.transpose(0, 1))) # [NA, NB]
            
            bin_distAN = current_binA.shape[-1] - (current_binA @ current_bin_ne.transpose(0, 1)) - ((1 - current_binA) @ (1 - current_bin_ne.transpose(0, 1))) # [NA, NE]
            bin_distBN = current_binB.shape[-1] - (current_binB @ current_bin_ne.transpose(0, 1)) - ((1 - current_binB) @ (1 - current_bin_ne.transpose(0, 1))) # [NA, NE]
            
            # Net FA余弦相似度小
            if FA_flag[idx] == 1:
                FA_bin_mask = bin_distAB >= (1 - self.FA_bin_thr) * current_binA.shape[-1] 

                dis_desc_fa += (2 - torch.mean(torch.sqrt(2 * (1 - cross_sim_AB_sp[FA_bin_mask]) + eps)))

                valid_batch_size -= 1
                valid_batch_size_FA += 1
                countA += new_numA
                countB += new_numB
                continue

            # 真匹配的trans
            try:
                FAN_bin_mask = bin_distAN >= (1 - self.FA_bin_thr) * current_binA.shape[-1] 
                FBN_bin_mask = bin_distBN >= (1 - self.FA_bin_thr) * current_binB.shape[-1] 
                # topk ?
                crossAN_mean = torch.mean(cross_sim_AN_sp[FAN_bin_mask])
                crossBN_mean = torch.mean(cross_sim_BN_sp[FBN_bin_mask])

                assert pntA_H.shape[0] > 0 and pntB_invH.shape[0] > 0 
                
                # 点对欧氏距离
                key_disAB = self.get_dis(pntA_H[:, :2], pntB[:, :2])            # repeatNA x NB
                key_disBA = self.get_dis(pntB_invH[:, :2], pntA[:, :2])
                pairAB_A, pairAB_B, dis_pairAB, _ = self.get_point_pair(key_disAB, dis_thre=self.correspond)  # p -> k # NTA(<1.5), NTA(<1.5), NTA(<1.5), NTA        
                pairBA_B, pairBA_A, dis_pairBA, _  = self.get_point_pair(key_disBA, dis_thre=self.correspond)  # p -> k # NTB(<1.5), NTB(<1.5), NTB(<1.5), NTB 
                
                # 点距离mask
                nn_maskAB = torch.zeros((pntA_H.shape[0], pntB.shape[0]), device=self.device) 
                nn_maskAB[pairAB_A, pairAB_B] = 1

                nn_maskBA = torch.zeros((pntB_invH.shape[0], pntA.shape[0]), device=self.device) 
                nn_maskBA[pairBA_B, pairBA_A] = 1

                # 点对曼哈顿距离
                key_manhattandisAB = self.get_manhattan_dis(pntA_H[:, :2], pntB[:, :2])
                key_manhattandisBA = self.get_manhattan_dis(pntB_invH[:, :2], pntA[:, :2])
                # print('pdis:', dis_pairAB.shape[0], dis_pairBA.shape[0])
                assert dis_pairAB.shape[0] > 0 and dis_pairBA.shape[0] > 0     

                pntA_H_normalized = pntA_H / pntA_H.new_tensor([W - 1, H - 1]).to(pntA_H.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)
                pntB_invH_normalized = pntB_invH / pntB_invH.new_tensor([W - 1, H - 1]).to(pntB_invH.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)

                # 用于score_map
                pntA_H_new = copy.deepcopy(pntA_H.detach())
                pntB_invH_new = copy.deepcopy(pntB_invH.detach())
                pntA_H_new[:, 0] += 10                   # 120 x 36 -> 128 x 56
                pntA_H_new[:, 1] += 4 
                pntB_invH_new[:, 0] += 10
                pntB_invH_new[:, 1] += 4
                
                pntA_H_normalized_new = pntA_H_new / pntA_H_new.new_tensor([W + 19, H + 7]).to(pntA_H.device) * 2 - 1

                # pntB_invH_new = warp_points(pntB_invH_new[:, :2], inv_Homo_en[idx].squeeze(), device=self.device)       # 转到A上，而不是AT上
                
                pntB_invH_normalized_new = pntB_invH_new / pntB_invH_new.new_tensor([W + 19, H + 7]).to(pntB_invH.device) * 2 - 1 
                
                # print('1_2:', main_ori_maskATB.shape[0])
                # exit()
                ori_kpAT_patch_ext = F.grid_sample(ori_kp_patchA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntA_H_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0).transpose(0, 1)          # repeatNA x 1
                ori_kpB_patch_ext = F.grid_sample(ori_all_patchB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntB_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0).transpose(0, 1)          # NTB x 1
                ori_kpA_patch_ext = F.grid_sample(ori_all_patchA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntA_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0).transpose(0, 1)          # NTA x 1
                ori_kpBT_patch_ext = F.grid_sample(ori_kp_patchB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntB_invH_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0).transpose(0, 1)          # repeatNB x 1
                # print('1_2_1:', pntB_invH_normalized_new.shape[0])
                ori_maskATB, dis_oriATB = self.get_main_ori_consistence_AT(ori_kpAT_patch_ext, ori_kpB_patch_ext)  # repeatNA x NTB
                # print('1_2_2:', ori_maskATB.shape)
                ori_maskBTA, dis_oriBTA = self.get_main_ori_consistence_AT(ori_kpBT_patch_ext, ori_kpA_patch_ext)  # repeatNB x NTA

                match_maskAB_nb = (nn_maskAB == 1) * ori_maskATB           # repeatNA X NTB
                match_maskBA_nb = (nn_maskBA == 1) * ori_maskBTA          # repeatNB X NTA
                pairAB_A_nb_new, pairAB_B_nb_new = torch.where(match_maskAB_nb == 1)
                pairBA_B_nb_new, pairBA_A_nb_new = torch.where(match_maskBA_nb == 1)
                # assert pairAB_A_new.shape[0] > 0 and pairBA_B_new.shape[0] > 0 

                # 4x4邻域方向一致性
                ori_kpAB_patch_ext = F.grid_sample(ori_all_patchB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntA_H_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0).transpose(0, 1)  
                ori_kpBA_patch_ext = F.grid_sample(ori_all_patchA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntB_invH_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0).transpose(0, 1)  
                # print('1_2_4:', ori_kpAB_patch_ext.shape)
                ori_maskATAB, dis_oriATAB = self.get_main_ori_consistence_AT(ori_kpAT_patch_ext, ori_kpAB_patch_ext)  # repeatNA x repeatNA
                ori_maskBTBA, dis_oriBTBA = self.get_main_ori_consistence_AT(ori_kpBT_patch_ext, ori_kpBA_patch_ext)  # repeatNB x repeatNB
                
                # 黑白相似度
                bin_maskATB = bin_distAB <= (1 - self.FR_bin_thr) * current_binA.shape[-1]  
                bin_maskBTA = bin_maskATB.transpose(0, 1)  

                match_maskAB = match_maskAB_nb * bin_maskATB[mask_pointA, :]               # repeatNA X NB
                match_maskBA = match_maskBA_nb * bin_maskBTA[mask_pointB, :]               # repeatNB X NA

                pairAB_A_new, pairAB_B_new = torch.where(match_maskAB == 1)
                pairBA_B_new, pairBA_A_new = torch.where(match_maskBA == 1)
                # print('bin_mask:', pairAB_A_new.shape[0], pairBA_B_new.shape[0])
                assert pairAB_A_new.shape[0] > 0 and pairBA_B_new.shape[0] > 0 

                bin_kpAB_T = (F.grid_sample(bin_allB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntA_H_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0) >= 0.5).float()  # [256, repeatNA]
                bin_kpBA_T = (F.grid_sample(bin_allA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntB_invH_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0) >= 0.5).float()  # [256, repeatNB]
                bin_distATAB = bin_kpAB_T.shape[0] - (current_binA @ bin_kpAB_T) - ((1 - current_binA) @ (1 - bin_kpAB_T)) # [NTA, repeatNA]
                bin_distBTBA = bin_kpBA_T.shape[0] - (current_binB @ bin_kpBA_T) - ((1 - current_binB) @ (1 - bin_kpBA_T)) # [NTB, repeatNB]

                bin_maskATAB = bin_distATAB <= (1 - self.FR_bin_thr) * bin_kpAB_T.shape[0] 
                bin_maskBTBA = bin_distBTBA <= (1 - self.FR_bin_thr) * bin_kpBA_T.shape[0] 
                bin_maskATAB = bin_maskATAB[mask_pointA, :]
                bin_maskBTBA = bin_maskBTBA[mask_pointB, :]

                vmaskAH_nb = torch.diag(ori_maskATAB)
                vmaskBH_nb = torch.diag(ori_maskBTBA)
                vmaskAH = torch.diag(ori_maskATAB * bin_maskATAB) == 1      # [repeatNA, 1]
                vmaskBH = torch.diag(ori_maskBTBA * bin_maskBTBA) == 1      # [repeatNB, 1]

                # print('main_ori:', torch.sum(vmaskAH), torch.sum(vmaskBH))
                assert torch.sum(vmaskAH) > 0 and torch.sum(vmaskBH) > 0

                # SOSR: 简化的self-attention
                k_neighbor = 3
                cross_sim_AA_sp = current_descA @ current_descA.transpose(0, 1)
                cross_sim_BB_sp = current_descB @ current_descB.transpose(0, 1)
                # print('SOSR:', pairAB_A_new.shape[0], pairBA_B_new.shape[0])
                assert pairAB_A_new.shape[0] >= k_neighbor and pairBA_B_new.shape[0] >= k_neighbor 

                match_sim_AB_AA = cross_sim_AA_sp[mask_pointA, :][:, mask_pointA][pairAB_A_new, :][:, pairAB_A_new]
                match_sim_BA_BB = cross_sim_BB_sp[mask_pointB, :][:, mask_pointB][pairBA_B_new, :][:, pairBA_B_new]
                match_sim_AB_BB = cross_sim_BB_sp[pairAB_B_new, :][:, pairAB_B_new]
                match_sim_BA_AA = cross_sim_AA_sp[pairBA_A_new, :][:, pairBA_A_new]
                match_values_AB_AA, match_indices_AB_AA = torch.topk(match_sim_AB_AA, dim=1, k=k_neighbor, largest=False)
                match_values_BA_BB, match_indices_BA_BB = torch.topk(match_sim_BA_BB, dim=1, k=k_neighbor, largest=False)
                match_values_AB_BB_all = match_sim_AB_BB[:, match_indices_AB_AA]
                match_values_BA_AA_all = match_sim_BA_AA[:, match_indices_BA_BB]
                match_values_AB_BB = torch.diagonal(match_values_AB_BB_all, 0, dim1=0, dim2=1).transpose(0, 1)
                match_values_BA_AA = torch.diagonal(match_values_BA_AA_all, 0, dim1=0, dim2=1).transpose(0, 1)
                neighbor_dis_AB = (match_values_AB_AA - match_values_AB_BB) * (match_values_AB_AA - match_values_AB_BB)
                neighbor_dis_BA = (match_values_BA_BB - match_values_BA_AA) * (match_values_BA_BB - match_values_BA_AA)

                # PA VS PB
                # 计算bin值
                valid_cross_sim_AB_sp_mean = torch.mean(cross_sim_AB_sp[mask_pointA, :][match_maskAB == 1], dim=-1)
                valid_cross_sim_AB_sp_nb_mean = torch.mean(cross_sim_AB_sp[mask_pointA, :][match_maskAB_nb == 1], dim=-1)
                novalid_cross_sim_AB_sp_mean = (torch.sum(torch.sum(cross_sim_AB_sp.detach(), 1), 0) - valid_cross_sim_AB_sp_nb_mean * pairAB_A_nb_new.shape[0]) / (new_numA * new_numB - pairAB_A_nb_new.shape[0] + eps)
                valid_cross_sim_BA_sp_mean = torch.mean(cross_sim_AB_sp[:, mask_pointB][match_maskBA.transpose(0, 1) == 1], dim=-1)
                valid_cross_sim_BA_sp_nb_mean = torch.mean(cross_sim_AB_sp[:, mask_pointB][match_maskBA_nb.transpose(0, 1) == 1], dim=-1)
                novalid_cross_sim_BA_sp_mean = (torch.sum(torch.sum(cross_sim_AB_sp.detach(), 1), 0) - valid_cross_sim_BA_sp_nb_mean * pairBA_B_nb_new.shape[0]) / (new_numA * new_numB - pairBA_B_nb_new.shape[0] + eps)

                valid_indexesA = torch.tensor(list(range(cross_sim_AB_sp.shape[0])), device=self.device)[mask_pointA][pairAB_A_new]
                valid_indexesA_nb = torch.tensor(list(range(cross_sim_AB_sp.shape[0])), device=self.device)[mask_pointA][pairAB_A_nb_new]
                # cross_sim_BA_sp = current_descB @ current_descA.transpose(0, 1)
                cross_sim_AB_out_sp = torch.cat((cross_sim_AB_sp, torch.ones((cross_sim_AB_sp.shape[0], 2), device=cross_sim_AB_sp.device) * 2), dim=-1)      # NA X (NB + 2)
                cross_sim_AB_out_nb_sp = torch.cat((cross_sim_AB_sp, torch.ones((cross_sim_AB_sp.shape[0], 2), device=cross_sim_AB_sp.device) * 2), dim=-1)      # NA X (NB + 2)
                # cross_sim_BA_out_sp = torch.cat((cross_sim_BA_sp, torch.ones((numB, 1), device=cross_sim_BA_sp.device)), dim=-1)      # NB X (NA + 1)
                # valid_indexesB = torch.tensor(list(range(numB)), device=self.device)[mask_pointB][pairBA_B]
                # print('1_2')
                cross_sim_AB_out_sp[valid_indexesA, -1] = novalid_cross_sim_AB_sp_mean
                cross_sim_AB_out_sp[valid_indexesA, -2] = crossAN_mean
                cross_sim_AB_out_nb_sp[valid_indexesA_nb, -1] = novalid_cross_sim_AB_sp_mean
                novalid_indexesA = torch.tensor(list(range(cross_sim_AB_sp.shape[0])), device=self.device)[cross_sim_AB_out_nb_sp[:, -1]==2]
                cross_sim_AB_out_sp[novalid_indexesA, -1] = valid_cross_sim_AB_sp_mean
                # nomatch对不增加negtives的均值bin
                cross_sim_AB_out_sp[novalid_indexesA, -2] = -1 # crossAN_mean # -1

                soft_cross_sim_AtoB_sp = F.softmax((cross_sim_AB_out_sp - 1) / t_des, dim=-1)
                # soft_cross_sim_BtoA = F.softmax((cross_sim_BA_out - 1) / t_des, dim=-1)
                # print('1_3')
                soft_valid_cross_sim_AB_sp = soft_cross_sim_AtoB_sp[mask_pointA, :-2][match_maskAB==1]
                # soft_valid_cross_sim_BA = soft_cross_sim_BtoA[mask_pointB, :-1][pairBA_B, pairBA_A]
                soft_novalid_cross_sim_AB_sp = soft_cross_sim_AtoB_sp[novalid_indexesA, -1]
                # soft_novalid_cross_sim_BA = soft_cross_sim_BtoA[cross_sim_BA_out[:, -1]==1, -1]
                log_soft_valid_cross_sim_AB_sp = -torch.log(soft_valid_cross_sim_AB_sp + eps) * (1 - dis_oriATB[match_maskAB==1] / self.ori_diff) * (1 - bin_distAB[mask_pointA, :][match_maskAB==1] / current_binA.shape[-1]) * (1 - key_disAB[match_maskAB==1].detach() / self.correspond)
                # log_soft_valid_cross_sim_BA = -torch.log(soft_valid_cross_sim_BA + eps)
                log_soft_novalid_cross_sim_AB_sp = -torch.log(soft_novalid_cross_sim_AB_sp + eps)
                # log_soft_novalid_cross_sim_BA = -torch.log(soft_novalid_cross_sim_BA + eps)
                dis_cross_sim_mean_sp = torch.sum(torch.cat((4*log_soft_valid_cross_sim_AB_sp, log_soft_novalid_cross_sim_AB_sp), dim=-1), dim=-1) / new_numA
                
                # PA VS PAB
                # match_mask_A = copy.deepcopy(mask_pointA)
                # match_mask_B = copy.deepcopy(mask_pointB)
                match_mask_A = torch.zeros(cross_sim_AB_sp.shape[0], device=self.device)
                match_mask_nb_A = torch.zeros(cross_sim_AB_sp.shape[0], device=self.device)
                valid_match_indexesA = torch.tensor(list(range(cross_sim_AB_sp.shape[0])), device=self.device)[mask_pointA][vmaskAH]
                valid_match_indexesA_nb = torch.tensor(list(range(cross_sim_AB_sp.shape[0])), device=self.device)[mask_pointA][vmaskAH_nb]
                match_mask_A[valid_match_indexesA] = 1
                match_mask_nb_A[valid_match_indexesA_nb] = 1

                match_mask_B = torch.zeros(cross_sim_AB_sp.shape[1], device=self.device)
                match_mask_nb_B = torch.zeros(cross_sim_AB_sp.shape[1], device=self.device)
                valid_match_indexesB = torch.tensor(list(range(cross_sim_AB_sp.shape[1])), device=self.device)[mask_pointB][vmaskBH]
                valid_match_indexesB_nb = torch.tensor(list(range(cross_sim_AB_sp.shape[1])), device=self.device)[mask_pointB][vmaskBH_nb]
                match_mask_B[valid_match_indexesB] = 1
                match_mask_nb_B[valid_match_indexesB_nb] = 1

                cross_sim_AB = current_descA @ desc_mapB[idx, :, :, :].view(-1, H * W)
                # cross_sim_AB = cross_sim_AB[mask_pointA, :]
                cross_sim_AB_all = F.grid_sample(cross_sim_AB.view(-1, H, W).unsqueeze(0),
                                                pntA_H_normalized[vmaskAH, :].detach().view(1, 1, -1, 2),
                                                mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NA x repeatNA
                valid_cross_sim_AB_mean = torch.trace(cross_sim_AB_all[match_mask_A==1, :]) / cross_sim_AB_all[match_mask_A==1, :].shape[0]
                # novalid_cross_sim_AB_mean = (torch.sum(torch.sum(cross_sim_AB.detach(), 1), 1) - valid_cross_sim_AB_mean * pairAB_A.shape[0]) / (new_numA * H * W - pairAB_A.shape[0])

                cross_sim_BA = current_descB @ desc_mapA[idx, :, :, :].view(-1, H * W)   # M x H x W
                # cross_sim_BA = cross_sim_BA[mask_pointB, :]
                cross_sim_BA_all = F.grid_sample(cross_sim_BA.view(-1, H, W).unsqueeze(0),
                                                pntB_invH_normalized[vmaskBH, :].detach().view(1, 1, -1, 2),
                                                mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NB x match_nB
                valid_cross_sim_BA_mean = torch.trace(cross_sim_BA_all[match_mask_B==1, :]) / cross_sim_BA_all[match_mask_B==1, :].shape[0]
                # novalid_cross_sim_BA_mean = (torch.sum(torch.sum(cross_sim_BA.detach(), 1), 1) - valid_cross_sim_BA_mean * pairBA_B.shape[0]) / (new_numB * H * W - pairBA_B.shape[0])

                cross_sim_AB_out = torch.cat((cross_sim_AB, torch.ones((cross_sim_AB.shape[0], 2), device=cross_sim_AB.device)), dim=-1)      # NA X (H X W + 2)
                cross_sim_BA_out = torch.cat((cross_sim_BA, torch.ones((cross_sim_BA.shape[0], 2), device=cross_sim_BA.device)), dim=-1)      # NB X (H X W + 2)
                # print(3)
                # cross_sim_AB_out[mask_pointA, -1] -= 1
                # cross_sim_BA_out[mask_pointB, -1] -= 1
                # cross_sim_AB_out[match_mask_A, -1] -= 1
                cross_sim_AB_out[match_mask_A==1, -1] = novalid_cross_sim_AB_sp_mean
                cross_sim_AB_out[match_mask_A==1, -2] = crossAN_mean
                cross_sim_AB_out[match_mask_nb_A==0, -1] = valid_cross_sim_AB_mean
                cross_sim_AB_out[match_mask_nb_A==0, -2] = -1 # crossAN_mean # -1

                cross_sim_BA_out[match_mask_B==1, -1] = novalid_cross_sim_BA_sp_mean
                cross_sim_BA_out[match_mask_B==1, -2] = crossBN_mean
                cross_sim_BA_out[match_mask_nb_B==0, -1] = valid_cross_sim_BA_mean
                cross_sim_BA_out[match_mask_nb_B==0, -2] = -1 # crossBN_mean # -1

                soft_cross_sim_AtoB = F.softmax((cross_sim_AB_out - 1) / t_des, dim=-1)         # NA X (H X W + 1)
                soft_cross_sim_BtoA = F.softmax((cross_sim_BA_out - 1) / t_des, dim=-1)         # NB X (H X W + 1)
                soft_cross_sim_AB_all = F.grid_sample(soft_cross_sim_AtoB[:, :-2].view(-1, H, W).unsqueeze(0),
                                                    pntA_H_normalized[vmaskAH, :].detach().view(1, 1, -1, 2),
                                                    mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NA x match_nA
                
                soft_cross_sim_BA_all = F.grid_sample(soft_cross_sim_BtoA[:, :-2].view(-1, H, W).unsqueeze(0),
                                                    pntB_invH_normalized[vmaskBH, :].detach().view(1, 1, -1, 2),
                                                    mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NB x match_nB
                # soft_valid_cross_sim_AB_all = soft_cross_sim_AB_all[mask_pointA, :]             # repeat_nA x repeat_nA
                # soft_valid_cross_sim_BA_all = soft_cross_sim_BA_all[mask_pointB, :]             # repeat_nB x repeat_nB

                soft_valid_cross_sim_AB_all = soft_cross_sim_AB_all[match_mask_A==1, :]             # match_nA x match_nA
                soft_valid_cross_sim_BA_all = soft_cross_sim_BA_all[match_mask_B==1, :]             # match_nB x match_nB

                valid_mask_AB = torch.eye(soft_valid_cross_sim_AB_all.shape[0]) == 1
                valid_mask_BA = torch.eye(soft_valid_cross_sim_BA_all.shape[0]) == 1
                # print(4)
                # 取对角线
                soft_valid_cross_sim_AB = soft_valid_cross_sim_AB_all[valid_mask_AB]
                soft_valid_cross_sim_BA = soft_valid_cross_sim_BA_all[valid_mask_BA]

                # soft_novalid_cross_sim_AB = soft_cross_sim_AtoB[mask_pointA==False, -1]              # (NA-repeat_nA) x 1
                # soft_novalid_cross_sim_BA = soft_cross_sim_BtoA[mask_pointB==False, -1]
                soft_novalid_cross_sim_AB = soft_cross_sim_AtoB[match_mask_nb_A==0, -1]               # (NA-match_nA) x 1
                soft_novalid_cross_sim_BA = soft_cross_sim_BtoA[match_mask_nb_B==0, -1]
                # print(soft_novalid_cross_sim_AB, soft_novalid_cross_sim_BA)

                log_soft_valid_cross_sim_AB = -torch.log(soft_valid_cross_sim_AB + eps) * (1 - torch.diag(dis_oriATAB)[vmaskAH] / self.ori_diff) * (1 - torch.diag(bin_distATAB[mask_pointA, :])[vmaskAH] / bin_kpAB_T.shape[0])
                log_soft_valid_cross_sim_BA = -torch.log(soft_valid_cross_sim_BA + eps) * (1 - torch.diag(dis_oriBTBA)[vmaskBH] / self.ori_diff) * (1 - torch.diag(bin_distBTBA[mask_pointB, :])[vmaskBH] / bin_kpBA_T.shape[0])
                log_soft_novalid_cross_sim_AB = -torch.log(soft_novalid_cross_sim_AB + eps)
                log_soft_novalid_cross_sim_BA = -torch.log(soft_novalid_cross_sim_BA + eps)

                dis_cross_sim_mean = torch.sum(torch.cat((4*log_soft_valid_cross_sim_AB, 4*log_soft_valid_cross_sim_BA, log_soft_novalid_cross_sim_AB, log_soft_novalid_cross_sim_BA), dim=-1), dim=-1) / (new_numA + new_numB)
                
                # print(5)
                valid_cross_sim_AB = cross_sim_AB[mask_pointA, :]   # repeat_nA x (H X W)
                valid_cross_sim_BA = cross_sim_BA[mask_pointB, :]   # repeat_nB x (H X W)
                exp_valid_cross_sim_AtoB = torch.exp((valid_cross_sim_AB - 1) / t_rel).view(-1, H, W)
                exp_valid_cross_sim_BtoA = torch.exp((valid_cross_sim_BA - 1) / t_rel).view(-1, H, W)
                exp_valid_cross_sim_AB_all = F.grid_sample(exp_valid_cross_sim_AtoB.unsqueeze(0),
                                                        pntA_H_normalized.detach().view(1, 1, -1, 2),
                                                        mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # repeat_nA x repeat_nA
                
                exp_valid_cross_sim_BA_all = F.grid_sample(exp_valid_cross_sim_BtoA.unsqueeze(0),
                                                        pntB_invH_normalized.detach().view(1, 1, -1, 2),
                                                        mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # repeat_nB x repeat_nB

                repeat_mask_AB = torch.eye(exp_valid_cross_sim_AB_all.shape[0]) == 1
                repeat_mask_BA = torch.eye(exp_valid_cross_sim_BA_all.shape[0]) == 1
                rel_valid_cross_sim_AB = exp_valid_cross_sim_AB_all[repeat_mask_AB]
                rel_valid_cross_sim_BA = exp_valid_cross_sim_BA_all[repeat_mask_BA]

                # pntA_H_normalized_new = copy.deepcopy(pntA_H_normalized.detach())
                # pntB_invH_normalized_new = copy.deepcopy(pntB_invH_normalized.detach())

                # pntA_H_normalized_new[:, 0] += 2
                # pntB_invH_normalized_new[:, 0] += 2

                scoresAB_all = F.grid_sample(scores_mapB[idx, :, :, :].unsqueeze(0),
                                            pntA_H_normalized_new.view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)      # 1 x repeat_nA

                scoresBA_all = F.grid_sample(scores_mapA[idx, :, :, :].unsqueeze(0),
                                            pntB_invH_normalized_new.view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)      # 1 x repeat_nB
                # print(6)
                scores_AAB = scoresA[idx][pmA][mask_pointA] * scoresAB_all
                scores_BBA = scoresB[idx][pmB][mask_pointB] * scoresBA_all
                scores_sum_AAB = torch.sum(scores_AAB, dim=-1)
                scores_sum_BBA = torch.sum(scores_BBA, dim=-1)
                scores_normalize_AAB = scores_AAB / (scores_sum_AAB + eps)
                scores_normalize_BBA = scores_BBA / (scores_sum_BBA + eps)
                rel_meanA = torch.sum(scores_normalize_AAB * (1 - rel_valid_cross_sim_AB), dim=-1) / pntA_H_normalized_new.shape[0]
                rel_meanB = torch.sum(scores_normalize_BBA * (1 - rel_valid_cross_sim_BA), dim=-1) / pntB_invH_normalized_new.shape[0]

                # # 熵loss
                # current_descA_std, current_descB_std = descA_std[countA:countA+new_numA], descB_std[countB:countB+new_numB]
                # desc_std += torch.mean(current_descA_std) + torch.mean(current_descB_std)
                # countA_T += numA_T
                # countB_T += numB_T

                dis_neighbor_mean_total += torch.mean(torch.sum(neighbor_dis_AB, dim=1)) + torch.mean(torch.sum(neighbor_dis_BA, dim=1))
                dis_desc += dis_cross_sim_mean_sp
                dis_desc += dis_cross_sim_mean

                dis_pair_meanAB = torch.mean(key_manhattandisAB[pairAB_A, pairAB_B])
                dis_pair_meanBA = torch.mean(key_manhattandisBA[pairBA_B, pairBA_A])

                dis_peak_mean = torch.mean(torch.cat((scoreddisA[idx][pmA], scoreddisB[idx][pmB]), dim=0))
                # dis_peak_meanB = torch.mean(scoreddisB[idx])
                
                dis_mean_total += dis_pair_meanAB + dis_pair_meanBA
                dis_peak_scored += dis_peak_mean

                dis_rel += rel_meanA + rel_meanB
                
                countA += new_numA
                countB += new_numB
                count_ne += new_num_ne
                # # Penalty
                # scores_mean += (-torch.log(torch.mean(scoresA[idx], dim=-1) + eps) - torch.log(torch.mean(scoresB[idx], dim=-1) + eps)) 
                # print(scores_mean)
            except:
                # dis_mean_total += 0
                # dis_peak_scored += 0
                # dis_desc += 0
                # dis_rel += 0
                # print('Overlapping too small or Repeatable point pairs distance is greater than correspond(1.5):', pntA.shape[0], pntA_H.shape[0], pntB.shape[0], pntB_invH.shape[0], dis_pairAB.shape[0], dis_pairBA.shape[0])
                valid_batch_size -= 1
                countA += new_numA
                countB += new_numB
                count_ne += new_num_ne
                # countA_T += numA_T
                # countB_T += numB_T

        valid_batch_size = valid_batch_size if valid_batch_size > 0 else eps
        # Reprojection Loss 
        reprojection_loss = dis_mean_total / (valid_batch_size * 2)
        # Dispersity Peak Loss
        dispersity_peak_loss = dis_peak_scored / valid_batch_size
        # NRE Loss
        descriptor_loss = dis_desc / (2 * valid_batch_size)
        # Reliability Loss
        reliability_loss = dis_rel / (valid_batch_size * 2)
        # SOSR Loss
        sosr_loss = dis_neighbor_mean_total / ((valid_batch_size * 2))
        # # Entropy loss
        # std_loss = (valid_batch_size * 2) / desc_std  
        # # Score Penalty
        # score_penalty = scores_mean / (valid_batch_size * 2)
        # FA Desc loss
        FA_des_loss = dis_desc_fa / valid_batch_size_FA if valid_batch_size_FA > 0 else 0

        loss_total = wrp * reprojection_loss + wpl * dispersity_peak_loss + wdl * descriptor_loss + wrl * reliability_loss + sosr_loss + FA_des_loss
        loss_group = {
            'reprojection_loss': reprojection_loss, 
            'dispersity_peak_loss': dispersity_peak_loss,
            'descriptor_loss': descriptor_loss,
            'reliability_loss': reliability_loss,
            'sosr_loss': sosr_loss,
            # 'std_loss': std_loss,
            'FA_des_loss': FA_des_loss,
            }
        return loss_total, loss_group

    # patch/dense AT角度 黑白相似度加量化 FA two negtives
    def detector_selfsupervised_loss_dkd_patch_ext_restrict_modify_oriR_ratio_FA_qtbw_ns_wg_nori_AT_NE2(self, kpA, kpB, pmaskA, pmaskB, descA, descB, desc_mapA, desc_mapB, scoreddisA, scoreddisB, scoresA, scoresB, scores_mapA, scores_mapB, Homo, inv_Homo, inv_Homo_en, ori_all_patchA, ori_all_patchB, ori_kp_patchA, ori_kp_patchB, bin_allA, bin_allB, bin_kpA, bin_kpB, kp_ne, pmask_ne, desc_ne, bin_kp_ne, kp_ne2, pmask_ne2, desc_ne2, bin_kp_ne2, trans_angle, FA_flag, H, W, wrp=1, wpl=1, wdl=1, wrl=1, t_des=0.02, t_rel=1):
        # pmaskA: (BxMax_num) 32x350=11200
        batch_size = len(kpA)
        max_num = pmaskA.shape[-1] // batch_size    # 350
        dis_mean_total = 0
        dis_neighbor_mean_total = 0
        dis_peak_scored = 0
        dis_desc = 0
        dis_rel = 0
        desc_std = 0
        eps = 1e-12
        valid_batch_size = batch_size
        valid_batch_size_FA = 0
        countA, countB, count_ne, count_ne2 = 0, 0, 0, 0
        dis_desc_fa = 0
        # countA_T, countB_T = 0, 0
        for idx in range(batch_size):
            pntA, pntB, pnt_ne, pnt_ne2 = kpA[idx], kpB[idx], kp_ne[idx], kp_ne2[idx]     # M X 2 (x,y)
            # kmask_TA, kmask_TB = kmask_T_allA[idx], kmask_T_allB[idx]
            pntA = pntA.float()
            pntB = pntB.float()
            pnt_ne = pnt_ne.float()
            pnt_ne2 = pnt_ne2.float()

            # 剔除部分按压区域的点,且保留在重叠区域的点
            numA, numB, num_ne, num_ne2 = pntA.shape[0], pntB.shape[0], pnt_ne.shape[0], pnt_ne2.shape[0]
            # numA_T, numB_T = pntA[kmask_TA].shape[0], pntB[kmask_TB].shape[0]
            pmA, pmB, pm_ne, pm_ne2 = pmaskA[max_num * idx:max_num * idx + numA].bool(), pmaskB[max_num * idx:max_num * idx + numB].bool(), pmask_ne[max_num * idx:max_num * idx + num_ne].bool(), pmask_ne2[max_num * idx:max_num * idx + num_ne2].bool()
            pntA, pntB, pnt_ne, pnt_ne2 = pntA[pmA, :], pntB[pmB, :], pnt_ne[pm_ne, :], pnt_ne2[pm_ne2, :] 
            new_numA, new_numB, new_num_ne, new_num_ne2 = pntA.shape[0], pntB.shape[0], pnt_ne.shape[0], pnt_ne2.shape[0]      
            
            pntA = (pntA + 1) / 2 * pntA.new_tensor([[W + 3, H - 1]]).to(pntA.device)
            pntB = (pntB + 1) / 2 * pntB.new_tensor([[W + 3, H - 1]]).to(pntB.device)

            # [120, 40] -> [120, 36],实际只取中心118x32区域的点对
            pntA[:, 0] -= 2
            pntB[:, 0] -= 2
            
            pntA_normalized = pntA / pntA.new_tensor([W - 1, H - 1]).to(pntA.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)
            pntB_normalized = pntB / pntB.new_tensor([W - 1, H - 1]).to(pntB.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)

            pntA_H = warp_points(pntA[:, :2], Homo[idx].squeeze(), device=self.device)  # 利用变换矩阵变换坐标点
            pntA_H, mask_pointA = filter_points(pntA_H, torch.tensor([W, H], device=self.device), return_mask=True)
            pntB_invH = warp_points(pntB[:, :2], inv_Homo[idx].squeeze(), device=self.device)
            pntB_invH, mask_pointB = filter_points(pntB_invH, torch.tensor([W, H], device=self.device), return_mask=True)
            
            current_descA, current_descB = descA[countA:countA+new_numA], descB[countB:countB+new_numB]
            current_desc_ne = desc_ne[count_ne:count_ne+new_num_ne]
            current_desc_ne2 = desc_ne2[count_ne2:count_ne2+new_num_ne2]
            cross_sim_AB_sp = current_descA @ current_descB.transpose(0, 1)     # NTA X NTB
            
            cross_sim_AN_sp = current_descA @ current_desc_ne.transpose(0, 1)
            cross_sim_BN_sp = current_descB @ current_desc_ne.transpose(0, 1)
            cross_sim_AN2_sp = current_descA @ current_desc_ne2.transpose(0, 1)
            cross_sim_BN2_sp = current_descB @ current_desc_ne2.transpose(0, 1)
            
            # 黑白相似度
            current_binA, current_binB = (bin_kpA[countA:countA+new_numA] >= 0.5).float(), (bin_kpB[countB:countB+new_numB] >= 0.5).float()   # [NA, 256] [NB_256]
            current_bin_ne = (bin_kp_ne[count_ne:count_ne+new_num_ne] >= 0.5).float()
            current_bin_ne2 = (bin_kp_ne2[count_ne2:count_ne2+new_num_ne2] >= 0.5).float()
            bin_distAB = current_binA.shape[-1] - (current_binA @ current_binB.transpose(0, 1)) - ((1 - current_binA) @ (1 - current_binB.transpose(0, 1))) # [NA, NB]
            
            bin_distAN = current_binA.shape[-1] - (current_binA @ current_bin_ne.transpose(0, 1)) - ((1 - current_binA) @ (1 - current_bin_ne.transpose(0, 1))) # [NA, NE]
            bin_distBN = current_binB.shape[-1] - (current_binB @ current_bin_ne.transpose(0, 1)) - ((1 - current_binB) @ (1 - current_bin_ne.transpose(0, 1))) # [NA, NE]
            bin_distAN2 = current_binA.shape[-1] - (current_binA @ current_bin_ne2.transpose(0, 1)) - ((1 - current_binA) @ (1 - current_bin_ne2.transpose(0, 1))) # [NA, NE]
            bin_distBN2 = current_binB.shape[-1] - (current_binB @ current_bin_ne2.transpose(0, 1)) - ((1 - current_binB) @ (1 - current_bin_ne2.transpose(0, 1))) # [NA, NE]
            
             # Net FA余弦相似度小
            if FA_flag[idx] == 1:
                FA_bin_mask = bin_distAB >= (1 - self.FA_bin_thr) * current_binA.shape[-1] 

                dis_desc_fa += (2 - torch.mean(torch.sqrt(2 * (1 - cross_sim_AB_sp[FA_bin_mask]) + eps)))

                valid_batch_size -= 1
                valid_batch_size_FA += 1
                countA += new_numA
                countB += new_numB
                continue

            # 真匹配的trans
            try:
                FAN_bin_mask = bin_distAN >= (1 - self.FA_bin_thr) * current_binA.shape[-1] 
                FBN_bin_mask = bin_distBN >= (1 - self.FA_bin_thr) * current_binB.shape[-1] 
                FAN2_bin_mask = bin_distAN2 >= (1 - self.FA_bin_thr) * current_binA.shape[-1] 
                FBN2_bin_mask = bin_distBN2 >= (1 - self.FA_bin_thr) * current_binB.shape[-1] 
                # topk ?
                crossAN_mean = torch.mean(cross_sim_AN_sp[FAN_bin_mask])
                crossBN_mean = torch.mean(cross_sim_BN_sp[FBN_bin_mask])
                crossAN2_mean = torch.mean(cross_sim_AN2_sp[FAN2_bin_mask])
                crossBN2_mean = torch.mean(cross_sim_BN2_sp[FBN2_bin_mask])

                assert pntA_H.shape[0] > 0 and pntB_invH.shape[0] > 0 
                
                # 点对欧氏距离
                key_disAB = self.get_dis(pntA_H[:, :2], pntB[:, :2])            # repeatNA x NB
                key_disBA = self.get_dis(pntB_invH[:, :2], pntA[:, :2])
                pairAB_A, pairAB_B, dis_pairAB, _ = self.get_point_pair(key_disAB, dis_thre=self.correspond)  # p -> k # NTA(<1.5), NTA(<1.5), NTA(<1.5), NTA        
                pairBA_B, pairBA_A, dis_pairBA, _  = self.get_point_pair(key_disBA, dis_thre=self.correspond)  # p -> k # NTB(<1.5), NTB(<1.5), NTB(<1.5), NTB 
                
                # 点距离mask
                nn_maskAB = torch.zeros((pntA_H.shape[0], pntB.shape[0]), device=self.device) 
                nn_maskAB[pairAB_A, pairAB_B] = 1

                nn_maskBA = torch.zeros((pntB_invH.shape[0], pntA.shape[0]), device=self.device) 
                nn_maskBA[pairBA_B, pairBA_A] = 1

                # 点对曼哈顿距离
                key_manhattandisAB = self.get_manhattan_dis(pntA_H[:, :2], pntB[:, :2])
                key_manhattandisBA = self.get_manhattan_dis(pntB_invH[:, :2], pntA[:, :2])
                # print('pdis:', dis_pairAB.shape[0], dis_pairBA.shape[0])
                assert dis_pairAB.shape[0] > 0 and dis_pairBA.shape[0] > 0     

                pntA_H_normalized = pntA_H / pntA_H.new_tensor([W - 1, H - 1]).to(pntA_H.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)
                pntB_invH_normalized = pntB_invH / pntB_invH.new_tensor([W - 1, H - 1]).to(pntB_invH.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)

                # 用于score_map
                pntA_H_new = copy.deepcopy(pntA_H.detach())
                pntB_invH_new = copy.deepcopy(pntB_invH.detach())
                pntA_H_new[:, 0] += 10                   # 120 x 36 -> 128 x 56
                pntA_H_new[:, 1] += 4 
                pntB_invH_new[:, 0] += 10
                pntB_invH_new[:, 1] += 4
                
                pntA_H_normalized_new = pntA_H_new / pntA_H_new.new_tensor([W + 19, H + 7]).to(pntA_H.device) * 2 - 1

                # pntB_invH_new = warp_points(pntB_invH_new[:, :2], inv_Homo_en[idx].squeeze(), device=self.device)       # 转到A上，而不是AT上
                
                pntB_invH_normalized_new = pntB_invH_new / pntB_invH_new.new_tensor([W + 19, H + 7]).to(pntB_invH.device) * 2 - 1 
                
                # print('1_2:', main_ori_maskATB.shape[0])
                # exit()
                ori_kpAT_patch_ext = F.grid_sample(ori_kp_patchA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntA_H_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0).transpose(0, 1)          # repeatNA x 1
                ori_kpB_patch_ext = F.grid_sample(ori_all_patchB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntB_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0).transpose(0, 1)          # NTB x 1
                ori_kpA_patch_ext = F.grid_sample(ori_all_patchA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntA_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0).transpose(0, 1)          # NTA x 1
                ori_kpBT_patch_ext = F.grid_sample(ori_kp_patchB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntB_invH_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0).transpose(0, 1)          # repeatNB x 1
                # print('1_2_1:', pntB_invH_normalized_new.shape[0])
                ori_maskATB, dis_oriATB = self.get_main_ori_consistence_AT(ori_kpAT_patch_ext, ori_kpB_patch_ext)  # repeatNA x NTB
                # print('1_2_2:', ori_maskATB.shape)
                ori_maskBTA, dis_oriBTA = self.get_main_ori_consistence_AT(ori_kpBT_patch_ext, ori_kpA_patch_ext)  # repeatNB x NTA

                match_maskAB_nb = (nn_maskAB == 1) * ori_maskATB           # repeatNA X NTB
                match_maskBA_nb = (nn_maskBA == 1) * ori_maskBTA          # repeatNB X NTA
                pairAB_A_nb_new, pairAB_B_nb_new = torch.where(match_maskAB_nb == 1)
                pairBA_B_nb_new, pairBA_A_nb_new = torch.where(match_maskBA_nb == 1)
                # assert pairAB_A_new.shape[0] > 0 and pairBA_B_new.shape[0] > 0 

                # 4x4邻域方向一致性
                ori_kpAB_patch_ext = F.grid_sample(ori_all_patchB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntA_H_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0).transpose(0, 1)  
                ori_kpBA_patch_ext = F.grid_sample(ori_all_patchA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntB_invH_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0).transpose(0, 1)  
                # print('1_2_4:', ori_kpAB_patch_ext.shape)
                ori_maskATAB, dis_oriATAB = self.get_main_ori_consistence_AT(ori_kpAT_patch_ext, ori_kpAB_patch_ext)  # repeatNA x repeatNA
                ori_maskBTBA, dis_oriBTBA = self.get_main_ori_consistence_AT(ori_kpBT_patch_ext, ori_kpBA_patch_ext)  # repeatNB x repeatNB
                
                # 黑白相似度
                bin_maskATB = bin_distAB <= (1 - self.FR_bin_thr) * current_binA.shape[-1]  
                bin_maskBTA = bin_maskATB.transpose(0, 1)  

                match_maskAB = match_maskAB_nb * bin_maskATB[mask_pointA, :]               # repeatNA X NB
                match_maskBA = match_maskBA_nb * bin_maskBTA[mask_pointB, :]               # repeatNB X NA

                pairAB_A_new, pairAB_B_new = torch.where(match_maskAB == 1)
                pairBA_B_new, pairBA_A_new = torch.where(match_maskBA == 1)
                # print('bin_mask:', pairAB_A_new.shape[0], pairBA_B_new.shape[0])
                assert pairAB_A_new.shape[0] > 0 and pairBA_B_new.shape[0] > 0 

                bin_kpAB_T = (F.grid_sample(bin_allB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntA_H_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0) >= 0.5).float()  # [256, repeatNA]
                bin_kpBA_T = (F.grid_sample(bin_allA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntB_invH_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0) >= 0.5).float()  # [256, repeatNB]
                bin_distATAB = bin_kpAB_T.shape[0] - (current_binA @ bin_kpAB_T) - ((1 - current_binA) @ (1 - bin_kpAB_T)) # [NTA, repeatNA]
                bin_distBTBA = bin_kpBA_T.shape[0] - (current_binB @ bin_kpBA_T) - ((1 - current_binB) @ (1 - bin_kpBA_T)) # [NTB, repeatNB]

                bin_maskATAB = bin_distATAB <= (1 - self.FR_bin_thr) * bin_kpAB_T.shape[0] 
                bin_maskBTBA = bin_distBTBA <= (1 - self.FR_bin_thr) * bin_kpBA_T.shape[0] 
                bin_maskATAB = bin_maskATAB[mask_pointA, :]
                bin_maskBTBA = bin_maskBTBA[mask_pointB, :]

                vmaskAH_nb = torch.diag(ori_maskATAB)
                vmaskBH_nb = torch.diag(ori_maskBTBA)
                vmaskAH = torch.diag(ori_maskATAB * bin_maskATAB) == 1      # [repeatNA, 1]
                vmaskBH = torch.diag(ori_maskBTBA * bin_maskBTBA) == 1      # [repeatNB, 1]

                # print('main_ori:', torch.sum(vmaskAH), torch.sum(vmaskBH))
                assert torch.sum(vmaskAH) > 0 and torch.sum(vmaskBH) > 0

                # SOSR: 简化的self-attention
                k_neighbor = 3
                cross_sim_AA_sp = current_descA @ current_descA.transpose(0, 1)
                cross_sim_BB_sp = current_descB @ current_descB.transpose(0, 1)
                # print('SOSR:', pairAB_A_new.shape[0], pairBA_B_new.shape[0])
                assert pairAB_A_new.shape[0] >= k_neighbor and pairBA_B_new.shape[0] >= k_neighbor 

                match_sim_AB_AA = cross_sim_AA_sp[mask_pointA, :][:, mask_pointA][pairAB_A_new, :][:, pairAB_A_new]
                match_sim_BA_BB = cross_sim_BB_sp[mask_pointB, :][:, mask_pointB][pairBA_B_new, :][:, pairBA_B_new]
                match_sim_AB_BB = cross_sim_BB_sp[pairAB_B_new, :][:, pairAB_B_new]
                match_sim_BA_AA = cross_sim_AA_sp[pairBA_A_new, :][:, pairBA_A_new]
                match_values_AB_AA, match_indices_AB_AA = torch.topk(match_sim_AB_AA, dim=1, k=k_neighbor, largest=False)
                match_values_BA_BB, match_indices_BA_BB = torch.topk(match_sim_BA_BB, dim=1, k=k_neighbor, largest=False)
                match_values_AB_BB_all = match_sim_AB_BB[:, match_indices_AB_AA]
                match_values_BA_AA_all = match_sim_BA_AA[:, match_indices_BA_BB]
                match_values_AB_BB = torch.diagonal(match_values_AB_BB_all, 0, dim1=0, dim2=1).transpose(0, 1)
                match_values_BA_AA = torch.diagonal(match_values_BA_AA_all, 0, dim1=0, dim2=1).transpose(0, 1)
                neighbor_dis_AB = (match_values_AB_AA - match_values_AB_BB) * (match_values_AB_AA - match_values_AB_BB)
                neighbor_dis_BA = (match_values_BA_BB - match_values_BA_AA) * (match_values_BA_BB - match_values_BA_AA)

                # PA VS PB
                # 计算bin值
                valid_cross_sim_AB_sp_mean = torch.mean(cross_sim_AB_sp[mask_pointA, :][match_maskAB == 1], dim=-1)
                valid_cross_sim_AB_sp_nb_mean = torch.mean(cross_sim_AB_sp[mask_pointA, :][match_maskAB_nb == 1], dim=-1)
                novalid_cross_sim_AB_sp_mean = (torch.sum(torch.sum(cross_sim_AB_sp.detach(), 1), 0) - valid_cross_sim_AB_sp_nb_mean * pairAB_A_nb_new.shape[0]) / (new_numA * new_numB - pairAB_A_nb_new.shape[0] + eps)
                valid_cross_sim_BA_sp_mean = torch.mean(cross_sim_AB_sp[:, mask_pointB][match_maskBA.transpose(0, 1) == 1], dim=-1)
                valid_cross_sim_BA_sp_nb_mean = torch.mean(cross_sim_AB_sp[:, mask_pointB][match_maskBA_nb.transpose(0, 1) == 1], dim=-1)
                novalid_cross_sim_BA_sp_mean = (torch.sum(torch.sum(cross_sim_AB_sp.detach(), 1), 0) - valid_cross_sim_BA_sp_nb_mean * pairBA_B_nb_new.shape[0]) / (new_numA * new_numB - pairBA_B_nb_new.shape[0] + eps)

                valid_indexesA = torch.tensor(list(range(cross_sim_AB_sp.shape[0])), device=self.device)[mask_pointA][pairAB_A_new]
                valid_indexesA_nb = torch.tensor(list(range(cross_sim_AB_sp.shape[0])), device=self.device)[mask_pointA][pairAB_A_nb_new]
                # cross_sim_BA_sp = current_descB @ current_descA.transpose(0, 1)
                cross_sim_AB_out_sp = torch.cat((cross_sim_AB_sp, torch.ones((cross_sim_AB_sp.shape[0], 3), device=cross_sim_AB_sp.device) * 2), dim=-1)      # NA X (NB + 2)
                cross_sim_AB_out_nb_sp = torch.cat((cross_sim_AB_sp, torch.ones((cross_sim_AB_sp.shape[0], 3), device=cross_sim_AB_sp.device) * 2), dim=-1)      # NA X (NB + 2)
                # cross_sim_BA_out_sp = torch.cat((cross_sim_BA_sp, torch.ones((numB, 1), device=cross_sim_BA_sp.device)), dim=-1)      # NB X (NA + 1)
                # valid_indexesB = torch.tensor(list(range(numB)), device=self.device)[mask_pointB][pairBA_B]
                # print('1_2')
                cross_sim_AB_out_sp[valid_indexesA, -1] = novalid_cross_sim_AB_sp_mean
                cross_sim_AB_out_sp[valid_indexesA, -2] = crossAN_mean
                cross_sim_AB_out_sp[valid_indexesA, -3] = crossAN2_mean
                cross_sim_AB_out_nb_sp[valid_indexesA_nb, -1] = novalid_cross_sim_AB_sp_mean
                novalid_indexesA = torch.tensor(list(range(cross_sim_AB_sp.shape[0])), device=self.device)[cross_sim_AB_out_nb_sp[:, -1]==2]
                cross_sim_AB_out_sp[novalid_indexesA, -1] = valid_cross_sim_AB_sp_mean
                # nomatch对不增加negtives的均值bin
                cross_sim_AB_out_sp[novalid_indexesA, -2] = -1 # crossAN_mean # -1
                cross_sim_AB_out_sp[novalid_indexesA, -3] = -1 # crossAN_mean # -1

                soft_cross_sim_AtoB_sp = F.softmax((cross_sim_AB_out_sp - 1) / t_des, dim=-1)
                # soft_cross_sim_BtoA = F.softmax((cross_sim_BA_out - 1) / t_des, dim=-1)
                # print('1_3')
                soft_valid_cross_sim_AB_sp = soft_cross_sim_AtoB_sp[mask_pointA, :-3][match_maskAB==1]
                # soft_valid_cross_sim_BA = soft_cross_sim_BtoA[mask_pointB, :-1][pairBA_B, pairBA_A]
                soft_novalid_cross_sim_AB_sp = soft_cross_sim_AtoB_sp[novalid_indexesA, -1]
                # soft_novalid_cross_sim_BA = soft_cross_sim_BtoA[cross_sim_BA_out[:, -1]==1, -1]
                log_soft_valid_cross_sim_AB_sp = -torch.log(soft_valid_cross_sim_AB_sp + eps) * (1 - dis_oriATB[match_maskAB==1] / self.ori_diff) * (1 - bin_distAB[mask_pointA, :][match_maskAB==1] / current_binA.shape[-1]) * (1 - key_disAB[match_maskAB==1].detach() / self.correspond)
                # log_soft_valid_cross_sim_BA = -torch.log(soft_valid_cross_sim_BA + eps)
                log_soft_novalid_cross_sim_AB_sp = -torch.log(soft_novalid_cross_sim_AB_sp + eps)
                # log_soft_novalid_cross_sim_BA = -torch.log(soft_novalid_cross_sim_BA + eps)
                dis_cross_sim_mean_sp = torch.sum(torch.cat((4*log_soft_valid_cross_sim_AB_sp, log_soft_novalid_cross_sim_AB_sp), dim=-1), dim=-1) / new_numA
                
                # PA VS PAB
                # match_mask_A = copy.deepcopy(mask_pointA)
                # match_mask_B = copy.deepcopy(mask_pointB)
                match_mask_A = torch.zeros(cross_sim_AB_sp.shape[0], device=self.device)
                match_mask_nb_A = torch.zeros(cross_sim_AB_sp.shape[0], device=self.device)
                valid_match_indexesA = torch.tensor(list(range(cross_sim_AB_sp.shape[0])), device=self.device)[mask_pointA][vmaskAH]
                valid_match_indexesA_nb = torch.tensor(list(range(cross_sim_AB_sp.shape[0])), device=self.device)[mask_pointA][vmaskAH_nb]
                match_mask_A[valid_match_indexesA] = 1
                match_mask_nb_A[valid_match_indexesA_nb] = 1

                match_mask_B = torch.zeros(cross_sim_AB_sp.shape[1], device=self.device)
                match_mask_nb_B = torch.zeros(cross_sim_AB_sp.shape[1], device=self.device)
                valid_match_indexesB = torch.tensor(list(range(cross_sim_AB_sp.shape[1])), device=self.device)[mask_pointB][vmaskBH]
                valid_match_indexesB_nb = torch.tensor(list(range(cross_sim_AB_sp.shape[1])), device=self.device)[mask_pointB][vmaskBH_nb]
                match_mask_B[valid_match_indexesB] = 1
                match_mask_nb_B[valid_match_indexesB_nb] = 1

                cross_sim_AB = current_descA @ desc_mapB[idx, :, :, :].view(-1, H * W)
                # cross_sim_AB = cross_sim_AB[mask_pointA, :]
                cross_sim_AB_all = F.grid_sample(cross_sim_AB.view(-1, H, W).unsqueeze(0),
                                                pntA_H_normalized[vmaskAH, :].detach().view(1, 1, -1, 2),
                                                mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NA x repeatNA
                valid_cross_sim_AB_mean = torch.trace(cross_sim_AB_all[match_mask_A==1, :]) / cross_sim_AB_all[match_mask_A==1, :].shape[0]
                # novalid_cross_sim_AB_mean = (torch.sum(torch.sum(cross_sim_AB.detach(), 1), 1) - valid_cross_sim_AB_mean * pairAB_A.shape[0]) / (new_numA * H * W - pairAB_A.shape[0])

                cross_sim_BA = current_descB @ desc_mapA[idx, :, :, :].view(-1, H * W)   # M x H x W
                # cross_sim_BA = cross_sim_BA[mask_pointB, :]
                cross_sim_BA_all = F.grid_sample(cross_sim_BA.view(-1, H, W).unsqueeze(0),
                                                pntB_invH_normalized[vmaskBH, :].detach().view(1, 1, -1, 2),
                                                mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NB x match_nB
                valid_cross_sim_BA_mean = torch.trace(cross_sim_BA_all[match_mask_B==1, :]) / cross_sim_BA_all[match_mask_B==1, :].shape[0]
                # novalid_cross_sim_BA_mean = (torch.sum(torch.sum(cross_sim_BA.detach(), 1), 1) - valid_cross_sim_BA_mean * pairBA_B.shape[0]) / (new_numB * H * W - pairBA_B.shape[0])

                cross_sim_AB_out = torch.cat((cross_sim_AB, torch.ones((cross_sim_AB.shape[0], 3), device=cross_sim_AB.device)), dim=-1)      # NA X (H X W + 2)
                cross_sim_BA_out = torch.cat((cross_sim_BA, torch.ones((cross_sim_BA.shape[0], 3), device=cross_sim_BA.device)), dim=-1)      # NB X (H X W + 2)
                # print(3)
                # cross_sim_AB_out[mask_pointA, -1] -= 1
                # cross_sim_BA_out[mask_pointB, -1] -= 1
                # cross_sim_AB_out[match_mask_A, -1] -= 1
                cross_sim_AB_out[match_mask_A==1, -1] = novalid_cross_sim_AB_sp_mean
                cross_sim_AB_out[match_mask_A==1, -2] = crossAN_mean
                cross_sim_AB_out[match_mask_A==1, -3] = crossAN2_mean
                cross_sim_AB_out[match_mask_nb_A==0, -1] = valid_cross_sim_AB_mean
                cross_sim_AB_out[match_mask_nb_A==0, -2] = -1 # crossAN_mean # -1
                cross_sim_AB_out[match_mask_nb_A==0, -3] = -1 # crossAN_mean # -1

                cross_sim_BA_out[match_mask_B==1, -1] = novalid_cross_sim_BA_sp_mean
                cross_sim_BA_out[match_mask_B==1, -2] = crossBN_mean
                cross_sim_BA_out[match_mask_B==1, -3] = crossBN2_mean
                cross_sim_BA_out[match_mask_nb_B==0, -1] = valid_cross_sim_BA_mean
                cross_sim_BA_out[match_mask_nb_B==0, -2] = -1 # crossBN_mean # -1
                cross_sim_BA_out[match_mask_nb_B==0, -3] = -1 # crossBN_mean # -1

                soft_cross_sim_AtoB = F.softmax((cross_sim_AB_out - 1) / t_des, dim=-1)         # NA X (H X W + 1)
                soft_cross_sim_BtoA = F.softmax((cross_sim_BA_out - 1) / t_des, dim=-1)         # NB X (H X W + 1)
                soft_cross_sim_AB_all = F.grid_sample(soft_cross_sim_AtoB[:, :-3].view(-1, H, W).unsqueeze(0),
                                                    pntA_H_normalized[vmaskAH, :].detach().view(1, 1, -1, 2),
                                                    mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NA x match_nA
                
                soft_cross_sim_BA_all = F.grid_sample(soft_cross_sim_BtoA[:, :-3].view(-1, H, W).unsqueeze(0),
                                                    pntB_invH_normalized[vmaskBH, :].detach().view(1, 1, -1, 2),
                                                    mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NB x match_nB
                # soft_valid_cross_sim_AB_all = soft_cross_sim_AB_all[mask_pointA, :]             # repeat_nA x repeat_nA
                # soft_valid_cross_sim_BA_all = soft_cross_sim_BA_all[mask_pointB, :]             # repeat_nB x repeat_nB

                soft_valid_cross_sim_AB_all = soft_cross_sim_AB_all[match_mask_A==1, :]             # match_nA x match_nA
                soft_valid_cross_sim_BA_all = soft_cross_sim_BA_all[match_mask_B==1, :]             # match_nB x match_nB

                valid_mask_AB = torch.eye(soft_valid_cross_sim_AB_all.shape[0]) == 1
                valid_mask_BA = torch.eye(soft_valid_cross_sim_BA_all.shape[0]) == 1
                # print(4)
                # 取对角线
                soft_valid_cross_sim_AB = soft_valid_cross_sim_AB_all[valid_mask_AB]
                soft_valid_cross_sim_BA = soft_valid_cross_sim_BA_all[valid_mask_BA]

                # soft_novalid_cross_sim_AB = soft_cross_sim_AtoB[mask_pointA==False, -1]              # (NA-repeat_nA) x 1
                # soft_novalid_cross_sim_BA = soft_cross_sim_BtoA[mask_pointB==False, -1]
                soft_novalid_cross_sim_AB = soft_cross_sim_AtoB[match_mask_nb_A==0, -1]               # (NA-match_nA) x 1
                soft_novalid_cross_sim_BA = soft_cross_sim_BtoA[match_mask_nb_B==0, -1]
                # print(soft_novalid_cross_sim_AB, soft_novalid_cross_sim_BA)

                log_soft_valid_cross_sim_AB = -torch.log(soft_valid_cross_sim_AB + eps) * (1 - torch.diag(dis_oriATAB)[vmaskAH] / self.ori_diff) * (1 - torch.diag(bin_distATAB[mask_pointA, :])[vmaskAH] / bin_kpAB_T.shape[0])
                log_soft_valid_cross_sim_BA = -torch.log(soft_valid_cross_sim_BA + eps) * (1 - torch.diag(dis_oriBTBA)[vmaskBH] / self.ori_diff) * (1 - torch.diag(bin_distBTBA[mask_pointB, :])[vmaskBH] / bin_kpBA_T.shape[0])
                log_soft_novalid_cross_sim_AB = -torch.log(soft_novalid_cross_sim_AB + eps)
                log_soft_novalid_cross_sim_BA = -torch.log(soft_novalid_cross_sim_BA + eps)

                dis_cross_sim_mean = torch.sum(torch.cat((4*log_soft_valid_cross_sim_AB, 4*log_soft_valid_cross_sim_BA, log_soft_novalid_cross_sim_AB, log_soft_novalid_cross_sim_BA), dim=-1), dim=-1) / (new_numA + new_numB)
                
                # print(5)
                valid_cross_sim_AB = cross_sim_AB[mask_pointA, :]   # repeat_nA x (H X W)
                valid_cross_sim_BA = cross_sim_BA[mask_pointB, :]   # repeat_nB x (H X W)
                exp_valid_cross_sim_AtoB = torch.exp((valid_cross_sim_AB - 1) / t_rel).view(-1, H, W)
                exp_valid_cross_sim_BtoA = torch.exp((valid_cross_sim_BA - 1) / t_rel).view(-1, H, W)
                exp_valid_cross_sim_AB_all = F.grid_sample(exp_valid_cross_sim_AtoB.unsqueeze(0),
                                                        pntA_H_normalized.detach().view(1, 1, -1, 2),
                                                        mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # repeat_nA x repeat_nA
                
                exp_valid_cross_sim_BA_all = F.grid_sample(exp_valid_cross_sim_BtoA.unsqueeze(0),
                                                        pntB_invH_normalized.detach().view(1, 1, -1, 2),
                                                        mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # repeat_nB x repeat_nB

                repeat_mask_AB = torch.eye(exp_valid_cross_sim_AB_all.shape[0]) == 1
                repeat_mask_BA = torch.eye(exp_valid_cross_sim_BA_all.shape[0]) == 1
                rel_valid_cross_sim_AB = exp_valid_cross_sim_AB_all[repeat_mask_AB]
                rel_valid_cross_sim_BA = exp_valid_cross_sim_BA_all[repeat_mask_BA]

                # pntA_H_normalized_new = copy.deepcopy(pntA_H_normalized.detach())
                # pntB_invH_normalized_new = copy.deepcopy(pntB_invH_normalized.detach())

                # pntA_H_normalized_new[:, 0] += 2
                # pntB_invH_normalized_new[:, 0] += 2

                scoresAB_all = F.grid_sample(scores_mapB[idx, :, :, :].unsqueeze(0),
                                            pntA_H_normalized_new.view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)      # 1 x repeat_nA

                scoresBA_all = F.grid_sample(scores_mapA[idx, :, :, :].unsqueeze(0),
                                            pntB_invH_normalized_new.view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)      # 1 x repeat_nB
                # print(6)
                scores_AAB = scoresA[idx][pmA][mask_pointA] * scoresAB_all
                scores_BBA = scoresB[idx][pmB][mask_pointB] * scoresBA_all
                scores_sum_AAB = torch.sum(scores_AAB, dim=-1)
                scores_sum_BBA = torch.sum(scores_BBA, dim=-1)
                scores_normalize_AAB = scores_AAB / (scores_sum_AAB + eps)
                scores_normalize_BBA = scores_BBA / (scores_sum_BBA + eps)
                rel_meanA = torch.sum(scores_normalize_AAB * (1 - rel_valid_cross_sim_AB), dim=-1) / pntA_H_normalized_new.shape[0]
                rel_meanB = torch.sum(scores_normalize_BBA * (1 - rel_valid_cross_sim_BA), dim=-1) / pntB_invH_normalized_new.shape[0]

                # # 熵loss
                # current_descA_std, current_descB_std = descA_std[countA:countA+new_numA], descB_std[countB:countB+new_numB]
                # desc_std += torch.mean(current_descA_std) + torch.mean(current_descB_std)
                # countA_T += numA_T
                # countB_T += numB_T

                dis_neighbor_mean_total += torch.mean(torch.sum(neighbor_dis_AB, dim=1)) + torch.mean(torch.sum(neighbor_dis_BA, dim=1))
                dis_desc += dis_cross_sim_mean_sp
                dis_desc += dis_cross_sim_mean

                dis_pair_meanAB = torch.mean(key_manhattandisAB[pairAB_A, pairAB_B])
                dis_pair_meanBA = torch.mean(key_manhattandisBA[pairBA_B, pairBA_A])

                dis_peak_mean = torch.mean(torch.cat((scoreddisA[idx][pmA], scoreddisB[idx][pmB]), dim=0))
                # dis_peak_meanB = torch.mean(scoreddisB[idx])
                
                dis_mean_total += dis_pair_meanAB + dis_pair_meanBA
                dis_peak_scored += dis_peak_mean

                dis_rel += rel_meanA + rel_meanB
                
                countA += new_numA
                countB += new_numB
                count_ne += new_num_ne
                # # Penalty
                # scores_mean += (-torch.log(torch.mean(scoresA[idx], dim=-1) + eps) - torch.log(torch.mean(scoresB[idx], dim=-1) + eps)) 
                # print(scores_mean)
            except:
                # dis_mean_total += 0
                # dis_peak_scored += 0
                # dis_desc += 0
                # dis_rel += 0
                # print('Overlapping too small or Repeatable point pairs distance is greater than correspond(1.5):', pntA.shape[0], pntA_H.shape[0], pntB.shape[0], pntB_invH.shape[0], dis_pairAB.shape[0], dis_pairBA.shape[0])
                valid_batch_size -= 1
                countA += new_numA
                countB += new_numB
                count_ne += new_num_ne
                # countA_T += numA_T
                # countB_T += numB_T

        valid_batch_size = valid_batch_size if valid_batch_size > 0 else eps
        # Reprojection Loss 
        reprojection_loss = dis_mean_total / (valid_batch_size * 2)
        # Dispersity Peak Loss
        dispersity_peak_loss = dis_peak_scored / valid_batch_size
        # NRE Loss
        descriptor_loss = dis_desc / (2 * valid_batch_size)
        # Reliability Loss
        reliability_loss = dis_rel / (valid_batch_size * 2)
        # SOSR Loss
        sosr_loss = dis_neighbor_mean_total / ((valid_batch_size * 2))
        # # Entropy loss
        # std_loss = (valid_batch_size * 2) / desc_std  
        # # Score Penalty
        # score_penalty = scores_mean / (valid_batch_size * 2)
        # FA Desc loss
        FA_des_loss = dis_desc_fa / valid_batch_size_FA if valid_batch_size_FA > 0 else 0

        loss_total = wrp * reprojection_loss + wpl * dispersity_peak_loss + wdl * descriptor_loss + wrl * reliability_loss + sosr_loss + FA_des_loss
        loss_group = {
            'reprojection_loss': reprojection_loss, 
            'dispersity_peak_loss': dispersity_peak_loss,
            'descriptor_loss': descriptor_loss,
            'reliability_loss': reliability_loss,
            'sosr_loss': sosr_loss,
            # 'std_loss': std_loss,
            'FA_des_loss': FA_des_loss,
            }
        return loss_total, loss_group


    # sift点
    def detector_selfsupervised_loss_dkd_patch_ext_restrict_modify_oriR_ratio_FA_bw_ns_wg_nori_sift(self, kpA, kpB, pmaskA, pmaskB, descA, descB, desc_mapA, desc_mapB, scoreddisA, scoreddisB, scoresA, scoresB, scores_mapA, scores_mapB, Homo, inv_Homo, inv_Homo_en, ori_all_patchA, ori_all_patchB, ori_kp_patchA, ori_kp_patchB, bin_allA, bin_allB, bin_kpA, bin_kpB, trans_angle, FA_flag, H, W, wrp=1, wpl=1, wdl=1, wrl=1, t_des=0.02, t_rel=1):
        # pmaskA: (BxMax_num) 32x350=11200
        batch_size = len(kpA)
        max_num = pmaskA.shape[-1] // batch_size    # 350
        dis_mean_total = 0
        dis_neighbor_mean_total = 0
        dis_peak_scored = 0
        dis_desc = 0
        dis_rel = 0
        desc_std = 0
        eps = 1e-12
        valid_batch_size = batch_size
        valid_batch_size_FA = 0
        countA, countB = 0, 0
        dis_desc_fa = 0
        # countA_T, countB_T = 0, 0
        for idx in range(batch_size):
            pntA, pntB = kpA[idx], kpB[idx]     # M X 2 (x,y)
            # kmask_TA, kmask_TB = kmask_T_allA[idx], kmask_T_allB[idx]
            pntA = pntA.float()
            pntB = pntB.float()

            # 剔除部分按压区域的点,且保留在重叠区域的点
            numA, numB = pntA.shape[0], pntB.shape[0]
            # numA_T, numB_T = pntA[kmask_TA].shape[0], pntB[kmask_TB].shape[0]
            pmA, pmB = pmaskA[max_num * idx:max_num * idx + numA].bool(), pmaskB[max_num * idx:max_num * idx + numB].bool()
            pntA, pntB = pntA[pmA, :], pntB[pmB, :]
            new_numA, new_numB = pntA.shape[0], pntB.shape[0]       
            
            pntA = (pntA + 1) / 2 * pntA.new_tensor([[W + 3, H - 1]]).to(pntA.device)
            pntB = (pntB + 1) / 2 * pntB.new_tensor([[W + 3, H - 1]]).to(pntB.device)

            # [120, 40] -> [120, 36],实际只取中心118x32区域的点对
            pntA[:, 0] -= 2
            pntB[:, 0] -= 2
            
            pntA_normalized = pntA / pntA.new_tensor([W - 1, H - 1]).to(pntA.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)
            pntB_normalized = pntB / pntB.new_tensor([W - 1, H - 1]).to(pntB.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)

            pntA_H = warp_points(pntA[:, :2], Homo[idx].squeeze(), device=self.device)  # 利用变换矩阵变换坐标点
            pntA_H, mask_pointA = filter_points(pntA_H, torch.tensor([W, H], device=self.device), return_mask=True)
            pntB_invH = warp_points(pntB[:, :2], inv_Homo[idx].squeeze(), device=self.device)
            pntB_invH, mask_pointB = filter_points(pntB_invH, torch.tensor([W, H], device=self.device), return_mask=True)
            
            current_descA, current_descB = descA[countA:countA+new_numA], descB[countB:countB+new_numB]
            cross_sim_AB_sp = current_descA @ current_descB.transpose(0, 1)     # NTA X NTB
            
            # 黑白相似度
            current_binA, current_binB = bin_kpA[countA:countA+new_numA], bin_kpB[countB:countB+new_numB]   # [NA, 256] [NB_256]
            bin_distAB = current_binA.shape[-1] - (current_binA @ current_binB.transpose(0, 1)) - ((1 - current_binA) @ (1 - current_binB.transpose(0, 1))) # [NA, NB]

            # Net FA余弦相似度小
            if FA_flag[idx] == 1:
                FA_bin_mask = bin_distAB >= (1 - self.FA_bin_thr) * current_binA.shape[-1] 
                # print(current_binA.shape, bin_distAB[0, :])
                # print(FA_bin_mask.shape, torch.sum(FA_bin_mask))
                dis_desc_fa += (2 - torch.mean(torch.sqrt(2 * (1 - cross_sim_AB_sp[FA_bin_mask]) + eps)))

                valid_batch_size -= 1
                valid_batch_size_FA += 1
                countA += new_numA
                countB += new_numB
                continue
            
            # 真匹配的trans
            try:
                assert pntA_H.shape[0] > 0 and pntB_invH.shape[0] > 0 
                
                # 点对欧氏距离
                key_disAB = self.get_dis(pntA_H[:, :2], pntB[:, :2])            # repeatNA x NB
                key_disBA = self.get_dis(pntB_invH[:, :2], pntA[:, :2])
                pairAB_A, pairAB_B, dis_pairAB, _ = self.get_point_pair(key_disAB, dis_thre=self.correspond)  # p -> k # NTA(<1.5), NTA(<1.5), NTA(<1.5), NTA        
                pairBA_B, pairBA_A, dis_pairBA, _  = self.get_point_pair(key_disBA, dis_thre=self.correspond)  # p -> k # NTB(<1.5), NTB(<1.5), NTB(<1.5), NTB 
                
                # 点距离mask
                nn_maskAB = torch.zeros((pntA_H.shape[0], pntB.shape[0]), device=self.device) 
                nn_maskAB[pairAB_A, pairAB_B] = 1

                nn_maskBA = torch.zeros((pntB_invH.shape[0], pntA.shape[0]), device=self.device) 
                nn_maskBA[pairBA_B, pairBA_A] = 1

                assert dis_pairAB.shape[0] > 0 and dis_pairBA.shape[0] > 0     

                pntA_H_normalized = pntA_H / pntA_H.new_tensor([W - 1, H - 1]).to(pntA_H.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)
                pntB_invH_normalized = pntB_invH / pntB_invH.new_tensor([W - 1, H - 1]).to(pntB_invH.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)

                ori_maskATB, dis_oriATB = self.get_main_ori_consistence_caltrans(ori_kp_patchA[countA:countA+new_numA], ori_kp_patchB[countB:countB+new_numB], trans_angle[idx])  # NTA x NTB
                
                ori_maskBTA = ori_maskATB.transpose(0, 1)

                match_maskAB_nb = (nn_maskAB == 1) * ori_maskATB[mask_pointA, :]           # repeatNA X NTB
                match_maskBA_nb = (nn_maskBA == 1) * ori_maskBTA[mask_pointB, :]           # repeatNB X NTA
                pairAB_A_nb_new, pairAB_B_nb_new = torch.where(match_maskAB_nb == 1)
                pairBA_B_nb_new, pairBA_A_nb_new = torch.where(match_maskBA_nb == 1)

                # 主方向一致性
                ori_kpAB_patch_ext = F.grid_sample(ori_all_patchB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntA_H_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  
                ori_kpBA_patch_ext = F.grid_sample(ori_all_patchA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntB_invH_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  
                # print('1_2_4:', ori_kpAB_patch_ext.shape)
                ori_maskATAB, dis_oriATAB = self.get_main_ori_consistence_caltrans(ori_kp_patchA[countA:countA+new_numA], ori_kpAB_patch_ext.transpose(0, 1), trans_angle[idx])  # NTA x repeatNA
                ori_maskBTBA, dis_oriBTBA = self.get_main_ori_consistence_caltrans(ori_kp_patchB[countB:countB+new_numB], ori_kpBA_patch_ext.transpose(0, 1), -trans_angle[idx])  # NTB x repeatNB
                
                ori_maskATAB = ori_maskATAB[mask_pointA, :]         # repeatNA x repeatNA
                ori_maskBTBA = ori_maskBTBA[mask_pointB, :]
                dis_oriATAB = dis_oriATAB[mask_pointA, :]         # repeatNA x repeatNA
                dis_oriBTBA = dis_oriBTBA[mask_pointB, :]
                
                # 黑白相似度
                bin_maskATB = bin_distAB <= (1 - self.FR_bin_thr) * current_binA.shape[-1]  
                bin_maskBTA = bin_maskATB.transpose(0, 1)  

                match_maskAB = match_maskAB_nb * bin_maskATB[mask_pointA, :]               # repeatNA X NB
                match_maskBA = match_maskBA_nb * bin_maskBTA[mask_pointB, :]               # repeatNB X NA

                pairAB_A_new, pairAB_B_new = torch.where(match_maskAB == 1)
                pairBA_B_new, pairBA_A_new = torch.where(match_maskBA == 1)
                # print('bin_mask:', pairAB_A_new.shape[0], pairBA_B_new.shape[0])
                assert pairAB_A_new.shape[0] > 0 and pairBA_B_new.shape[0] > 0 

                bin_kpAB_T = F.grid_sample(bin_allB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntA_H_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # [256, repeatNA]
                bin_kpBA_T = F.grid_sample(bin_allA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntB_invH_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # [256, repeatNB]
                bin_distATAB = bin_kpAB_T.shape[0] - (current_binA @ bin_kpAB_T) - ((1 - current_binA) @ (1 - bin_kpAB_T)) # [NTA, repeatNA]
                bin_distBTBA = bin_kpBA_T.shape[0] - (current_binB @ bin_kpBA_T) - ((1 - current_binB) @ (1 - bin_kpBA_T)) # [NTB, repeatNB]

                bin_maskATAB = bin_distATAB <= (1 - self.FR_bin_thr) * bin_kpAB_T.shape[0] 
                bin_maskBTBA = bin_distBTBA <= (1 - self.FR_bin_thr) * bin_kpBA_T.shape[0] 
                bin_maskATAB = bin_maskATAB[mask_pointA, :]
                bin_maskBTBA = bin_maskBTBA[mask_pointB, :]

                vmaskAH_nb = torch.diag(ori_maskATAB)
                vmaskBH_nb = torch.diag(ori_maskBTBA)
                vmaskAH = torch.diag(ori_maskATAB * bin_maskATAB) == 1      # [repeatNA, 1]
                vmaskBH = torch.diag(ori_maskBTBA * bin_maskBTBA) == 1      # [repeatNB, 1]

                # print('main_ori:', torch.sum(vmaskAH), torch.sum(vmaskBH))
                assert torch.sum(vmaskAH) > 0 and torch.sum(vmaskBH) > 0

                # SOSR: 简化的self-attention
                k_neighbor = 3
                cross_sim_AA_sp = current_descA @ current_descA.transpose(0, 1)
                cross_sim_BB_sp = current_descB @ current_descB.transpose(0, 1)
                # print('SOSR:', pairAB_A_new.shape[0], pairBA_B_new.shape[0])
                assert pairAB_A_new.shape[0] >= k_neighbor and pairBA_B_new.shape[0] >= k_neighbor 

                match_sim_AB_AA = cross_sim_AA_sp[mask_pointA, :][:, mask_pointA][pairAB_A_new, :][:, pairAB_A_new]
                match_sim_BA_BB = cross_sim_BB_sp[mask_pointB, :][:, mask_pointB][pairBA_B_new, :][:, pairBA_B_new]
                match_sim_AB_BB = cross_sim_BB_sp[pairAB_B_new, :][:, pairAB_B_new]
                match_sim_BA_AA = cross_sim_AA_sp[pairBA_A_new, :][:, pairBA_A_new]
                match_values_AB_AA, match_indices_AB_AA = torch.topk(match_sim_AB_AA, dim=1, k=k_neighbor, largest=False)
                match_values_BA_BB, match_indices_BA_BB = torch.topk(match_sim_BA_BB, dim=1, k=k_neighbor, largest=False)
                match_values_AB_BB_all = match_sim_AB_BB[:, match_indices_AB_AA]
                match_values_BA_AA_all = match_sim_BA_AA[:, match_indices_BA_BB]
                match_values_AB_BB = torch.diagonal(match_values_AB_BB_all, 0, dim1=0, dim2=1).transpose(0, 1)
                match_values_BA_AA = torch.diagonal(match_values_BA_AA_all, 0, dim1=0, dim2=1).transpose(0, 1)
                neighbor_dis_AB = (match_values_AB_AA - match_values_AB_BB) * (match_values_AB_AA - match_values_AB_BB)
                neighbor_dis_BA = (match_values_BA_BB - match_values_BA_AA) * (match_values_BA_BB - match_values_BA_AA)
                # print('1_1')
                # PA VS PB
                valid_cross_sim_AB_sp_mean = torch.mean(cross_sim_AB_sp[mask_pointA, :][match_maskAB == 1], dim=-1)
                valid_cross_sim_AB_sp_nb_mean = torch.mean(cross_sim_AB_sp[mask_pointA, :][match_maskAB_nb == 1], dim=-1)
                novalid_cross_sim_AB_sp_mean = (torch.sum(torch.sum(cross_sim_AB_sp.detach(), 1), 0) - valid_cross_sim_AB_sp_nb_mean * pairAB_A_nb_new.shape[0]) / (new_numA * new_numB - pairAB_A_nb_new.shape[0] + eps)
                valid_cross_sim_BA_sp_mean = torch.mean(cross_sim_AB_sp[:, mask_pointB][match_maskBA.transpose(0, 1) == 1], dim=-1)
                valid_cross_sim_BA_sp_nb_mean = torch.mean(cross_sim_AB_sp[:, mask_pointB][match_maskBA_nb.transpose(0, 1) == 1], dim=-1)
                novalid_cross_sim_BA_sp_mean = (torch.sum(torch.sum(cross_sim_AB_sp.detach(), 1), 0) - valid_cross_sim_BA_sp_nb_mean * pairBA_B_nb_new.shape[0]) / (new_numA * new_numB - pairBA_B_nb_new.shape[0] + eps)

                valid_indexesA = torch.tensor(list(range(cross_sim_AB_sp.shape[0])), device=self.device)[mask_pointA][pairAB_A_new]
                valid_indexesA_nb = torch.tensor(list(range(cross_sim_AB_sp.shape[0])), device=self.device)[mask_pointA][pairAB_A_nb_new]
                # cross_sim_BA_sp = current_descB @ current_descA.transpose(0, 1)
                cross_sim_AB_out_sp = torch.cat((cross_sim_AB_sp, torch.ones((cross_sim_AB_sp.shape[0], 1), device=cross_sim_AB_sp.device) * 2), dim=-1)      # NA X (NB + 1)
                cross_sim_AB_out_nb_sp = torch.cat((cross_sim_AB_sp, torch.ones((cross_sim_AB_sp.shape[0], 1), device=cross_sim_AB_sp.device) * 2), dim=-1)      # NA X (NB + 1)
                # cross_sim_BA_out_sp = torch.cat((cross_sim_BA_sp, torch.ones((numB, 1), device=cross_sim_BA_sp.device)), dim=-1)      # NB X (NA + 1)
                # valid_indexesB = torch.tensor(list(range(numB)), device=self.device)[mask_pointB][pairBA_B]
                # print('1_2')
                cross_sim_AB_out_sp[valid_indexesA, -1] = novalid_cross_sim_AB_sp_mean
                cross_sim_AB_out_nb_sp[valid_indexesA_nb, -1] = novalid_cross_sim_AB_sp_mean
                novalid_indexesA = torch.tensor(list(range(cross_sim_AB_sp.shape[0])), device=self.device)[cross_sim_AB_out_nb_sp[:, -1]==2]
                cross_sim_AB_out_sp[novalid_indexesA, -1] = valid_cross_sim_AB_sp_mean

                soft_cross_sim_AtoB_sp = F.softmax((cross_sim_AB_out_sp - 1) / t_des, dim=-1)
                # soft_cross_sim_BtoA = F.softmax((cross_sim_BA_out - 1) / t_des, dim=-1)
                # print('1_3')
                soft_valid_cross_sim_AB_sp = soft_cross_sim_AtoB_sp[mask_pointA, :-1][match_maskAB==1]
                # soft_valid_cross_sim_BA = soft_cross_sim_BtoA[mask_pointB, :-1][pairBA_B, pairBA_A]
                soft_novalid_cross_sim_AB_sp = soft_cross_sim_AtoB_sp[novalid_indexesA, -1]
                # soft_novalid_cross_sim_BA = soft_cross_sim_BtoA[cross_sim_BA_out[:, -1]==1, -1]
                log_soft_valid_cross_sim_AB_sp = -torch.log(soft_valid_cross_sim_AB_sp + eps) * (1 - dis_oriATB[mask_pointA, :][match_maskAB==1] / self.ori_diff) * (1 - bin_distAB[mask_pointA, :][match_maskAB==1] / current_binA.shape[-1]) * (1 - key_disAB[match_maskAB==1] / self.correspond)
                # log_soft_valid_cross_sim_BA = -torch.log(soft_valid_cross_sim_BA + eps)
                log_soft_novalid_cross_sim_AB_sp = -torch.log(soft_novalid_cross_sim_AB_sp + eps)
                # log_soft_novalid_cross_sim_BA = -torch.log(soft_novalid_cross_sim_BA + eps)
                dis_cross_sim_mean_sp = torch.sum(torch.cat((log_soft_valid_cross_sim_AB_sp, log_soft_novalid_cross_sim_AB_sp), dim=-1), dim=-1) / new_numA
                # print(2)
                # PA VS PAB
                # match_mask_A = copy.deepcopy(mask_pointA)
                # match_mask_B = copy.deepcopy(mask_pointB)
                match_mask_A = torch.zeros(cross_sim_AB_sp.shape[0], device=self.device)
                match_mask_nb_A = torch.zeros(cross_sim_AB_sp.shape[0], device=self.device)
                valid_match_indexesA = torch.tensor(list(range(cross_sim_AB_sp.shape[0])), device=self.device)[mask_pointA][vmaskAH]
                valid_match_indexesA_nb = torch.tensor(list(range(cross_sim_AB_sp.shape[0])), device=self.device)[mask_pointA][vmaskAH_nb]
                match_mask_A[valid_match_indexesA] = 1
                match_mask_nb_A[valid_match_indexesA_nb] = 1

                match_mask_B = torch.zeros(cross_sim_AB_sp.shape[1], device=self.device)
                match_mask_nb_B = torch.zeros(cross_sim_AB_sp.shape[1], device=self.device)
                valid_match_indexesB = torch.tensor(list(range(cross_sim_AB_sp.shape[1])), device=self.device)[mask_pointB][vmaskBH]
                valid_match_indexesB_nb = torch.tensor(list(range(cross_sim_AB_sp.shape[1])), device=self.device)[mask_pointB][vmaskBH_nb]
                match_mask_B[valid_match_indexesB] = 1
                match_mask_nb_B[valid_match_indexesB_nb] = 1
                # match_mask_A = copy.deepcopy(vmaskAH)
                # match_mask_B = copy.deepcopy(vmaskBH)

                cross_sim_AB = current_descA @ desc_mapB[idx, :, :, :].view(-1, H * W)
                # cross_sim_AB = cross_sim_AB[mask_pointA, :]
                cross_sim_AB_all = F.grid_sample(cross_sim_AB.view(-1, H, W).unsqueeze(0),
                                                pntA_H_normalized[vmaskAH, :].detach().view(1, 1, -1, 2),
                                                mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NA x repeatNA
                valid_cross_sim_AB_mean = torch.trace(cross_sim_AB_all[match_mask_A==1, :]) / cross_sim_AB_all[match_mask_A==1, :].shape[0]
                # novalid_cross_sim_AB_mean = (torch.sum(torch.sum(cross_sim_AB.detach(), 1), 1) - valid_cross_sim_AB_mean * pairAB_A.shape[0]) / (new_numA * H * W - pairAB_A.shape[0])

                cross_sim_BA = current_descB @ desc_mapA[idx, :, :, :].view(-1, H * W)   # M x H x W
                # cross_sim_BA = cross_sim_BA[mask_pointB, :]
                cross_sim_BA_all = F.grid_sample(cross_sim_BA.view(-1, H, W).unsqueeze(0),
                                                pntB_invH_normalized[vmaskBH, :].detach().view(1, 1, -1, 2),
                                                mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NB x match_nB
                valid_cross_sim_BA_mean = torch.trace(cross_sim_BA_all[match_mask_B==1, :]) / cross_sim_BA_all[match_mask_B==1, :].shape[0]
                # novalid_cross_sim_BA_mean = (torch.sum(torch.sum(cross_sim_BA.detach(), 1), 1) - valid_cross_sim_BA_mean * pairBA_B.shape[0]) / (new_numB * H * W - pairBA_B.shape[0])

                cross_sim_AB_out = torch.cat((cross_sim_AB, torch.ones((cross_sim_AB.shape[0], 1), device=cross_sim_AB.device)), dim=-1)      # NA X (H X W + 1)
                cross_sim_BA_out = torch.cat((cross_sim_BA, torch.ones((cross_sim_BA.shape[0], 1), device=cross_sim_BA.device)), dim=-1)      # NB X (H X W + 1)
                # print(3)
                # cross_sim_AB_out[mask_pointA, -1] -= 1
                # cross_sim_BA_out[mask_pointB, -1] -= 1
                # cross_sim_AB_out[match_mask_A, -1] -= 1
                cross_sim_AB_out[match_mask_A==1, -1] = novalid_cross_sim_AB_sp_mean
                cross_sim_AB_out[match_mask_nb_A==0, -1] = valid_cross_sim_AB_mean

                cross_sim_BA_out[match_mask_B==1, -1] = novalid_cross_sim_BA_sp_mean
                cross_sim_BA_out[match_mask_nb_B==0, -1] = valid_cross_sim_BA_mean

                soft_cross_sim_AtoB = F.softmax((cross_sim_AB_out - 1) / t_des, dim=-1)         # NA X (H X W + 1)
                soft_cross_sim_BtoA = F.softmax((cross_sim_BA_out - 1) / t_des, dim=-1)         # NB X (H X W + 1)
                soft_cross_sim_AB_all = F.grid_sample(soft_cross_sim_AtoB[:, :-1].view(-1, H, W).unsqueeze(0),
                                                    pntA_H_normalized[vmaskAH, :].detach().view(1, 1, -1, 2),
                                                    mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NA x match_nA
                
                soft_cross_sim_BA_all = F.grid_sample(soft_cross_sim_BtoA[:, :-1].view(-1, H, W).unsqueeze(0),
                                                    pntB_invH_normalized[vmaskBH, :].detach().view(1, 1, -1, 2),
                                                    mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NB x match_nB
                # soft_valid_cross_sim_AB_all = soft_cross_sim_AB_all[mask_pointA, :]             # repeat_nA x repeat_nA
                # soft_valid_cross_sim_BA_all = soft_cross_sim_BA_all[mask_pointB, :]             # repeat_nB x repeat_nB

                soft_valid_cross_sim_AB_all = soft_cross_sim_AB_all[match_mask_A==1, :]             # match_nA x match_nA
                soft_valid_cross_sim_BA_all = soft_cross_sim_BA_all[match_mask_B==1, :]             # match_nB x match_nB

                valid_mask_AB = torch.eye(soft_valid_cross_sim_AB_all.shape[0]) == 1
                valid_mask_BA = torch.eye(soft_valid_cross_sim_BA_all.shape[0]) == 1
                # print(4)
                # 取对角线
                soft_valid_cross_sim_AB = soft_valid_cross_sim_AB_all[valid_mask_AB]
                soft_valid_cross_sim_BA = soft_valid_cross_sim_BA_all[valid_mask_BA]

                # soft_novalid_cross_sim_AB = soft_cross_sim_AtoB[mask_pointA==False, -1]              # (NA-repeat_nA) x 1
                # soft_novalid_cross_sim_BA = soft_cross_sim_BtoA[mask_pointB==False, -1]
                soft_novalid_cross_sim_AB = soft_cross_sim_AtoB[match_mask_nb_A==0, -1]               # (NA-match_nA) x 1
                soft_novalid_cross_sim_BA = soft_cross_sim_BtoA[match_mask_nb_B==0, -1]
                # print(soft_novalid_cross_sim_AB, soft_novalid_cross_sim_BA)

                log_soft_valid_cross_sim_AB = -torch.log(soft_valid_cross_sim_AB + eps) * (1 - torch.diag(dis_oriATAB)[vmaskAH] / self.ori_diff) * (1 - torch.diag(bin_distATAB[mask_pointA, :])[vmaskAH] / bin_kpAB_T.shape[0])
                log_soft_valid_cross_sim_BA = -torch.log(soft_valid_cross_sim_BA + eps) * (1 - torch.diag(dis_oriBTBA)[vmaskBH] / self.ori_diff) * (1 - torch.diag(bin_distBTBA[mask_pointB, :])[vmaskBH] / bin_kpBA_T.shape[0])
                log_soft_novalid_cross_sim_AB = -torch.log(soft_novalid_cross_sim_AB + eps)
                log_soft_novalid_cross_sim_BA = -torch.log(soft_novalid_cross_sim_BA + eps)

                dis_cross_sim_mean = torch.sum(torch.cat((log_soft_valid_cross_sim_AB, log_soft_valid_cross_sim_BA, log_soft_novalid_cross_sim_AB, log_soft_novalid_cross_sim_BA), dim=-1), dim=-1) / (new_numA + new_numB)

                countA += new_numA
                countB += new_numB

                dis_neighbor_mean_total += torch.mean(torch.sum(neighbor_dis_AB, dim=1)) + torch.mean(torch.sum(neighbor_dis_BA, dim=1))
                dis_desc += dis_cross_sim_mean_sp
                dis_desc += dis_cross_sim_mean

            except:
                # dis_mean_total += 0
                # dis_peak_scored += 0
                # dis_desc += 0
                # dis_rel += 0
                # print('Overlapping too small or Repeatable point pairs distance is greater than correspond(1.5):', pntA.shape[0], pntA_H.shape[0], pntB.shape[0], pntB_invH.shape[0], dis_pairAB.shape[0], dis_pairBA.shape[0])
                valid_batch_size -= 1
                countA += new_numA
                countB += new_numB

        valid_batch_size = valid_batch_size if valid_batch_size > 0 else eps
        # NRE Loss
        descriptor_loss = dis_desc / (2 * valid_batch_size)
        # SOSR Loss
        sosr_loss = dis_neighbor_mean_total / ((valid_batch_size * 2))
        FA_des_loss = dis_desc_fa / valid_batch_size_FA if valid_batch_size_FA > 0 else 0

        loss_total = wdl * descriptor_loss + sosr_loss + FA_des_loss
        loss_group = {
            # 'reprojection_loss': reprojection_loss, 
            # 'dispersity_peak_loss': dispersity_peak_loss,
            'descriptor_loss': descriptor_loss,
            # 'reliability_loss': reliability_loss,
            'sosr_loss': sosr_loss,
            # 'std_loss': std_loss,
            'FA_des_loss': FA_des_loss,
            }
        return loss_total, loss_group



    def detector_selfsupervised_loss_dkd_dense_ext_restrict_modify_oriR_ratio_FA_nm(self, kpA, kpB, pmaskA, pmaskB, descA, descB, desc_mapA, desc_mapB, scoreddisA, scoreddisB, scoresA, scoresB, scores_mapA, scores_mapB, Homo, inv_Homo, inv_Homo_en, ori_allA, ori_allB, ori_all_patchA, ori_all_patchB, ori_kpA, ori_kpB, ori_kp_patchA, ori_kp_patchB, kmask_T_allA, kmask_T_allB, FA_flag, H, W, wrp=1, wpl=1, wdl=1, wrl=1, t_des=0.02, t_rel=1):
        # pmaskA: (BxMax_num) 32x350=11200
        batch_size = len(kpA)
        max_num = pmaskA.shape[-1] // batch_size    # 350
        dis_mean_total = 0
        dis_neighbor_mean_total = 0
        dis_peak_scored = 0
        dis_desc = 0
        dis_rel = 0
        desc_std = 0
        eps = 1e-12
        valid_batch_size = batch_size
        valid_batch_size_FA = 0
        countA, countB = 0, 0
        dis_desc_fa = 0
        # countA_T, countB_T = 0, 0
        for idx in range(batch_size):
            pntA, pntB = kpA[idx], kpB[idx]     # M X 2 (x,y)
            # kmask_TA, kmask_TB = kmask_T_allA[idx], kmask_T_allB[idx]
            pntA = pntA.float()
            pntB = pntB.float()

            # 剔除部分按压区域的点且保留在重叠区域的点
            numA, numB = pntA.shape[0], pntB.shape[0]
            # numA_T, numB_T = pntA[kmask_TA].shape[0], pntB[kmask_TB].shape[0]
            pmA, pmB = pmaskA[max_num * idx:max_num * idx + numA].bool(), pmaskB[max_num * idx:max_num * idx + numB].bool()
            pntA, pntB = pntA[pmA, :], pntB[pmB, :]
            new_numA, new_numB = pntA.shape[0], pntB.shape[0]
            
            pntA = (pntA + 1) / 2 * pntA.new_tensor([[W + 3, H - 1]]).to(pntA.device)
            pntB = (pntB + 1) / 2 * pntB.new_tensor([[W + 3, H - 1]]).to(pntB.device)

            # [120, 40] -> [120, 36],实际只取中心118x32区域的点对
            pntA[:, 0] -= 2
            pntB[:, 0] -= 2
            
            pntA_normalized = pntA / pntA.new_tensor([W - 1, H - 1]).to(pntA.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)
            pntB_normalized = pntB / pntB.new_tensor([W - 1, H - 1]).to(pntB.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)

            pntA_H = warp_points(pntA[:, :2], Homo[idx].squeeze(), device=self.device)  # 利用变换矩阵变换坐标点
            # pntA_H, mask_pointA = filter_points(pntA_H, torch.tensor([W, H], device=self.device), return_mask=True)
            pntB_invH = warp_points(pntB[:, :2], inv_Homo[idx].squeeze(), device=self.device)
            # pntB_invH, mask_pointB = filter_points(pntB_invH, torch.tensor([W, H], device=self.device), return_mask=True)
            
            current_descA, current_descB = descA[countA:countA+new_numA], descB[countB:countB+new_numB]
            cross_sim_AB_sp = current_descA @ current_descB.transpose(0, 1)

            # Net FA余弦相似度小
            if FA_flag[idx] == 1:
                dis_desc_fa += (2 - torch.mean(torch.sqrt(2 * (1 - cross_sim_AB_sp) + eps)))
                valid_batch_size -= 1
                valid_batch_size_FA += 1
                countA += new_numA
                countB += new_numB
                continue
            
            # 真匹配的trans
            try:
                assert pntA_H.shape[0] > 0 and pntB_invH.shape[0] > 0 
                
                # 点对欧氏距离
                key_disAB = self.get_dis(pntA_H[:, :2], pntB[:, :2])
                key_disBA = self.get_dis(pntB_invH[:, :2], pntA[:, :2])
                pairAB_A, pairAB_B, dis_pairAB, _ = self.get_point_pair(key_disAB, dis_thre=self.correspond)  # p -> k # NTA(<1.5), NTA(<1.5), NTA(<1.5), NTA        
                pairBA_B, pairBA_A, dis_pairBA, _  = self.get_point_pair(key_disBA, dis_thre=self.correspond)  # p -> k # NTB(<1.5), NTB(<1.5), NTB(<1.5), NTB 
                
                # 点距离mask
                nn_maskAB = torch.zeros((pntA_H.shape[0], pntB.shape[0]), device=self.device) 
                nn_maskAB[pairAB_A, pairAB_B] = 1

                nn_maskBA = torch.zeros((pntB_invH.shape[0], pntA.shape[0]), device=self.device) 
                nn_maskBA[pairBA_B, pairBA_A] = 1

                # 点对曼哈顿距离
                key_manhattandisAB = self.get_manhattan_dis(pntA_H[:, :2], pntB[:, :2])
                key_manhattandisBA = self.get_manhattan_dis(pntB_invH[:, :2], pntA[:, :2])
                assert dis_pairAB.shape[0] > 0 and dis_pairBA.shape[0] > 0     

                pntA_H_normalized = pntA_H / pntA_H.new_tensor([W - 1, H - 1]).to(pntA_H.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)
                pntB_invH_normalized = pntB_invH / pntB_invH.new_tensor([W - 1, H - 1]).to(pntB_invH.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)

                # 用于score_map
                pntA_H_new = copy.deepcopy(pntA_H.detach())
                pntB_invH_new = copy.deepcopy(pntB_invH.detach())
                pntA_H_new[:, 0] += 2
                pntB_invH_new[:, 0] += 2
                
                pntA_H_normalized_new = pntA_H_new / pntA_H_new.new_tensor([W + 3, H - 1]).to(pntA_H.device) * 2 - 1

                pntB_invH_new = warp_points(pntB_invH_new[:, :2], inv_Homo_en[idx].squeeze(), device=self.device)       # 转到A上，而不是AT上
                
                pntB_invH_normalized_new = pntB_invH_new / pntB_invH_new.new_tensor([W + 3, H - 1]).to(pntB_invH.device) * 2 - 1 

                # PA VS PB 有一定偏移
                ori_kpA_ext = F.grid_sample(ori_allA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntA_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  
                ori_kpB_ext = F.grid_sample(ori_allB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntB_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  

                main_ori_maskATB = self.get_main_ori_consistence(ori_kpA[countA:countA+numA][pmA].unsqueeze(1), ori_kpB_ext)  # NTA x NTB 
                main_ori_maskBTA = self.get_main_ori_consistence(ori_kpB[countB:countB+numB][pmB].unsqueeze(1), ori_kpA_ext)  # NTB x NTA 
                
                # print(ori_all_patchA[idx, :, :5, 0], ori_all_patchB[idx, :, :5, 0])
                # exit()
                ori_kpA_patch_ext = F.grid_sample(ori_all_patchA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntA_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  
                ori_kpB_patch_ext = F.grid_sample(ori_all_patchB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntB_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  

                ori_maskATB = self.get_ori_consistence_ratio(ori_kp_patchA[countA:countA+numA][pmA, :], ori_kpB_patch_ext)  # NTA x NTB
                ori_maskBTA = self.get_ori_consistence_ratio(ori_kp_patchB[countB:countB+numB][pmB, :], ori_kpA_patch_ext)  # NTB x NTA

                # match_maskAB = (nn_maskAB == 1) * main_ori_maskATB
                # match_maskBA = (nn_maskBA == 1) * main_ori_maskBTA
                match_maskAB = (nn_maskAB == 1) * main_ori_maskATB * (ori_maskATB >= self.ori_ratio)
                match_maskBA = (nn_maskBA == 1) * main_ori_maskBTA * (ori_maskBTA >= self.ori_ratio)

                pairAB_A_new, pairAB_B_new = torch.where(match_maskAB == 1)
                pairBA_B_new, pairBA_A_new = torch.where(match_maskBA == 1)
                assert pairAB_A_new.shape[0] > 0 and pairBA_B_new.shape[0] > 0 
                # print('1:', pairAB_A_new.shape[0], pairBA_B_new.shape[0])
                # PA VS PAB 没有中心点距离偏移
                # 中心主方向一致性
                ori_kpAB_ext = F.grid_sample(ori_allB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntA_H_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  
                ori_kpBA_ext = F.grid_sample(ori_allA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntB_invH_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  
                main_ori_maskATAB = self.get_main_ori_consistence(ori_kpA[countA:countA+numA][pmA].unsqueeze(1), ori_kpAB_ext)  # NTAxNTA 
                main_ori_maskBTBA = self.get_main_ori_consistence(ori_kpB[countB:countB+numB][pmB].unsqueeze(1), ori_kpBA_ext)  # NTBxNTB 

                # 4x4邻域方向一致性
                ori_kpAB_patch_ext = F.grid_sample(ori_all_patchB[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntA_H_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  
                ori_kpBA_patch_ext = F.grid_sample(ori_all_patchA[idx, :, :, :].view(-1, H, W).unsqueeze(0),
                                            pntB_invH_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  

                ori_maskATAB = self.get_ori_consistence_ratio(ori_kp_patchA[countA:countA+numA][pmA, :], ori_kpAB_patch_ext)  # NTAxNTA 
                ori_maskBTBA = self.get_ori_consistence_ratio(ori_kp_patchB[countB:countB+numB][pmB, :], ori_kpBA_patch_ext)  # NTBxNTB

                # vmaskAH = torch.diag(main_ori_maskATAB) == 1
                # vmaskBH = torch.diag(main_ori_maskBTBA) == 1
                vmaskAH = torch.diag(main_ori_maskATAB * (ori_maskATAB >= self.ori_ratio)) == 1
                vmaskBH = torch.diag(main_ori_maskBTBA * (ori_maskBTBA >= self.ori_ratio)) == 1
                assert torch.sum(vmaskAH) > 0 and torch.sum(vmaskBH) > 0
                # print('2:', torch.sum(vmaskAH), torch.sum(vmaskBH))
                
                # SOSR: 简化的self-attention
                k_neighbor = 3
                cross_sim_AA_sp = current_descA @ current_descA.transpose(0, 1)
                cross_sim_BB_sp = current_descB @ current_descB.transpose(0, 1)

                match_sim_AB_AA = cross_sim_AA_sp[pairAB_A_new, :][:, pairAB_A_new]
                match_sim_BA_BB = cross_sim_BB_sp[pairBA_B_new, :][:, pairBA_B_new]
                match_sim_AB_BB = cross_sim_BB_sp[pairAB_B_new, :][:, pairAB_B_new]
                match_sim_BA_AA = cross_sim_AA_sp[pairBA_A_new, :][:, pairBA_A_new]
                match_values_AB_AA, match_indices_AB_AA = torch.topk(match_sim_AB_AA, dim=1, k=k_neighbor, largest=False)
                match_values_BA_BB, match_indices_BA_BB = torch.topk(match_sim_BA_BB, dim=1, k=k_neighbor, largest=False)
                match_values_AB_BB_all = match_sim_AB_BB[:, match_indices_AB_AA]
                match_values_BA_AA_all = match_sim_BA_AA[:, match_indices_BA_BB]
                match_values_AB_BB = torch.diagonal(match_values_AB_BB_all, 0, dim1=0, dim2=1).transpose(0, 1)
                match_values_BA_AA = torch.diagonal(match_values_BA_AA_all, 0, dim1=0, dim2=1).transpose(0, 1)
                neighbor_dis_AB = (match_values_AB_AA - match_values_AB_BB) * (match_values_AB_AA - match_values_AB_BB)
                neighbor_dis_BA = (match_values_BA_BB - match_values_BA_AA) * (match_values_BA_BB - match_values_BA_AA)

                # PA VS PB

                # valid_cross_sim_AB_sp_mean = torch.mean(cross_sim_AB_sp[match_maskAB == 1], dim=-1)
                # novalid_cross_sim_AB_sp_mean = (torch.sum(torch.sum(cross_sim_AB_sp.detach(), 1), 0) - valid_cross_sim_AB_sp_mean * pairAB_A_new.shape[0]) / (new_numA * new_numB - pairAB_A_new.shape[0] + eps)
                # valid_cross_sim_BA_sp_mean = torch.mean(cross_sim_AB_sp[match_maskBA.transpose(0, 1) == 1], dim=-1)
                # novalid_cross_sim_BA_sp_mean = (torch.sum(torch.sum(cross_sim_AB_sp.detach(), 1), 0) - valid_cross_sim_BA_sp_mean * pairBA_B_new.shape[0]) / (new_numA * new_numB - pairBA_B_new.shape[0] + eps)

                valid_indexesA = torch.tensor(list(range(new_numA)), device=self.device)[pairAB_A_new]
                # cross_sim_BA_sp = current_descB @ current_descA.transpose(0, 1)
                cross_sim_AB_out_sp = torch.cat((cross_sim_AB_sp, torch.ones((new_numA, 1), device=cross_sim_AB_sp.device) * 2), dim=-1)      # NA X (NB + 1)
                # cross_sim_BA_out_sp = torch.cat((cross_sim_BA_sp, torch.ones((numB, 1), device=cross_sim_BA_sp.device)), dim=-1)      # NB X (NA + 1)
                # valid_indexesB = torch.tensor(list(range(numB)), device=self.device)[mask_pointB][pairBA_B]
                cross_sim_AB_out_sp[valid_indexesA, -1] = 0 # novalid_cross_sim_AB_sp_mean
                novalid_indexesA = torch.tensor(list(range(new_numA)), device=self.device)[cross_sim_AB_out_sp[:, -1]==2]
                cross_sim_AB_out_sp[novalid_indexesA, -1] = 1 # valid_cross_sim_AB_sp_mean

                soft_cross_sim_AtoB_sp = F.softmax((cross_sim_AB_out_sp - 1) / t_des, dim=-1)
                # soft_cross_sim_BtoA = F.softmax((cross_sim_BA_out - 1) / t_des, dim=-1)
                
                soft_valid_cross_sim_AB_sp = soft_cross_sim_AtoB_sp[:, :-1][match_maskAB==1]
                # soft_valid_cross_sim_BA = soft_cross_sim_BtoA[mask_pointB, :-1][pairBA_B, pairBA_A]
                soft_novalid_cross_sim_AB_sp = soft_cross_sim_AtoB_sp[novalid_indexesA, -1]
                # soft_novalid_cross_sim_BA = soft_cross_sim_BtoA[cross_sim_BA_out[:, -1]==1, -1]
                log_soft_valid_cross_sim_AB_sp = -torch.log(soft_valid_cross_sim_AB_sp + eps) * ori_maskATB[match_maskAB==1]
                # log_soft_valid_cross_sim_BA = -torch.log(soft_valid_cross_sim_BA + eps)
                log_soft_novalid_cross_sim_AB_sp = -torch.log(soft_novalid_cross_sim_AB_sp + eps)
                # log_soft_novalid_cross_sim_BA = -torch.log(soft_novalid_cross_sim_BA + eps)
                dis_cross_sim_mean_sp = torch.sum(torch.cat((log_soft_valid_cross_sim_AB_sp, log_soft_novalid_cross_sim_AB_sp), dim=-1), dim=-1) / new_numA

                # PA VS PAB
                # match_mask_A = copy.deepcopy(mask_pointA)
                # match_mask_B = copy.deepcopy(mask_pointB)
                match_mask_A = copy.deepcopy(vmaskAH)
                match_mask_B = copy.deepcopy(vmaskBH)

                cross_sim_AB = current_descA @ desc_mapB[idx, :, :, :].view(-1, H * W)
                # cross_sim_AB_all = F.grid_sample(cross_sim_AB.view(-1, H, W).unsqueeze(0),
                #                                 pntA_H_normalized[vmaskAH, :].detach().view(1, 1, -1, 2),
                #                                 mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NA x match_nA

                # valid_cross_sim_AB_mean = torch.trace(cross_sim_AB_all[match_mask_A, :]) / cross_sim_AB_all[match_mask_A, :].shape[0]
                # novalid_cross_sim_AB_mean = (torch.sum(torch.sum(cross_sim_AB.detach(), 1), 1) - valid_cross_sim_AB_mean * pairAB_A.shape[0]) / (new_numA * H * W - pairAB_A.shape[0])

                cross_sim_BA = current_descB @ desc_mapA[idx, :, :, :].view(-1, H * W)   # M x H x W
                # cross_sim_BA_all = F.grid_sample(cross_sim_BA.view(-1, H, W).unsqueeze(0),
                #                                 pntB_invH_normalized[vmaskBH, :].detach().view(1, 1, -1, 2),
                #                                 mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NB x match_nB

                # valid_cross_sim_BA_mean = torch.trace(cross_sim_BA_all[match_mask_B, :]) / cross_sim_BA_all[match_mask_B, :].shape[0]
                # novalid_cross_sim_BA_mean = (torch.sum(torch.sum(cross_sim_BA.detach(), 1), 1) - valid_cross_sim_BA_mean * pairBA_B.shape[0]) / (new_numB * H * W - pairBA_B.shape[0])

                cross_sim_AB_out = torch.cat((cross_sim_AB, torch.ones((new_numA, 1), device=cross_sim_AB.device)), dim=-1)      # NA X (H X W + 1)
                cross_sim_BA_out = torch.cat((cross_sim_BA, torch.ones((new_numB, 1), device=cross_sim_BA.device)), dim=-1)      # NB X (H X W + 1)
                # print(match_mask_A.shape, cross_sim_AB_out.shape)
                # cross_sim_AB_out[mask_pointA, -1] -= 1
                # cross_sim_BA_out[mask_pointB, -1] -= 1
                # cross_sim_AB_out[match_mask_A, -1] -= 1
                cross_sim_AB_out[match_mask_A, -1] = 0 # novalid_cross_sim_AB_sp_mean
                cross_sim_AB_out[match_mask_A==False, -1] = 1 # valid_cross_sim_AB_mean

                cross_sim_BA_out[match_mask_B, -1] = 0 # novalid_cross_sim_BA_sp_mean
                cross_sim_BA_out[match_mask_B==False, -1] = 1 # valid_cross_sim_BA_mean

                soft_cross_sim_AtoB = F.softmax((cross_sim_AB_out - 1) / t_des, dim=-1)         # NA X (H X W + 1)
                soft_cross_sim_BtoA = F.softmax((cross_sim_BA_out - 1) / t_des, dim=-1)         # NB X (H X W + 1)
                soft_cross_sim_AB_all = F.grid_sample(soft_cross_sim_AtoB[:, :-1].view(-1, H, W).unsqueeze(0),
                                                    pntA_H_normalized[vmaskAH, :].detach().view(1, 1, -1, 2),
                                                    mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NA x match_nA
                
                soft_cross_sim_BA_all = F.grid_sample(soft_cross_sim_BtoA[:, :-1].view(-1, H, W).unsqueeze(0),
                                                    pntB_invH_normalized[vmaskBH, :].detach().view(1, 1, -1, 2),
                                                    mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NB x match_nB
                # soft_valid_cross_sim_AB_all = soft_cross_sim_AB_all[mask_pointA, :]             # repeat_nA x repeat_nA
                # soft_valid_cross_sim_BA_all = soft_cross_sim_BA_all[mask_pointB, :]             # repeat_nB x repeat_nB

                soft_valid_cross_sim_AB_all = soft_cross_sim_AB_all[match_mask_A, :]             # match_nA x match_nA
                soft_valid_cross_sim_BA_all = soft_cross_sim_BA_all[match_mask_B, :]             # match_nB x match_nB

                valid_mask_AB = torch.eye(soft_valid_cross_sim_AB_all.shape[0]) == 1
                valid_mask_BA = torch.eye(soft_valid_cross_sim_BA_all.shape[0]) == 1

                # 取对角线
                soft_valid_cross_sim_AB = soft_valid_cross_sim_AB_all[valid_mask_AB]
                soft_valid_cross_sim_BA = soft_valid_cross_sim_BA_all[valid_mask_BA]

                # soft_novalid_cross_sim_AB = soft_cross_sim_AtoB[mask_pointA==False, -1]              # (NA-repeat_nA) x 1
                # soft_novalid_cross_sim_BA = soft_cross_sim_BtoA[mask_pointB==False, -1]
                soft_novalid_cross_sim_AB = soft_cross_sim_AtoB[match_mask_A==False, -1]               # (NA-match_nA) x 1
                soft_novalid_cross_sim_BA = soft_cross_sim_BtoA[match_mask_B==False, -1]
                # print(soft_novalid_cross_sim_AB, soft_novalid_cross_sim_BA)

                log_soft_valid_cross_sim_AB = -torch.log(soft_valid_cross_sim_AB + eps) * torch.diag(ori_maskATAB)[vmaskAH]
                log_soft_valid_cross_sim_BA = -torch.log(soft_valid_cross_sim_BA + eps) * torch.diag(ori_maskBTBA)[vmaskBH]
                log_soft_novalid_cross_sim_AB = -torch.log(soft_novalid_cross_sim_AB + eps)
                log_soft_novalid_cross_sim_BA = -torch.log(soft_novalid_cross_sim_BA + eps)

                dis_cross_sim_mean = torch.sum(torch.cat((log_soft_valid_cross_sim_AB, log_soft_valid_cross_sim_BA, log_soft_novalid_cross_sim_AB, log_soft_novalid_cross_sim_BA), dim=-1), dim=-1) / (pntA.shape[0] + pntB.shape[0])

                # valid_cross_sim_AB = cross_sim_AB[mask_pointA, :]   # repeat_nA x (H X W)
                # valid_cross_sim_BA = cross_sim_BA[mask_pointB, :]   # repeat_nB x (H X W)
                exp_valid_cross_sim_AtoB = torch.exp((cross_sim_AB - 1) / t_rel).view(-1, H, W)
                exp_valid_cross_sim_BtoA = torch.exp((cross_sim_BA - 1) / t_rel).view(-1, H, W)
                exp_valid_cross_sim_AB_all = F.grid_sample(exp_valid_cross_sim_AtoB.unsqueeze(0),
                                                        pntA_H_normalized.detach().view(1, 1, -1, 2),
                                                        mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # repeat_nA x repeat_nA
                
                exp_valid_cross_sim_BA_all = F.grid_sample(exp_valid_cross_sim_BtoA.unsqueeze(0),
                                                        pntB_invH_normalized.detach().view(1, 1, -1, 2),
                                                        mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # repeat_nB x repeat_nB

                repeat_mask_AB = torch.eye(exp_valid_cross_sim_AB_all.shape[0]) == 1
                repeat_mask_BA = torch.eye(exp_valid_cross_sim_BA_all.shape[0]) == 1
                rel_valid_cross_sim_AB = exp_valid_cross_sim_AB_all[repeat_mask_AB]
                rel_valid_cross_sim_BA = exp_valid_cross_sim_BA_all[repeat_mask_BA]

                # pntA_H_normalized_new = copy.deepcopy(pntA_H_normalized.detach())
                # pntB_invH_normalized_new = copy.deepcopy(pntB_invH_normalized.detach())

                # pntA_H_normalized_new[:, 0] += 2
                # pntB_invH_normalized_new[:, 0] += 2

                scoresAB_all = F.grid_sample(scores_mapB[idx, :, :, :].unsqueeze(0),
                                            pntA_H_normalized_new.view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)      # 1 x repeat_nA

                scoresBA_all = F.grid_sample(scores_mapA[idx, :, :, :].unsqueeze(0),
                                            pntB_invH_normalized_new.view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)      # 1 x repeat_nB

                scores_AAB = scoresA[idx][pmA] * scoresAB_all
                scores_BBA = scoresB[idx][pmB] * scoresBA_all
                scores_sum_AAB = torch.sum(scores_AAB, dim=-1)
                scores_sum_BBA = torch.sum(scores_BBA, dim=-1)
                scores_normalize_AAB = scores_AAB / (scores_sum_AAB + eps)
                scores_normalize_BBA = scores_BBA / (scores_sum_BBA + eps)
                rel_meanA = torch.sum(scores_normalize_AAB * (1 - rel_valid_cross_sim_AB), dim=-1) / pntA_H_normalized_new.shape[0]
                rel_meanB = torch.sum(scores_normalize_BBA * (1 - rel_valid_cross_sim_BA), dim=-1) / pntB_invH_normalized_new.shape[0]

                # # 熵loss
                # current_descA_std, current_descB_std = descA_std[countA:countA+new_numA], descB_std[countB:countB+new_numB]
                # desc_std += torch.mean(current_descA_std) + torch.mean(current_descB_std)

                countA += new_numA
                countB += new_numB
                # countA_T += numA_T
                # countB_T += numB_T

                dis_neighbor_mean_total += torch.mean(torch.sum(neighbor_dis_AB, dim=1)) + torch.mean(torch.sum(neighbor_dis_BA, dim=1))
                dis_desc += dis_cross_sim_mean_sp
                dis_desc += dis_cross_sim_mean

                dis_pair_meanAB = torch.mean(key_manhattandisAB[pairAB_A, pairAB_B])
                dis_pair_meanBA = torch.mean(key_manhattandisBA[pairBA_B, pairBA_A])

                dis_peak_mean = torch.mean(torch.cat((scoreddisA[idx][pmA], scoreddisB[idx][pmB]), dim=0))
                # dis_peak_meanB = torch.mean(scoreddisB[idx])
                
                dis_mean_total += dis_pair_meanAB + dis_pair_meanBA
                dis_peak_scored += dis_peak_mean

                dis_rel += rel_meanA + rel_meanB
                # # Penalty
                # scores_mean += (-torch.log(torch.mean(scoresA[idx], dim=-1) + eps) - torch.log(torch.mean(scoresB[idx], dim=-1) + eps)) 
                # print(scores_mean)
            except:
                # dis_mean_total += 0
                # dis_peak_scored += 0
                # dis_desc += 0
                # dis_rel += 0
                # print('Overlapping too small or Repeatable point pairs distance is greater than correspond(1.5):', pntA.shape[0], pntA_H.shape[0], pntB.shape[0], pntB_invH.shape[0], dis_pairAB.shape[0], dis_pairBA.shape[0])
                valid_batch_size -= 1
                countA += new_numA
                countB += new_numB
                # countA_T += numA_T
                # countB_T += numB_T

        valid_batch_size = valid_batch_size if valid_batch_size > 0 else eps
        # Reprojection Loss 
        reprojection_loss = dis_mean_total / (valid_batch_size * 2)
        # Dispersity Peak Loss
        dispersity_peak_loss = dis_peak_scored / valid_batch_size
        # NRE Loss
        descriptor_loss = dis_desc / (2 * valid_batch_size)
        # Reliability Loss
        reliability_loss = dis_rel / (valid_batch_size * 2)
        # SOSR Loss
        sosr_loss = dis_neighbor_mean_total / ((valid_batch_size * 2))
        # # Entropy loss
        # std_loss = (valid_batch_size * 2) / desc_std  
        # # Score Penalty
        # score_penalty = scores_mean / (valid_batch_size * 2)
        # FA Desc loss
        FA_des_loss = dis_desc_fa / valid_batch_size_FA if valid_batch_size_FA > 0 else 0

        loss_total = wrp * reprojection_loss + wpl * dispersity_peak_loss + wdl * descriptor_loss + wrl * reliability_loss + sosr_loss + FA_des_loss
        loss_group = {
            'reprojection_loss': reprojection_loss, 
            'dispersity_peak_loss': dispersity_peak_loss,
            'descriptor_loss': descriptor_loss,
            'reliability_loss': reliability_loss,
            'sosr_loss': sosr_loss,
            # 'std_loss': std_loss,
            'FA_des_loss': FA_des_loss,
            }
        return loss_total, loss_group



    def detector_selfsupervised_loss_dkd_dense_restrict(self, kpA, kpB, pmaskA, pmaskB, descA, descB, desc_mapA, desc_mapB, scoreddisA, scoreddisB, scoresA, scoresB, scores_mapA, scores_mapB, Homo, inv_Homo, H, W, wrp=1, wpl=1, wdl=1, wrl=1, t_des=0.02, t_rel=1):
        # pmaskA: (BxMax_num) 32x300=9600
        batch_size = len(kpA)
        max_num = pmaskA.shape[-1] // batch_size    # 300
        dis_mean_total = 0
        dis_neighbor_mean_total = 0
        dis_peak_scored = 0
        dis_desc = 0
        dis_rel = 0
        eps = 1e-12
        valid_batch_size = batch_size
        countA, countB = 0, 0
        for idx in range(batch_size):
            pntA, pntB = kpA[idx], kpB[idx]     # M X 2 (x,y)
            pntA = pntA.float()
            pntB = pntB.float()
            # pntA = torch.tensor(pntA, device=self.device).type(torch.FloatTensor)
            # pntB = torch.tensor(pntB, device=self.device).type(torch.FloatTensor)
            numA, numB = pntA.shape[0], pntB.shape[0]
            pmA, pmB = pmaskA[max_num * idx:max_num * idx + numA].bool(), pmaskB[max_num * idx:max_num * idx + numB].bool()
            pntA, pntB = pntA[pmA, :], pntB[pmB, :]
            new_numA, new_numB = pntA.shape[0], pntB.shape[0]
            pntA = (pntA + 1) / 2 * pntA.new_tensor([[W - 1, H - 1]]).to(pntA.device)
            pntB = (pntB + 1) / 2 * pntB.new_tensor([[W - 1, H - 1]]).to(pntB.device)
            pntA_H = warp_points(pntA[:, :2], Homo[idx].squeeze(), device=self.device)  # 利用变换矩阵变换坐标点
            pntA_H, mask_pointA = filter_points(pntA_H, torch.tensor([W, H], device=self.device), return_mask=True)
            pntB_invH = warp_points(pntB[:, :2], inv_Homo[idx].squeeze(), device=self.device)
            pntB_invH, mask_pointB = filter_points(pntB_invH, torch.tensor([W, H], device=self.device), return_mask=True)
            
            try:
                assert pntA_H.shape[0] > 0 and pntB_invH.shape[0] > 0 
                # print(pntA_H.shape, pntB.shape, pntB_invH.shape, pntA.shape)
                key_disAB = self.get_dis(pntA_H[:, :2], pntB[:, :2])
                key_disBA = self.get_dis(pntB_invH[:, :2], pntA[:, :2])
                pairAB_A, pairAB_B, dis_pairAB, vmaskAH = self.get_point_pair(key_disAB, dis_thre=self.correspond)  # p -> k
                pairBA_B, pairBA_A, dis_pairBA, vmaskBH  = self.get_point_pair(key_disBA, dis_thre=self.correspond)  # p -> k
                key_manhattandisAB = self.get_manhattan_dis(pntA_H[:, :2], pntB[:, :2])
                key_manhattandisBA = self.get_manhattan_dis(pntB_invH[:, :2], pntA[:, :2])
                assert dis_pairAB.shape[0] > 0 and dis_pairBA.shape[0] > 0     
                # dis_pair_meanAB = torch.mean(dis_pairAB)
                # dis_pair_meanBA = torch.mean(dis_pairBA)
                dis_pair_meanAB = torch.mean(key_manhattandisAB[pairAB_A, pairAB_B])
                dis_pair_meanBA = torch.mean(key_manhattandisBA[pairBA_B, pairBA_A])
                dis_peak_mean = torch.mean(torch.cat((scoreddisA[idx][pmA], scoreddisB[idx][pmB]), dim=0))
                # dis_peak_meanB = torch.mean(scoreddisB[idx])
                
                dis_mean_total += dis_pair_meanAB + dis_pair_meanBA
                dis_peak_scored += dis_peak_mean
                pntA_H_normalized = pntA_H / pntA_H.new_tensor([W - 1, H - 1]).to(pntA_H.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)
                pntB_invH_normalized = pntB_invH / pntB_invH.new_tensor([W - 1, H - 1]).to(pntB_invH.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)

                current_descA, current_descB = descA[countA:countA+new_numA], descB[countB:countB+new_numB]
                
                # SOSR:
                k_neighbor = 3
                cross_sim_AA_sp = current_descA @ current_descA.transpose(0, 1)
                cross_sim_BB_sp = current_descB @ current_descB.transpose(0, 1)
                match_sim_AB_AA = cross_sim_AA_sp[mask_pointA, :][:, mask_pointA][pairAB_A, :][:, pairAB_A]
                match_sim_BA_BB = cross_sim_BB_sp[mask_pointB, :][:, mask_pointB][pairBA_B, :][:, pairBA_B]
                match_sim_AB_BB = cross_sim_BB_sp[pairAB_B, :][:, pairAB_B]
                match_sim_BA_AA = cross_sim_AA_sp[pairBA_A, :][:, pairBA_A]
                match_values_AB_AA, match_indices_AB_AA = torch.topk(match_sim_AB_AA, dim=1, k=k_neighbor, largest=False)
                match_values_BA_BB, match_indices_BA_BB = torch.topk(match_sim_BA_BB, dim=1, k=k_neighbor, largest=False)
                match_values_AB_BB_all = match_sim_AB_BB[:, match_indices_AB_AA]
                match_values_BA_AA_all = match_sim_BA_AA[:, match_indices_BA_BB]
                match_values_AB_BB = torch.diagonal(match_values_AB_BB_all, 0, dim1=0, dim2=1).transpose(0, 1)
                match_values_BA_AA = torch.diagonal(match_values_BA_AA_all, 0, dim1=0, dim2=1).transpose(0, 1)
                neighbor_dis_AB = (match_values_AB_AA - match_values_AB_BB) * (match_values_AB_AA - match_values_AB_BB)
                neighbor_dis_BA = (match_values_BA_BB - match_values_BA_AA) * (match_values_BA_BB - match_values_BA_AA)
                dis_neighbor_mean_total += torch.mean(torch.sum(neighbor_dis_AB, dim=1)) + torch.mean(torch.sum(neighbor_dis_BA, dim=1))

                # PA VS PB
                cross_sim_AB_sp = current_descA @ current_descB.transpose(0, 1)
                # print(cross_sim_AB_sp.shape, mask_pointA.shape, pairAB_A.shape)
                valid_cross_sim_AB_sp_mean = torch.mean(cross_sim_AB_sp[mask_pointA, :][pairAB_A, pairAB_B], dim=-1)
                novalid_cross_sim_AB_sp_mean = (torch.sum(torch.sum(cross_sim_AB_sp.detach(), 1), 0) - valid_cross_sim_AB_sp_mean * pairAB_A.shape[0]) / (new_numA * new_numB - pairAB_A.shape[0])
                valid_cross_sim_BA_sp_mean = torch.mean(cross_sim_AB_sp[:, mask_pointB][pairBA_A, pairBA_B], dim=-1)
                novalid_cross_sim_BA_sp_mean = (torch.sum(torch.sum(cross_sim_AB_sp.detach(), 1), 0) - valid_cross_sim_BA_sp_mean * pairBA_B.shape[0]) / (new_numA * new_numB - pairBA_B.shape[0])

                valid_indexesA = torch.tensor(list(range(new_numA)), device=self.device)[mask_pointA][pairAB_A]
                # cross_sim_BA_sp = current_descB @ current_descA.transpose(0, 1)
                cross_sim_AB_out_sp = torch.cat((cross_sim_AB_sp, torch.ones((new_numA, 1), device=cross_sim_AB_sp.device) * 2), dim=-1)      # NA X (NB + 1)
                # cross_sim_BA_out_sp = torch.cat((cross_sim_BA_sp, torch.ones((numB, 1), device=cross_sim_BA_sp.device)), dim=-1)      # NB X (NA + 1)
                # valid_indexesB = torch.tensor(list(range(numB)), device=self.device)[mask_pointB][pairBA_B]
                cross_sim_AB_out_sp[valid_indexesA, -1] = novalid_cross_sim_AB_sp_mean
                novalid_indexesA = torch.tensor(list(range(new_numA)), device=self.device)[cross_sim_AB_out_sp[:, -1]==2]
                cross_sim_AB_out_sp[novalid_indexesA, -1] = valid_cross_sim_AB_sp_mean
                # cross_sim_BA_out_sp[valid_indexesB, -1] -= 1

                # print(cross_sim_AB_out[:, -1])
                # valid_cross_sim_AB_sp = cross_sim_AB_sp[mask_pointA, :]   # repeat_nA x nB
                # valid_cross_sim_BA = cross_sim_BA[mask_pointB, :]   # repeat_nB x nA

                soft_cross_sim_AtoB_sp = F.softmax((cross_sim_AB_out_sp - 1) / t_des, dim=-1)
                # soft_cross_sim_BtoA = F.softmax((cross_sim_BA_out - 1) / t_des, dim=-1)
                
                soft_valid_cross_sim_AB_sp = soft_cross_sim_AtoB_sp[mask_pointA, :-1][pairAB_A, pairAB_B]
                # soft_valid_cross_sim_BA = soft_cross_sim_BtoA[mask_pointB, :-1][pairBA_B, pairBA_A]
                soft_novalid_cross_sim_AB_sp = soft_cross_sim_AtoB_sp[novalid_indexesA, -1]
                # soft_novalid_cross_sim_BA = soft_cross_sim_BtoA[cross_sim_BA_out[:, -1]==1, -1]
                log_soft_valid_cross_sim_AB_sp = -torch.log(soft_valid_cross_sim_AB_sp + eps)
                # log_soft_valid_cross_sim_BA = -torch.log(soft_valid_cross_sim_BA + eps)
                log_soft_novalid_cross_sim_AB_sp = -torch.log(soft_novalid_cross_sim_AB_sp + eps)
                # log_soft_novalid_cross_sim_BA = -torch.log(soft_novalid_cross_sim_BA + eps)
                dis_cross_sim_mean_sp = torch.sum(torch.cat((log_soft_valid_cross_sim_AB_sp, log_soft_novalid_cross_sim_AB_sp), dim=-1), dim=-1) / new_numA
                dis_desc += dis_cross_sim_mean_sp

                # PA VS PAB
                match_mask_A = copy.deepcopy(mask_pointA)
                match_mask_B = copy.deepcopy(mask_pointB)
                match_mask_A[mask_pointA] = copy.deepcopy(vmaskAH)
                match_mask_B[mask_pointB] = copy.deepcopy(vmaskBH)

                cross_sim_AB = current_descA @ desc_mapB[idx, :, :, :].view(-1, H * W)
                cross_sim_AB_all = F.grid_sample(cross_sim_AB.view(-1, H, W).unsqueeze(0),
                                                pntA_H_normalized[vmaskAH, :].detach().view(1, 1, -1, 2),
                                                mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NA x match_nA

                valid_cross_sim_AB_mean = torch.trace(cross_sim_AB_all[match_mask_A, :]) / cross_sim_AB_all[match_mask_A, :].shape[0]
                # novalid_cross_sim_AB_mean = (torch.sum(torch.sum(cross_sim_AB.detach(), 1), 1) - valid_cross_sim_AB_mean * pairAB_A.shape[0]) / (new_numA * H * W - pairAB_A.shape[0])

                cross_sim_BA = current_descB @ desc_mapA[idx, :, :, :].view(-1, H * W)   # M x H x W
                cross_sim_BA_all = F.grid_sample(cross_sim_BA.view(-1, H, W).unsqueeze(0),
                                                pntB_invH_normalized[vmaskBH, :].detach().view(1, 1, -1, 2),
                                                mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NB x match_nB

                valid_cross_sim_BA_mean = torch.trace(cross_sim_BA_all[match_mask_B, :]) / cross_sim_BA_all[match_mask_B, :].shape[0]
                # novalid_cross_sim_BA_mean = (torch.sum(torch.sum(cross_sim_BA.detach(), 1), 1) - valid_cross_sim_BA_mean * pairBA_B.shape[0]) / (new_numB * H * W - pairBA_B.shape[0])

                cross_sim_AB_out = torch.cat((cross_sim_AB, torch.ones((new_numA, 1), device=cross_sim_AB.device)), dim=-1)      # NA X (H X W + 1)
                cross_sim_BA_out = torch.cat((cross_sim_BA, torch.ones((new_numB, 1), device=cross_sim_BA.device)), dim=-1)      # NB X (H X W + 1)
                # print(match_mask_A.shape, cross_sim_AB_out.shape)
                # cross_sim_AB_out[mask_pointA, -1] -= 1
                # cross_sim_BA_out[mask_pointB, -1] -= 1
                # cross_sim_AB_out[match_mask_A, -1] -= 1
                cross_sim_AB_out[match_mask_A, -1] = novalid_cross_sim_AB_sp_mean
                cross_sim_AB_out[match_mask_A==False, -1] = valid_cross_sim_AB_mean
                # print(1)
                cross_sim_BA_out[match_mask_B, -1] = novalid_cross_sim_BA_sp_mean
                cross_sim_BA_out[match_mask_B==False, -1] = valid_cross_sim_BA_mean
                # print(2)
                soft_cross_sim_AtoB = F.softmax((cross_sim_AB_out - 1) / t_des, dim=-1)         # NA X (H X W + 1)
                soft_cross_sim_BtoA = F.softmax((cross_sim_BA_out - 1) / t_des, dim=-1)         # NB X (H X W + 1)
                soft_cross_sim_AB_all = F.grid_sample(soft_cross_sim_AtoB[:, :-1].view(-1, H, W).unsqueeze(0),
                                                    pntA_H_normalized[vmaskAH, :].detach().view(1, 1, -1, 2),
                                                    mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NA x match_nA
                
                soft_cross_sim_BA_all = F.grid_sample(soft_cross_sim_BtoA[:, :-1].view(-1, H, W).unsqueeze(0),
                                                    pntB_invH_normalized[vmaskBH, :].detach().view(1, 1, -1, 2),
                                                    mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NB x match_nB
                # soft_valid_cross_sim_AB_all = soft_cross_sim_AB_all[mask_pointA, :]             # repeat_nA x repeat_nA
                # soft_valid_cross_sim_BA_all = soft_cross_sim_BA_all[mask_pointB, :]             # repeat_nB x repeat_nB

                soft_valid_cross_sim_AB_all = soft_cross_sim_AB_all[match_mask_A, :]             # match_nA x match_nA
                soft_valid_cross_sim_BA_all = soft_cross_sim_BA_all[match_mask_B, :]             # match_nB x match_nB

                valid_mask_AB = torch.eye(soft_valid_cross_sim_AB_all.shape[0]) == 1
                valid_mask_BA = torch.eye(soft_valid_cross_sim_BA_all.shape[0]) == 1


                # 取对角线
                soft_valid_cross_sim_AB = soft_valid_cross_sim_AB_all[valid_mask_AB]
                soft_valid_cross_sim_BA = soft_valid_cross_sim_BA_all[valid_mask_BA]

                # soft_novalid_cross_sim_AB = soft_cross_sim_AtoB[mask_pointA==False, -1]              # (NA-repeat_nA) x 1
                # soft_novalid_cross_sim_BA = soft_cross_sim_BtoA[mask_pointB==False, -1]
                soft_novalid_cross_sim_AB = soft_cross_sim_AtoB[match_mask_A==False, -1]               # (NA-match_nA) x 1
                soft_novalid_cross_sim_BA = soft_cross_sim_BtoA[match_mask_B==False, -1]

                log_soft_valid_cross_sim_AB = -torch.log(soft_valid_cross_sim_AB + eps)
                log_soft_valid_cross_sim_BA = -torch.log(soft_valid_cross_sim_BA + eps)
                log_soft_novalid_cross_sim_AB = -torch.log(soft_novalid_cross_sim_AB + eps)
                log_soft_novalid_cross_sim_BA = -torch.log(soft_novalid_cross_sim_BA + eps)

                dis_cross_sim_mean = torch.sum(torch.cat((log_soft_valid_cross_sim_AB, log_soft_valid_cross_sim_BA, log_soft_novalid_cross_sim_AB, log_soft_novalid_cross_sim_BA), dim=-1), dim=-1) / (pntA.shape[0] + pntB.shape[0])
                dis_desc += dis_cross_sim_mean
                
                valid_cross_sim_AB = cross_sim_AB[mask_pointA, :]   # repeat_nA x (H X W)
                valid_cross_sim_BA = cross_sim_BA[mask_pointB, :]   # repeat_nB x (H X W)
                exp_valid_cross_sim_AtoB = torch.exp((valid_cross_sim_AB - 1) / t_rel).view(-1, H, W)
                exp_valid_cross_sim_BtoA = torch.exp((valid_cross_sim_BA - 1) / t_rel).view(-1, H, W)
                exp_valid_cross_sim_AB_all = F.grid_sample(exp_valid_cross_sim_AtoB.unsqueeze(0),
                                                        pntA_H_normalized.detach().view(1, 1, -1, 2),
                                                        mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # repeat_nA x repeat_nA
                
                exp_valid_cross_sim_BA_all = F.grid_sample(exp_valid_cross_sim_BtoA.unsqueeze(0),
                                                        pntB_invH_normalized.detach().view(1, 1, -1, 2),
                                                        mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # repeat_nB x repeat_nB

                repeat_mask_AB = torch.eye(exp_valid_cross_sim_AB_all.shape[0]) == 1
                repeat_mask_BA = torch.eye(exp_valid_cross_sim_BA_all.shape[0]) == 1
                rel_valid_cross_sim_AB = exp_valid_cross_sim_AB_all[repeat_mask_AB]
                rel_valid_cross_sim_BA = exp_valid_cross_sim_BA_all[repeat_mask_BA]

                scoresAB_all = F.grid_sample(scores_mapB[idx, :, :, :].unsqueeze(0),
                                            pntA_H_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)      # 1 x repeat_nA

                scoresBA_all = F.grid_sample(scores_mapA[idx, :, :, :].unsqueeze(0),
                                            pntB_invH_normalized.detach().view(1, 1, -1, 2),
                                            mode='bilinear', align_corners=True).squeeze(2).squeeze(0)      # 1 x repeat_nB
                scores_AAB = scoresA[idx][pmA][mask_pointA] * scoresAB_all
                scores_BBA = scoresB[idx][pmB][mask_pointB] * scoresBA_all
                scores_sum_AAB = torch.sum(scores_AAB, dim=-1)
                scores_sum_BBA = torch.sum(scores_BBA, dim=-1)
                scores_normalize_AAB = scores_AAB / (scores_sum_AAB + eps)
                scores_normalize_BBA = scores_BBA / (scores_sum_BBA + eps)
                rel_meanA = torch.sum(scores_normalize_AAB * (1 - rel_valid_cross_sim_AB), dim=-1) / pntA_H_normalized.shape[0]
                rel_meanB = torch.sum(scores_normalize_BBA * (1 - rel_valid_cross_sim_BA), dim=-1) / pntB_invH_normalized.shape[0]
                dis_rel += rel_meanA + rel_meanB
                countA += new_numA
                countB += new_numB

                # # Penalty
                # scores_mean += (-torch.log(torch.mean(scoresA[idx], dim=-1) + eps) - torch.log(torch.mean(scoresB[idx], dim=-1) + eps)) 
                # print(scores_mean)
            except:
                # dis_mean_total += 0
                # dis_peak_scored += 0
                # dis_desc += 0
                # dis_rel += 0
                print('Overlapping too small or Repeatable point pairs distance is greater than correspond(4):', pntA.shape[0], pntA_H.shape[0], pntB.shape[0], pntB_invH.shape[0])
                valid_batch_size -= 1
                countA += new_numA
                countB += new_numB

        valid_batch_size = valid_batch_size if valid_batch_size > 0 else eps
        # Reprojection Loss 
        reprojection_loss = dis_mean_total / (valid_batch_size * 2)
        # Dispersity Peak Loss
        dispersity_peak_loss = dis_peak_scored / valid_batch_size
        # NRE Loss
        descriptor_loss = dis_desc / (2 * valid_batch_size)
        # Reliability Loss
        reliability_loss = dis_rel / (valid_batch_size * 2)
        # SOSR Loss
        sosr_loss = dis_neighbor_mean_total / ((valid_batch_size * 2))
        # # Score Penalty
        # score_penalty = scores_mean / (valid_batch_size * 2)
        loss_total = wrp * reprojection_loss + wpl * dispersity_peak_loss + wdl * descriptor_loss + wrl * reliability_loss + sosr_loss
        loss_group = {
            'reprojection_loss': reprojection_loss, 
            'dispersity_peak_loss': dispersity_peak_loss,
            'descriptor_loss': descriptor_loss,
            'reliability_loss': reliability_loss,
            'sosr_loss': sosr_loss
            }
        return loss_total, loss_group

    def detector_selfsupervised_loss_dkd_dense_sift(self, kpA, kpB, pmaskA, pmaskB, descA, descB, desc_mapA, desc_mapB, scoreddisA, scoreddisB, scoresA, scoresB, scores_mapA, scores_mapB, Homo, inv_Homo, H, W, wrp=1, wpl=1, wdl=1, wrl=1, t_des=0.02, t_rel=1):
        # pmaskA: (BxMax_num) 32x300=9600
        batch_size = len(kpA)
        max_num = pmaskA.shape[-1] // batch_size    # 300
        dis_mean_total = 0
        dis_neighbor_mean_total = 0
        dis_peak_scored = 0
        dis_desc = 0
        dis_rel = 0
        eps = 1e-12
        valid_batch_size = batch_size
        countA, countB = 0, 0
        for idx in range(batch_size):
            pntA, pntB = kpA[idx], kpB[idx]     # M X 2 (x,y)
            pntA = pntA.float()
            pntB = pntB.float()
            # pntA = torch.tensor(pntA, device=self.device).type(torch.FloatTensor)
            # pntB = torch.tensor(pntB, device=self.device).type(torch.FloatTensor)
            numA, numB = pntA.shape[0], pntB.shape[0]
            pmA, pmB = pmaskA[max_num * idx:max_num * idx + numA].bool(), pmaskB[max_num * idx:max_num * idx + numB].bool()
            pntA, pntB = pntA[pmA, :], pntB[pmB, :]
            new_numA, new_numB = pntA.shape[0], pntB.shape[0]
            pntA = (pntA + 1) / 2 * pntA.new_tensor([[W - 1, H - 1]]).to(pntA.device)
            pntB = (pntB + 1) / 2 * pntB.new_tensor([[W - 1, H - 1]]).to(pntB.device)
            pntA_H = warp_points(pntA[:, :2], Homo[idx].squeeze(), device=self.device)  # 利用变换矩阵变换坐标点
            pntA_H, mask_pointA = filter_points(pntA_H, torch.tensor([W, H], device=self.device), return_mask=True)
            pntB_invH = warp_points(pntB[:, :2], inv_Homo[idx].squeeze(), device=self.device)
            pntB_invH, mask_pointB = filter_points(pntB_invH, torch.tensor([W, H], device=self.device), return_mask=True)
            
            try:
                assert pntA_H.shape[0] > 0 and pntB_invH.shape[0] > 0 
                # print(pntA_H.shape, pntB.shape, pntB_invH.shape, pntA.shape)
                key_disAB = self.get_dis(pntA_H[:, :2], pntB[:, :2])
                key_disBA = self.get_dis(pntB_invH[:, :2], pntA[:, :2])
                pairAB_A, pairAB_B, dis_pairAB, vmaskAH = self.get_point_pair(key_disAB, dis_thre=self.correspond)  # p -> k
                pairBA_B, pairBA_A, dis_pairBA, vmaskBH  = self.get_point_pair(key_disBA, dis_thre=self.correspond)  # p -> k
                assert dis_pairAB.shape[0] > 0 and dis_pairBA.shape[0] > 0     

                pntA_H_normalized = pntA_H / pntA_H.new_tensor([W - 1, H - 1]).to(pntA_H.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)
                pntB_invH_normalized = pntB_invH / pntB_invH.new_tensor([W - 1, H - 1]).to(pntB_invH.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)

                current_descA, current_descB = descA[countA:countA+new_numA], descB[countB:countB+new_numB]
                
                # SOSR:
                k_neighbor = 3
                cross_sim_AA_sp = current_descA @ current_descA.transpose(0, 1)
                cross_sim_BB_sp = current_descB @ current_descB.transpose(0, 1)
                match_sim_AB_AA = cross_sim_AA_sp[mask_pointA, :][:, mask_pointA][pairAB_A, :][:, pairAB_A]
                match_sim_BA_BB = cross_sim_BB_sp[mask_pointB, :][:, mask_pointB][pairBA_B, :][:, pairBA_B]
                match_sim_AB_BB = cross_sim_BB_sp[pairAB_B, :][:, pairAB_B]
                match_sim_BA_AA = cross_sim_AA_sp[pairBA_A, :][:, pairBA_A]
                match_values_AB_AA, match_indices_AB_AA = torch.topk(match_sim_AB_AA, dim=1, k=k_neighbor, largest=False)
                match_values_BA_BB, match_indices_BA_BB = torch.topk(match_sim_BA_BB, dim=1, k=k_neighbor, largest=False)
                match_values_AB_BB_all = match_sim_AB_BB[:, match_indices_AB_AA]
                match_values_BA_AA_all = match_sim_BA_AA[:, match_indices_BA_BB]
                match_values_AB_BB = torch.diagonal(match_values_AB_BB_all, 0, dim1=0, dim2=1).transpose(0, 1)
                match_values_BA_AA = torch.diagonal(match_values_BA_AA_all, 0, dim1=0, dim2=1).transpose(0, 1)
                neighbor_dis_AB = (match_values_AB_AA - match_values_AB_BB) * (match_values_AB_AA - match_values_AB_BB)
                neighbor_dis_BA = (match_values_BA_BB - match_values_BA_AA) * (match_values_BA_BB - match_values_BA_AA)
                dis_neighbor_mean_total += torch.mean(torch.sum(neighbor_dis_AB, dim=1)) + torch.mean(torch.sum(neighbor_dis_BA, dim=1))

                # PA VS PB
                cross_sim_AB_sp = current_descA @ current_descB.transpose(0, 1)
                # cross_sim_BA_sp = current_descB @ current_descA.transpose(0, 1)
                cross_sim_AB_out_sp = torch.cat((cross_sim_AB_sp, torch.ones((new_numA, 1), device=cross_sim_AB_sp.device)), dim=-1)      # NA X (NB + 1)
                # cross_sim_BA_out_sp = torch.cat((cross_sim_BA_sp, torch.ones((numB, 1), device=cross_sim_BA_sp.device)), dim=-1)      # NB X (NA + 1)
                valid_indexesA = torch.tensor(list(range(new_numA)), device=self.device)[mask_pointA][pairAB_A]
                # valid_indexesB = torch.tensor(list(range(numB)), device=self.device)[mask_pointB][pairBA_B]
                cross_sim_AB_out_sp[valid_indexesA, -1] -= 1
                # cross_sim_BA_out_sp[valid_indexesB, -1] -= 1
                # print(cross_sim_AB_out[:, -1])
                # valid_cross_sim_AB_sp = cross_sim_AB_sp[mask_pointA, :]   # repeat_nA x nB
                # valid_cross_sim_BA = cross_sim_BA[mask_pointB, :]   # repeat_nB x nA

                soft_cross_sim_AtoB_sp = F.softmax((cross_sim_AB_out_sp - 1) / t_des, dim=-1)
                # soft_cross_sim_BtoA = F.softmax((cross_sim_BA_out - 1) / t_des, dim=-1)
                
                soft_valid_cross_sim_AB_sp = soft_cross_sim_AtoB_sp[mask_pointA, :-1][pairAB_A, pairAB_B]
                # soft_valid_cross_sim_BA = soft_cross_sim_BtoA[mask_pointB, :-1][pairBA_B, pairBA_A]
                soft_novalid_cross_sim_AB_sp = soft_cross_sim_AtoB_sp[cross_sim_AB_out_sp[:, -1]==1, -1]
                # soft_novalid_cross_sim_BA = soft_cross_sim_BtoA[cross_sim_BA_out[:, -1]==1, -1]
                log_soft_valid_cross_sim_AB_sp = -torch.log(soft_valid_cross_sim_AB_sp + eps)
                # log_soft_valid_cross_sim_BA = -torch.log(soft_valid_cross_sim_BA + eps)
                log_soft_novalid_cross_sim_AB_sp = -torch.log(soft_novalid_cross_sim_AB_sp + eps)
                # log_soft_novalid_cross_sim_BA = -torch.log(soft_novalid_cross_sim_BA + eps)
                dis_cross_sim_mean_sp = torch.sum(torch.cat((log_soft_valid_cross_sim_AB_sp, log_soft_novalid_cross_sim_AB_sp), dim=-1), dim=-1) / new_numA
                dis_desc += dis_cross_sim_mean_sp

                # PA VS PAB
                cross_sim_AB = current_descA @ desc_mapB[idx, :, :, :].view(-1, H * W)
                cross_sim_BA = current_descB @ desc_mapA[idx, :, :, :].view(-1, H * W)   # M x H x W
                cross_sim_AB_out = torch.cat((cross_sim_AB, torch.ones((new_numA, 1), device=cross_sim_AB.device)), dim=-1)      # NA X (H X W + 1)
                cross_sim_BA_out = torch.cat((cross_sim_BA, torch.ones((new_numB, 1), device=cross_sim_BA.device)), dim=-1)      # NB X (H X W + 1)

                match_mask_A = copy.deepcopy(mask_pointA)
                match_mask_B = copy.deepcopy(mask_pointB)
                match_mask_A[mask_pointA] = copy.deepcopy(vmaskAH)
                match_mask_B[mask_pointB] = copy.deepcopy(vmaskBH)
 
                # cross_sim_AB_out[mask_pointA, -1] -= 1
                # cross_sim_BA_out[mask_pointB, -1] -= 1
                cross_sim_AB_out[match_mask_A, -1] -= 1
                cross_sim_BA_out[match_mask_B, -1] -= 1
                soft_cross_sim_AtoB = F.softmax((cross_sim_AB_out - 1) / t_des, dim=-1)         # NA X (H X W + 1)
                soft_cross_sim_BtoA = F.softmax((cross_sim_BA_out - 1) / t_des, dim=-1)         # NB X (H X W + 1)
                soft_cross_sim_AB_all = F.grid_sample(soft_cross_sim_AtoB[:, :-1].view(-1, H, W).unsqueeze(0),
                                                    pntA_H_normalized[vmaskAH, :].detach().view(1, 1, -1, 2),
                                                    mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NA x match_nA
                
                soft_cross_sim_BA_all = F.grid_sample(soft_cross_sim_BtoA[:, :-1].view(-1, H, W).unsqueeze(0),
                                                    pntB_invH_normalized[vmaskBH, :].detach().view(1, 1, -1, 2),
                                                    mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # NB x match_nB
                # soft_valid_cross_sim_AB_all = soft_cross_sim_AB_all[mask_pointA, :]             # repeat_nA x repeat_nA
                # soft_valid_cross_sim_BA_all = soft_cross_sim_BA_all[mask_pointB, :]             # repeat_nB x repeat_nB

                soft_valid_cross_sim_AB_all = soft_cross_sim_AB_all[match_mask_A, :]             # match_nA x match_nA
                soft_valid_cross_sim_BA_all = soft_cross_sim_BA_all[match_mask_B, :]             # match_nB x match_nB

                valid_mask_AB = torch.eye(soft_valid_cross_sim_AB_all.shape[0]) == 1
                valid_mask_BA = torch.eye(soft_valid_cross_sim_BA_all.shape[0]) == 1


                # 取对角线
                soft_valid_cross_sim_AB = soft_valid_cross_sim_AB_all[valid_mask_AB]
                soft_valid_cross_sim_BA = soft_valid_cross_sim_BA_all[valid_mask_BA]

                # soft_novalid_cross_sim_AB = soft_cross_sim_AtoB[mask_pointA==False, -1]              # (NA-repeat_nA) x 1
                # soft_novalid_cross_sim_BA = soft_cross_sim_BtoA[mask_pointB==False, -1]
                soft_novalid_cross_sim_AB = soft_cross_sim_AtoB[match_mask_A==False, -1]               # (NA-match_nA) x 1
                soft_novalid_cross_sim_BA = soft_cross_sim_BtoA[match_mask_B==False, -1]

                log_soft_valid_cross_sim_AB = -torch.log(soft_valid_cross_sim_AB + eps)
                log_soft_valid_cross_sim_BA = -torch.log(soft_valid_cross_sim_BA + eps)
                log_soft_novalid_cross_sim_AB = -torch.log(soft_novalid_cross_sim_AB + eps)
                log_soft_novalid_cross_sim_BA = -torch.log(soft_novalid_cross_sim_BA + eps)

                dis_cross_sim_mean = torch.sum(torch.cat((log_soft_valid_cross_sim_AB, log_soft_valid_cross_sim_BA, log_soft_novalid_cross_sim_AB, log_soft_novalid_cross_sim_BA), dim=-1), dim=-1) / (pntA.shape[0] + pntB.shape[0])
                dis_desc += dis_cross_sim_mean
                
                countA += new_numA
                countB += new_numB

                # # Penalty
                # scores_mean += (-torch.log(torch.mean(scoresA[idx], dim=-1) + eps) - torch.log(torch.mean(scoresB[idx], dim=-1) + eps)) 
                # print(scores_mean)
            except:
                # dis_mean_total += 0
                # dis_peak_scored += 0
                # dis_desc += 0
                # dis_rel += 0
                print('Overlapping too small or Repeatable point pairs distance is greater than correspond(4):', pntA.shape[0], pntA_H.shape[0], pntB.shape[0], pntB_invH.shape[0])
                valid_batch_size -= 1
                countA += new_numA
                countB += new_numB

        valid_batch_size = valid_batch_size if valid_batch_size > 0 else eps
        # # Reprojection Loss 
        # reprojection_loss = dis_mean_total / (valid_batch_size * 2)
        # # Dispersity Peak Loss
        # dispersity_peak_loss = dis_peak_scored / valid_batch_size
        # NRE Loss
        descriptor_loss = dis_desc / (2 * valid_batch_size)
        # # Reliability Loss
        # reliability_loss = dis_rel / (valid_batch_size * 2)
        # SOSR Loss
        sosr_loss = dis_neighbor_mean_total / ((valid_batch_size * 2))
        # # Score Penalty
        # score_penalty = scores_mean / (valid_batch_size * 2)
        loss_total = wdl * descriptor_loss + sosr_loss
        loss_group = {
            # 'reprojection_loss': reprojection_loss, 
            # 'dispersity_peak_loss': dispersity_peak_loss,
            'descriptor_loss': descriptor_loss,
            # 'reliability_loss': reliability_loss,
            'sosr_loss': sosr_loss
            }
        return loss_total, loss_group

    def detector_selfsupervised_loss_dkd_sparse(self, kpA, kpB, descA, descB, desc_mapA, desc_mapB, scoreddisA, scoreddisB, scoresA, scoresB, scores_mapA, scores_mapB, Homo, inv_Homo, H, W, wrp=1, wpl=1, wdl=1, wrl=1, t_des=0.02, t_rel=1):
        batch_size = len(kpA)

        dis_mean_total = 0
        dis_peak_scored = 0
        dis_desc = 0
        dis_rel = 0
        eps = 1e-12
        valid_batch_size = batch_size
        countA, countB = 0, 0
        
        for idx in range(batch_size):
            pntA, pntB = kpA[idx], kpB[idx]     # M X 2 (x,y)
            pntA = pntA.float()
            pntB = pntB.float()
            # pntA = torch.tensor(pntA, device=self.device).type(torch.FloatTensor)
            # pntB = torch.tensor(pntB, device=self.device).type(torch.FloatTensor)
            # print(pntA.shape, pntA, W, H, pntA.device)
            # pntA = (pntA + 1) / 2 * torch.tensor([[W - 1, H - 1]], device=pntA.device)
            # pntB = (pntB + 1) / 2 * torch.tensor([[W - 1, H - 1]], device=pntB.device)         
            pntA = (pntA + 1) / 2 * pntA.new_tensor([[W - 1, H - 1]])
            pntB = (pntB + 1) / 2 * pntB.new_tensor([[W - 1, H - 1]])
            numA, numB = pntA.shape[0], pntB.shape[0]
            pntA_H = warp_points(pntA[:, :2], Homo[idx].squeeze(), device=self.device)  # 利用变换矩阵变换坐标点
            pntA_H, mask_pointA = filter_points(pntA_H, torch.tensor([W, H], device=self.device), return_mask=True)
            pntB_invH = warp_points(pntB[:, :2], inv_Homo[idx].squeeze(), device=self.device)
            pntB_invH, mask_pointB = filter_points(pntB_invH, torch.tensor([W, H], device=self.device), return_mask=True)
            try:
                assert pntA_H.shape[0] > 0 and pntB_invH.shape[0] > 0 
                # print(pntA_H.shape, pntB.shape, pntB_invH.shape, pntA.shape)
                key_disAB = self.get_dis(pntA_H[:, :2], pntB[:, :2])
                key_disBA = self.get_dis(pntB_invH[:, :2], pntA[:, :2])
                pairAB_A, pairAB_B, dis_pairAB, _ = self.get_point_pair(key_disAB, dis_thre=self.correspond)  # p -> k
                pairBA_B, pairBA_A, dis_pairBA, _ = self.get_point_pair(key_disBA, dis_thre=self.correspond)  # p -> k
                key_manhattandisAB = self.get_manhattan_dis(pntA_H[:, :2], pntB[:, :2])
                key_manhattandisBA = self.get_manhattan_dis(pntB_invH[:, :2], pntA[:, :2])

                assert dis_pairAB.shape[0] > 0 and dis_pairBA.shape[0] > 0     
                # dis_pair_meanAB = torch.mean(dis_pairAB)
                # dis_pair_meanBA = torch.mean(dis_pairBA)
                dis_pair_meanAB = torch.mean(key_manhattandisAB[pairAB_A, pairAB_B])
                dis_pair_meanBA = torch.mean(key_manhattandisBA[pairBA_B, pairBA_A])

                dis_peak_mean = torch.mean(torch.cat((scoreddisA[idx], scoreddisB[idx]), dim=0))
                # dis_peak_meanB = torch.mean(scoreddisB[idx])

                dis_mean_total += dis_pair_meanAB + dis_pair_meanBA
                dis_peak_scored += dis_peak_mean

                # pntA_H_normalized = pntA_H / pntA_H.new_tensor([W - 1, H - 1]).to(pntA_H.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)
                # pntB_invH_normalized = pntB_invH / pntB_invH.new_tensor([W - 1, H - 1]).to(pntB_invH.device) * 2 - 1  # (w,h) -> (-1~1,-1~1)
                current_descA, current_descB = descA[countA:countA+numA], descB[countB:countB+numB]

                cross_sim_AB = current_descA @ current_descB.transpose(0, 1)
                cross_sim_BA = current_descB @ current_descA.transpose(0, 1)
                cross_sim_AB_out = torch.cat((cross_sim_AB, torch.ones((numA, 1), device=cross_sim_AB.device)), dim=-1)      # NA X (NB + 1)
                cross_sim_BA_out = torch.cat((cross_sim_BA, torch.ones((numB, 1), device=cross_sim_BA.device)), dim=-1)      # NB X (NA + 1)
                valid_indexesA = torch.tensor(list(range(numA)), device=self.device)[mask_pointA][pairAB_A]
                valid_indexesB = torch.tensor(list(range(numB)), device=self.device)[mask_pointB][pairBA_B]
                cross_sim_AB_out[valid_indexesA, -1] -= 1
                cross_sim_BA_out[valid_indexesB, -1] -= 1
                # print(cross_sim_AB_out[:, -1])
                valid_cross_sim_AB = cross_sim_AB[mask_pointA, :]   # repeat_nA x nB
                valid_cross_sim_BA = cross_sim_BA[mask_pointB, :]   # repeat_nB x nA

                soft_cross_sim_AtoB = F.softmax((cross_sim_AB_out - 1) / t_des, dim=-1)
                soft_cross_sim_BtoA = F.softmax((cross_sim_BA_out - 1) / t_des, dim=-1)

                # soft_valid_cross_sim_AB_all = F.grid_sample(soft_valid_cross_sim_AtoB.unsqueeze(0),
                #                                             pntA_H_normalized.view(1, 1, -1, 2),
                #                                             mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # repeat_nA x repeat_nA
                
                # soft_valid_cross_sim_BA_all = F.grid_sample(soft_valid_cross_sim_BtoA.unsqueeze(0),
                #                                             pntB_invH_normalized.view(1, 1, -1, 2),
                #                                             mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # repeat_nA x repeat_nA

                # valid_mask_AB = torch.eye(valid_cross_sim_AB.shape[0]) == 1
                # valid_mask_BA = torch.eye(valid_cross_sim_BA.shape[0]) == 1

                # 取对角线
                soft_valid_cross_sim_AB = soft_cross_sim_AtoB[mask_pointA, :-1][pairAB_A, pairAB_B]
                soft_valid_cross_sim_BA = soft_cross_sim_BtoA[mask_pointB, :-1][pairBA_B, pairBA_A]
                soft_novalid_cross_sim_AB = soft_cross_sim_AtoB[cross_sim_AB_out[:, -1]==1, -1]
                soft_novalid_cross_sim_BA = soft_cross_sim_BtoA[cross_sim_BA_out[:, -1]==1, -1]
                log_soft_valid_cross_sim_AB = -torch.log(soft_valid_cross_sim_AB + eps)
                log_soft_valid_cross_sim_BA = -torch.log(soft_valid_cross_sim_BA + eps)
                log_soft_novalid_cross_sim_AB = -torch.log(soft_novalid_cross_sim_AB + eps)
                log_soft_novalid_cross_sim_BA = -torch.log(soft_novalid_cross_sim_BA + eps)
                dis_cross_sim_mean = torch.sum(torch.cat((log_soft_valid_cross_sim_AB, log_soft_valid_cross_sim_BA, log_soft_novalid_cross_sim_AB, log_soft_novalid_cross_sim_BA), dim=-1), dim=-1) / (numA + numB)
                dis_desc += dis_cross_sim_mean
                
                exp_valid_cross_sim_AtoB = torch.exp((valid_cross_sim_AB - 1) / t_rel)  # repeat_nA x nB
                exp_valid_cross_sim_BtoA = torch.exp((valid_cross_sim_BA - 1) / t_rel)  # repeat_nB x nA
                # exp_valid_cross_sim_AB_all = F.grid_sample(exp_valid_cross_sim_AtoB.unsqueeze(0),
                #                                         pntA_H_normalized.view(1, 1, -1, 2),
                #                                         mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # repeat_nA x repeat_nA
                
                # exp_valid_cross_sim_BA_all = F.grid_sample(exp_valid_cross_sim_BtoA.unsqueeze(0),
                #                                             pntB_invH_normalized.view(1, 1, -1, 2),
                #                                             mode='bilinear', align_corners=True).squeeze(2).squeeze(0)  # repeat_nA x repeat_nA
                # rel_valid_cross_sim_AB = exp_valid_cross_sim_AB_all[valid_mask_AB]
                # rel_valid_cross_sim_BA = exp_valid_cross_sim_BA_all[valid_mask_BA]
                rel_valid_cross_sim_AB = exp_valid_cross_sim_AtoB[pairAB_A, pairAB_B]
                rel_valid_cross_sim_BA = exp_valid_cross_sim_BtoA[pairBA_B, pairBA_A]

                # scoresAB_all = F.grid_sample(scores_mapB[idx, :, :, :].unsqueeze(0),
                #                             pntA_H_normalized.view(1, 1, -1, 2),
                #                             mode='bilinear', align_corners=True).squeeze(2).squeeze(0)      # 1 x repeat_nA

                # scoresBA_all = F.grid_sample(scores_mapA[idx, :, :, :].unsqueeze(0),
                #                             pntB_invH_normalized.view(1, 1, -1, 2),
                #                             mode='bilinear', align_corners=True).squeeze(2).squeeze(0)      # 1 x repeat_nB
                scores_AAB = scoresA[idx][mask_pointA][pairAB_A] * scoresB[idx][pairAB_B]
                scores_BBA = scoresB[idx][mask_pointB][pairBA_B] * scoresA[idx][pairBA_A]
                scores_sum_AAB = torch.sum(scores_AAB, dim=-1)
                scores_sum_BBA = torch.sum(scores_BBA, dim=-1)
                scores_normalize_AAB = scores_AAB / (scores_sum_AAB + eps)
                scores_normalize_BBA = scores_BBA / (scores_sum_BBA + eps)
                rel_meanA = torch.sum(scores_normalize_AAB * (1 - rel_valid_cross_sim_AB), dim=-1) / numA
                rel_meanB = torch.sum(scores_normalize_BBA * (1 - rel_valid_cross_sim_BA), dim=-1) / numB
                dis_rel += rel_meanA + rel_meanB
                countA += numA
                countB += numB

            except:
                # dis_mean_total += 0
                # dis_peak_scored += 0
                # dis_desc += 0
                # dis_rel += 0
                print('Overlapping too small or Repeatable point pairs distance is greater than correspond(4):', pntA.shape[0], pntA_H.shape[0], pntB.shape[0], pntB_invH.shape[0])
                valid_batch_size -= 1
                countA += numA
                countB += numB
            

        valid_batch_size = valid_batch_size if valid_batch_size > 0 else eps
        # Reprojection Loss 
        reprojection_loss = dis_mean_total / (valid_batch_size * 2)
        # Dispersity Peak Loss
        dispersity_peak_loss = dis_peak_scored / valid_batch_size
        # NRE Loss
        descriptor_loss = dis_desc / valid_batch_size
        # Reliability Loss
        reliability_loss = dis_rel / (valid_batch_size * 2)
        
        loss_total = wrp * reprojection_loss + wpl * dispersity_peak_loss + wdl * descriptor_loss + wrl * reliability_loss
        loss_group = {
            'reprojection_loss': reprojection_loss, 
            'dispersity_peak_loss': dispersity_peak_loss,
            'descriptor_loss': descriptor_loss,
            'reliability_loss': reliability_loss}
        return loss_total, loss_group

    def train_val_sample(self, sample, n_iter=0, train=False):
        """
        # key function
        :param sample:
        :param n_iter:
        :param train:
        :return:
        """
        to_floatTensor = lambda x: torch.tensor(x).type(torch.FloatTensor)

        task = "train" if train else "val"
        tb_interval = self.config["tensorboard_interval"]
        det_loss_type = self.config["model"]["detector_loss"]["loss_type"]

        add_dustbin = False
        if det_loss_type == "l2":
            add_dustbin = False
        elif det_loss_type == "softmax":    # 如果是softmax，打开add_dustbin，即64维增加1维=65维
            add_dustbin = True
        elif det_loss_type == "focalloss":
            add_dustbin = True

        self.scalar_dict, self.images_dict, self.hist_dict = {}, {}, {}

        ## get the inputs
        imgA, imgA_pmask, _, labelA_sort, _, imgB, imgB_pmask, _, labelB_sort, valid_mask_H, name, homography, inv_homography, homography_o, inv_homography_o, trans_rot, _, siftpA, siftpB, siftmA, siftmB, imgA_ext, imgB_ext, imgA_crop, homography_en, inv_homography_en, imgA_ext_T, imgB_ext_T, FA_flag, bin_img_extA, bin_img_extTA, bin_img_extB, bin_img_extTB, img_ne, img_ne_ext, img_ne_pmask, bin_img_ne_ext, img_ne2, img_ne2_ext, img_ne2_pmask, bin_img_ne2_ext = (
            sample['image'],
            sample['image_pmask'].to(self.device), 
            sample['labels'].to(self.device),
            sample['labels_sort'].to(self.device),
            sample['valid_mask'].to(self.device),
            sample['image_H'],
            sample['image_H_pmask'].to(self.device),
            sample['labels_H'].to(self.device),
            sample['labels_H_sort'].to(self.device),
            sample['valid_mask_H'].to(self.device),
            sample['name'],
            sample['homography'],
            sample['inv_homography'],           # 120 x 40
            sample['homography_o'],
            sample['inv_homography_o'],         # 120 x 36
            sample['rotation'],
            sample['shear'],
            sample['sift_pntA'],
            sample['sift_pntB'],
            sample['sift_maskA'],
            sample['sift_maskB'],
            sample['image_ext'],
            sample['image_H_ext'],
            sample['image_crop'],
            sample['homography_en'],
            sample['inv_homography_en'],        # 120 x 40
            sample['imgA_ext_T'],
            sample['imgB_ext_T'],
            sample['FA_flag'],
            sample["bin_image_ext"],
            sample["bin_image_H_ext"],
            sample["bin_imgA_ext_T"],
            sample["bin_imgB_ext_T"],
            sample["image_ne"],
            sample["image_ne_ext"],
            sample["image_ne_pmask"],
            sample["bin_image_ne_ext"],
            sample["image_ne2"],
            sample["image_ne2_ext"],
            sample["image_ne2_pmask"],
            sample["bin_image_ne2_ext"],
            )
        # print(imgA.shape, bin_img_extA.shape)
        desc_labelA, desc_labelB = None, None
        batch_size, H, W = imgA.shape[0], imgA.shape[2], imgA.shape[3]  # 120 x 40
        self.batch_size = batch_size
        
        # train 
        self.optimizer.zero_grad()

        cal_orientation = 0

        sift_flag = False

        BTL_mode = False

        # change_act
        linear_iter = 100000
        law = n_iter / linear_iter
        if law >= 1:
            law = 1

        # 通道mask
        mask_64 = torch.randperm(8) < 8     # 2
        mask_64 = mask_64.unsqueeze(1).repeat(1, 16).transpose(0, 1).contiguous().view(-1).to(self.device)

        # # 空间mask
        # mask_64 = torch.randperm(16) < 4 # 4 # 8
        # mask_64 = mask_64.view(4, 4).unsqueeze(0).repeat(8, 1, 1).permute(1, 2, 0).contiguous().view(-1).to(self.device)

        mat_en_H, mat_en_invH = homography_en.to(self.device), inv_homography_en.to(self.device)
        mat_T_H, mat_T_invH = homography.to(self.device), inv_homography.to(self.device)
        outA = self.net(imgA.to(self.device), imgA_ext.to(self.device), sub_pixel=True, cal_orient=cal_orientation, trans_rot=trans_rot, pmask=imgA_pmask, sift_flag=sift_flag, siftp=siftpA, siftm=siftmA, h_en=mat_en_H, img_crop=imgA_crop.to(self.device), part_train_mask=mask_64, img_ext_T=imgA_ext_T.to(self.device), hT=mat_T_H, bin_img_ext=bin_img_extA, bin_img_ext_T=bin_img_extTA, dense_flag=False, is_teacher=True)  # linear_act_weight=law
        # semiA, coarse_descA, desc_mapA, scoresA, scores_mapA, scoredispersitysA, partial_maskA, ori_allA, ori_all_patchA, ori_kpA, ori_kp_patchA, kmask_TA = outA["keypoints"], outA["descriptors"], outA["descriptor_map"], outA["scores"], outA["scores_map"], outA["scoredispersitys"], outA['partial_mask'], outA['ori_all'], outA['ori_all_patch'], outA['ori_kp'], outA['ori_kp_patch'], outA['kmask_T']
        # semiA, coarse_descA, desc_mapA, scoresA, scores_mapA, scoredispersitysA, partial_maskA, ori_allA, ori_all_patchA, ori_kpA, ori_kp_patchA, kmask_TA, bin_allA, bin_kpA, bin_T_kpA = outA["keypoints"], outA["descriptors"], outA["descriptor_map"], outA["scores"], outA["scores_map"], outA["scoredispersitys"], outA['partial_mask'], outA['ori_all'], outA['ori_all_patch'], outA['ori_kp'], outA['ori_kp_patch'], outA['kmask_T'], outA['bin_all'], outA['bin_kp'], outA['bin_T_kp']
        semiA, coarse_descA, desc_mapA, scoresA, scores_mapA, scoredispersitysA, partial_maskA, ori_all_patchA, ori_kp_patchA, bin_allA, bin_kpA, coarse_descA_tea, fea_lossA = outA["keypoints"], outA["descriptors"], outA["descriptor_map"], outA["scores"], outA["scores_map"], outA["scoredispersitys"], outA['partial_mask'], outA['ori_all_patch'], outA['ori_kp_patch'], outA['bin_all'], outA['bin_kp'], outA['descriptors_teacher'], outA['fea_loss']


        outB = self.net(imgB.to(self.device), imgB_ext.to(self.device), sub_pixel=True, cal_orient=cal_orientation, pmask=imgB_pmask, sift_flag=sift_flag, siftp=siftpB, siftm=siftmB, part_train_mask=mask_64, img_ext_T=imgB_ext_T.to(self.device), hT=mat_T_invH, bin_img_ext=bin_img_extB, bin_img_ext_T=bin_img_extTB, dense_flag=False, is_teacher=True)
        # semiB, coarse_descB, desc_mapB, scoresB, scores_mapB, scoredispersitysB, partial_maskB, ori_allB, ori_all_patchB, ori_kpB, ori_kp_patchB, kmask_TB = outB["keypoints"], outB["descriptors"], outB["descriptor_map"], outB["scores"], outB["scores_map"], outB["scoredispersitys"], outB['partial_mask'], outB['ori_all'], outB['ori_all_patch'], outB['ori_kp'], outB['ori_kp_patch'], outB['kmask_T']
        # semiB, coarse_descB, desc_mapB, scoresB, scores_mapB, scoredispersitysB, partial_maskB, ori_allB, ori_all_patchB, ori_kpB, ori_kp_patchB, kmask_TB, bin_allB, bin_kpB, bin_T_kpB = outB["keypoints"], outB["descriptors"], outB["descriptor_map"], outB["scores"], outB["scores_map"], outB["scoredispersitys"], outB['partial_mask'], outB['ori_all'], outB['ori_all_patch'], outB['ori_kp'], outB['ori_kp_patch'], outB['kmask_T'], outB['bin_all'], outB['bin_kp'], outB['bin_T_kp']
        semiB, coarse_descB, desc_mapB, scoresB, scores_mapB, scoredispersitysB, partial_maskB, ori_all_patchB, ori_kp_patchB, bin_allB, bin_kpB, coarse_descB_tea, fea_lossB = outB["keypoints"], outB["descriptors"], outB["descriptor_map"], outB["scores"], outB["scores_map"], outB["scoredispersitys"], outB['partial_mask'], outB['ori_all_patch'], outB['ori_kp_patch'], outB['bin_all'], outB['bin_kp'], outB['descriptors_teacher'], outB['fea_loss']

        # 随机非同手指图
        out_ne = self.net(img_ne.to(self.device), img_ne_ext.to(self.device), sub_pixel=True, cal_orient=cal_orientation, pmask=img_ne_pmask, sift_flag=sift_flag, siftp=None, siftm=None, part_train_mask=mask_64, img_ext_T=None, hT=None, bin_img_ext=bin_img_ne_ext, bin_img_ext_T=None, dense_flag=False, is_teacher=False)
        semi_ne, coarse_desc_ne, partial_mask_ne, bin_kp_ne = out_ne["keypoints"], out_ne["descriptors"], out_ne["partial_mask"], out_ne["bin_kp"] 

        out_ne2 = self.net(img_ne2.to(self.device), img_ne2_ext.to(self.device), sub_pixel=True, cal_orient=cal_orientation, pmask=img_ne2_pmask, sift_flag=sift_flag, siftp=None, siftm=None, part_train_mask=mask_64, img_ext_T=None, hT=None, bin_img_ext=bin_img_ne2_ext, bin_img_ext_T=None, dense_flag=False, is_teacher=False)
        semi_ne2, coarse_desc_ne2, partial_mask_ne2, bin_kp_ne2 = out_ne2["keypoints"], out_ne2["descriptors"], out_ne2["partial_mask"], out_ne2["bin_kp"] 

        # ===detecAB===
        mat_H, mat_invH = homography_o.to(self.device), inv_homography_o.to(self.device)

        # # T值调整
        # temperature = 20
        # if n_iter >= 20000:
        #     temperature = 15

        loss_det_selfsupervised, loss_group = self.detector_selfsupervised_loss_dkd_patch_ext_restrict_modify_oriR_ratio_NFA_qtbw_ns_wg_nori_AT_NE2_SKKD_FGD(
                            semiA, 
                            semiB,
                            partial_maskA,
                            partial_maskB, 
                            coarse_descA,
                            coarse_descA_tea,
                            fea_lossA,
                            coarse_descB,
                            coarse_descB_tea,
                            fea_lossB,
                            desc_mapA,
                            desc_mapB,
                            scoredispersitysA, 
                            scoredispersitysB, 
                            scoresA,
                            scoresB,
                            scores_mapA,
                            scores_mapB,
                            mat_H, 
                            mat_invH,
                            mat_en_invH,
                            # ori_allA,
                            # ori_allB,
                            ori_all_patchA, 
                            ori_all_patchB,
                            # ori_kpA, 
                            # ori_kpB,
                            ori_kp_patchA, 
                            ori_kp_patchB,
                            # kmask_TA,
                            # kmask_TB,
                            bin_allA,
                            bin_allB,
                            bin_kpA,
                            bin_kpB,
                            # bin_T_kpA,
                            # bin_T_kpB,
                            semi_ne,
                            partial_mask_ne,
                            coarse_desc_ne,
                            bin_kp_ne,
                            semi_ne2,
                            partial_mask_ne2,
                            coarse_desc_ne2,
                            bin_kp_ne2,
                            trans_rot,
                            FA_flag,
                            H,
                            W - 4,
                            1,
                            1,
                            5,
                            1,
                            0.04,   # 1. / temperature,
                            0.02,
                            0.04
                            )
        
        loss_det_A = torch.tensor([0]).to(self.device)
        loss_det_B = torch.tensor([0]).to(self.device)

        # ===descriptor loss===
        mask_desc = valid_mask_H.squeeze()
        lambda_loss = self.config["model"]["lambda_loss"]
        self_supervised = self.config["model"]["dense_loss"]["self_supervised"]

        if lambda_loss > 0:
            ze = torch.tensor([0]).to(self.device)
            from utils.utils import descriptor_loss_fix
            if not self_supervised:
                loss_desc, loss_descA, loss_descB = self.descriptor_loss(
                    desc_labelA,
                    desc_labelB,
                    coarse_descA,
                    coarse_descB,
                    labelA_sort,
                    labelB_sort,
                    device=self.device
                )
                positive_dist, negative_dist = ze, ze
            else:
                loss_desc, mask, positive_dist, negative_dist = self.descriptor_loss(
                    coarse_descA,
                    coarse_descB,
                    homography,
                    mask_valid=mask_desc,
                    device=self.device,
                )
                loss_descA, loss_descB = ze, ze
        else:
            ze = torch.tensor([0]).to(self.device)
            loss_desc, loss_descA, loss_descB, positive_dist, negative_dist = ze, ze, ze, ze, ze
        loss_desc *= lambda_loss
        
        # loss = loss_det_A + loss_det_B + loss_desc
        loss = loss_det_selfsupervised  + loss_desc

        self.loss = loss
        self.scalar_dict.update(
            {
                "loss": loss,
                "loss_detA": loss_det_A,
                "loss_detB": loss_det_B,
                # "loss_res": loss_res,
                "loss_selfsupervised": loss_det_selfsupervised,
                "loss_desc_total": loss_desc,
                "loss_descA": loss_descA,
                "loss_descB": loss_descB,
                "positive_dist": positive_dist,
                "negative_dist": negative_dist,
            }
        )
        self.input_to_imgDict(sample, self.images_dict)

        if train:
            loss.backward()
            # loss.backward(torch.ones_like(loss))             
            self.optimizer.step()       # 更新网络参数
        
        if n_iter % tb_interval == 0 or task == "val":
            logging.info(
                "current iteration: %d, tensorboard_interval: %d", n_iter, tb_interval
            )
            logging.debug(
                "current iteration: %d, tensorboard_interval: %d", n_iter, tb_interval
            )
            print('The each part of loss:')
            self.printLosses(loss_group, task)
            topk = 150
            net_match_hanming_dis_mean, net_nomatch_hanming_dis_mean = 128, 128
            pts_A_lable = getPtsFromLabels2D(toNumpy(labelA_sort[0, 0, :, :])).transpose(1, 0)   # (3, N)
            pts_B_lable = getPtsFromLabels2D(toNumpy(labelB_sort[0, 0, :, :])).transpose(1, 0)
            try: 
                # === get A's heatmap & pts ===
                # heatmapA = flattenDetection_new(semiA, tensor=True)
                # pts_A = getPtsFromHeatmap(toNumpy(heatmapA)[0, 0, :, :], self.conf_thresh, self.nms_dist)  # only touch one
                # pts_A = getPtsFromHeatmapByCoordinates(heatmapA[0, 0, :, :].unsqueeze(0).unsqueeze(0), self.conf_thresh, self.w_size, bord=0)
                pts_A = semiA[0].to(self.device)
                pts_A = (pts_A + 1) / 2 * pts_A.new_tensor([[W - 1, H - 1]]).to(pts_A.device)
                numA = pts_A.shape[0]
                pm_A = partial_maskA[:numA].bool()
                pts_A = pts_A[pm_A, :]
                new_numA = pts_A.shape[0]
                pts_A[:, 0] -= 2

                # print(new_numA)
                if sift_flag:
                    topk_indices_A = torch.tensor(list(range(pts_A.shape[0]))).to(pts_A.device)
                else:
                    topk_indices_A = torch.topk(scoresA[0][pm_A], topk).indices if pts_A.shape[0] >= topk else scoresA[0][pm_A] >= 0
                pts_A = pts_A[topk_indices_A, :]
                # pts_A = pts_A.transpose(0, 1)
                # pts_A = pts_A.transpose()[:, [0, 1]]
                # pts_A = pts_A.transpose()[:, [0, 1]]
                
                warped_pts_A = warp_points(pts_A, mat_H[0].squeeze(), device=pts_A.device)  # 利用变换矩阵变换坐标点
                warped_pts_A, mask_points = filter_points(warped_pts_A, torch.tensor([W - 4, H], device=pts_A.device), return_mask=True)
                # print(warped_pts_A.shape[0])
                # === get B's heatmap & pts ===
                # heatmapB = flattenDetection_new(semiB, tensor=True)

                # heatmapB = heatmapB * valid_mask_H
                pts_B = semiB[0].to(self.device)
                pts_B = (pts_B + 1) / 2 * pts_B.new_tensor([[W - 1, H - 1]]).to(pts_B.device)
                numB = pts_B.shape[0]
                pm_B = partial_maskB[:numB].bool()
                pts_B = pts_B[pm_B, :]
                new_numB = pts_B.shape[0]
                pts_B[:, 0] -= 2

                if sift_flag:
                    topk_indices_B = torch.tensor(list(range(pts_B.shape[0]))).to(pts_B.device)
                else:
                    topk_indices_B = torch.topk(scoresB[0][pm_B], topk).indices if pts_B.shape[0] >= topk else scoresB[0][pm_B] >= 0
                pts_B = pts_B[topk_indices_B, :]
                # pts_B = getPtsFromHeatmap(toNumpy(heatmapB)[0, 0, :, :], self.conf_thresh, self.nms_dist)  # only touch one
                # pts_B = getPtsFromHeatmapByCoordinates(heatmapB[0, 0, :, :].unsqueeze(0).unsqueeze(0), self.conf_thresh, self.w_size, bord=0)
                # pts_B = pts_B.transpose(0, 1)
                # pts_B = pts_B.transpose()[:, [0, 1]]

                key_disAtoB = self.get_dis(warped_pts_A[:, :2], pts_B[:, :2])
                pos_repeatA_mask, pos_repeatB_mask, _, _ = self.get_point_pair(key_disAtoB, dis_thre=self.correspond)  # p -> k
                assert pos_repeatA_mask.shape[0] > 0 
                pos_repeatA = pts_A[mask_points, :][pos_repeatA_mask, :]
                pos_repeatB = pts_B[pos_repeatB_mask, :]

                # Hanming Distance Nearest Neighborhood
                pred_descA = coarse_descA[:new_numA][topk_indices_A, :]
                pred_descB = coarse_descB[:new_numB][topk_indices_B, :]
                # print(1, topk_indices_A.shape)
                net_match_mask = torch.zeros((pts_A.shape[0], pts_B.shape[0]), device=self.device) 
                net_A_all_indexes = torch.tensor(list(range(pts_A.shape[0])), device=self.device)
                net_pos_repeatA_indices = net_A_all_indexes[mask_points][pos_repeatA_mask]
                net_match_mask[net_pos_repeatA_indices, pos_repeatB_mask] = 1
                # net_match_hanming_dis, net_nomatch_hanming_dis = self.get_match_nomatch_dis_nosampler_hadama(pred_descA, pred_descB, net_match_mask)
                if pred_descA.shape[-1] == 128:
                    net_match_hanming_dis, net_nomatch_hanming_dis, hanmingdist_AtoB = self.get_match_nomatch_dis_nosampler_hadama_permute(pred_descA, pred_descB, net_match_mask, th1=300, th2=300)
                else:
                    if BTL_mode:
                        net_match_hanming_dis, net_nomatch_hanming_dis, hanmingdist_AtoB = self.get_match_nomatch_dis_nosampler_nohadama_permute_256(pred_descA, pred_descB, net_match_mask, th1=300, th2=300)
                    else:
                        net_match_hanming_dis, net_nomatch_hanming_dis, hanmingdist_AtoB = self.get_match_nomatch_dis_nosampler_hadama_permute_256(pred_descA, pred_descB, net_match_mask, th1=300, th2=300)
                net_match_hanming_dis_mean = torch.mean(net_match_hanming_dis, dim=-1)
                net_nomatch_hanming_dis_mean = torch.mean(net_nomatch_hanming_dis, dim=-1)

                # hanmingdist_AtoB = self.get_des_hanmingdis(pred_descA, pred_descB)

                pos_nncandA_mask, pos_nncandB_mask, _, _ = self.get_point_pair(hanmingdist_AtoB, dis_thre=pred_descA.shape[1] + 1)
                pos_nncandA = pts_A[pos_nncandA_mask, :]
                pos_nncandB = pts_B[pos_nncandB_mask, :]

                hanming_thr_ratio = 0.35        # 5% nomatch
                pos_nnA_mask, pos_nnB_mask, _, _ = self.get_point_pair(hanmingdist_AtoB, dis_thre=int(pred_descA.shape[1] * hanming_thr_ratio))
                pos_nnA = pts_A[pos_nnA_mask, :]
                pos_nnB = pts_B[pos_nnB_mask, :]
                print(new_numA, new_numB, warped_pts_A.shape[0], ' pos_nnA:', pos_nnA.shape, ' pos_nnB:', pos_nnB.shape)
                # desc_repeatA = desc_mapA[0, :, torch.tensor(pos_repeatA[:, 1]).long(), torch.tensor(pos_repeatA[:, 0]).long()].transpose(1, 0)
                # desc_repeatB = desc_mapB[0, :, torch.tensor(pos_repeatB[:, 1]).long(), torch.tensor(pos_repeatB[:, 0]).long()].transpose(1, 0)
            except:
                print("The number of points is not enough or overlapping too small!")
                # print("The number of points is not enough or overlapping too small!", pos_repeatA_mask.shape[0])
            else:
                pred, img_pair = {}, {}
                pred.update({
                    "pts": pts_A.detach().cpu().numpy(), 
                    "pts_H": pts_B.detach().cpu().numpy(),
                    "lab": pts_A_lable,
                    "lab_H": pts_B_lable,
                    "pts_TH": warped_pts_A.detach().cpu().numpy(),
                    "pts_repeatA": pos_repeatA.detach().cpu().numpy(),
                    "pts_repeatB": pos_repeatB.detach().cpu().numpy(),
                    "pts_nncandA": pos_nncandA.detach().cpu().numpy(),
                    "pts_nncandB": pos_nncandB.detach().cpu().numpy(),
                    "pts_nnA": pos_nnA.detach().cpu().numpy(),
                    "pts_nnB": pos_nnB.detach().cpu().numpy(),
                    })
                # print(imgA[0].shape)
                img_pair.update({
                    "img": imgA[0][0, :, 2:-2].cpu().numpy().squeeze(),
                    "img_H": imgB[0][0, :, 2:-2].cpu().numpy().squeeze()
                    })
                img_pts = draw_keypoints_pair_train(img_pair, pred, None, radius=1, s=1, H=mat_H[0].detach().cpu().squeeze())
                f = Path(self.webdir) / (str(n_iter) + '_' + str(name[0]) + ".bmp")
                saveImg(img_pts, str(f))

                img_nn_match = draw_match_pair_train(img_pair, pred, radius=1, s=1)
                f1 = Path(self.webdir) / (str(n_iter) + '_' + str(name[0]) + "_nn_match.bmp")
                saveImg(img_nn_match, str(f1))
                # draw_match_picture(imgA[0].cpu().squeeze(), imgB[0].cpu().squeeze(), str(save_match_patho), mat_Ho[0].detach().cpu().squeeze())

            # #计算第一张图卡阈值后的hanming距离,从置信度最高的地方开始
            # # desc_A = sample_desc_from_points_torch(coarse_descA[0, :, :, :].detach().cpu().unsqueeze(0), torch.tensor(pts_A_lable).transpose(1, 0)).transpose(1, 0)#根据点的置信度获取描述子
            # desc_A = desc_mapA[0, :, torch.tensor(pts_A_lable[:120, 1]).long(), torch.tensor(pts_A_lable[:120, 0]).long()].transpose(1, 0)
            # for i in range(15):
            #     desc_predict = desc_A[i,:]
            #     desc_predict = torch.sigmoid(desc_predict)
            #     desc_A_thres = torch.where(desc_predict > 0.5, torch.ones_like(desc_predict), torch.zeros_like(desc_predict))
            #     desc_tmp = desc_labelA[0,i,:]#根据置信度排序
            #     hanmingdist = sum([e1!=e2 for (e1, e2) in zip(desc_tmp, desc_A_thres)])
            #     print("A  -- top 15 of %d dist : %d"%(i, hanmingdist))
            # # desc_A_single = torch.sigmoid(desc_A)
            # desc_A_single = copy.deepcopy(desc_A)
            # desc_A_single_thres = torch.where(desc_A_single > 0.5, torch.ones_like(desc_A_single), torch.zeros_like(desc_A_single))
            # dist_list = []
            # for (e1, e2) in zip(desc_A_single_thres, desc_labelA[0, :, :]):
            #     dist_list.append(sum(e1!=e2))
            # dist_meanA = sum(dist_list) / len(dist_list)
            # print("A -- dist mean: %d"%(dist_meanA))

            # desc_B = desc_mapB[0, :, torch.tensor(pts_B_lable[:120, 1]).long(), torch.tensor(pts_B_lable[:120, 0]).long()].transpose(1, 0)
            # for i in range(15):
            #     desc_predict = desc_B[i,:]
            #     desc_predict = torch.sigmoid(desc_predict)
            #     desc_B_thres = torch.where(desc_predict > 0.5, torch.ones_like(desc_predict), torch.zeros_like(desc_predict))
            #     desc_tmp = desc_labelB[0,i,:]#根据置信度排序
            #     hanmingdist = sum([e1!=e2 for (e1, e2) in zip(desc_tmp, desc_B_thres)])
            #     print("B -- top 15 of %d dist : %d"%(i, hanmingdist))

            # # desc_B_single = torch.sigmoid(desc_B)
            # desc_B_single = copy.deepcopy(desc_B)
            # desc_B_single_thres = torch.where(desc_B_single > 0.5, torch.ones_like(desc_B_single), torch.zeros_like(desc_B_single))
            # dist_list = []
            # for (e1, e2) in zip(desc_B_single_thres, desc_labelB[0, :, :]):
            #     dist_list.append(sum(e1!=e2))
            # dist_meanB = sum(dist_list) / len(dist_list)
            # print("B -- dist mean: %d"%(dist_meanB))


            self.printLosses(self.scalar_dict, task)

            self.logger.debug("current iteration: %d", n_iter)
            self.logger.debug(
                "loss: %f, loss_detA: %f, loss_detB: %f, loss_det_selfsupervised: %f, loss_desctotal: %f, loss_descA: %f, loss_descB: %f",\
                loss, loss_det_A, loss_det_B, loss_det_selfsupervised, loss_desc, loss_descA, loss_descB
            )
            self.logger.debug(
                "Match pairs hamming dis mean: %f, Nomatch pairs hamming dis mean: %f",\
                net_match_hanming_dis_mean, net_nomatch_hanming_dis_mean
            )

            # 打印具体的各块loss
            for loss_element in list(loss_group):
                # print ('add to tb: ', element)
                self.logger.debug(
                    loss_element + ': %f', \
                    loss_group[loss_element].item() if type(loss_group[loss_element]) is torch.Tensor else loss_group[loss_element]
                )

            # self.logger.debug(
            #     "Hamming disA: %f, Hamming disB: %f",\
            #     dist_meanA, dist_meanB
            # )
            # self.tb_images_dict(task, self.images_dict, max_img=2)
            # self.tb_hist_dict(task, self.hist_dict)

        self.tb_scalar_dict(self.scalar_dict, task)

        return loss.item()


    def heatmap_to_nms(self, images_dict, heatmap, name):
        """
        return: 
            heatmap_nms_batch: np [batch, H, W]
        """
        from utils.var_dim import toNumpy

        heatmap_np = toNumpy(heatmap)
        ## heatmap_nms
        # nms_dist = self.config['model']['nms']                      # Andy 添加，直接采用yaml中的定义
        # conf_thresh = self.config['model']['detection_threshold']   # Andy 添加，直接采用yaml中的定义
        heatmap_nms_batch = [self.heatmap_nms(self, h) for h in heatmap_np]  # [batch, H, W] 这里需要修改
        heatmap_nms_batch = np.stack(heatmap_nms_batch, axis=0)
        # images_dict.update({name + '_nms_batch': heatmap_nms_batch})
        images_dict.update({name + "_nms_batch": heatmap_nms_batch[:, np.newaxis, ...]})
        return heatmap_nms_batch

    def get_residual_loss(self, labels_2D, heatmap, labels_res, name=""):
        # labels_2D：非极大值移植后的heatmap， heatmap：网络输出的未NMS的heatmap
        if abs(labels_2D).sum() == 0:
            return
        outs_res = self.pred_soft_argmax(
            labels_2D, heatmap, labels_res, patch_size=5, device=self.device
        )# 标签的点，和网络预测的heatmap做NMS之后的点，之间的loss
        self.hist_dict[name + "_resi_loss_x"] = outs_res["loss"][:, 0]
        self.hist_dict[name + "_resi_loss_y"] = outs_res["loss"][:, 1]
        err = abs(outs_res["loss"]).mean(dim=0)
        # print("err[0]: ", err[0])
        var = abs(outs_res["loss"]).std(dim=0)
        self.scalar_dict[name + "_resi_loss_x"] = err[0]
        self.scalar_dict[name + "_resi_loss_y"] = err[1]
        self.scalar_dict[name + "_resi_var_x"] = var[0]
        self.scalar_dict[name + "_resi_var_y"] = var[1]
        self.images_dict[name + "_patches"] = outs_res["patches"]
        return outs_res

    ######## static methods ########
    @staticmethod
    def batch_precision_recall(batch_pred, batch_labels):
        precision_recall_list = []
        for i in range(batch_labels.shape[0]):
            precision_recall = precisionRecall_torch_soft(batch_pred[i], batch_labels[i], soft_margin=3)
            precision_recall_list.append(precision_recall)
        precision = np.mean(
            [
                precision_recall["precision"]
                for precision_recall in precision_recall_list
            ]
        )
        recall = np.mean(
            [precision_recall["recall"] for precision_recall in precision_recall_list]
        )
        return {"precision": precision, "recall": recall}

    @staticmethod
    def pred_soft_argmax(labels_2D, heatmap, labels_res, patch_size=5, device="cuda"):
        """

        return:
            dict {'loss': mean of difference btw pred and res}
        """
        from utils.losses import norm_patches

        outs = {}
        # extract patches
        from utils.losses import extract_patches
        from utils.losses import soft_argmax_2d

        label_idx = labels_2D[...].nonzero().long()

        # patch_size = self.config['params']['patch_size']
        patches = extract_patches(
            label_idx.to(device), heatmap.to(device), patch_size=patch_size
        )
        # norm patches
        patches = norm_patches(patches)

        # predict offsets
        from utils.losses import do_log

        if 0:
            patches_log = do_log(patches)
            # with torch.no_grad():
            dxdy = soft_argmax_2d(
                patches_log, normalized_coordinates=False
            )  # tensor [B, N, patch, patch]
        else:
            dxdy = soft_argmax_2d(
            patches, normalized_coordinates=False
        )  # tensor [B, N, patch, patch], soft_argmax作为非极大值抑制NMS的可微分版本
        
       
        
        dxdy = dxdy.squeeze(1)  # tensor [N, 2]
        dxdy = dxdy - patch_size // 2       # 网络预测的点（NMS后的极值点）对标签位置的偏移

        # extract residual
        def ext_from_points(labels_res, points):
            """
            input:
                labels_res: tensor [batch, channel, H, W]
                points: tensor [N, 4(pos0(batch), pos1(0), pos2(H), pos3(W) )]
            return:
                tensor [N, channel]
            """
            # labels_res = labels_res.transpose(1, 2).transpose(2, 3).unsqueeze(1)
            labels_res = labels_res.unsqueeze(1)
            points_res = labels_res[
                points[:, 0], points[:, 1], points[:, 2], points[:, 3], :
            ]  # tensor [N, 2]
            return points_res

        points_res = ext_from_points(labels_res, label_idx)

        # loss
        outs["pred"] = dxdy
        outs["points_res"] = points_res
        # ls = lambda x, y: dxdy.cpu() - points_res.cpu()
        # outs['loss'] = dxdy.cpu() - points_res.cpu()
        outs["loss"] = dxdy.to(device) - points_res.to(device)
        outs["patches"] = patches
        return outs

    @staticmethod
    def flatten_64to1(semi, cell_size=8):
        """
        input: 
            semi: tensor[batch, cell_size*cell_size, Hc, Wc]
            (Hc = H/8)
        outpus:
            heatmap: tensor[batch, 1, H, W]
        """
        from utils.d2s import DepthToSpace

        depth2space = DepthToSpace(cell_size)
        heatmap = depth2space(semi)
        return heatmap

    @staticmethod
    def heatmap_nms(self, heatmap, nms_dist=2, conf_thresh=0.01):
        """
        input:
            heatmap: np [(1), H, W]
        """
        from utils.utils import getPtsFromHeatmap
        
        nms_dist = self.config['model']['nms']
        conf_thresh = self.config['model']['detection_threshold']
        heatmap = heatmap.squeeze()     # [1,128,128] --> [128,128]
        # print("heatmap: ", heatmap.shape)
        pts_nms = getPtsFromHeatmap(heatmap, conf_thresh, nms_dist)
        semi_thd_nms_sample = np.zeros_like(heatmap)
        semi_thd_nms_sample[
            pts_nms[1, :].astype(np.int), pts_nms[0, :].astype(np.int)
        ] = 1
        return semi_thd_nms_sample


if __name__ == "__main__":
    # load config
    filename = "configs/superpoint_finger_train_heatmap.yaml"
    import yaml

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    torch.set_default_tensor_type(torch.FloatTensor)
    with open(filename, "r") as f:
        config = yaml.load(f)

    from utils.loader import dataLoader as dataLoader

    # data = dataLoader(config, dataset='hpatches')
    task = config["data"]["dataset"]

    data = dataLoader(config, dataset=task, warp_input=True)
    # test_set, test_loader = data['test_set'], data['test_loader']
    train_loader, val_loader = data["train_loader"], data["val_loader"]

    # model_fe = Train_model_frontend(config)
    # print('==> Successfully loaded pre-trained network.')

    train_agent = Train_model_heatmap(config, device=device)

    train_agent.train_loader = train_loader
    # train_agent.val_loader = val_loader

    train_agent.loadModel()
    train_agent.dataParallel()
    train_agent.train()

    # epoch += 1
    try:
        model_fe.train()

    # catch exception
    except KeyboardInterrupt:
        logging.info("ctrl + c is pressed. save model")
    # is_best = True
